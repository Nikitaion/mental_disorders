{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitaion/mental_disorders/blob/main/mental_disorders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xviXFSvcd-gZ",
        "outputId": "9b6fc826-490a-4cde-b9a4-7470a659dd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-17 16:03:57--  https://raw.githubusercontent.com/Nikitaion/mental_disorders/main/data/150922_mental_disorders_data_without_somatika.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14432 (14K) [text/plain]\n",
            "Saving to: ‘ds.csv’\n",
            "\n",
            "ds.csv              100%[===================>]  14.09K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-09-17 16:03:57 (9.80 MB/s) - ‘ds.csv’ saved [14432/14432]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Nikitaion/mental_disorders/main/data/150922_mental_disorders_data_without_somatika.csv -O ds.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6YXg1QZeuWS",
        "outputId": "e0dd07cc-9501-428a-b49f-d8005dc10af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import  train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "0lKSFBRwg3oI",
        "outputId": "cf99d6bf-6631-4d24-af28-63367dbc8a59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Снинговый номер Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "0            УП-1   М          32                                   4   \n",
              "1            УП-2   М          26                                   2   \n",
              "2            УП-3   М          49                                   2   \n",
              "3            УП-4   М          50                                   2   \n",
              "4            УП-6   М          39                                   2   \n",
              "\n",
              "   Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "0                            0                                 0   \n",
              "1                            0                                 0   \n",
              "2                            0                                 0   \n",
              "3                            0                                 0   \n",
              "4                            0                                 0   \n",
              "\n",
              "   Удовлетворенность семеными отношениями  \\\n",
              "0                                       5   \n",
              "1                                       5   \n",
              "2                                       5   \n",
              "3                                       5   \n",
              "4                                       5   \n",
              "\n",
              "   Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "0                                          0                    7   \n",
              "1                                          0                   10   \n",
              "2                                          1                   10   \n",
              "3                                          1                    7   \n",
              "4                                          1                    7   \n",
              "\n",
              "   Были ли нарушения сна  ...  Стаж шизофр   P   N   G  Была попытка суицида?  \\\n",
              "0                      1  ...          3.7  11  11  18                      0   \n",
              "1                      1  ...          2.0  10  25  36                      0   \n",
              "2                      0  ...         23.0   9  16  23                      0   \n",
              "3                      1  ...         34.0  13  13  20                      0   \n",
              "4                      0  ...          4.0   9  13  22                      0   \n",
              "\n",
              "   PSQI  psqi больше 5  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "0     6              1                             0   \n",
              "1     8              1                             0   \n",
              "2     3              0                             0   \n",
              "3     6              1                             0   \n",
              "4     4              0                             0   \n",
              "\n",
              "   (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "0                          0                            0  \n",
              "1                          1                            1  \n",
              "2                          0                            0  \n",
              "3                          0                            0  \n",
              "4                          0                            0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-243f0156-7e52-4adc-9372-90b4d430cbd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Снинговый номер</th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>...</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>Была попытка суицида?</th>\n",
              "      <th>PSQI</th>\n",
              "      <th>psqi больше 5</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>УП-1</td>\n",
              "      <td>М</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3.7</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>УП-2</td>\n",
              "      <td>М</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>УП-3</td>\n",
              "      <td>М</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>УП-4</td>\n",
              "      <td>М</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>УП-6</td>\n",
              "      <td>М</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-243f0156-7e52-4adc-9372-90b4d430cbd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-243f0156-7e52-4adc-9372-90b4d430cbd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-243f0156-7e52-4adc-9372-90b4d430cbd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "ds = pd.read_csv(\"/content/ds.csv\")\n",
        "ds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "ASj1vcYIhAzw",
        "outputId": "a7bb6f35-f835-402c-b36e-509603f83006"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Снинговый номер Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "175          УП-224   М          53                                   4   \n",
              "176          УП-225   М          36                                   4   \n",
              "177          УП-227   Ж          38                                   2   \n",
              "178          УП-228   М          27                                   4   \n",
              "179          УП-230   М          36                                   4   \n",
              "\n",
              "     Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "175                            0                                 0   \n",
              "176                            0                                 0   \n",
              "177                            0                                 1   \n",
              "178                            1                                 0   \n",
              "179                            0                                 0   \n",
              "\n",
              "     Удовлетворенность семеными отношениями  \\\n",
              "175                                       3   \n",
              "176                                       2   \n",
              "177                                       4   \n",
              "178                                       2   \n",
              "179                                       5   \n",
              "\n",
              "     Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "175                                          0                    6   \n",
              "176                                          1                   10   \n",
              "177                                          1                    4   \n",
              "178                                          0                    8   \n",
              "179                                          1                    3   \n",
              "\n",
              "     Были ли нарушения сна  ...  Стаж шизофр   P   N   G  \\\n",
              "175                      1  ...         27.0  12  16  31   \n",
              "176                      1  ...         23.0  19  26  47   \n",
              "177                      1  ...          5.0  10  10  27   \n",
              "178                      1  ...          8.0  11  18  31   \n",
              "179                      0  ...          3.0  13  21  33   \n",
              "\n",
              "     Была попытка суицида?  PSQI  psqi больше 5  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "175                      0     7              1                             0   \n",
              "176                      0     5              0                             0   \n",
              "177                      1    11              1                             1   \n",
              "178                      0     5              0                             0   \n",
              "179                      0     2              0                             0   \n",
              "\n",
              "     (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "175                          0                            0  \n",
              "176                          0                            0  \n",
              "177                          0                            1  \n",
              "178                          0                            1  \n",
              "179                          0                            0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e03bb284-671e-4ca4-889a-1e80552bbc7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Снинговый номер</th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>...</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>Была попытка суицида?</th>\n",
              "      <th>PSQI</th>\n",
              "      <th>psqi больше 5</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>УП-224</td>\n",
              "      <td>М</td>\n",
              "      <td>53</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>27.0</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>УП-225</td>\n",
              "      <td>М</td>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>23.0</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>УП-227</td>\n",
              "      <td>Ж</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>УП-228</td>\n",
              "      <td>М</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>УП-230</td>\n",
              "      <td>М</td>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e03bb284-671e-4ca4-889a-1e80552bbc7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e03bb284-671e-4ca4-889a-1e80552bbc7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e03bb284-671e-4ca4-889a-1e80552bbc7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "ds.tail()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_N2ueZDTxGN",
        "outputId": "3f49f957-2d0b-4765-8c63-3bef0e7555c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 180 entries, 0 to 179\n",
            "Data columns (total 26 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Снинговый номер                            180 non-null    object \n",
            " 1   Пол                                        180 non-null    object \n",
            " 2   Полных лет                                 180 non-null    int64  \n",
            " 3   Образование(0-начальное, 4-высшее)         180 non-null    int64  \n",
            " 4   Род занятий(0-0, работает-1                180 non-null    int64  \n",
            " 5   Семейное положение(0-0, 1-женат)           180 non-null    int64  \n",
            " 6   Удовлетворенность семеными отношениями     180 non-null    int64  \n",
            " 7   Удовлетворенность материальным положением  180 non-null    int64  \n",
            " 8   Здоровье от 1 до 10                        180 non-null    int64  \n",
            " 9   Были ли нарушения сна                      180 non-null    int64  \n",
            " 10  ИМТ                                        180 non-null    float64\n",
            " 11  Операции                                   180 non-null    int64  \n",
            " 12  ЧМТ                                        180 non-null    int64  \n",
            " 13  Насл отягощенность                         180 non-null    int64  \n",
            " 14  Дебют                                      180 non-null    float64\n",
            " 15  Частота госпит                             180 non-null    int64  \n",
            " 16  Стаж шизофр                                180 non-null    float64\n",
            " 17  P                                          180 non-null    int64  \n",
            " 18  N                                          180 non-null    int64  \n",
            " 19  G                                          180 non-null    int64  \n",
            " 20  Была попытка суицида?                      180 non-null    int64  \n",
            " 21  PSQI                                       180 non-null    int64  \n",
            " 22  psqi больше 5                              180 non-null    int64  \n",
            " 23  (ТРЕВОГА)Гаиильтон больше 16               180 non-null    int64  \n",
            " 24  (ДЕПРЕССИЯ)madrs больше 6                  180 non-null    int64  \n",
            " 25  (ДЕПРЕССИЯ)Калгари больше 5                180 non-null    int64  \n",
            "dtypes: float64(3), int64(21), object(2)\n",
            "memory usage: 36.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ydmKTum1euwu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FV4kacAYeuzT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[['N', 'PSQI']]"
      ],
      "metadata": {
        "id": "E1-ZYGviVJA_",
        "outputId": "a6bc4bb8-95ff-4bf5-f4d0-4b6374b7ee5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      N  PSQI\n",
              "0    11     6\n",
              "1    25     8\n",
              "2    16     3\n",
              "3    13     6\n",
              "4    13     4\n",
              "..   ..   ...\n",
              "175  16     7\n",
              "176  26     5\n",
              "177  10    11\n",
              "178  18     5\n",
              "179  21     2\n",
              "\n",
              "[180 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2acce0d6-3c22-4377-bec6-3648e22e2965\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N</th>\n",
              "      <th>PSQI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>26</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2acce0d6-3c22-4377-bec6-3648e22e2965')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2acce0d6-3c22-4377-bec6-3648e22e2965 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2acce0d6-3c22-4377-bec6-3648e22e2965');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow_probability as tfp\n",
        "# tfp.stats.correlation(ds['PSQI'], ds['N'])"
      ],
      "metadata": {
        "id": "MryEqya5VJDa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2oclsp8-VJF0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UgENhvX1VJJL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5kHDI6VTxyX",
        "outputId": "afc83d6d-097b-4b3b-d299-d2a9ad695a5f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Снинговый номер                              0\n",
              "Пол                                          0\n",
              "Полных лет                                   0\n",
              "Образование(0-начальное, 4-высшее)           0\n",
              "Род занятий(0-0, работает-1                  0\n",
              "Семейное положение(0-0, 1-женат)             0\n",
              "Удовлетворенность семеными отношениями       0\n",
              "Удовлетворенность материальным положением    0\n",
              "Здоровье от 1 до 10                          0\n",
              "Были ли нарушения сна                        0\n",
              "ИМТ                                          0\n",
              "Операции                                     0\n",
              "ЧМТ                                          0\n",
              "Насл отягощенность                           0\n",
              "Дебют                                        0\n",
              "Частота госпит                               0\n",
              "Стаж шизофр                                  0\n",
              "P                                            0\n",
              "N                                            0\n",
              "G                                            0\n",
              "Была попытка суицида?                        0\n",
              "PSQI                                         0\n",
              "psqi больше 5                                0\n",
              "(ТРЕВОГА)Гаиильтон больше 16                 0\n",
              "(ДЕПРЕССИЯ)madrs больше 6                    0\n",
              "(ДЕПРЕССИЯ)Калгари больше 5                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXPhKu8mT4cS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pEJ79uoXQZdV"
      },
      "outputs": [],
      "source": [
        "# drop unnecessary columns\n",
        "ds = ds.drop(columns=['Снинговый номер'])\n",
        "# ds = ds.drop(columns=['Здоровье от 1 до 10', 'Удовлетворенность материальным положением', 'Рост', 'Вес', 'BARS (акатизия)', 'SAS (Экстрапир)', 'AIMS (непр дв)', 'ESS', 'шкала общего клин впечатления', 'шкала соц функционир'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-YpnvKCkznI",
        "outputId": "405ed339-8ac5-4866-8a19-44d20b874e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 180 entries, 0 to 179\n",
            "Data columns (total 25 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Пол                                        180 non-null    object \n",
            " 1   Полных лет                                 180 non-null    int64  \n",
            " 2   Образование(0-начальное, 4-высшее)         180 non-null    int64  \n",
            " 3   Род занятий(0-0, работает-1                180 non-null    int64  \n",
            " 4   Семейное положение(0-0, 1-женат)           180 non-null    int64  \n",
            " 5   Удовлетворенность семеными отношениями     180 non-null    int64  \n",
            " 6   Удовлетворенность материальным положением  180 non-null    int64  \n",
            " 7   Здоровье от 1 до 10                        180 non-null    int64  \n",
            " 8   Были ли нарушения сна                      180 non-null    int64  \n",
            " 9   ИМТ                                        180 non-null    float64\n",
            " 10  Операции                                   180 non-null    int64  \n",
            " 11  ЧМТ                                        180 non-null    int64  \n",
            " 12  Насл отягощенность                         180 non-null    int64  \n",
            " 13  Дебют                                      180 non-null    float64\n",
            " 14  Частота госпит                             180 non-null    int64  \n",
            " 15  Стаж шизофр                                180 non-null    float64\n",
            " 16  P                                          180 non-null    int64  \n",
            " 17  N                                          180 non-null    int64  \n",
            " 18  G                                          180 non-null    int64  \n",
            " 19  Была попытка суицида?                      180 non-null    int64  \n",
            " 20  PSQI                                       180 non-null    int64  \n",
            " 21  psqi больше 5                              180 non-null    int64  \n",
            " 22  (ТРЕВОГА)Гаиильтон больше 16               180 non-null    int64  \n",
            " 23  (ДЕПРЕССИЯ)madrs больше 6                  180 non-null    int64  \n",
            " 24  (ДЕПРЕССИЯ)Калгари больше 5                180 non-null    int64  \n",
            "dtypes: float64(3), int64(21), object(1)\n",
            "memory usage: 35.3+ KB\n"
          ]
        }
      ],
      "source": [
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "psWgB8oSkcF-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Пол'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy9-88v9bi2u",
        "outputId": "9fc0f4b5-1b81-4ac1-a0ca-325fe459b909"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "М    136\n",
              "Ж     44\n",
              "Name: Пол, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Пол'] = np.where(ds['Пол']=='М',1,0)"
      ],
      "metadata": {
        "id": "0HsMmuGXbX0i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Пол'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTxS-svEbkoK",
        "outputId": "767f528c-575e-4e01-aaec-4647fb0b9f45"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    136\n",
              "0     44\n",
              "Name: Пол, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "eYGpxa6cG2Oi",
        "outputId": "8b60803c-8790-4c17-c865-4b3f1634e3e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "0    1          32                                   4   \n",
              "1    1          26                                   2   \n",
              "2    1          49                                   2   \n",
              "3    1          50                                   2   \n",
              "4    1          39                                   2   \n",
              "\n",
              "   Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "0                            0                                 0   \n",
              "1                            0                                 0   \n",
              "2                            0                                 0   \n",
              "3                            0                                 0   \n",
              "4                            0                                 0   \n",
              "\n",
              "   Удовлетворенность семеными отношениями  \\\n",
              "0                                       5   \n",
              "1                                       5   \n",
              "2                                       5   \n",
              "3                                       5   \n",
              "4                                       5   \n",
              "\n",
              "   Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "0                                          0                    7   \n",
              "1                                          0                   10   \n",
              "2                                          1                   10   \n",
              "3                                          1                    7   \n",
              "4                                          1                    7   \n",
              "\n",
              "   Были ли нарушения сна        ИМТ  ...  Стаж шизофр   P   N   G  \\\n",
              "0                      1  24.012346  ...          3.7  11  11  18   \n",
              "1                      1  20.244898  ...          2.0  10  25  36   \n",
              "2                      0  29.752744  ...         23.0   9  16  23   \n",
              "3                      1  22.093170  ...         34.0  13  13  20   \n",
              "4                      0  20.761246  ...          4.0   9  13  22   \n",
              "\n",
              "   Была попытка суицида?  PSQI  psqi больше 5  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "0                      0     6              1                             0   \n",
              "1                      0     8              1                             0   \n",
              "2                      0     3              0                             0   \n",
              "3                      0     6              1                             0   \n",
              "4                      0     4              0                             0   \n",
              "\n",
              "   (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "0                          0                            0  \n",
              "1                          1                            1  \n",
              "2                          0                            0  \n",
              "3                          0                            0  \n",
              "4                          0                            0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-982148e7-0d5a-45b5-8988-c8fd397732a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>ИМТ</th>\n",
              "      <th>...</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>Была попытка суицида?</th>\n",
              "      <th>PSQI</th>\n",
              "      <th>psqi больше 5</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>24.012346</td>\n",
              "      <td>...</td>\n",
              "      <td>3.7</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>20.244898</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>29.752744</td>\n",
              "      <td>...</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>22.093170</td>\n",
              "      <td>...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>20.761246</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-982148e7-0d5a-45b5-8988-c8fd397732a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-982148e7-0d5a-45b5-8988-c8fd397732a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-982148e7-0d5a-45b5-8988-c8fd397732a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "ds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dNDEEZMXqCI",
        "outputId": "3c5e2c41-35bf-4e35-8f35-ee84ee7deef6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Пол                                          0\n",
              "Полных лет                                   0\n",
              "Образование(0-начальное, 4-высшее)           0\n",
              "Род занятий(0-0, работает-1                  0\n",
              "Семейное положение(0-0, 1-женат)             0\n",
              "Удовлетворенность семеными отношениями       0\n",
              "Удовлетворенность материальным положением    0\n",
              "Здоровье от 1 до 10                          0\n",
              "Были ли нарушения сна                        0\n",
              "ИМТ                                          0\n",
              "Операции                                     0\n",
              "ЧМТ                                          0\n",
              "Насл отягощенность                           0\n",
              "Дебют                                        0\n",
              "Частота госпит                               0\n",
              "Стаж шизофр                                  0\n",
              "P                                            0\n",
              "N                                            0\n",
              "G                                            0\n",
              "Была попытка суицида?                        0\n",
              "PSQI                                         0\n",
              "psqi больше 5                                0\n",
              "(ТРЕВОГА)Гаиильтон больше 16                 0\n",
              "(ДЕПРЕССИЯ)madrs больше 6                    0\n",
              "(ДЕПРЕССИЯ)Калгари больше 5                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Check for na values\n",
        "ds.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kak3ZDUIIWNo",
        "outputId": "4bd64142-2b8a-403d-e621-90cbcd942c90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 180 entries, 0 to 179\n",
            "Data columns (total 25 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Пол                                        180 non-null    int64  \n",
            " 1   Полных лет                                 180 non-null    int64  \n",
            " 2   Образование(0-начальное, 4-высшее)         180 non-null    int64  \n",
            " 3   Род занятий(0-0, работает-1                180 non-null    int64  \n",
            " 4   Семейное положение(0-0, 1-женат)           180 non-null    int64  \n",
            " 5   Удовлетворенность семеными отношениями     180 non-null    int64  \n",
            " 6   Удовлетворенность материальным положением  180 non-null    int64  \n",
            " 7   Здоровье от 1 до 10                        180 non-null    int64  \n",
            " 8   Были ли нарушения сна                      180 non-null    int64  \n",
            " 9   ИМТ                                        180 non-null    float64\n",
            " 10  Операции                                   180 non-null    int64  \n",
            " 11  ЧМТ                                        180 non-null    int64  \n",
            " 12  Насл отягощенность                         180 non-null    int64  \n",
            " 13  Дебют                                      180 non-null    float64\n",
            " 14  Частота госпит                             180 non-null    int64  \n",
            " 15  Стаж шизофр                                180 non-null    float64\n",
            " 16  P                                          180 non-null    int64  \n",
            " 17  N                                          180 non-null    int64  \n",
            " 18  G                                          180 non-null    int64  \n",
            " 19  Была попытка суицида?                      180 non-null    int64  \n",
            " 20  PSQI                                       180 non-null    int64  \n",
            " 21  psqi больше 5                              180 non-null    int64  \n",
            " 22  (ТРЕВОГА)Гаиильтон больше 16               180 non-null    int64  \n",
            " 23  (ДЕПРЕССИЯ)madrs больше 6                  180 non-null    int64  \n",
            " 24  (ДЕПРЕССИЯ)Калгари больше 5                180 non-null    int64  \n",
            "dtypes: float64(3), int64(22)\n",
            "memory usage: 35.3 KB\n"
          ]
        }
      ],
      "source": [
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLmf_yhQIdAS",
        "outputId": "d2be12e5-222e-4718-94b1-7b03174f898c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 180 entries, 0 to 179\n",
            "Data columns (total 25 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Пол                                        180 non-null    float32\n",
            " 1   Полных лет                                 180 non-null    float32\n",
            " 2   Образование(0-начальное, 4-высшее)         180 non-null    float32\n",
            " 3   Род занятий(0-0, работает-1                180 non-null    float32\n",
            " 4   Семейное положение(0-0, 1-женат)           180 non-null    float32\n",
            " 5   Удовлетворенность семеными отношениями     180 non-null    float32\n",
            " 6   Удовлетворенность материальным положением  180 non-null    float32\n",
            " 7   Здоровье от 1 до 10                        180 non-null    float32\n",
            " 8   Были ли нарушения сна                      180 non-null    float32\n",
            " 9   ИМТ                                        180 non-null    float32\n",
            " 10  Операции                                   180 non-null    float32\n",
            " 11  ЧМТ                                        180 non-null    float32\n",
            " 12  Насл отягощенность                         180 non-null    float32\n",
            " 13  Дебют                                      180 non-null    float32\n",
            " 14  Частота госпит                             180 non-null    float32\n",
            " 15  Стаж шизофр                                180 non-null    float32\n",
            " 16  P                                          180 non-null    float32\n",
            " 17  N                                          180 non-null    float32\n",
            " 18  G                                          180 non-null    float32\n",
            " 19  Была попытка суицида?                      180 non-null    float32\n",
            " 20  PSQI                                       180 non-null    float32\n",
            " 21  psqi больше 5                              180 non-null    float32\n",
            " 22  (ТРЕВОГА)Гаиильтон больше 16               180 non-null    float32\n",
            " 23  (ДЕПРЕССИЯ)madrs больше 6                  180 non-null    float32\n",
            " 24  (ДЕПРЕССИЯ)Калгари больше 5                180 non-null    float32\n",
            "dtypes: float32(25)\n",
            "memory usage: 17.7 KB\n"
          ]
        }
      ],
      "source": [
        "# turn dataset to float32\n",
        "ds = ds.astype(np.float32)\n",
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Ai6pimUakX",
        "outputId": "78ca6bed-7716-40bd-9ed4-3783aa2e27a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    105\n",
              "0.0     75\n",
              "Name: psqi больше 5, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "ds['psqi больше 5'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fytj8feUaq7",
        "outputId": "888bfaee-507f-4900-d72c-c5284337f8d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    139\n",
              "1.0     41\n",
              "Name: (ТРЕВОГА)Гаиильтон больше 16, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "ds['(ТРЕВОГА)Гаиильтон больше 16'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z96bukAkUata",
        "outputId": "93179817-8576-459b-b297-c73e6320155f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    121\n",
              "1.0     59\n",
              "Name: (ДЕПРЕССИЯ)madrs больше 6, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "ds['(ДЕПРЕССИЯ)madrs больше 6'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['(ДЕПРЕССИЯ)Калгари больше 5'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2SUV1exnNuK",
        "outputId": "e92d422a-87a4-4b24-a3ae-741ecc510915"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    139\n",
              "1.0     41\n",
              "Name: (ДЕПРЕССИЯ)Калгари больше 5, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z0Fx5Wsrk2mi"
      },
      "outputs": [],
      "source": [
        "# Let's try to use 'psqi больше 5' as y value\n",
        "data = ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "x-rJ0J9gvL8Q"
      },
      "outputs": [],
      "source": [
        "# Create X, y\n",
        "y = data['psqi больше 5']\n",
        "X = data.drop(columns=['PSQI', 'psqi больше 5', '(ТРЕВОГА)Гаиильтон больше 16', '(ДЕПРЕССИЯ)madrs больше 6', '(ДЕПРЕССИЯ)Калгари больше 5'])\n",
        "# X = data.drop(columns=['Нарушения сна больше 5'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JV3JWvaa8vS2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "I1vVG5N_8vWH",
        "outputId": "cec971f4-5f5d-424f-87c1-a7568ef7c273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Пол', 'Полных лет', 'Образование(0-начальное, 4-высшее)',\n",
              "       'Род занятий(0-0, работает-1', 'Семейное положение(0-0, 1-женат)',\n",
              "       'Удовлетворенность семеными отношениями',\n",
              "       'Удовлетворенность материальным положением', 'Здоровье от 1 до 10',\n",
              "       'Были ли нарушения сна', 'ИМТ', 'Операции', 'ЧМТ', 'Насл отягощенность',\n",
              "       'Дебют', 'Частота госпит', 'Стаж шизофр', 'P', 'N', 'G',\n",
              "       'Была попытка суицида?'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Пол'].plot.hist()"
      ],
      "metadata": {
        "id": "TvFjqRJs9FKq",
        "outputId": "c563d3c9-b938-461d-80ab-f5cf00b62c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc530595210>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Полных лет'].plot.hist()"
      ],
      "metadata": {
        "id": "cSzNKuAE8vY0",
        "outputId": "e2f24447-a170-4783-b942-2ebd3b344cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc53003ba50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Образование(0-начальное, 4-высшее)'].plot.hist()"
      ],
      "metadata": {
        "id": "rS7RThGt8vbA",
        "outputId": "4e1f86a1-913f-439a-8f23-a36c50a721fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52ffde590>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQoElEQVR4nO3de6xlZX3G8e8DAwXUisopUgYcrARLFSqOSEO0FGqKokArpRgvQNFpqlYsTWQkRmyTJpi04qWtloLt4BVEKwhYg4ia/iE4g1RuUiYIOggy3hhUIqK//rHXvD2dnsOsmTl7r3P5fpKdsy7vPuv38jLzzFrv2munqpAkCWCnoQuQJM0fhoIkqTEUJEmNoSBJagwFSVKzbOgCdsRee+1VK1asGLoMSVpQ1q1b972qmppp34IOhRUrVrB27dqhy5CkBSXJPbPt8/KRJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqVnQn2jWwrFi9VWDHPfu844b5LjSQuWZgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqRmbKGQ5INJHkhyy7RtT05yTZI7u59P6rYnyXuTrE/y9SSHjasuSdLsxnmm8G/AsVtsWw1cW1UHAtd26wAvBg7sXquA94+xLknSLMYWClX1ZeAHW2w+AVjTLa8BTpy2/eIa+QqwZ5J9xlWbJGlmk55T2Luq7uuW7wf27pb3Bb49rd2Gbtv/k2RVkrVJ1m7cuHF8lUrSEjTYRHNVFVDb8b4LqmplVa2cmpoaQ2WStHRNOhS+u/myUPfzgW77vcB+09ot77ZJkiZo0qFwBXBqt3wqcPm07a/p7kI6Anhw2mUmSdKEjO3R2Uk+BhwF7JVkA3AucB5waZIzgHuAk7vmVwMvAdYDPwVOH1ddkqTZjS0UquoVs+w6Zoa2BbxhXLVIkvrxE82SpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVIzSCgk+csktya5JcnHkuyW5IAk1ydZn+SSJLsOUZskLWUTD4Uk+wJvAlZW1bOAnYFTgHcC51fVM4AfAmdMujZJWuqGuny0DNg9yTJgD+A+4Gjgsm7/GuDEgWqTpCVr4qFQVfcCfwd8i1EYPAisA35UVY92zTYA+066Nkla6oa4fPQk4ATgAODXgccBx27D+1clWZtk7caNG8dUpSQtTUNcPvp94JtVtbGqfg58CjgS2LO7nASwHLh3pjdX1QVVtbKqVk5NTU2mYklaIoYIhW8BRyTZI0mAY4DbgOuAk7o2pwKXD1CbJC1pQ8wpXM9oQvlG4OauhguAs4GzkqwHngJcNOnaJGmpW7b1JnOvqs4Fzt1i813A4QOUI0nq+IlmSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLU9AqFJM8edyGSpOH1PVP4pyQ3JHl9kieOtSJJ0mB6hUJVvQB4JbAfsC7JR5O8aKyVSZImrvecQlXdCbwNOBv4XeC9Sb6R5I/GVZwkabL6zikckuR84HbgaOBlVfWb3fL5Y6xPkjRBy3q2ex9wIXBOVT28eWNVfSfJ28ZSmSRp4vqGwnHAw1X1C4AkOwG7VdVPq+pDY6tOkjRRfecUPg/sPm19j26bJGkR6RsKu1XVjzevdMt7jKckSdJQ+obCT5IctnklyXOBhx+jvSRpAeo7p/Bm4BNJvgMEeCrwJ2OrSpI0iF6hUFVfTfJM4KBu0x1V9fPtPWiSPRndzfQsoIA/Be4ALgFWAHcDJ1fVD7f3GJKkbbctD8R7HnAIcBjwiiSv2YHjvgf4j6p6JnAoo88/rAauraoDgWu7dUnSBPU6U0jyIeA3gJuAX3SbC7h4Ww/YPTvphcBpAFX1CPBIkhOAo7pma4AvMvr0tCRpQvrOKawEDq6qmoNjHgBsBP41yaHAOuBMYO+quq9rcz+w9xwcS5K0DfpePrqF0eTyXFjG6BLU+6vqOcBP2OJSURc+MwZQklVJ1iZZu3HjxjkqSZIE/UNhL+C2JJ9LcsXm13YecwOwoaqu79YvYxQS302yD0D384GZ3lxVF1TVyqpaOTU1tZ0lSJJm0vfy0Tvm6oBVdX+Sbyc5qKruAI4BbutepwLndT8vn6tjSpL66XtL6peSPA04sKo+n2QPYOcdOO5fAB9JsitwF3A6o7OWS5OcAdwDnLwDv1+StB363n30OmAV8GRGdyHtC3yA0b/yt1lV3cRo8npL2/X7JElzo++cwhuAI4FN0L5w59fGVZQkaRh9Q+Fn3ecJAEiyjFnuDpIkLVx9Q+FLSc4Bdu++m/kTwGfGV5YkaQh9Q2E1ow+c3Qz8GXA1o+9rliQtIn3vPvol8C/dS5K0SPW9++ibzDCHUFVPn/OKJEmD2ZZnH222G/DHjG5PlSQtIr3mFKrq+9Ne91bVu4HjxlybJGnC+l4+Omza6k6Mzhz6nmVIkhaIvn+x//205UfpvhltzquRJA2q791HvzfuQiRJw+t7+eisx9pfVe+am3IkSUPalruPngds/g6FlwE3AHeOoyhJ0jD6hsJy4LCqegggyTuAq6rqVeMqTJI0eX0fc7E38Mi09UfwO5QladHpe6ZwMXBDkn/v1k8E1oynJEnSUPreffS3ST4LvKDbdHpVfW18ZUmShtD38hHAHsCmqnoPsCHJAWOqSZI0kF6hkORc4Gzgrd2mXYAPj6soSdIw+p4p/CFwPPATgKr6DvCEcRUlSRpG31B4pKqK7vHZSR43vpIkSUPpGwqXJvlnYM8krwM+j1+4I0mLzlbvPkoS4BLgmcAm4CDg7VV1zZhrkyRN2FZDoaoqydVV9WzAIJCkRazv5aMbkzxvrJVIkgbX9xPNzwdeleRuRncghdFJxCHjKkySNHmPGQpJ9q+qbwF/MKF6JEkD2tqZwqcZPR31niSfrKqXT6IoSdIwtjankGnLTx9nIZKk4W0tFGqWZUnSIrS1UDg0yaYkDwGHdMubkjyUZNOOHDjJzkm+luTKbv2AJNcnWZ/kkiS77sjvlyRtu8cMharauap+taqeUFXLuuXN67+6g8c+E7h92vo7gfOr6hnAD4EzdvD3S5K20bY8OnvOJFkOHAdc2K0HOBq4rGuyhtEX+UiSJmiQUADeDbwF+GW3/hTgR1X1aLe+Adh3iMIkaSnr++G1OZPkpcADVbUuyVHb8f5VwCqA/ffff46rk6T+Vqy+arBj333ecWP5vUOcKRwJHN99OvrjjC4bvYfRE1g3h9Ry4N6Z3lxVF1TVyqpaOTU1NYl6JWnJmHgoVNVbq2p5Va0ATgG+UFWvBK4DTuqanQpcPunaJGmpG2pOYSZnA2clWc9ojuGigeuRpCVn4nMK01XVF4Evdst3AYcPWY8kLXXz6UxBkjQwQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSc2yoQuQNLdWrL5qkOPefd5xgxxXc8szBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJaiYeCkn2S3JdktuS3JrkzG77k5Nck+TO7ueTJl2bJC11Q5wpPAr8VVUdDBwBvCHJwcBq4NqqOhC4tluXJE3QxEOhqu6rqhu75YeA24F9gROANV2zNcCJk65Nkpa6QecUkqwAngNcD+xdVfd1u+4H9p7lPauSrE2yduPGjROpU5KWisFCIcnjgU8Cb66qTdP3VVUBNdP7quqCqlpZVSunpqYmUKkkLR2DhEKSXRgFwkeq6lPd5u8m2afbvw/wwBC1SdJSNsTdRwEuAm6vqndN23UFcGq3fCpw+aRrk6SlbojvUzgSeDVwc5Kbum3nAOcBlyY5A7gHOHmA2iRpSZt4KFTVfwKZZfcxk6xFkvR/+YlmSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSM8TXcc4LK1ZfNdix7z7vuMGOLUmPxTMFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqRmXoVCkmOT3JFkfZLVQ9cjSUvNvAmFJDsD/wi8GDgYeEWSg4etSpKWlnkTCsDhwPqququqHgE+DpwwcE2StKSkqoauAYAkJwHHVtVru/VXA8+vqjdu0W4VsKpbPQi4YzsPuRfwve1873xjX+afxdIPsC/z1Y705WlVNTXTjgX3JTtVdQFwwY7+niRrq2rlHJQ0OPsy/yyWfoB9ma/G1Zf5dPnoXmC/aevLu22SpAmZT6HwVeDAJAck2RU4Bbhi4JokaUmZN5ePqurRJG8EPgfsDHywqm4d4yF3+BLUPGJf5p/F0g+wL/PVWPoybyaaJUnDm0+XjyRJAzMUJEnNog6FJB9M8kCSW2bZnyTv7R6r8fUkh026xr569OWoJA8mual7vX3SNfaVZL8k1yW5LcmtSc6coc28H5ue/VgQ45JktyQ3JPmvri9/PUObX0lySTcm1ydZMflKt65nX05LsnHauLx2iFr7SLJzkq8luXKGfXM/JlW1aF/AC4HDgFtm2f8S4LNAgCOA64eueQf6chRw5dB19uzLPsBh3fITgP8GDl5oY9OzHwtiXLr/zo/vlncBrgeO2KLN64EPdMunAJcMXfcO9OU04B+GrrVnf84CPjrT/0fjGJNFfaZQVV8GfvAYTU4ALq6RrwB7JtlnMtVtmx59WTCq6r6qurFbfgi4Hdh3i2bzfmx69mNB6P47/7hb3aV7bXkXygnAmm75MuCYJJlQib317MuCkGQ5cBxw4SxN5nxMFnUo9LAv8O1p6xtYoH+oO7/TnTJ/NslvDV1MH93p7nMY/WtuugU1No/RD1gg49JdprgJeAC4pqpmHZOqehR4EHjKZKvsp0dfAF7eXZq8LMl+M+yfD94NvAX45Sz753xMlnooLCY3MnqeyaHA+4BPD1zPViV5PPBJ4M1VtWnoerbXVvqxYMalqn5RVb/N6GkChyd51tA1ba8effkMsKKqDgGu4X//tT1vJHkp8EBVrZvkcZd6KCyaR2tU1abNp8xVdTWwS5K9Bi5rVkl2YfQX6Ueq6lMzNFkQY7O1fiy0cQGoqh8B1wHHbrGrjUmSZcATge9PtrptM1tfqur7VfWzbvVC4LmTrq2HI4Hjk9zN6KnRRyf58BZt5nxMlnooXAG8prvT5Qjgwaq6b+iitkeSp26+lpjkcEZjOy//wHZ1XgTcXlXvmqXZvB+bPv1YKOOSZCrJnt3y7sCLgG9s0ewK4NRu+STgC9XNcM4nffqyxfzU8Yzmg+aVqnprVS2vqhWMJpG/UFWv2qLZnI/JvHnMxTgk+Rijuz/2SrIBOJfRpBNV9QHgakZ3uawHfgqcPkylW9ejLycBf57kUeBh4JT5+Ae2cyTwauDm7rovwDnA/rCgxqZPPxbKuOwDrMnoy652Ai6tqiuT/A2wtqquYBSAH0qyntFND6cMV+5j6tOXNyU5HniUUV9OG6zabTTuMfExF5KkZqlfPpIkTWMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJzf8A0ZmtCR66/3MAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Удовлетворенность семеными отношениями'].plot.hist()"
      ],
      "metadata": {
        "id": "qcJXSM9x9KeR",
        "outputId": "745de3df-40d2-4919-d63b-cc9ab891c927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52feffe10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Удовлетворенность материальным положением'].plot.hist()"
      ],
      "metadata": {
        "id": "ZaW99Tv29M2p",
        "outputId": "d277e548-68e5-4723-d848-ed9a1708ae28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fe85190>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Здоровье от 1 до 10'].plot.hist()"
      ],
      "metadata": {
        "id": "t9RAlre-9NDZ",
        "outputId": "11f7d2d9-19f6-41ff-94fa-9a3a03f07bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fe18590>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Были ли нарушения сна'].plot.hist()"
      ],
      "metadata": {
        "id": "vHaj2_J99NR3",
        "outputId": "c1259ed3-dab2-449e-e23f-eec2635be975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fd9ad90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['ИМТ'].plot.hist()"
      ],
      "metadata": {
        "id": "1xC2ChxODvpM",
        "outputId": "f447ffbf-3df3-4e85-eb7a-1d6005c3336c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fd20c90>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Операции'].plot.hist()"
      ],
      "metadata": {
        "id": "QKyiTn8z8vdN",
        "outputId": "dad389a9-11c5-4b96-b270-892e3668fafa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fcb3790>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X['Аллергии'].plot.hist()"
      ],
      "metadata": {
        "id": "9mM7BGvI9N5N"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X['Забол кожи'].plot.hist()"
      ],
      "metadata": {
        "id": "9OIttp848vfV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X['ГБ'].plot.hist()"
      ],
      "metadata": {
        "id": "UQSDw5Sj9P2P"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X['Панкреатит'].plot.hist()"
      ],
      "metadata": {
        "id": "IkrDKxnY9P4y"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X['Дисфункция ЖКТ'].plot.hist()"
      ],
      "metadata": {
        "id": "fe_keiy09P7M"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['ЧМТ'].plot.hist()"
      ],
      "metadata": {
        "id": "loEyKK3y9P9v",
        "outputId": "b7efd4a6-36f4-4a0b-da3a-c4efe94f0cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fbc3c90>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Насл отягощенность'].plot.hist()"
      ],
      "metadata": {
        "id": "lB6JgIeJ9QAB",
        "outputId": "16d1605b-240a-4d5a-d64b-153753e39e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fb41210>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Дебют'].plot.hist()"
      ],
      "metadata": {
        "id": "73hXHFoX9QCa",
        "outputId": "e1626673-1ed7-4916-fb5d-0cb6211732e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fad9e90>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQiUlEQVR4nO3dfYxldX3H8feHBwuoKSLrlrDgoBIpqYp0QA3aIkZLiwK2lmrVbBri2hQTjKayEFMx0QT/ULSNVVexrI+ADwgFteKKGv8BdwXlSQPi0rICuz4QwBrowrd/3DM6LLOzd5Y598zu7/1KJnPO794755Nfsp85+5tzz01VIUlqxx5DB5AkTZbFL0mNsfglqTEWvyQ1xuKXpMbsNXSAcRx44IE1NTU1dAxJ2qVs2LDhF1W1bNvxXaL4p6amWL9+/dAxJGmXkuSOucZd6pGkxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMbsEu/clXZkavWVgxx343knDXJc6fHwjF+SGmPxS1JjLH5JaozFL0mN6fWPu0k2AvcDDwNbq2o6yQHAxcAUsBE4rap+3WcOSdLvTeKM/6VVdVRVTXf7q4F1VXU4sK7blyRNyBBLPacAa7vttcCpA2SQpGb1XfwFfCPJhiSrurHlVXVXt303sHyuFyZZlWR9kvVbtmzpOaYktaPvN3C9uKo2JXkacFWSH89+sKoqSc31wqpaA6wBmJ6envM5kqSF6/WMv6o2dd83A5cCxwL3JDkIoPu+uc8MkqRH6634kzwxyZNntoFXADcClwMru6etBC7rK4Mk6bH6XOpZDlyaZOY4n6uqryf5PnBJktOBO4DTeswgSdpGb8VfVbcDz5tj/JfAy/o6riRpfr5zV5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1Jj+r4tsxoytfrKoSNIGoNn/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1Jjei/+JHsmuS7JFd3+YUmuSXJbkouTPKHvDJKk35vEGf+ZwC2z9t8HnF9VzwJ+DZw+gQySpE6vxZ9kBXAS8IluP8AJwBe7p6wFTu0zgyTp0fo+4/8g8A7gkW7/qcC9VbW1278TOLjnDJKkWXor/iSvBDZX1YadfP2qJOuTrN+yZcsip5OkdvV5xn8ccHKSjcBFjJZ4PgTsn2Sv7jkrgE1zvbiq1lTVdFVNL1u2rMeYktSW3oq/qs6uqhVVNQW8FvhWVb0euBp4Tfe0lcBlfWWQJD3WENfxnwW8LcltjNb8LxgggyQ1a68dP+Xxq6pvA9/utm8Hjp3EcSVJj+U7dyWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjJnI5p7S7mlp95WDH3njeSYMdW7s2z/glqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqzFjFn+Q5fQeRJE3GuGf8/57k2iT/lOQPe00kSerVWMVfVS8BXg8cAmxI8rkkL+81mSSpF2Ov8VfVrcA7gbOAPwf+NcmPk/x1X+EkSYtv3DX+5yY5H7gFOAF4VVX9cbd9fo/5JEmLbNwPW/834BPAOVX125nBqvp5knf2kkyS1Itxi/8k4LdV9TBAkj2Afarqf6vq072lkyQtunHX+L8J7Dtrf79uTJK0ixm3+Pepqgdmdrrt/fqJJEnq07jF/5skR8/sJPlT4LfzPJ8k+3TX/v8wyU1J3t2NH5bkmiS3Jbk4yRN2Pr4kaaHGXeN/K/CFJD8HAvwR8Hc7eM2DwAlV9UCSvYHvJfka8Dbg/Kq6KMlHgdOBj+xcfEnSQo1V/FX1/SRHAM/uhn5SVf+3g9cUMLM8tHf3VYwuAf37bnwtcC4WvyRNzLhn/ADHAFPda45OQlV9ar4XJNkT2AA8C/gw8FPg3qra2j3lTuDg7bx2FbAK4NBDD11ATEnSfMYq/iSfBp4JXA883A0XMG/xd5d/HpVkf+BS4Ihxg1XVGmANwPT0dI37OknS/MY9458GjuyWbxasqu5NcjXwImD/JHt1Z/0rgE078zMlSTtn3Kt6bmT0B92xJVnWnemTZF/g5Yxu+XA18JruaSuByxbycyVJj8+4Z/wHAjcnuZbR1ToAVNXJ87zmIGBtt86/B3BJVV2R5GbgoiTvAa4DLti56JKknTFu8Z+70B9cVT8Cnj/H+O3AsQv9eZKkxTHu5ZzfSfJ04PCq+maS/YA9+40mSerDuLdlfhPwReBj3dDBwFf6CiVJ6s+4f9w9AzgOuA9+96EsT+srlCSpP+MW/4NV9dDMTpK9GF3HL0naxYxb/N9Jcg6wb/dZu18A/rO/WJKkvoxb/KuBLcANwJuBrzL6/F1J0i5m3Kt6HgE+3n1JknZh496r52fMsaZfVc9Y9ESSpF4t5F49M/YB/hY4YPHjSJL6NtYaf1X9ctbXpqr6IKMPYJck7WLGXeo5etbuHoz+B7CQe/lLkpaIccv7/bO2twIbgdMWPY0kqXfjXtXz0r6DSJImY9ylnrfN93hVfWBx4kiS+raQq3qOAS7v9l8FXAvc2kcoSVJ/xi3+FcDRVXU/QJJzgSur6g19BZMk9WPcWzYsBx6atf9QNyZJ2sWMe8b/KeDaJJd2+6cCa/uJJEnq07hX9bw3ydeAl3RD/1BV1/UXS5LUl3GXegD2A+6rqg8BdyY5rKdMkqQejfvRi+8CzgLO7ob2Bj7TVyhJUn/GPeN/NXAy8BuAqvo58OS+QkmS+jNu8T9UVUV3a+YkT+wvkiSpT+MW/yVJPgbsn+RNwDfxQ1kkaZe0w6t6kgS4GDgCuA94NvAvVXVVz9kkST3YYfFXVSX5alU9B7DsJWkXN+5Szw+SHNNrEknSRIz7zt0XAG9IspHRlT1h9J+B5/YVTJLUj3mLP8mhVfXfwF9MKI8kqWc7OuP/CqO7ct6R5EtV9TeTCCVJ6s+O1vgza/sZfQaRJE3Gjoq/trO9Q0kOSXJ1kpuT3JTkzG78gCRXJbm1+/6UhYaWJO28HRX/85Lcl+R+4Lnd9n1J7k9y3w5euxV4e1UdCbwQOCPJkcBqYF1VHQ6s6/YlSRMy7xp/Ve25sz+4qu4C7uq2709yC3AwcApwfPe0tcC3Gd0ATpI0AQu5LfNOSzIFPB+4Blje/VIAuJvtfJJXklVJ1idZv2XLlknElKQm9F78SZ4EfAl4a1U9anlo9o3ftlVVa6pquqqmly1b1ndMSWpGr8WfZG9Gpf/ZqvpyN3xPkoO6xw8CNveZQZL0aL0Vf3dztwuAW6rqA7MeuhxY2W2vBC7rK4Mk6bHGvWXDzjgOeCNwQ5Lru7FzgPMY3eb5dOAO4LQeM0iSttFb8VfV93j0G8Bme1lfx5UkzW8iV/VIkpYOi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMXsNHUCLb2r1lUNHkLSEecYvSY2x+CWpMRa/JDXGNX5pFzXU33I2nnfSIMfV4vGMX5IaY/FLUmMsfklqjMUvSY3prfiTfDLJ5iQ3zho7IMlVSW7tvj+lr+NLkubW5xn/hcCJ24ytBtZV1eHAum5fkjRBvRV/VX0X+NU2w6cAa7vttcCpfR1fkjS3Sa/xL6+qu7rtu4Hl23tiklVJ1idZv2XLlsmkk6QGDPbH3aoqoOZ5fE1VTVfV9LJlyyaYTJJ2b5Mu/nuSHATQfd884eNLUvMmXfyXAyu77ZXAZRM+viQ1r7d79ST5PHA8cGCSO4F3AecBlyQ5HbgDOK2v40vqx5Cf9+B9ghZHb8VfVa/bzkMv6+uYkqQd8527ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5Ia09tHL0rSYhvy836H0NdnDHvGL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSY3b76/iHuu63r+tvJenx8oxfkhpj8UtSYyx+SWrMbr/GP5TW7ikiadcxyBl/khOT/CTJbUlWD5FBklo18eJPsifwYeAvgSOB1yU5ctI5JKlVQ5zxHwvcVlW3V9VDwEXAKQPkkKQmDbHGfzDwP7P27wResO2TkqwCVnW7DyT5yU4e70DgFzv52j6Za2HMtTDmWpglmSvve9y5nj7X4JL9425VrQHWPN6fk2R9VU0vQqRFZa6FMdfCmGthWss1xFLPJuCQWfsrujFJ0gQMUfzfBw5PcliSJwCvBS4fIIckNWniSz1VtTXJW4D/AvYEPllVN/V4yMe9XNQTcy2MuRbGXAvTVK5UVR8/V5K0RHnLBklqjMUvSY3ZrYs/ycYkNyS5Psn6AXN8MsnmJDfOGjsgyVVJbu2+P2WJ5Do3yaZuzq5P8lcD5DokydVJbk5yU5Izu/FB52yeXIPOWZJ9klyb5Iddrnd344cluaa7NcrF3cUUSyHXhUl+Nmu+jppkrln59kxyXZIruv1B52ueXIs+X7t18XdeWlVHDXyN7oXAiduMrQbWVdXhwLpuf9Iu5LG5AM7v5uyoqvrqhDMBbAXeXlVHAi8Ezuhu6zH0nG0vFww7Zw8CJ1TV84CjgBOTvBB4X5frWcCvgdOXSC6Af541X9dPONeMM4FbZu0PPV8zts0FizxfLRT/4Krqu8Cvthk+BVjbba8FTp1oKLaba3BVdVdV/aDbvp/RP4KDGXjO5sk1qBp5oNvdu/sq4ATgi934EPO1vVyDS7ICOAn4RLcfBp6vuXL1ZXcv/gK+kWRDdwuIpWR5Vd3Vbd8NLB8yzDbekuRH3VLQxJegZksyBTwfuIYlNGfb5IKB56xbHrge2AxcBfwUuLeqtnZPuZMBfkltm6uqZubrvd18nZ/kDyadC/gg8A7gkW7/qSyB+Zoj14xFna/dvfhfXFVHM7oT6BlJ/mzoQHOp0TW1S+JMCPgI8ExG/zW/C3j/UEGSPAn4EvDWqrpv9mNDztkcuQafs6p6uKqOYvRO+GOBIyadYS7b5kryJ8DZjPIdAxwAnDXJTEleCWyuqg2TPO6OzJNr0edrty7+qtrUfd8MXMroH8RScU+SgwC675sHzgNAVd3T/WN9BPg4A81Zkr0Zletnq+rL3fDgczZXrqUyZ12We4GrgRcB+yeZeZPmoLdGmZXrxG7JrKrqQeA/mPx8HQecnGQjo7sDnwB8iOHn6zG5knymj/nabYs/yROTPHlmG3gFcOP8r5qoy4GV3fZK4LIBs/zOTLF2Xs0Ac9att14A3FJVH5j10KBztr1cQ89ZkmVJ9u+29wVezujvD1cDr+meNsR8zZXrx7N+eYfROvpE56uqzq6qFVU1xeiWMd+qqtcz8HxtJ9cb+pivJXt3zkWwHLh0NFfsBXyuqr4+RJAknweOBw5McifwLuA84JIkpwN3AKctkVzHd5eLFbARePOkczE683kjcEO3PgxwDsPP2fZyvW7gOTsIWJvRhxztAVxSVVckuRm4KMl7gOsY/dJaCrm+lWQZEOB64B8nnGt7zmLY+dqezy72fHnLBklqzG671CNJmpvFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhrz/zmH8XPRmDYQAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Частота госпит'].plot.hist()"
      ],
      "metadata": {
        "id": "dfRTqleE9QFD",
        "outputId": "fc92b886-98f7-4416-8583-0cce6b1af622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fa91410>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Стаж шизофр'].plot.hist()"
      ],
      "metadata": {
        "id": "MPLll8-L9u8u",
        "outputId": "ad1a5470-f0cc-42dc-ca2a-1fad1f1947b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fe10390>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['P'].plot.hist()"
      ],
      "metadata": {
        "id": "WR2YxXxd9u_V",
        "outputId": "60f051a6-42ce-470f-f0f2-92bbea532045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52f957fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['N'].plot.hist()"
      ],
      "metadata": {
        "id": "n15glR8-9vB2",
        "outputId": "77bc2299-6d83-46fb-c342-a329a1860b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52f8e2150>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['G'].plot.hist()"
      ],
      "metadata": {
        "id": "jNFwr3Rt9vEi",
        "outputId": "3c048b4e-22ea-48cf-bf8c-bff089ec1d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52f860ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Была попытка суицида?'].plot.hist()"
      ],
      "metadata": {
        "id": "3Fwjsi4iNyVs",
        "outputId": "e74a9005-e1c8-4987-851e-c187172dc46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52fc09750>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.min()"
      ],
      "metadata": {
        "id": "SjbyFES59vHG",
        "outputId": "8efe558f-e383-45eb-fd79-12f16e666b3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Пол                                           0.000000\n",
              "Полных лет                                   19.000000\n",
              "Образование(0-начальное, 4-высшее)            1.000000\n",
              "Род занятий(0-0, работает-1                   0.000000\n",
              "Семейное положение(0-0, 1-женат)              0.000000\n",
              "Удовлетворенность семеными отношениями        1.000000\n",
              "Удовлетворенность материальным положением     0.000000\n",
              "Здоровье от 1 до 10                           1.000000\n",
              "Были ли нарушения сна                         0.000000\n",
              "ИМТ                                          14.005112\n",
              "Операции                                      0.000000\n",
              "ЧМТ                                           0.000000\n",
              "Насл отягощенность                            0.000000\n",
              "Дебют                                         5.000000\n",
              "Частота госпит                                0.000000\n",
              "Стаж шизофр                                   0.500000\n",
              "P                                             7.000000\n",
              "N                                             5.000000\n",
              "G                                            16.000000\n",
              "Была попытка суицида?                         0.000000\n",
              "dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.max()"
      ],
      "metadata": {
        "id": "Ov1NYpWJ9vLD",
        "outputId": "2faaee18-fd73-4602-c771-6b74ee61fb79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Пол                                           1.000000\n",
              "Полных лет                                   67.000000\n",
              "Образование(0-начальное, 4-высшее)            4.000000\n",
              "Род занятий(0-0, работает-1                   1.000000\n",
              "Семейное положение(0-0, 1-женат)              1.000000\n",
              "Удовлетворенность семеными отношениями        5.000000\n",
              "Удовлетворенность материальным положением     1.000000\n",
              "Здоровье от 1 до 10                          10.000000\n",
              "Были ли нарушения сна                         1.000000\n",
              "ИМТ                                          40.404041\n",
              "Операции                                      1.000000\n",
              "ЧМТ                                           2.000000\n",
              "Насл отягощенность                            1.000000\n",
              "Дебют                                        45.000000\n",
              "Частота госпит                                2.000000\n",
              "Стаж шизофр                                  41.000000\n",
              "P                                            32.000000\n",
              "N                                            37.000000\n",
              "G                                            56.000000\n",
              "Была попытка суицида?                         1.000000\n",
              "dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8MPctJWaFgp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eoSFxsKXaFjZ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recursive feature elimination (feature selection)"
      ],
      "metadata": {
        "id": "6__3yeowZurC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Without scaling\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        " \n",
        "lr = LinearRegression()\n",
        "#select 5 the most informative features\n",
        "rfe = RFE(lr, n_features_to_select=5) \n",
        "selector = rfe.fit(X,y)\n",
        "selector.support_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZgqfNgPZutk",
        "outputId": "b4ac2b6c-1a99-4d14-f6be-1a12706a85d9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True, False, False, False, False, False, False,  True,\n",
              "       False, False, False, False,  True, False,  True, False, False,\n",
              "       False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selector.ranking_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5e_Fa3NZuv8",
        "outputId": "6b4f2b9d-8783-4d9c-bd70-0a44f0338415"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  1,  8,  3,  4, 13,  5,  7,  1, 15,  6,  9, 14,  1, 16,  1, 12,\n",
              "       10, 11,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With scaling\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = minmax_scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "IZm5ISGTZuyJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "#select 5 the most informative features\n",
        "rfe = RFE(lr, n_features_to_select=5) \n",
        "selector = rfe.fit(X_scaled,y)\n",
        "X.columns[selector.support_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEhomgyhZu0m",
        "outputId": "c7b091f9-2fe2-4359-9c1a-bf26e3dcd6c5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Полных лет', 'Дебют', 'Стаж шизофр', 'N', 'G'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selector.ranking_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WMVWWaOZu3j",
        "outputId": "3ce9cb21-d58f-4278-ebd6-8371f2589d9b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4,  1, 10,  7,  9, 14, 11,  6,  3,  8, 12, 13, 15,  1, 16,  1,  2,\n",
              "        1,  1,  5])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[False,  Полных лет, False, False, False, False, False, False, False,\n",
        "       False, False, False, False,  Дебют, False,  Стаж шизофр, False,  N,\n",
        "        G])\n",
        "\n",
        "Полных лет, G, N, Стаж шизофр, Дебют"
      ],
      "metadata": {
        "id": "E6kRoWoDdrY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "#select 5 the most informative features\n",
        "rfe = RFE(lr, n_features_to_select=3) \n",
        "selector = rfe.fit(X_scaled,y)\n",
        "\n",
        "X.columns[selector.support_]\n",
        "# Полных лет Стаж шизофр, Дебют"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUvPGl25drvw",
        "outputId": "dadc4d0c-e955-4d74-e957-655cb144bbe9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Полных лет', 'Дебют', 'Стаж шизофр'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selector.ranking_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmaSGWsydryY",
        "outputId": "19d60351-6c9a-4215-9a71-e825351b6c5b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  1, 12,  9, 11, 16, 13,  8,  5, 10, 14, 15, 17,  1, 18,  1,  4,\n",
              "        3,  2,  7])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_s14onwvdr00"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V4VkmXfGJU73"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ridge regression"
      ],
      "metadata": {
        "id": "bWVE9lVYJU-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "clf = Ridge(alpha=1.0)\n",
        "clf.fit(X_scaled, y)\n",
        "clf.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu1WF01jdr3X",
        "outputId": "2b710d51-5112-4427-a6f1-45466ab1d901"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.23175219, -0.02697261, -0.03729384, -0.14539498,  0.13882285,\n",
              "        0.04455977, -0.07623333, -0.13897881,  0.25573903, -0.08939964,\n",
              "        0.04722007, -0.03500349,  0.01163663,  0.04991342,  0.01213992,\n",
              "       -0.05580775,  0.21841994, -0.38015437,  0.35581154,  0.15863894],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNlDvdjDdr6q",
        "outputId": "1d41f777-ff86-41d6-ac0a-d5f6e19f7131"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35628915"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLA1NUAJKHvd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBl9ZGQpZu59"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LASSO regression (feature selection)"
      ],
      "metadata": {
        "id": "SkuZbKUBBkOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso"
      ],
      "metadata": {
        "id": "qRuBoZdY7yy9"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DG_91ub87y1z"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "                     ('scaler',StandardScaler()),\n",
        "                     ('model',Lasso())\n",
        "])\n"
      ],
      "metadata": {
        "id": "0BjWX-gC7_TQ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = GridSearchCV(pipeline,\n",
        "                      {'model__alpha':np.arange(0.1,10,0.1)},\n",
        "                      cv = 5, scoring=\"neg_mean_squared_error\",verbose=3\n",
        "                      )"
      ],
      "metadata": {
        "id": "P4DMl7uv8Bt6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "-I6VjLFw8DqO",
        "outputId": "ad2c452c-b47a-4eab-e0b7-214de0503b58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 99 candidates, totalling 495 fits\n",
            "[CV 1/5] END .................model__alpha=0.1;, score=-0.261 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.1;, score=-0.227 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.1;, score=-0.234 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.1;, score=-0.248 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.2;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.2;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.2;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.2;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.2;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .model__alpha=0.30000000000000004;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .model__alpha=0.30000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .model__alpha=0.30000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .model__alpha=0.30000000000000004;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .model__alpha=0.30000000000000004;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.4;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.4;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.4;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.4;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.4;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.5;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.5;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.5;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.5;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.5;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=0.7000000000000001;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=0.7000000000000001;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=0.7000000000000001;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=0.7000000000000001;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=0.7000000000000001;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.8;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.8;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.8;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.8;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.8;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.9;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.9;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.9;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.9;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.9;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=1.0;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=1.0;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=1.0;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=1.0;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=1.0;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=1.1;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=1.1;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=1.1;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=1.1;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=1.1;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.2000000000000002;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.2000000000000002;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.2000000000000002;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.2000000000000002;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.2000000000000002;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.3000000000000003;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.3000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.3000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.3000000000000003;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.3000000000000003;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.4000000000000001;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.4000000000000001;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.4000000000000001;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.4000000000000001;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.4000000000000001;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.5000000000000002;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.5000000000000002;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.5000000000000002;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.5000000000000002;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.5000000000000002;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=1.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=1.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=1.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=1.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=1.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.7000000000000002;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.7000000000000002;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.7000000000000002;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.7000000000000002;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.7000000000000002;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.8000000000000003;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.8000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.8000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.8000000000000003;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.8000000000000003;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.9000000000000001;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.9000000000000001;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.9000000000000001;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.9000000000000001;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.9000000000000001;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.0;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.0;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.0;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.0;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.0;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.1;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.1;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.1;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.1;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.1;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.2;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.2;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.2;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.2;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.2;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.3000000000000003;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.3000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.3000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.3000000000000003;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.3000000000000003;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.4000000000000004;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.4000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.4000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.4000000000000004;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.4000000000000004;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.5000000000000004;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.5000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.5000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.5000000000000004;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.5000000000000004;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.7;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.7;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.7;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.7;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.7;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.8000000000000003;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.8000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.8000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.8000000000000003;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.8000000000000003;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.9000000000000004;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.9000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.9000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.9000000000000004;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.9000000000000004;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.0000000000000004;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.0000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.0000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.0000000000000004;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.0000000000000004;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=3.1;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=3.1;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=3.1;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=3.1;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=3.1;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=3.2;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=3.2;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=3.2;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=3.2;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=3.2;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.3000000000000003;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.3000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.3000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.3000000000000003;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.3000000000000003;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.4000000000000004;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.4000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.4000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.4000000000000004;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.4000000000000004;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.5000000000000004;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.5000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.5000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.5000000000000004;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.5000000000000004;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=3.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=3.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=3.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=3.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=3.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=3.7;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=3.7;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=3.7;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=3.7;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=3.7;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.8000000000000003;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.8000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.8000000000000003;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.8000000000000003;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.8000000000000003;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.9000000000000004;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.9000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.9000000000000004;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.9000000000000004;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.9000000000000004;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.0;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.0;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.0;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.0;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.0;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.1;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.1;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.1;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.1;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.1;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.2;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.2;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.2;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.2;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.2;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.3;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.3;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.3;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.3;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.3;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=4.3999999999999995;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=4.3999999999999995;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=4.3999999999999995;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=4.3999999999999995;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=4.3999999999999995;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.5;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.5;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.5;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.5;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.5;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.7;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.7;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.7;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.7;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.7;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.8;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.8;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.8;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.8;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.8;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.9;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.9;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.9;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.9;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.9;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.0;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.0;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.0;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.0;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.0;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.1;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.1;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.1;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.1;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.1;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.2;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.2;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.2;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.2;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.2;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.3;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.3;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.3;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.3;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.3;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.4;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.4;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.4;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.4;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.4;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.5;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.5;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.5;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.5;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.5;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.7;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.7;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.7;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.7;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.7;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.8;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.8;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.8;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.8;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.8;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.9;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.9;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.9;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.9;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.9;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.0;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.0;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.0;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.0;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.0;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.1;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.1;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.1;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.1;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.1;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.2;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.2;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.2;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.2;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.2;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.3;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.3;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.3;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.3;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.3;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.4;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.4;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.4;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.4;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.4;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.5;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.5;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.5;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.5;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.5;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.7;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.7;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.7;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.7;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.7;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.8;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.8;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.8;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.8;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.8;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.9;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.9;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.9;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.9;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.9;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.0;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.0;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.0;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.0;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.0;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.1;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.1;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.1;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.1;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.1;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.2;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.2;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.2;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.2;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.2;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.3;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.3;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.3;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.3;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.3;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.4;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.4;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.4;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.4;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.4;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.5;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.5;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.5;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.5;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.5;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.7;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.7;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.7;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.7;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.7;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.8;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.8;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.8;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.8;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.8;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.9;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.9;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.9;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.9;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.9;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.0;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.0;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.0;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.0;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.0;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.1;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.1;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.1;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.1;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.1;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.2;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.2;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.2;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.2;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.2;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.3;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.3;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.3;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.3;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.3;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.4;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.4;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.4;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.4;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.4;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.5;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.5;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.5;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.5;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.5;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.7;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.7;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.7;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.7;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.7;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.8;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.8;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.8;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.8;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.8;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.9;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.9;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.9;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.9;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.9;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.0;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.0;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.0;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.0;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.0;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.1;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.1;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.1;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.1;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.1;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.2;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.2;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.2;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.2;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.2;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.3;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.3;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.3;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.3;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.3;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.4;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.4;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.4;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.4;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.4;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.5;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.5;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.5;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.5;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.5;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.6;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.6;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.6;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.6;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.6;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END ...model__alpha=9.700000000000001;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END ...model__alpha=9.700000000000001;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END ...model__alpha=9.700000000000001;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END ...model__alpha=9.700000000000001;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END ...model__alpha=9.700000000000001;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.8;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.8;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.8;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.8;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.8;, score=-0.257 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.9;, score=-0.264 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.9;, score=-0.236 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.9;, score=-0.236 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.9;, score=-0.217 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.9;, score=-0.257 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                                       ('model', Lasso())]),\n",
              "             param_grid={'model__alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
              "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6,\n",
              "       2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9,\n",
              "       4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. , 5.1, 5.2,\n",
              "       5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6. , 6.1, 6.2, 6.3, 6.4, 6.5,\n",
              "       6.6, 6.7, 6.8, 6.9, 7. , 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8,\n",
              "       7.9, 8. , 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9. , 9.1,\n",
              "       9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9])},\n",
              "             scoring='neg_mean_squared_error', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search.best_params_\n"
      ],
      "metadata": {
        "id": "467Y8gXz8Kqb",
        "outputId": "649b2fb4-fcc3-47d8-df4f-ca70f7c01e95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model__alpha': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients = search.best_estimator_.named_steps['model'].coef_\n"
      ],
      "metadata": {
        "id": "r5ZsQXb78Py9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients"
      ],
      "metadata": {
        "id": "c6v7Dm-q8RPP",
        "outputId": "aae7d7e7-63b2-48c2-d335-c0f7051b3379",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
              "        0.        , -0.        , -0.        ,  0.03737169, -0.        ,\n",
              "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
              "        0.        ,  0.        , -0.        ,  0.        ,  0.        ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importance = np.abs(coefficients)\n",
        "importance"
      ],
      "metadata": {
        "id": "Qaa48PUw8T4V",
        "outputId": "c1f1d8cd-fe2f-4a5d-e16e-a7584e81a5dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03737169, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(['Пол', 'Полных лет', 'Образование(0-начальное, 4-высшее)',\n",
        "       'Род занятий(0-0, работает-1', 'Семейное положение(0-0, 1-женат)',\n",
        "       'Удовлетворенность семеными отношениями', 'Здоровье от 1 до 10', 'Были ли нарушения сна', 'ИМТ', 'Операции',\n",
        "       'Удовлетворенность материальным положением','ЧМТ',\n",
        "       'Насл отягощенность', 'Дебют', 'Частота госпит', 'Стаж шизофр', 'P',\n",
        "       'N', 'G', 'Была попытка суицида?'])[importance > 0]\n"
      ],
      "metadata": {
        "id": "Crjl4-ak8VZF",
        "outputId": "d9b7f7c3-ec62-4a5f-e9fe-a7b4b8a00c81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ИМТ'], dtype='<U41')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(['Пол', 'Полных лет', 'Образование(0-начальное, 4-высшее)',\n",
        "       'Род занятий(0-0, работает-1', 'Семейное положение(0-0, 1-женат)',\n",
        "       'Удовлетворенность семеными отношениями', 'Здоровье от 1 до 10', 'Были ли нарушения сна', 'ИМТ', 'Операции',\n",
        "       'Удовлетворенность материальным положением','ЧМТ',\n",
        "       'Насл отягощенность', 'Дебют', 'Частота госпит', 'Стаж шизофр', 'P',\n",
        "       'N', 'G', 'Была попытка суицида?'])[importance == 0]\n"
      ],
      "metadata": {
        "id": "VpSqwmgK8XI8",
        "outputId": "cba4ebe8-c4b5-4bce-fcbf-a39f483cf2c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Пол', 'Полных лет', 'Образование(0-начальное, 4-высшее)',\n",
              "       'Род занятий(0-0, работает-1', 'Семейное положение(0-0, 1-женат)',\n",
              "       'Удовлетворенность семеными отношениями', 'Здоровье от 1 до 10',\n",
              "       'Были ли нарушения сна', 'Операции',\n",
              "       'Удовлетворенность материальным положением', 'ЧМТ',\n",
              "       'Насл отягощенность', 'Дебют', 'Частота госпит', 'Стаж шизофр',\n",
              "       'P', 'N', 'G', 'Была попытка суицида?'], dtype='<U41')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyb98Ux-9IQl"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "It37YfGRBkQf"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find 3 best predictors witn chi square and ANOVA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2 # chi^2\n",
        "from sklearn.feature_selection import f_classif # ANOVA\n",
        "\n",
        "X_chi2 = SelectKBest(chi2, k=5).fit_transform(X, y)\n",
        "X_anova = SelectKBest(f_classif, k=5).fit_transform(X, y)"
      ],
      "metadata": {
        "id": "oW3UvZbiNUcI"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the Top Selected Features\n",
        "\n",
        "https://ml2021.medium.com/chi-square-and-anova-feature-selection-for-ml-5e1063ab0991"
      ],
      "metadata": {
        "id": "8aImEuZChXVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_score = chi2(X, y)\n",
        "f_score\n",
        "# The first array is the F_score , 2nd one is the P_values\n",
        "# the smaller the P value the more significant the difference in the features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3x7wS6Key9P",
        "outputId": "e417939d-5f91-47f1-a61e-b597bc4ebc43"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([6.58823529e-01, 4.35251509e-02, 4.21709295e-02, 3.57142857e-01,\n",
              "        3.65714286e-01, 1.67574361e-04, 7.50066756e-01, 2.89349161e+00,\n",
              "        5.00000000e+00, 3.43775229e-02, 1.42016807e+00, 3.60653061e-01,\n",
              "        4.40816327e-01, 2.31704838e-01, 1.47783251e-01, 9.47373170e-02,\n",
              "        1.48680254e+01, 2.27850208e+00, 1.48578212e+01, 5.15714286e+00]),\n",
              " array([4.16975589e-01, 8.34739570e-01, 8.37294294e-01, 5.50097317e-01,\n",
              "        5.45349668e-01, 9.89671632e-01, 3.86455096e-01, 8.89379861e-02,\n",
              "        2.53473187e-02, 8.52906081e-01, 2.33375742e-01, 5.48143766e-01,\n",
              "        5.06728712e-01, 6.30262588e-01, 7.00662828e-01, 7.58238877e-01,\n",
              "        1.15300917e-04, 1.31178513e-01, 1.15926370e-04, 2.31509520e-02]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pvalues = pd.Series(f_score[1])\n",
        "pvalues.index = X.columns\n",
        "pvalues.sort_values(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xp3b1pMe9AS",
        "outputId": "300ce166-2214-4dca-ee3a-43e74772f845"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "P                                            0.000115\n",
              "G                                            0.000116\n",
              "Была попытка суицида?                        0.023151\n",
              "Были ли нарушения сна                        0.025347\n",
              "Здоровье от 1 до 10                          0.088938\n",
              "N                                            0.131179\n",
              "Операции                                     0.233376\n",
              "Удовлетворенность материальным положением    0.386455\n",
              "Пол                                          0.416976\n",
              "Насл отягощенность                           0.506729\n",
              "Семейное положение(0-0, 1-женат)             0.545350\n",
              "ЧМТ                                          0.548144\n",
              "Род занятий(0-0, работает-1                  0.550097\n",
              "Дебют                                        0.630263\n",
              "Частота госпит                               0.700663\n",
              "Стаж шизофр                                  0.758239\n",
              "Полных лет                                   0.834740\n",
              "Образование(0-начальное, 4-высшее)           0.837294\n",
              "ИМТ                                          0.852906\n",
              "Удовлетворенность семеными отношениями       0.989672\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now use the SelectKBest Model with the chi2 classifier to find the best features\n",
        "\n",
        "sel_ = SelectKBest(chi2, k=5).fit(X, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pelM22yef1sD",
        "outputId": "8dd128be-6fed-4ed5-9b17-3376ac2bddf0"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Здоровье от 1 до 10', 'Были ли нарушения сна', 'P', 'G',\n",
              "       'Была попытка суицида?'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tra8Cu0Af292"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TvTeApRfKkw"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "QVqfCfsgQHwV",
        "outputId": "9d5f117a-d156-4666-9e2f-3f11729e424f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "0   1.0        32.0                                 4.0   \n",
              "1   1.0        26.0                                 2.0   \n",
              "2   1.0        49.0                                 2.0   \n",
              "3   1.0        50.0                                 2.0   \n",
              "4   1.0        39.0                                 2.0   \n",
              "5   1.0        26.0                                 2.0   \n",
              "6   1.0        35.0                                 3.0   \n",
              "7   1.0        31.0                                 3.0   \n",
              "8   1.0        23.0                                 2.0   \n",
              "9   1.0        37.0                                 3.0   \n",
              "10  1.0        39.0                                 3.0   \n",
              "11  1.0        29.0                                 1.0   \n",
              "12  1.0        36.0                                 4.0   \n",
              "13  1.0        33.0                                 3.0   \n",
              "14  1.0        24.0                                 2.0   \n",
              "15  1.0        54.0                                 4.0   \n",
              "16  1.0        32.0                                 2.0   \n",
              "17  1.0        29.0                                 2.0   \n",
              "18  1.0        49.0                                 2.0   \n",
              "19  1.0        34.0                                 2.0   \n",
              "\n",
              "    Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "0                           0.0                               0.0   \n",
              "1                           0.0                               0.0   \n",
              "2                           0.0                               0.0   \n",
              "3                           0.0                               0.0   \n",
              "4                           0.0                               0.0   \n",
              "5                           1.0                               1.0   \n",
              "6                           0.0                               0.0   \n",
              "7                           0.0                               0.0   \n",
              "8                           0.0                               0.0   \n",
              "9                           1.0                               0.0   \n",
              "10                          1.0                               0.0   \n",
              "11                          0.0                               0.0   \n",
              "12                          0.0                               0.0   \n",
              "13                          1.0                               1.0   \n",
              "14                          1.0                               0.0   \n",
              "15                          0.0                               0.0   \n",
              "16                          0.0                               0.0   \n",
              "17                          0.0                               0.0   \n",
              "18                          0.0                               0.0   \n",
              "19                          1.0                               0.0   \n",
              "\n",
              "    Удовлетворенность семеными отношениями  \\\n",
              "0                                      5.0   \n",
              "1                                      5.0   \n",
              "2                                      5.0   \n",
              "3                                      5.0   \n",
              "4                                      5.0   \n",
              "5                                      5.0   \n",
              "6                                      5.0   \n",
              "7                                      1.0   \n",
              "8                                      4.0   \n",
              "9                                      5.0   \n",
              "10                                     1.0   \n",
              "11                                     5.0   \n",
              "12                                     1.0   \n",
              "13                                     5.0   \n",
              "14                                     5.0   \n",
              "15                                     2.0   \n",
              "16                                     5.0   \n",
              "17                                     4.0   \n",
              "18                                     4.0   \n",
              "19                                     4.0   \n",
              "\n",
              "    Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "0                                         0.0                  7.0   \n",
              "1                                         0.0                 10.0   \n",
              "2                                         1.0                 10.0   \n",
              "3                                         1.0                  7.0   \n",
              "4                                         1.0                  7.0   \n",
              "5                                         1.0                 10.0   \n",
              "6                                         1.0                  5.0   \n",
              "7                                         0.0                  3.0   \n",
              "8                                         1.0                  7.0   \n",
              "9                                         0.0                  7.0   \n",
              "10                                        0.0                  1.0   \n",
              "11                                        1.0                 10.0   \n",
              "12                                        0.0                  7.0   \n",
              "13                                        1.0                 10.0   \n",
              "14                                        1.0                  5.0   \n",
              "15                                        0.0                  5.0   \n",
              "16                                        1.0                  9.0   \n",
              "17                                        1.0                 10.0   \n",
              "18                                        0.0                 10.0   \n",
              "19                                        0.0                 10.0   \n",
              "\n",
              "    Были ли нарушения сна        ИМТ  ...  Стаж шизофр     P     N     G  \\\n",
              "0                     1.0  24.012346  ...         3.70  11.0  11.0  18.0   \n",
              "1                     1.0  20.244898  ...         2.00  10.0  25.0  36.0   \n",
              "2                     0.0  29.752745  ...        23.00   9.0  16.0  23.0   \n",
              "3                     1.0  22.093170  ...        34.00  13.0  13.0  20.0   \n",
              "4                     0.0  20.761246  ...         4.00   9.0  13.0  22.0   \n",
              "5                     1.0  25.737082  ...         1.00   7.0   9.0  21.0   \n",
              "6                     0.0  23.547880  ...        12.20  14.0  20.0  40.0   \n",
              "7                     1.0  26.128611  ...         9.00   7.0   7.0  16.0   \n",
              "8                     0.0  18.812147  ...         5.67  15.0  11.0  28.0   \n",
              "9                     0.0  20.761246  ...        11.00  18.0   7.0  22.0   \n",
              "10                    1.0  23.148148  ...        16.00  19.0  13.0  41.0   \n",
              "11                    1.0  25.661152  ...        16.00  15.0   9.0  26.0   \n",
              "12                    1.0  29.407787  ...        15.00  11.0  19.0  48.0   \n",
              "13                    1.0  26.827421  ...        13.00   9.0   7.0  25.0   \n",
              "14                    1.0  25.390625  ...         8.00  12.0  11.0  23.0   \n",
              "15                    0.0  29.411764  ...        19.00  14.0  11.0  31.0   \n",
              "16                    0.0  22.724403  ...        17.00   8.0   9.0  22.0   \n",
              "17                    0.0  21.877550  ...        11.00   8.0   9.0  24.0   \n",
              "18                    0.0  24.092970  ...        20.00   7.0   7.0  18.0   \n",
              "19                    1.0  22.386314  ...        17.00  13.0  12.0  28.0   \n",
              "\n",
              "    Была попытка суицида?  PSQI  psqi больше 5  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "0                     0.0   6.0            1.0                           0.0   \n",
              "1                     0.0   8.0            1.0                           0.0   \n",
              "2                     0.0   3.0            0.0                           0.0   \n",
              "3                     0.0   6.0            1.0                           0.0   \n",
              "4                     0.0   4.0            0.0                           0.0   \n",
              "5                     0.0   1.0            0.0                           0.0   \n",
              "6                     0.0   8.0            1.0                           1.0   \n",
              "7                     0.0   6.0            1.0                           0.0   \n",
              "8                     0.0   8.0            1.0                           0.0   \n",
              "9                     0.0   7.0            1.0                           0.0   \n",
              "10                    0.0  11.0            1.0                           1.0   \n",
              "11                    0.0   8.0            1.0                           0.0   \n",
              "12                    0.0  10.0            1.0                           1.0   \n",
              "13                    1.0  10.0            1.0                           0.0   \n",
              "14                    1.0   7.0            1.0                           1.0   \n",
              "15                    0.0   5.0            0.0                           0.0   \n",
              "16                    0.0   3.0            0.0                           0.0   \n",
              "17                    0.0   4.0            0.0                           0.0   \n",
              "18                    0.0   2.0            0.0                           0.0   \n",
              "19                    0.0   8.0            1.0                           0.0   \n",
              "\n",
              "    (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "0                         0.0                          0.0  \n",
              "1                         1.0                          1.0  \n",
              "2                         0.0                          0.0  \n",
              "3                         0.0                          0.0  \n",
              "4                         0.0                          0.0  \n",
              "5                         0.0                          0.0  \n",
              "6                         1.0                          0.0  \n",
              "7                         0.0                          0.0  \n",
              "8                         0.0                          0.0  \n",
              "9                         0.0                          0.0  \n",
              "10                        1.0                          1.0  \n",
              "11                        0.0                          0.0  \n",
              "12                        1.0                          1.0  \n",
              "13                        1.0                          0.0  \n",
              "14                        1.0                          1.0  \n",
              "15                        0.0                          0.0  \n",
              "16                        0.0                          0.0  \n",
              "17                        0.0                          0.0  \n",
              "18                        0.0                          0.0  \n",
              "19                        1.0                          1.0  \n",
              "\n",
              "[20 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c09a5e26-fd93-423c-8d72-5b3fcccf3c95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>ИМТ</th>\n",
              "      <th>...</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>Была попытка суицида?</th>\n",
              "      <th>PSQI</th>\n",
              "      <th>psqi больше 5</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.012346</td>\n",
              "      <td>...</td>\n",
              "      <td>3.70</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.244898</td>\n",
              "      <td>...</td>\n",
              "      <td>2.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.752745</td>\n",
              "      <td>...</td>\n",
              "      <td>23.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.093170</td>\n",
              "      <td>...</td>\n",
              "      <td>34.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.761246</td>\n",
              "      <td>...</td>\n",
              "      <td>4.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.737082</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.547880</td>\n",
              "      <td>...</td>\n",
              "      <td>12.20</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.128611</td>\n",
              "      <td>...</td>\n",
              "      <td>9.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.812147</td>\n",
              "      <td>...</td>\n",
              "      <td>5.67</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.761246</td>\n",
              "      <td>...</td>\n",
              "      <td>11.00</td>\n",
              "      <td>18.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.148148</td>\n",
              "      <td>...</td>\n",
              "      <td>16.00</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.661152</td>\n",
              "      <td>...</td>\n",
              "      <td>16.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.407787</td>\n",
              "      <td>...</td>\n",
              "      <td>15.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.827421</td>\n",
              "      <td>...</td>\n",
              "      <td>13.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.390625</td>\n",
              "      <td>...</td>\n",
              "      <td>8.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.411764</td>\n",
              "      <td>...</td>\n",
              "      <td>19.00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.724403</td>\n",
              "      <td>...</td>\n",
              "      <td>17.00</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.877550</td>\n",
              "      <td>...</td>\n",
              "      <td>11.00</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.092970</td>\n",
              "      <td>...</td>\n",
              "      <td>20.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.386314</td>\n",
              "      <td>...</td>\n",
              "      <td>17.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c09a5e26-fd93-423c-8d72-5b3fcccf3c95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c09a5e26-fd93-423c-8d72-5b3fcccf3c95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c09a5e26-fd93-423c-8d72-5b3fcccf3c95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_chi2 # ['Здоровье от 1 до 10', 'Были ли нарушения сна', 'P', 'G', 'Была попытка суицида?']"
      ],
      "metadata": {
        "id": "RKzIBlkeNe7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f20890-fac4-4afc-e762-18fa2cf4b78d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.,  1., 11., 18.,  0.],\n",
              "       [10.,  1., 10., 36.,  0.],\n",
              "       [10.,  0.,  9., 23.,  0.],\n",
              "       [ 7.,  1., 13., 20.,  0.],\n",
              "       [ 7.,  0.,  9., 22.,  0.],\n",
              "       [10.,  1.,  7., 21.,  0.],\n",
              "       [ 5.,  0., 14., 40.,  0.],\n",
              "       [ 3.,  1.,  7., 16.,  0.],\n",
              "       [ 7.,  0., 15., 28.,  0.],\n",
              "       [ 7.,  0., 18., 22.,  0.],\n",
              "       [ 1.,  1., 19., 41.,  0.],\n",
              "       [10.,  1., 15., 26.,  0.],\n",
              "       [ 7.,  1., 11., 48.,  0.],\n",
              "       [10.,  1.,  9., 25.,  1.],\n",
              "       [ 5.,  1., 12., 23.,  1.],\n",
              "       [ 5.,  0., 14., 31.,  0.],\n",
              "       [ 9.,  0.,  8., 22.,  0.],\n",
              "       [10.,  0.,  8., 24.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [10.,  1., 13., 28.,  0.],\n",
              "       [ 9.,  1.,  8., 20.,  0.],\n",
              "       [10.,  0.,  7., 16.,  1.],\n",
              "       [ 4.,  1.,  8., 22.,  0.],\n",
              "       [10.,  0.,  8., 25.,  0.],\n",
              "       [ 5.,  1., 22., 37.,  0.],\n",
              "       [ 7.,  1., 11., 35.,  0.],\n",
              "       [ 7.,  0., 15., 31.,  1.],\n",
              "       [ 7.,  1., 13., 23.,  1.],\n",
              "       [ 9.,  1., 13., 30.,  0.],\n",
              "       [ 9.,  1., 10., 25.,  0.],\n",
              "       [ 9.,  0., 11., 18.,  0.],\n",
              "       [ 5.,  0., 13., 24.,  0.],\n",
              "       [ 2.,  0., 10., 31.,  0.],\n",
              "       [ 9.,  0., 13., 27.,  0.],\n",
              "       [10.,  1., 14., 27.,  1.],\n",
              "       [ 8.,  1.,  8., 28.,  0.],\n",
              "       [ 8.,  1., 12., 23.,  0.],\n",
              "       [ 7.,  1., 10., 29.,  0.],\n",
              "       [ 1.,  0., 22., 43.,  0.],\n",
              "       [ 7.,  1., 18., 33.,  0.],\n",
              "       [ 9.,  1., 17., 25.,  0.],\n",
              "       [ 9.,  0., 20., 30.,  0.],\n",
              "       [ 8.,  1., 17., 19.,  0.],\n",
              "       [10.,  0.,  9., 21.,  0.],\n",
              "       [10.,  1., 22., 36.,  1.],\n",
              "       [10.,  0., 11., 24.,  0.],\n",
              "       [ 9.,  1., 11., 22.,  0.],\n",
              "       [ 9.,  0.,  7., 16.,  1.],\n",
              "       [ 8.,  1., 10., 34.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [ 8.,  0., 20., 35.,  0.],\n",
              "       [10.,  1., 18., 25.,  0.],\n",
              "       [10.,  0.,  7., 22.,  0.],\n",
              "       [10.,  0., 12., 25.,  0.],\n",
              "       [10.,  0.,  7., 22.,  0.],\n",
              "       [10.,  1., 11., 28.,  0.],\n",
              "       [10.,  1.,  7., 18.,  0.],\n",
              "       [10.,  0.,  9., 19.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [ 6.,  0., 10., 21.,  0.],\n",
              "       [ 8.,  0.,  9., 18.,  0.],\n",
              "       [10.,  1.,  7., 18.,  0.],\n",
              "       [ 6.,  1., 17., 34.,  1.],\n",
              "       [ 9.,  1., 15., 20.,  0.],\n",
              "       [10.,  0., 11., 29.,  0.],\n",
              "       [ 6.,  1., 20., 32.,  0.],\n",
              "       [10.,  1., 15., 42.,  0.],\n",
              "       [ 3.,  1., 10., 26.,  0.],\n",
              "       [ 8.,  1., 10., 26.,  1.],\n",
              "       [ 7.,  1., 15., 31.,  0.],\n",
              "       [ 7.,  0.,  7., 23.,  0.],\n",
              "       [ 2.,  1.,  7., 30.,  0.],\n",
              "       [10.,  1.,  7., 24.,  0.],\n",
              "       [ 9.,  1.,  9., 18.,  0.],\n",
              "       [ 9.,  1.,  7., 18.,  0.],\n",
              "       [10.,  0., 16., 29.,  0.],\n",
              "       [ 6.,  0., 18., 32.,  0.],\n",
              "       [ 7.,  0.,  7., 25.,  0.],\n",
              "       [ 3.,  1., 28., 43.,  1.],\n",
              "       [ 8.,  0., 10., 21.,  1.],\n",
              "       [10.,  1.,  9., 27.,  0.],\n",
              "       [ 8.,  1., 14., 26.,  1.],\n",
              "       [10.,  1., 11., 28.,  0.],\n",
              "       [10.,  0.,  7., 24.,  0.],\n",
              "       [10.,  1.,  7., 16.,  1.],\n",
              "       [10.,  1.,  7., 16.,  0.],\n",
              "       [ 8.,  1.,  8., 23.,  0.],\n",
              "       [ 9.,  1.,  7., 24.,  1.],\n",
              "       [10.,  1.,  7., 18.,  0.],\n",
              "       [10.,  1.,  7., 21.,  0.],\n",
              "       [ 5.,  1.,  7., 18.,  0.],\n",
              "       [10.,  0., 17., 34.,  0.],\n",
              "       [ 5.,  0., 21., 28.,  0.],\n",
              "       [10.,  1.,  7., 30.,  1.],\n",
              "       [10.,  1.,  7., 16.,  0.],\n",
              "       [ 3.,  1., 14., 25.,  0.],\n",
              "       [10.,  0.,  7., 16.,  1.],\n",
              "       [ 7.,  0., 14., 20.,  0.],\n",
              "       [10.,  1., 20., 22.,  0.],\n",
              "       [10.,  0., 10., 26.,  0.],\n",
              "       [ 8.,  1.,  9., 17.,  0.],\n",
              "       [ 7.,  1.,  9., 18.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [ 5.,  1., 25., 16.,  1.],\n",
              "       [ 9.,  1., 15., 18.,  0.],\n",
              "       [ 9.,  1., 10., 20.,  0.],\n",
              "       [ 8.,  0., 15., 35.,  1.],\n",
              "       [ 9.,  0., 15., 31.,  0.],\n",
              "       [ 9.,  1., 14., 30.,  0.],\n",
              "       [ 9.,  0.,  7., 16.,  1.],\n",
              "       [10.,  1.,  7., 20.,  1.],\n",
              "       [ 3.,  0., 13., 25.,  0.],\n",
              "       [ 9.,  1.,  7., 20.,  0.],\n",
              "       [ 8.,  1.,  7., 19.,  0.],\n",
              "       [ 5.,  1.,  9., 30.,  0.],\n",
              "       [ 7.,  0.,  9., 25.,  0.],\n",
              "       [10.,  0.,  7., 22.,  0.],\n",
              "       [10.,  1.,  7., 19.,  0.],\n",
              "       [10.,  1.,  9., 29.,  0.],\n",
              "       [ 7.,  1., 15., 30.,  0.],\n",
              "       [ 8.,  0., 10., 19.,  0.],\n",
              "       [ 6.,  1., 16., 33.,  0.],\n",
              "       [ 5.,  1., 14., 38.,  0.],\n",
              "       [ 9.,  1., 10., 29.,  0.],\n",
              "       [ 5.,  1., 20., 44.,  0.],\n",
              "       [ 8.,  1., 25., 49.,  1.],\n",
              "       [ 8.,  0., 11., 24.,  0.],\n",
              "       [ 5.,  1., 10., 33.,  0.],\n",
              "       [ 7.,  1.,  8., 25.,  0.],\n",
              "       [ 7.,  0.,  9., 32.,  0.],\n",
              "       [ 7.,  1., 11., 28.,  0.],\n",
              "       [ 8.,  1.,  9., 31.,  0.],\n",
              "       [ 7.,  0., 25., 44.,  0.],\n",
              "       [ 5.,  1., 16., 39.,  1.],\n",
              "       [10.,  0., 18., 25.,  1.],\n",
              "       [ 6.,  0.,  9., 26.,  0.],\n",
              "       [ 5.,  1., 24., 44.,  0.],\n",
              "       [10.,  1., 14., 35.,  0.],\n",
              "       [ 8.,  1., 10., 38.,  1.],\n",
              "       [ 5.,  1., 15., 34.,  0.],\n",
              "       [ 8.,  1.,  7., 28.,  0.],\n",
              "       [ 7.,  0., 15., 33.,  0.],\n",
              "       [ 5.,  0., 12., 28.,  0.],\n",
              "       [ 8.,  1., 17., 28.,  0.],\n",
              "       [10.,  1.,  9., 24.,  0.],\n",
              "       [ 8.,  1., 17., 25.,  0.],\n",
              "       [ 5.,  0., 24., 42.,  0.],\n",
              "       [ 6.,  1., 11., 35.,  0.],\n",
              "       [ 9.,  0.,  9., 36.,  0.],\n",
              "       [ 1.,  1., 20., 41.,  0.],\n",
              "       [ 8.,  1., 17., 23.,  1.],\n",
              "       [ 7.,  1., 11., 34.,  1.],\n",
              "       [ 1.,  0., 21., 52.,  1.],\n",
              "       [ 8.,  0.,  7., 22.,  0.],\n",
              "       [ 8.,  0.,  9., 21.,  0.],\n",
              "       [ 9.,  1., 20., 46.,  0.],\n",
              "       [ 7.,  1., 11., 29.,  0.],\n",
              "       [ 5.,  1., 18., 41.,  1.],\n",
              "       [ 3.,  0., 26., 38.,  0.],\n",
              "       [ 4.,  1., 21., 49.,  0.],\n",
              "       [10.,  1.,  7., 22.,  0.],\n",
              "       [ 6.,  1.,  8., 17.,  0.],\n",
              "       [10.,  1.,  9., 16.,  0.],\n",
              "       [ 9.,  1., 18., 16.,  1.],\n",
              "       [10.,  0.,  7., 16.,  0.],\n",
              "       [10.,  1., 18., 21.,  1.],\n",
              "       [ 6.,  0., 32., 56.,  0.],\n",
              "       [ 9.,  0., 25., 32.,  0.],\n",
              "       [10.,  1.,  7., 16.,  0.],\n",
              "       [ 7.,  1., 19., 31.,  0.],\n",
              "       [ 9.,  1., 10., 23.,  0.],\n",
              "       [10.,  1.,  7., 27.,  0.],\n",
              "       [ 9.,  1., 14., 21.,  0.],\n",
              "       [10.,  1.,  7., 28.,  0.],\n",
              "       [ 6.,  1., 12., 31.,  0.],\n",
              "       [10.,  1., 19., 47.,  0.],\n",
              "       [ 4.,  1., 10., 27.,  1.],\n",
              "       [ 8.,  1., 11., 31.,  0.],\n",
              "       [ 3.,  0., 13., 33.,  0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA"
      ],
      "metadata": {
        "id": "wVd6jE3hZslG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "univariate = f_classif(X, y)\n",
        "univariate"
      ],
      "metadata": {
        "id": "EUMyT5pBZnG7",
        "outputId": "7d15d4b0-b908-4764-a436-5ad7b24df60d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.7057238e+00, 1.3677023e-02, 1.3590264e-01, 4.3057406e-01,\n",
              "        4.0778628e-01, 3.3776904e-04, 1.8478861e+00, 4.2277527e+00,\n",
              "        1.4127000e+01, 3.7693277e-02, 2.7013304e+00, 5.0126255e-01,\n",
              "        8.2112098e-01, 1.3415864e-01, 1.6337517e-01, 1.4161005e-02,\n",
              "        6.7678490e+00, 7.1855211e-01, 5.8342133e+00, 6.4264417e+00],\n",
              "       dtype=float32),\n",
              " array([1.0175351e-01, 9.0703249e-01, 7.1282691e-01, 5.1255471e-01,\n",
              "        5.2391601e-01, 9.8535746e-01, 1.7574911e-01, 4.1227754e-02,\n",
              "        2.3148650e-04, 8.4628171e-01, 1.0202970e-01, 4.7987193e-01,\n",
              "        3.6607760e-01, 7.1459359e-01, 6.8655312e-01, 9.0540951e-01,\n",
              "        1.0062584e-02, 3.9775762e-01, 1.6729033e-02, 1.2104519e-02],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 2nd values are the PValue and we capture those below\n",
        "univariate = pd.Series(univariate[1])\n",
        "univariate.index = X.columns\n",
        "univariate.sort_values(ascending=False).plot.bar(figsize=(20,6))"
      ],
      "metadata": {
        "id": "b9wq1WrOZzPA",
        "outputId": "6f1458d8-78be-442a-8cd7-606247142651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52f0d0110>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TOP 3 features\n",
        "sel_ = SelectKBest(f_classif, k=3).fit(X, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "id": "mIEtgv73S-y9",
        "outputId": "813ad5f0-7bd2-48cb-85c7-6c59691840ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Были ли нарушения сна', 'P', 'Была попытка суицида?'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TOP 5 features\n",
        "sel_ = SelectKBest(f_classif, k=5).fit(X, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "id": "BIbA_QH2aNMQ",
        "outputId": "11f2a3d4-5006-48b4-9529-7e306eb0dd7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Здоровье от 1 до 10', 'Были ли нарушения сна', 'P', 'G',\n",
              "       'Была попытка суицида?'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I90-1SNSaPPg"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lmy3RTQzZzxL"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_anova "
      ],
      "metadata": {
        "id": "RDWO9sN0O0xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25db42b-fce0-4ded-9bbd-3249f1bea0d6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.,  1., 11., 18.,  0.],\n",
              "       [10.,  1., 10., 36.,  0.],\n",
              "       [10.,  0.,  9., 23.,  0.],\n",
              "       [ 7.,  1., 13., 20.,  0.],\n",
              "       [ 7.,  0.,  9., 22.,  0.],\n",
              "       [10.,  1.,  7., 21.,  0.],\n",
              "       [ 5.,  0., 14., 40.,  0.],\n",
              "       [ 3.,  1.,  7., 16.,  0.],\n",
              "       [ 7.,  0., 15., 28.,  0.],\n",
              "       [ 7.,  0., 18., 22.,  0.],\n",
              "       [ 1.,  1., 19., 41.,  0.],\n",
              "       [10.,  1., 15., 26.,  0.],\n",
              "       [ 7.,  1., 11., 48.,  0.],\n",
              "       [10.,  1.,  9., 25.,  1.],\n",
              "       [ 5.,  1., 12., 23.,  1.],\n",
              "       [ 5.,  0., 14., 31.,  0.],\n",
              "       [ 9.,  0.,  8., 22.,  0.],\n",
              "       [10.,  0.,  8., 24.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [10.,  1., 13., 28.,  0.],\n",
              "       [ 9.,  1.,  8., 20.,  0.],\n",
              "       [10.,  0.,  7., 16.,  1.],\n",
              "       [ 4.,  1.,  8., 22.,  0.],\n",
              "       [10.,  0.,  8., 25.,  0.],\n",
              "       [ 5.,  1., 22., 37.,  0.],\n",
              "       [ 7.,  1., 11., 35.,  0.],\n",
              "       [ 7.,  0., 15., 31.,  1.],\n",
              "       [ 7.,  1., 13., 23.,  1.],\n",
              "       [ 9.,  1., 13., 30.,  0.],\n",
              "       [ 9.,  1., 10., 25.,  0.],\n",
              "       [ 9.,  0., 11., 18.,  0.],\n",
              "       [ 5.,  0., 13., 24.,  0.],\n",
              "       [ 2.,  0., 10., 31.,  0.],\n",
              "       [ 9.,  0., 13., 27.,  0.],\n",
              "       [10.,  1., 14., 27.,  1.],\n",
              "       [ 8.,  1.,  8., 28.,  0.],\n",
              "       [ 8.,  1., 12., 23.,  0.],\n",
              "       [ 7.,  1., 10., 29.,  0.],\n",
              "       [ 1.,  0., 22., 43.,  0.],\n",
              "       [ 7.,  1., 18., 33.,  0.],\n",
              "       [ 9.,  1., 17., 25.,  0.],\n",
              "       [ 9.,  0., 20., 30.,  0.],\n",
              "       [ 8.,  1., 17., 19.,  0.],\n",
              "       [10.,  0.,  9., 21.,  0.],\n",
              "       [10.,  1., 22., 36.,  1.],\n",
              "       [10.,  0., 11., 24.,  0.],\n",
              "       [ 9.,  1., 11., 22.,  0.],\n",
              "       [ 9.,  0.,  7., 16.,  1.],\n",
              "       [ 8.,  1., 10., 34.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [ 8.,  0., 20., 35.,  0.],\n",
              "       [10.,  1., 18., 25.,  0.],\n",
              "       [10.,  0.,  7., 22.,  0.],\n",
              "       [10.,  0., 12., 25.,  0.],\n",
              "       [10.,  0.,  7., 22.,  0.],\n",
              "       [10.,  1., 11., 28.,  0.],\n",
              "       [10.,  1.,  7., 18.,  0.],\n",
              "       [10.,  0.,  9., 19.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [ 6.,  0., 10., 21.,  0.],\n",
              "       [ 8.,  0.,  9., 18.,  0.],\n",
              "       [10.,  1.,  7., 18.,  0.],\n",
              "       [ 6.,  1., 17., 34.,  1.],\n",
              "       [ 9.,  1., 15., 20.,  0.],\n",
              "       [10.,  0., 11., 29.,  0.],\n",
              "       [ 6.,  1., 20., 32.,  0.],\n",
              "       [10.,  1., 15., 42.,  0.],\n",
              "       [ 3.,  1., 10., 26.,  0.],\n",
              "       [ 8.,  1., 10., 26.,  1.],\n",
              "       [ 7.,  1., 15., 31.,  0.],\n",
              "       [ 7.,  0.,  7., 23.,  0.],\n",
              "       [ 2.,  1.,  7., 30.,  0.],\n",
              "       [10.,  1.,  7., 24.,  0.],\n",
              "       [ 9.,  1.,  9., 18.,  0.],\n",
              "       [ 9.,  1.,  7., 18.,  0.],\n",
              "       [10.,  0., 16., 29.,  0.],\n",
              "       [ 6.,  0., 18., 32.,  0.],\n",
              "       [ 7.,  0.,  7., 25.,  0.],\n",
              "       [ 3.,  1., 28., 43.,  1.],\n",
              "       [ 8.,  0., 10., 21.,  1.],\n",
              "       [10.,  1.,  9., 27.,  0.],\n",
              "       [ 8.,  1., 14., 26.,  1.],\n",
              "       [10.,  1., 11., 28.,  0.],\n",
              "       [10.,  0.,  7., 24.,  0.],\n",
              "       [10.,  1.,  7., 16.,  1.],\n",
              "       [10.,  1.,  7., 16.,  0.],\n",
              "       [ 8.,  1.,  8., 23.,  0.],\n",
              "       [ 9.,  1.,  7., 24.,  1.],\n",
              "       [10.,  1.,  7., 18.,  0.],\n",
              "       [10.,  1.,  7., 21.,  0.],\n",
              "       [ 5.,  1.,  7., 18.,  0.],\n",
              "       [10.,  0., 17., 34.,  0.],\n",
              "       [ 5.,  0., 21., 28.,  0.],\n",
              "       [10.,  1.,  7., 30.,  1.],\n",
              "       [10.,  1.,  7., 16.,  0.],\n",
              "       [ 3.,  1., 14., 25.,  0.],\n",
              "       [10.,  0.,  7., 16.,  1.],\n",
              "       [ 7.,  0., 14., 20.,  0.],\n",
              "       [10.,  1., 20., 22.,  0.],\n",
              "       [10.,  0., 10., 26.,  0.],\n",
              "       [ 8.,  1.,  9., 17.,  0.],\n",
              "       [ 7.,  1.,  9., 18.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [10.,  0.,  7., 18.,  0.],\n",
              "       [ 5.,  1., 25., 16.,  1.],\n",
              "       [ 9.,  1., 15., 18.,  0.],\n",
              "       [ 9.,  1., 10., 20.,  0.],\n",
              "       [ 8.,  0., 15., 35.,  1.],\n",
              "       [ 9.,  0., 15., 31.,  0.],\n",
              "       [ 9.,  1., 14., 30.,  0.],\n",
              "       [ 9.,  0.,  7., 16.,  1.],\n",
              "       [10.,  1.,  7., 20.,  1.],\n",
              "       [ 3.,  0., 13., 25.,  0.],\n",
              "       [ 9.,  1.,  7., 20.,  0.],\n",
              "       [ 8.,  1.,  7., 19.,  0.],\n",
              "       [ 5.,  1.,  9., 30.,  0.],\n",
              "       [ 7.,  0.,  9., 25.,  0.],\n",
              "       [10.,  0.,  7., 22.,  0.],\n",
              "       [10.,  1.,  7., 19.,  0.],\n",
              "       [10.,  1.,  9., 29.,  0.],\n",
              "       [ 7.,  1., 15., 30.,  0.],\n",
              "       [ 8.,  0., 10., 19.,  0.],\n",
              "       [ 6.,  1., 16., 33.,  0.],\n",
              "       [ 5.,  1., 14., 38.,  0.],\n",
              "       [ 9.,  1., 10., 29.,  0.],\n",
              "       [ 5.,  1., 20., 44.,  0.],\n",
              "       [ 8.,  1., 25., 49.,  1.],\n",
              "       [ 8.,  0., 11., 24.,  0.],\n",
              "       [ 5.,  1., 10., 33.,  0.],\n",
              "       [ 7.,  1.,  8., 25.,  0.],\n",
              "       [ 7.,  0.,  9., 32.,  0.],\n",
              "       [ 7.,  1., 11., 28.,  0.],\n",
              "       [ 8.,  1.,  9., 31.,  0.],\n",
              "       [ 7.,  0., 25., 44.,  0.],\n",
              "       [ 5.,  1., 16., 39.,  1.],\n",
              "       [10.,  0., 18., 25.,  1.],\n",
              "       [ 6.,  0.,  9., 26.,  0.],\n",
              "       [ 5.,  1., 24., 44.,  0.],\n",
              "       [10.,  1., 14., 35.,  0.],\n",
              "       [ 8.,  1., 10., 38.,  1.],\n",
              "       [ 5.,  1., 15., 34.,  0.],\n",
              "       [ 8.,  1.,  7., 28.,  0.],\n",
              "       [ 7.,  0., 15., 33.,  0.],\n",
              "       [ 5.,  0., 12., 28.,  0.],\n",
              "       [ 8.,  1., 17., 28.,  0.],\n",
              "       [10.,  1.,  9., 24.,  0.],\n",
              "       [ 8.,  1., 17., 25.,  0.],\n",
              "       [ 5.,  0., 24., 42.,  0.],\n",
              "       [ 6.,  1., 11., 35.,  0.],\n",
              "       [ 9.,  0.,  9., 36.,  0.],\n",
              "       [ 1.,  1., 20., 41.,  0.],\n",
              "       [ 8.,  1., 17., 23.,  1.],\n",
              "       [ 7.,  1., 11., 34.,  1.],\n",
              "       [ 1.,  0., 21., 52.,  1.],\n",
              "       [ 8.,  0.,  7., 22.,  0.],\n",
              "       [ 8.,  0.,  9., 21.,  0.],\n",
              "       [ 9.,  1., 20., 46.,  0.],\n",
              "       [ 7.,  1., 11., 29.,  0.],\n",
              "       [ 5.,  1., 18., 41.,  1.],\n",
              "       [ 3.,  0., 26., 38.,  0.],\n",
              "       [ 4.,  1., 21., 49.,  0.],\n",
              "       [10.,  1.,  7., 22.,  0.],\n",
              "       [ 6.,  1.,  8., 17.,  0.],\n",
              "       [10.,  1.,  9., 16.,  0.],\n",
              "       [ 9.,  1., 18., 16.,  1.],\n",
              "       [10.,  0.,  7., 16.,  0.],\n",
              "       [10.,  1., 18., 21.,  1.],\n",
              "       [ 6.,  0., 32., 56.,  0.],\n",
              "       [ 9.,  0., 25., 32.,  0.],\n",
              "       [10.,  1.,  7., 16.,  0.],\n",
              "       [ 7.,  1., 19., 31.,  0.],\n",
              "       [ 9.,  1., 10., 23.,  0.],\n",
              "       [10.,  1.,  7., 27.,  0.],\n",
              "       [ 9.,  1., 14., 21.,  0.],\n",
              "       [10.,  1.,  7., 28.,  0.],\n",
              "       [ 6.,  1., 12., 31.,  0.],\n",
              "       [10.,  1., 19., 47.,  0.],\n",
              "       [ 4.,  1., 10., 27.,  1.],\n",
              "       [ 8.,  1., 11., 31.,  0.],\n",
              "       [ 3.,  0., 13., 33.,  0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F21u74y3UP6q"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find 4 best predictors witn scalied data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = minmax_scaler.fit_transform(X)\n",
        "X_chi2_scaled = SelectKBest(chi2, k=4).fit_transform(X_scaled, y)\n",
        "X_anova_scaled = SelectKBest(f_classif, k=4).fit_transform(X_scaled, y)"
      ],
      "metadata": {
        "id": "023I6vdtNf5b"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUHcI8Zz8msw"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w4TOf6Gl8nDv"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hknAxieW8nHC"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_score_scaled = chi2(X_scaled, y)\n",
        "f_score_scaled\n",
        "# The first array is the F_score , 2nd one is the P_values\n",
        "# the smaller the P value the more significant the difference in the features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14mLv1Rcgpcb",
        "outputId": "9ebd2437-bf61-48c3-9745-d965b97a04c7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([6.58823529e-01, 1.74948487e-03, 2.31586224e-02, 3.57142857e-01,\n",
              "        3.65714286e-01, 5.69151964e-05, 7.50066756e-01, 3.69089345e-01,\n",
              "        5.00000000e+00, 3.00568182e-03, 1.42016807e+00, 1.80326531e-01,\n",
              "        4.40816327e-01, 7.36602681e-03, 7.38916256e-02, 2.41444284e-03,\n",
              "        1.36804244e+00, 1.11968375e-01, 9.04727204e-01, 5.15714286e+00]),\n",
              " array([0.41697559, 0.96663674, 0.8790453 , 0.55009732, 0.54534967,\n",
              "        0.99398064, 0.3864551 , 0.54350107, 0.02534732, 0.9562786 ,\n",
              "        0.23337574, 0.67109278, 0.50672871, 0.93160509, 0.78575263,\n",
              "        0.96081013, 0.24214851, 0.7379142 , 0.34151733, 0.02315095]))"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pvalues = pd.Series(f_score_scaled[1])\n",
        "pvalues.index = X.columns\n",
        "pvalues.sort_values(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvYgWRBqgtKI",
        "outputId": "c0882a8d-10f6-4b82-c78d-90008d80bcd4"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Была попытка суицида?                        0.023151\n",
              "Были ли нарушения сна                        0.025347\n",
              "Операции                                     0.233376\n",
              "P                                            0.242149\n",
              "G                                            0.341517\n",
              "Удовлетворенность материальным положением    0.386455\n",
              "Пол                                          0.416976\n",
              "Насл отягощенность                           0.506729\n",
              "Здоровье от 1 до 10                          0.543501\n",
              "Семейное положение(0-0, 1-женат)             0.545350\n",
              "Род занятий(0-0, работает-1                  0.550097\n",
              "ЧМТ                                          0.671093\n",
              "N                                            0.737914\n",
              "Частота госпит                               0.785753\n",
              "Образование(0-начальное, 4-высшее)           0.879045\n",
              "Дебют                                        0.931605\n",
              "ИМТ                                          0.956279\n",
              "Стаж шизофр                                  0.960810\n",
              "Полных лет                                   0.966637\n",
              "Удовлетворенность семеными отношениями       0.993981\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now use the SelectKBest Model with the chi2 classifier to find the best features\n",
        "\n",
        "sel_ = SelectKBest(chi2, k=5).fit(X_scaled, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm1xMp0jgz-e",
        "outputId": "c280d5f4-6b0b-4505-aab1-35b6f6e2f582"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Были ли нарушения сна', 'Операции', 'P', 'G', 'Была попытка суицида?'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOW1fDJzhImX"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA"
      ],
      "metadata": {
        "id": "YBuG7ukDhFuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "univariate_scaled = f_classif(X_scaled, y)\n",
        "univariate_scaled"
      ],
      "metadata": {
        "id": "OwBx45LZhG-8",
        "outputId": "2db976bc-112a-41cb-9d83-6c56fcb2fa7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.7057238e+00, 1.3638137e-02, 1.3597526e-01, 4.3057406e-01,\n",
              "        4.0778628e-01, 2.8147412e-04, 1.8478861e+00, 4.2278109e+00,\n",
              "        1.4127000e+01, 3.7138164e-02, 2.7013304e+00, 5.0126255e-01,\n",
              "        8.2112098e-01, 1.3372521e-01, 1.6337517e-01, 1.4198870e-02,\n",
              "        6.7677937e+00, 7.1852952e-01, 5.8341742e+00, 6.4264417e+00],\n",
              "       dtype=float32),\n",
              " array([1.0175351e-01, 9.0716410e-01, 7.1275359e-01, 5.1255471e-01,\n",
              "        5.2391601e-01, 9.8663318e-01, 1.7574911e-01, 4.1226376e-02,\n",
              "        2.3148650e-04, 8.4740371e-01, 1.0202970e-01, 4.7987193e-01,\n",
              "        3.6607760e-01, 7.1503466e-01, 6.8655312e-01, 9.0528375e-01,\n",
              "        1.0062884e-02, 3.9776501e-01, 1.6729392e-02, 1.2104519e-02],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 2nd values are the PValue and we capture those below\n",
        "univariate_scaled = pd.Series(univariate_scaled[1])\n",
        "univariate_scaled.index = X.columns\n",
        "univariate_scaled.sort_values(ascending=False).plot.bar(figsize=(20,6))"
      ],
      "metadata": {
        "id": "djLNEHfThKKz",
        "outputId": "ebcfec16-1208-4120-d5dd-65f6e39f5568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc52f06df10>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAJaCAYAAAC4H1cXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZgtZ1kv7N9DYphBIAGEJCSMHuYhMggqAioQBCeGyCQggU+ZRA9GUcRwDobRgcM5GJkHGY9yAkFBMAwiIAEZg2jEIAExzCBjAs/3R61OOp3ee3eyV3f1qrrv68qVrlq1ez11dfdatX71vs9b3R0AAAAApu1iYxcAAAAAwPYTAgEAAADMgBAIAAAAYAaEQAAAAAAzIAQCAAAAmIEDx3rigw8+uI844oixnh4AAABgct73vvd9vrsP2eyx0UKgI444IqeeeupYTw8AAAAwOVX1yT09ZjoYAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAM7DPEKiqnl9VZ1XVR/bweFXVn1TV6VX1oaq6+fLLBAAAAGB/bGUk0AuT3Hkvj98lyXUW/x2b5P/sf1kAAAAALNM+Q6DufnuSL+7lkHskeXEP3p3k+6vqB5ZVIAAAAAD7bxk9ga6e5FPrts9c7LuAqjq2qk6tqlM/97nPLeGpAQAAANiKHW0M3d0ndvdR3X3UIYccspNPDQAAADBrywiBPp3ksHXbhy72AQAAALBLLCMEOinJAxarhN06yVe6+z+W8H0BAAAAWJID93VAVb08ye2THFxVZyb5vSTflyTd/Zwkb0hy1ySnJ/lGkgdtV7FJcsRxJ2/nt7+AM044ekefDwAAAGA77DME6u5j9vF4J/nVpVUEAAAAwNLtaGNoAAAAAMYhBAIAAACYASEQAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwA0IgAAAAgBkQAgEAAADMgBAIAAAAYAaEQAAAAAAzIAQCAAAAmAEhEAAAAMAMCIEAAAAAZkAIBAAAADADQiAAAACAGRACAQAAAMzAgWMXwPkdcdzJO/p8Z5xw9I4+HwAAADAOIRA7SsgFAAAA4zAdDAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwA0IgAAAAgBkQAgEAAADMgBAIAAAAYAaEQAAAAAAzIAQCAAAAmAEhEAAAAMAMCIEAAAAAZkAIBAAAADADQiAAAACAGRACAQAAAMyAEAgAAABgBg4cuwCYiiOOO3lHn++ME47e0ecDAABgtRkJBAAAADADQiAAAACAGRACAQAAAMyAEAgAAABgBoRAAAAAADMgBAIAAACYASEQAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZ2FIIVFV3rqqPV9XpVXXcJo8fXlWnVNU/VtWHququyy8VAAAAgItqnyFQVR2Q5NlJ7pLk+kmOqarrbzjsd5K8qrtvluQ+Sf73sgsFAAAA4KLbykigWyY5vbs/0d3fSfKKJPfYcEwnudzi68sn+czySgQAAABgfx24hWOunuRT67bPTHKrDcc8McmbquqRSS6d5E5LqQ4AAACApVhWY+hjkrywuw9NctckL6mqC3zvqjq2qk6tqlM/97nPLempAQAAANiXrYRAn05y2LrtQxf71ntIklclSXe/K8klkhy88Rt194ndfVR3H3XIIYdctIoBAAAAuNC2EgK9N8l1qurIqjooQ+PnkzYc8+9J7pgkVfXfMoRAhvoAAAAA7BL7DIG6+5wkj0jyxiQfy7AK2Eer6viquvvisF9P8tCq+mCSlyf5pe7u7SoaAAAAgAtnK42h091vSPKGDfuesO7r05LcdrmlAQAAALAsy2oMDQAAAMAuJgQCAAAAmAEhEAAAAMAMCIEAAAAAZkAIBAAAADADQiAAAACAGRACAQAAAMyAEAgAAABgBoRAAAAAADMgBAIAAACYASEQAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwAweOXQCwGo447uQdfb4zTjh6R58PAABg6oRAABFyAQAA02c6GAAAAMAMCIEAAAAAZkAIBAAAADADQiAAAACAGRACAQAAAMyAEAgAAABgBoRAAAAAADNw4NgFALD9jjju5B19vjNOOHpHnw8AANg3I4EAAAAAZkAIBAAAADADQiAAAACAGRACAQAAAMyAEAgAAABgBoRAAAAAADMgBAIAAACYASEQAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwA0IgAAAAgBkQAgEAAADMgBAIAAAAYAaEQAAAAAAzIAQCAAAAmIEthUBVdeeq+nhVnV5Vx+3hmHtV1WlV9dGq+vPllgkAAADA/jhwXwdU1QFJnp3kJ5KcmeS9VXVSd5+27pjrJPmtJLft7i9V1ZW3q2AAAAAALrytjAS6ZZLTu/sT3f2dJK9Ico8Nxzw0ybO7+0tJ0t1nLbdMAAAAAPbHVkKgqyf51LrtMxf71rtukutW1Tur6t1VdedlFQgAAADA/tvndLAL8X2uk+T2SQ5N8vaqulF3f3n9QVV1bJJjk+Twww9f0lMDAAAAsC9bGQn06SSHrds+dLFvvTOTnNTdZ3f3vyX55wyh0Pl094ndfVR3H3XIIYdc1JoBAAAAuJC2EgK9N8l1qurIqjooyX2SnLThmNdmGAWUqjo4w/SwTyyxTgAAAAD2wz5DoO4+J8kjkrwxyceSvKq7P1pVx1fV3ReHvTHJF6rqtCSnJPnv3f2F7SoaAAAAgAtnSz2BuvsNSd6wYd8T1n3dSR67+A8AAACAXWYr08EAAAAAWHFCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwA0IgAAAAgBkQAgEAAADMgBAIAAAAYAaEQAAAAAAzIAQCAAAAmAEhEAAAAMAMCIEAAAAAZkAIBAAAADADQiAAAACAGRACAQAAAMzAgWMXAAD764jjTt7R5zvjhKN39PkAAGAZjAQCAAAAmAEhEAAAAMAMmA4GALuYqW4AACyLkUAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwA0IgAAAAgBkQAgEAAADMgBAIAAAAYAaEQAAAAAAzcODYBQAA83XEcSfv6POdccLRO/p8AAC7iZFAAAAAADMgBAIAAACYASEQAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwA0IgAAAAgBkQAgEAAADMgBAIAAAAYAaEQAAAAAAzIAQCAAAAmAEhEAAAAMAMCIEAAAAAZkAIBAAAADADWwqBqurOVfXxqjq9qo7by3E/X1VdVUctr0QAAAAA9tc+Q6CqOiDJs5PcJcn1kxxTVdff5LjLJnl0kvcsu0gAAAAA9s9WRgLdMsnp3f2J7v5Oklckuccmxz0pyVOSfGuJ9QEAAACwBFsJga6e5FPrts9c7DtXVd08yWHdffISawMAAABgSQ7c329QVRdL8swkv7SFY49NcmySHH744fv71AAAu9oRx+3s/bEzTjh6R58PAFgtWxkJ9Okkh63bPnSxb81lk9wwyVur6owkt05y0mbNobv7xO4+qruPOuSQQy561QAAAABcKFsJgd6b5DpVdWRVHZTkPklOWnuwu7/S3Qd39xHdfUSSdye5e3efui0VAwAAAHCh7TME6u5zkjwiyRuTfCzJq7r7o1V1fFXdfbsLBAAAAGD/baknUHe/IckbNux7wh6Ovf3+lwUAAADAMm1lOhgAAAAAK04IBAAAADADQiAAAACAGRACAQAAAMyAEAgAAABgBra0OhgAAGx0xHEn7+jznXHC0Tv6fAAwNUYCAQAAAMyAEAgAAABgBoRAAAAAADMgBAIAAACYASEQAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwA0IgAAAAgBkQAgEAAADMgBAIAAAAYAaEQAAAAAAzIAQCAAAAmAEhEAAAAMAMCIEAAAAAZkAIBAAAADADQiAAAACAGRACAQAAAMyAEAgAAABgBoRAAAAAADMgBAIAAACYASEQAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwA0IgAAAAgBkQAgEAAADMgBAIAAAAYAaEQAAAAAAzIAQCAAAAmAEhEAAAAMAMCIEAAAAAZkAIBAAAADADQiAAAACAGdhSCFRVd66qj1fV6VV13CaPP7aqTquqD1XVW6rqGssvFQAAAICLap8hUFUdkOTZSe6S5PpJjqmq62847B+THNXdN07ymiRPXXahAAAAAFx0WxkJdMskp3f3J7r7O0lekeQe6w/o7lO6+xuLzXcnOXS5ZQIAAACwP7YSAl09yafWbZ+52LcnD0nyV/tTFAAAAADLdeAyv1lV3S/JUUl+bA+PH5vk2CQ5/PDDl/nUAAAAAOzFVkYCfTrJYeu2D13sO5+qulOSxye5e3d/e7Nv1N0ndvdR3X3UIYccclHqBQAAAOAi2EoI9N4k16mqI6vqoCT3SXLS+gOq6mZJ/jRDAHTW8ssEAAAAYH/sMwTq7nOSPCLJG5N8LMmruvujVXV8Vd19cdjTklwmyaur6gNVddIevh0AAAAAI9hST6DufkOSN2zY94R1X99pyXUBAAAAsERbmQ4GAAAAwIoTAgEAAADMwFKXiAcAgKk44riTd/T5zjjh6B19PgDmx0ggAAAAgBkQAgEAAADMgBAIAAAAYAaEQAAAAAAzIAQCAAAAmAEhEAAAAMAMCIEAAAAAZkAIBAAAADADQiAAAACAGRACAQAAAMyAEAgAAABgBoRAAAAAADMgBAIAAACYASEQAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADBw4dgEAAMDOOuK4k3f0+c444egdfT4ANicEAgAAJkXIBbA508EAAAAAZkAIBAAAADADQiAAAACAGRACAQAAAMyAEAgAAABgBoRAAAAAADMgBAIAAACYASEQAAAAwAwIgQAAAABmQAgEAAAAMANCIAAAAIAZEAIBAAAAzIAQCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwAweOXQAAAABbd8RxJ+/o851xwtE7+nzA9jESCAAAAGAGhEAAAAAAMyAEAgAAAJgBIRAAAADADAiBAAAAAGZACAQAAAAwA5aIBwAAYNc44riTd/T5zjjh6B19PhiTkUAAAAAAM7ClkUBVdeckf5zkgCTP7e4TNjx+8SQvTnKLJF9Icu/uPmO5pQIAAMBqm/JIpymf21TscyRQVR2Q5NlJ7pLk+kmOqarrbzjsIUm+1N3XTvKHSZ6y7EIBAAAAuOi2Mh3slklO7+5PdPd3krwiyT02HHOPJC9afP2aJHesqlpemQAAAADsj61MB7t6kk+t2z4zya32dEx3n1NVX0lypSSfX0aRAAAAAGOawnS36u69H1D1C0nu3N2/vNi+f5Jbdfcj1h3zkcUxZy62/3VxzOc3fK9jkxy72Lxeko8v60S24OBMO5RyfqtryueWOL9V5/xW15TPLXF+q875ra4pn1vi/Fad81tdUz63ZOfP7xrdfchmD2xlJNCnkxy2bvvQxb7Njjmzqg5McvkMDaLPp7tPTHLiVipetqo6tbuPGuO5d4LzW11TPrfE+a0657e6pnxuifNbdc5vdU353BLnt+qc3+qa8rklu+v8ttIT6L1JrlNVR1bVQUnuk+SkDceclOSBi69/Icnf9r6GGAEAAACwY/Y5EmjR4+cRSd6YYYn453f3R6vq+CSndvdJSZ6X5CVVdXqSL2YIigAAAADYJbYyHSzd/YYkb9iw7wnrvv5Wknsut7SlG2Ua2g5yfqtryueWOL9V5/xW15TPLXF+q875ra4pn1vi/Fad81tdUz63ZBed3z4bQwMAAACw+rbSEwgAAACAFScEAgAAAJgBIdCKqqq7jV3Ddquqg6rqxlV1o8XKdCuvqg4fuwbYm6p6/dg1AADMXVVdraoOHrsO9k9VXbmqDl/7b+x6kgn3BKqqn9tsf3f/xU7Xsh2q6v3dffOx69guVXV0kuck+dckleTIJA/r7r8atbD9NPWf25qqunl3v3/sOpatqm6T5H5JfiTJDyT5ZpKPJDk5yUu7+ysjlrcUU/4dncPPb6OqOrG7jx27jv1VVY/o7v81dh3sv8X7+59mWHH2N7r7ZSOXtBRV9YDN9nf3i3e6Fi68qrriZvu7+4s7XcuyVNXlk/xWkp9JcuUkneSsJP8vyQnd/eURy9tvVXWPJId297MX2+9Jcsji4cd192tGK24JquoJSX4pw2vly7v7uHErWq6qukSShye5dpIPJ3led58zblXLVVV3T/KMJFfL8Ld3jSQf6+4bjFpYph0CnZ3ktCTvyxAiJEl394PHq2p5quqfkhyT884tSTKVD96L87tbd5++2L5WkpO7+wfHrWz/VNU/dvfNxq5ju00xSKiqv0rymQwXT6dmeDG/RJLrJvnxJD+d5JndfdJoRS5BVX05yds37u/uu49QztJM+ee3pw8vGd4fPtjdh+5kPdthiq8p6y0u9veku/tJO1bMNlt8ULtvki8l+Zup/Fyr6ntJ3p3h9WX9deejxqtqeapq09fGVX9vWFNV307y6Zz/urq7+5ojlbTfquqNSf42yYu6+7OLfVdN8sAkd+zunxyzvv1VVe9Mcp/u/tRi+wNJ7pjk0kle0N13HLO+/bX4LHSjDCHQnya5apI3JTkpya26+6UjlrffquqVSc5O8o4kd0nyye5+9LhVLVdVfTDJHZK8ubtvVlU/nuR+3f2QkUvb2hLxK+qGSZ6U5DJJfre7Pz5yPct29QzJ4vnerDL8ok3B19YCoIVPJPnaWMUs0dWr6k/29OBULhaTHFhVV8gFQ8qVvaOW5P7d/fkN+/4ryfsX/z1jIkN2P5fhtWVqpvzz+1yST+aC7weV4e4vu9/XN9l3qSS/nORKGa5npuL71t3g+a+xi1miGyR5UJKbJnlDhtGFG19zVtkVklw2yZOT/OfItWyH0yZ4k+6I7n7K+h2LMOgpVTWFm+IHrQVAC3/X3V9I8oWquvRYRS3RORmCyG8leWBV/XSSGyc5KEPQtequ3903SpKqel6Sfxi5nu1wdnd/oaouVlUX6+5TquqPxi4qmXAItAh97lVVt0jyzKr6TJIndvenRy5tWU7v7qkEPps5tarekORVGT7M3DPJe9em+a3wtL5vZhidNnXXy/lH4SXDz3Fl76itv5ivqmskuU53v7mqLpnkwO7+2kQu+P+ru982dhHLtvazqaondvcT93bMCvpEhru6/77xgar61CbHr6IbV9VXN9lfGS6SL7fTBS1Td58bvFbVZZM8OsmDk7wiEwllq+pZGd4HDl3cDKms8HvCRt39sSSPq6qLJ3lWklMy3MWfhO7+kcVUvt/OcG5P7e7N/iZX1eUX04u+nWHU6GkTmJryyap6XIaRQP+ZJFV1lQxTjKbw3nCF9Rvd/Yh1m4dk9T0ryY9mGM2V7n5dktctHvvoWEUt0dlrX3T3OVW1t2NX1Zer6jIZRti/rKrOyuY3fXbclKeDrV1sJMOFxo8luXZ3X2q8qpanqv52yiFQVb1gLw+v7LS+qU9pWDPlaW9V9dAkxya5Yndfq6quk+Q5qz7seE1V3au7XzV2Hdtlin+DVfWrGe6AfnCTxx7Z3c8aoaylmvJryprFtL7HZpgq9aIkf9zdXxq3quWpqgdutr+7X7TTtWyHqrpuhuDuZkn+OsNIoM+NW9X2qKpjMgSVr+nup49dzzIsrjsPSHLJDP07rpHkoavci3IxIvu4JPfIeaNC/zPDdKKnrPjo7FTVy5K8tbv/bMP+hyW5fXcfM05lbEVVfTfnBSKV4W/vG5nIzZ0kWYxI+1aGc7pvkssnedlixNqophwCTfpiI0kWIxAOn+BUt8mqqnd3963HrmO7TfkD22LO+S2TvGftHKvqw2tDWlfdDJrqn5nkmRv3d/cF9rF7TPk1JUmq6mlJfi7JiUme3d1TmiaVJKmqY7v7xLHr2C6LnkDvydAT6NyL66lM866qr+X8N1cvluQS3X3AeFVtn6q6dpLXdvcNx66FzVXVlZO8NsPorbWeqLdIcvEkP7M2+mnVVdUhSX4zyfUz9DJMkkx5MADbb8rTwSYT9mxmMS/06RnmhR5ZVTdNcvyEGvRdK8lTMnzYriTvTfKb3f0voxa2/36lqvY4CmEqjb2T3CZJquqAJOnu745bzlJ9u7u/szZstaoOzLoL/gl4ZTZpqp9kEiFQhju9l8mGflVTM5VVwdZ59dgFbLNfz/BB5neSPH7dsPjJ3BHNsArMZEOgDKOApvRecD7dfdmxa9hJ3X16Vf3E2HVsl6p6UHfvbdT9rtfdZyX54aq6Q4aeXMmwiMzfjljWdnhZhmuzozO8jj4wQy9Adrl14fklM7QE2TXv6VMeCfSJjbuy4l3+16uq92VoAv3WiY5G+MckT0jylsWuOyV5UnffZLyq9t/iTuFHkqz1Htm4CsUkUv3FFKnnJ/nBJN9L8rEkD+nufx21sCWoqqcm+XKSByR5ZJJfydA74PGjFrYkVXW9nNeEdnJN9ac+omTN1Ka97a2hfjKd0RZTtrgu+42N+6cyyjCZ9gjtPd3AmsrNq6o6NEMPlttl+ND2jiSP7u4zRy1sm1TVv3f34WPXwb5V1fu6+xZV9aHuvvFi33u7+4fGro2t2Y3XnpMdCZShw/hVk/x5hiZa3xm3nKU7u7u/sqGJ1pQSvS8leWN3fydJqupNSR4zbklL8dgkv5AhDX5Fkr+c4rD/JM9N8rReLLe9GLn23AxLca+645I8JMmHkzwswyowzx21oiWaQVP9vxm7gB1y1tgFLNnDMwTor8rQtHXSI7km6vJJ7pYLLhgwiRBo6iO0M0xz+5ecfxn1Ka1K+4IMnxnuudi+32Lfyo4GqqoP7emhJFfZyVrYL2sNlP9j0Zz9M0muOGI9XHi77jP6ZEcCJec2RPvFJD+d5F3d/fsjl7Q0i6X03pLhA+nPJ3lUhmVXHz5qYfupql6X4Q/lahmWx11bJv7aGZZz/mySrPpFVVVdM8l9MjTr+2SSJ3f3B8atannW361Yt++Dqz6Sa83E7/ZOuqn+mkUvgfVz6y+wstaqqaq7dffrx65jO1TVlTJ8OLt3hmVzX5mhKe2XRy2MLduNd0KXaQ8jtD8ylZ4yVXWnJL+b4SbrH6x6U+GNquoD3X3Tfe1bJVX1n0l+KsON1fM9lOTvu/tqO18VF1ZV3S3DyLTDMoxWu1yS31+70crutW4E5csyZBKV7I4RlFMeCZQM01CmmnI9MsnjM/QQeHmSN+a8KRyrbG2ViV9J8ndJ1u5i3CRDn5nnjFHUsnX3J6rq/2WYI3r/JNdNMpkQKMlXFisWvXix/YAMdy5WXlXdPcnTMu27vXvbXmmLu/XPzBA0n5VhBZiP5bx+Aqvs+CSTDIEWK2k8J8lzFtM27pPktKr6ze5+ybjVsUVTWNJ4bzYbof29sYpZtu5+c5I3LxYPeH1VnZzkmd39zZFLW5YvVNX9MlxTJ8kxSUZfwWc/vT7JZTa7yVhVb935crgo1t3c+UqmMaJ+Tp6x+P9nc96iJLtiBOVkRwJV1Z8n+YEML+YnZTEdbGp3LqZq46iRGq6qPrDqI0k2jAD6VIYpYSdP6CIqybmrapyYYW79p5OckuS3prBSw9T7cU1dVX0ww8/vzd19s6r68ST36+6HjFzafquqf8rwweX884R3wR2nZVncVTsmwxSN9yV5RnefNm5VbEVVHZnkP7r7W4vtSya5SnefMWphSzLVEdprquqx6zYPzDBd6srdfdWRSlqqqrpGhlEWt8nwIe3vkzxqCqNEWW17WLX1aRneA/+wu9+1wyUxAVMOgc7IeaOAOtNrDL3pPN+NU3BW1WJKyg2SrHX4v0OSf+ruXxmvqv23aAz9oST/L8lXs2Gk2lSWqa6qK2b4mzslye3X9k8hhK2qd3f3rddPbdhs+tuqmkFT/VO7+6hFGHSz7v7eVKYqLlaheG8m2HC+qo7PsDLKxzKE53/d3eeMWxUXRlWdmuSH1/X6OyjJO6fS3LSqLpVhhPZPZvgbfGOGBS2+NWphS1JVv7fZ/im1WoDdqKq+kGFAw3o/3d0Hj1EPW1dVT07y1LWp64tWNb/e3b8zbmUTDoGmrqo+muSuG/d39ydHKGdbVNVtk/xQhoupU7v7HSOXtN+q6onZyxTFqVxMVdW/ZV34mgkFCTO42/uhbDLceDEdZ+VV1ZuT/EySP0hycIYpYT/U3T88amFLMOWeK4sA/d+SfGOxa33fqp5KCDtle+i5MokAdq7W9Vb7Und/bex6LgorD7LbbfbePuX3+ynZw89uV6zeOtmeQFX1gM32d/eLN9u/gs7JsEz1t6dyl2kT/5Xkuxku9r86ci1L0d1PHLuGndDdR45dwzaaaj+uNedMJfDZg3sk+VaSX0ty3wwrFh0/akXLs7H555QcmfMH6BtXmGL3+1xV3X3dqpH3SPL5kWtamqratEnrVPrF7eG6+rczTJv6v0lO3tmKluYeSZ4wdhGwF1etqt9J8sUkZ2a4Eel9bzUcUFUX7+5vJ+dOg774yDUlmfBIoKo6K4DIY+kAACAASURBVMOQ8UpyrwzLyqa7HzlmXcuymO5WGVbQqiTvSvKY7v7XMetalqp6dJKHZriwqCQ/m+TE7n7WqIXtp6ra64VGd6/0h9GquuLalK9FA+UfXTz01qmuWjQ1i2lSt88F+8qs/FS+OZjqynXrRhduagqjDKeuqq6VYYWUqy92fSrJ/Sd03fKOJJdN8uQk5/a/6+63jVbUEi2m6W/0s9196I4Xs0RzGVFRVVfJMLo+Sf6hu88asx62rqp+PckBSS6T4YbI7ZIc0t2XGbUw9qmqfjPDKuUvWOx6UJKTuvup41U1mHIItL5fx8eS3KK7v7GPf7aSquriGZbOfVh3/8jY9SzDYkrKbbr764vtSyd516oP+a+qryf5XJLn5bxpDefq7mdc4B+tkLXeOFV1QoaLjZctHjomyXu7+7fHq245qurV2eTDaHffa4Rylm4RMH8vF+wrM4kP2Yu+OZ1hZb5v5rzpRJcbtbAlWKx89vQkB3X3pFauWywRf+5mhn5x505bnPjotUmpqsskSXf/19i1LFtVHZ1hdMwpGfpATGIU855U1TtW/bpzt0zN2E5Vda8MjYTfmuH180eS/Pfufs2YdXHRVNX3J3lThhkTx3f3W8etiL2pqjsnudNi82+6+41j1rNmstPBknxfVd0syeUyzFf+m6p6SHf/08h1Ld1iiNlLq2pKF1SVYSrYmu9mw8iEFXVkkt9I8uAkz03yrIldJK4FW3dNctPu/l6SVNWLkrw/w8XxqnvOhu3KeUtArrzuPmLsGrZTd182mezd3ycmuWWGC/109wcWKzKtvI0hT1VNfdri5FTV5ZP8XhYjRKvqbRk+wHxl1MKWqLtPTnJyVR2T5E1V9ZrufvrYdW2jad5Jnp7HZ+h9d1aSVNUhSd6cRAi0ghZNhm85dh1sTXf/dZK/HruOjaYcAv1mkj/L0Dvn/kk+k+SFOW96yuR092vHrmGJXpDkPVX1lxk+ZN8jw+iZlbZ4A35cVf1Bksck+WBVvTTDEo9TmG7zz1W19jf2/RnmLydD35VJvN5091s27quqyXyIqapfTfKyDSsZHNPd/3vcypZuih9ezu7ur1SdfybfWMVsl6q6ZqZxU2Bunp/kIxmm6CfDtdkLkmy2/PHKWTfKMBl+Py+WYUTsJEKgxXSwjX25pjBC9CZVtdnNuMmMEk1ysQ3Tv76Q4feTFTD1fmOMY7LTwTZTVQetLU3K7ldVN88w7zVJ3tHd/zhmPduhqi6b5Fez6H/U3Y8buaT9UlWHZWiWfMkkV8vQNLkyTNt4Ync/f8TylmKTvk6V5EFTGUGzhxV8JjNqZvG6kgxTFX8xizChu98/WlFLMuWV66rqwxk+gF48Qy+8h3X3G8atigtjD68tF9jH7lRVD9xsf3e/aKdr4cKpqqcluXGG67MkuXeSD6/6NedcTL3fGOOYbAhUVZveWeruv9jpWrjwquoSGeYsvyPJzZNcJ8mruvuboxa2nzbcKTx3d4ZRMgd19wE7X9VyLXpU3SHJIRnO7atJ3tfd/z5qYUuyaNC30a9097V2vJhtsPiwfeNevDlU1QFJPtTdNxi3suWoqlM22d3dfYcdL2bJqupSGYb9/2SGv703JnnSFFaQrKprLL78Vnf/514PZleqqndl6EPyd4vt2yZ5enffZtzKlmPdKNjz6e6373QtsFFV/XyS2y4239HdfzlmPVw4c+s3xvabcgh0dpLTkrwv5w0b7+5+8HhVLc+iv9Hz1m0fkOR3uvv3RyxraRbTwK6U5Owka1Ntzu7ue49XFRdGVd0uyXW6+wVVdXCSy3b3v41d13aoqrd39ySmmi7uGF4jyZ8udj0syae6e7PwC2BLFo3KX5RhenBlmC78S939wVELW5Kqet3iy9sl+bvF1z2VKRtVdZ0kf5Dk+hl6bSaxMt+qqqq7Jblikrd19yfHroetWfQbe3SSqfcbm4RNVjZdm2Y6+uvmlEOg6yV50mLzdye4XO6fZ+i58pAML+IvzPBC/htj1rUsi2Wqb5bks0muutj90e7+b+NVxVZV1e8lOSrJ9br7ulV1tSSv7u7b7uOf7np7GGX4pAmNlLlYhuDnjotdf5Pkud393T3/q9WxWCb3yUmu1t13qarrZ1iJcOV7ji2afT4uyQ1y/g9pKz/KiemoqsslyVTvZE9p+ux6VfV3GRp7/2GGJY8flKHXzMYp0uwym/SUqQxh5X2TvL+7P7vzVbFVe+g3dokpzB6YusVq1z+e81Y1vX2G/GX0hS0m0ah1M4vQ515VdYskz6yqz2ToSfLpkUtbiu7+xaq6d5IPJ/l6kl/s7neOXNYynd3d36uqZ61bYerbYxfFlv1shhDv/UnS3Z9Z9D+agp/eZN8/7HgV22Txd/e8DHeyO8nHpxIALbwwQzPaxy+2/znJKzOBxvMZ+hy9Msndkjw8yQOTfG7UimBhYz+1tQbm3X38KAVtn2neXU0u2d1vqapajBx5YlW9L4kQaPf7b0l+ed12JflBfdVWw9qqpqym7v7C4gbr1ZPcvbtfOHJJSSYcAm1YxeATSX4syb9kaCi58hbDch+d5P9meHG//+Lu0zf2/i9XxrOSpLuflJy7tKw3q9Xxne7uqlrrK3PpsQtalu5+0Ng1bKequn2GKRtnZLhQPKyqHjihvhYHd/erquq3kqS7z6mqqYRcV+ru51XVoxcNI99WVe8duyhY+Pri/49J8kdjFrIdquqxiy+vvO7rdPczRypp2b69+CDzL1X1iCSfTnKZkWtia762sYnwYnQJK6qqjkty3QyLypw8dj3s0emLkXiXSvIXSW5eVT+6G9rTTDYESnLqPrZX3euSPKK731zD7bTHJnlvhmkAK2/jahPd/ZUMDdFYDa+qqj9N8v1V9dAM0xb/bOSalqKqXpTk0RuWUH/GbnhBX5JnJPnJtSm0VXXdDCuK3GLUqpbn61V1pSxuElTVrXNe37FVd/bi//+xaCL5mQzThWF03f2MJKmq+619PTFrd+v/bN3XU/LoDB9kHpWh3cIdMow2ZPe7QVWdnqEP15lJXp91U4bZ3fbQV+YqSX4wyZdHKYqtuneSn0ry3SRv6u7vVtU9R64pyYR7Ak1dVV1u43z6qrpud//zWDUt0ybzl5MkU2mwOAdV9RMZVilKkjdlWNp57QPpS3pFX3w26/cwpR4QVfWh7r7xvvatqsUS8c9KcsMkH8mwit09p9CcdtHo8x1JDstwjpdL8vvdvenrKYyhqt7f3Tcfu47tUlWXmtCo7AtY9HTq7jaSZEUsbnwckGHk1pFJ7pnkoRl6lZzW3Z8fsTz2YfHzO9+uJK+bysqKjGOyI4F2czfuJfmZtfn0G0wiBEpyhQx30p6cxHLAK2Jjz4ckaxeJP5yh2fDailOV1e2bcLGqukJ3fylJquqKmdZr6alV9dwkL11s3zcTGknZ3e+vqh9Lcr0Mv4cf7+6z9/HPVsVnFqMmv5Lh4h52jcXqWZ3kmutv9Ezl5k5V3SZDb7HLJDm8qm6S5GHd/SvjVrYcVXVUhn5ql11sfyXJg7v7faMWxj6ta0J7VoYWGW9Z17D284v/2KU2ayK8WAWbXa6qPpzN84jRb6xOdiTQIjVd68R97sXwbujGvQyLnkdrOuf9Uj1qpJKWbjGd4beTnJLkqVNdSWRKqurMDCuHbOYx3X3YTtazHarqARl+L1+d4e/uF5L8z+5+yaiFLUlVXTzJr2ZYOSQZRpb87+6eRGP2qrpNd79r3fYVMry+PHTEspZi6iMsWG2L8PUCNvYqWVVV9Z4M7wcnrY0MraqPdPcNx61sORahwa929zsW27fL8N4w+ocZmLLFzcaNXt/dP7zjxXChVNVLM7RqeUKSD63tXzTXH9VkQ6A1U78oXiwJ/Jgk35fkWd39qZFLWrqqOibDXPTXdPfTx66HPdvbtKiJTZm6foZ+CEnyt9192pj1LFNV3bq73z12Hdulqt6e4YPLK6rqlzO8tvzP7n7FyKXtt8WHtB/LEE6eq7u/OE5FMB9V9Z7uvtX697qq+mB332Ts2pZhD1OhJ32NDbvButkt69/bpzS7ZdKq6oZJ/keG2RFP6O5/G7mkJBMOgdalpqckuX0WfzhTuxiuqtdmWCb+C0l+rrt/dOSSlmKxasHaL2cluViSS3T3AeNVxb5U1UeS3DnJdzKsRvHNdY9N4mKxqg7fbH93//tO17IdpvJz2pOqukSSl2ToCfSmJL8zld4WVfXtDCv2uFBk11n3vn7JJN/MeSOYLzdqYUtSVa9J8swk/yvJrTIEzEd1931GLWxJquqPMvzsXp7h53jvJN/KYupwd79/vOoAdp8No7hum+T3kry7ux8xUknnmnIINIvUdMMdp3d094+MXRPztQiBvpfkoAx9Ay6ToU/Vu5LcbQp/f+vm91bOPxVzEkPipzRiazOLxtAXy7C6zZeSPD2ZxgeYqf/smIap/p5W1cFJ/jjJnTK8L7wpw0qSU2lDcMpeHu7uvsNeHgcuoqr6uc32d/df7HQtXDgbehSvZRK7Io+YUjPT8+nuI8euYTstPsgkySWq6mYZfrEuPWJJS7WYbnMBU5p2M0Ubex9U1cWSXDPDHcMjFv10khVeHay7b5QkNXRmv1OGqZhvGrWo5br8ZhccE7rYeEaGN+RDMvSL+4HFtg8wsDNW8rV/XxYrLN13/b6qmsx1dndrNj8hVfXhtesZdr1XJjktyfuyLkhIMpXrssnazXnElEcCXSrJY5Mc3t3HVtV1klyvu18/cmlLsac7MlN5k66qd2yy+4bdfYUdL4alqKqHJ7lKhjeu/9Hd3xu5pP2yGBp/kwwrMX2ju39x5JKWoqpesMnu7u4H73gx26SqbpTk9Rmalf/l2PUsS1Vdoru/VVWXSZLu/q+xa4I1625evSzJL+a8aforPwovSarq17r7D9dt3z7J07v7qPGqWp6qukqGFVuv1t13Wdysu013P2/k0tiDPY0gyfC395zuPmQn6+GiqarrZRi9nCS/290fH7Metm7dze/z6e4X73QtG005BHplhsT0Ad19w0Uo9PfdfdORS+MiMt2N3aSqPpDk5t39vap6d3ffeuya2LequkuSJ2ZYyvkRSf5Xd584alFLsmg++JIkV8xwkf+5JA/s7o+MWhhkjzevJjONaLFq60FJjk/ylCSXT/Ko3dIEdH9V1V9lWCL+8d19k8Uop380mmT3Wiwj/rJsPvruF7r7sjtcEvuhqm6R4fXlM0me2N2fHrkk9mHdat73SvKqxde7YjXvyQxT3cS1uvvei5Wl0t3fWEzfmISqesJm+7v7+J2uZQdNM7FkVX1v3Wim74xaCRfGryX5qe7+clW9PMkTq+qd3X3bsQtbghOTPLa7T0nOHYlwYhLLyDK6qYxU3pPufmRVPSrJvyZ5eHe/cOSSlu3g7n5VVf1WknT3OVX13bGLYq8+lGE02gVuBFTVnUaoh4tgESSsfQb6RIZVQP8lyaVGK4ot6e5HJklV3W7t691iyiHQd6rqkln80VTVtZJ8e9ySlurri/8/JskfjVnIdtiwOlgy3NW+xEjlwLnW/W5eqqq+Gr+bq+au3X1OkixWBfv1xQiaKbj0WgCUJN391qqaTK84VtvUpxNV1WMXX749yePWVoXp7meOV9VSfb2qrpTzrqtvnWE6NLvXY5J8dQ+P/exOFsJ+OXUf2+x+u24gw5RDoN9L8tdJDquql2VYlu2XRq1oibr7GUlSVfdb+3pKNhuiuoc+QbCjDJ9ebWsBUJJU1YndfeyEpkt9oqp+N8OUsCS5X4a7hrAbvDCL6USL7X/O0PB0EiFQhhUxk+HGwCXXbU/FY5OclORaVfXODM31f2Hcktib7t7jdXN3CxJWxxeTnLzqvTTnaN0orkOr6k/W9u+G6WCT7QmUJIs7FrfO8Ib87sXKDZNSVe/v7pvv+8jVV1Vv7+4fHbsO5m0xwvBa3f2RqrpPkoOTvLi793S3beVU1dFJbpB1I5ymONV0aq+fVXWFJL+f5HaLXe/I0DfgS+NVBYOqem93/9D6JeKr6gNT6tVYVQ9K8n+SPKi7Xz52Pcu26AN0vQzX1R/v7rNHLgkmr6pemuQ2Sf5vkud39z+NXBJbVFUP3Gx/d79op2vZaLIjgdYtMb7WkO/KVXXlqSwxXlWvy5AsXrOqTlrb3913H6+q5amqD+eC08GOGKcaOJ/XJrlKVX02yVlJvpbk1Ul+atSqlqSqnpNhnvmPJ3luhju9/zBqUdvnrLELWKZF2POoqrrssGl1MHaVSU8nqqo/SHKNDKtGPqWq7p5hBcL/HLey5dhklZubV9WuWOUGpqy771dVl0tyTJIXVlVnGFX58sW0dnap7n7R4ubx4bttVbfJjgSa+hLjVfVjm+3v7rftdC3boaqusdn+7v7kTtcC61XVaUlumORT3X31xb4PdvdNxq1sOarqQ91943X/v0ySv7Iy3+5VVU/o7uOr6kZJXpxhdbAk+XysDsYusVgi/lkZXj8/kmE60T27+4OjFrYkVXV8dz9h3fbdkxw/lZFOVXVWkldkuCm3ZlescsPeVdVVu/uzY9fB/lmE6PfP0OvpY0muneRPuvtZe/2HjKaqfjrJ05Mc1N1HVtVNM7wvjD5oY7Ih0GamtMT4WsPBjbr7iztdC8xJVX0wwyiZt2ZYoaGSnDKhEOg93X2rqnp3kp9L8oUkH+3ua49c2rZZ6w00dh0XVVX9Q3ffsqr+PsPyzetXB/sf3X27vX4D2CFzm05UVZfo7m+NXccyrJ/Gx2qZ2tTnuVkEyg/KEPq8OMmLuvusqrpUktO6+4gx62PPqup9Se6Q5K3rpkF/pLtHX5BkstPB9mBKidd/JPl0NtyRSXLNccqB2bh8hpUZKsn7F/um9Nry+qr6/iRPy3B+neTPxi1p/+0pOM/wc7zrTtayDb61mAJ2mU1WB5tac1pW2KIx+0fXtqvqj5PcKMnzuvtloxW2BFV1aIaRTrfL8Lr5jiSPTnLmmHUt0ZTe52CV/HySP+zut6/f2d3fqKqHjFQTW3N2d3+lav3H9eyKBt+THQm0pyXGu/v7RippqdyRAbZbVV08w+vmyvftqKrvJvlkLhicV5Krd/dBoxS2BIuLwFslOSzJO5O8dPHQ/ZLctrvvMlZtsGYG12V/k+TPc/7V+e7b3T8xXlXLs2462PmYDrb7VdU5Sb6xfleGqXyXG6kkLoSqOjLJf6yNKlz0mLlKd58xamHsU1U9L8lbkhyXIcx7VJLv6+6Hj1pYJhwCbWZi08E+keTXknw7yWcyDAc8Z+//anVU1cW7+9sb9t2uu/9urJpgo1WfRrSZqQ4br6p/SXLH7v73TR77VHcfNkJZS1NVD05ybJIrZ7jA/2qS9yT53ak0pmV6JnZddoGVzqa0+llV/X9JDlhsnpPkm8nuWOWGvXPjeLVV1alJfri7v7PYPijJO7v7h8atjH1ZTNl7fJKfzHBt9sYkT9oN04RNB1tdb8uQKF4yydWSXKOqHtrdfzVuWUvzxqq6Z3d/rqoOztBU6ypJ3NFmNzlq7AK2Qe37kJX0R0mukOQCIVCSp+5wLUvX3c9P8vyx64ALaUrXZV+oqvslWVsa/pgMPdVW2qKP05OTPDjnvX4enmF1ot8eqy6YkQPXAqAk6e7vLIIgdrnu/kaGEOjxY9ey0WRHAu1pifHunmR/hKq6dpLX7oZGU8tQVbdL8sdJXpPkPhmam7563Krg/Krqr7v7zmPXsUxV9Y0kp6/flWHY+I1HKoktqqpLJHlIkhskucTa/u5+8GhFwUJVnZILXpfddEKrtl4jQ0+g2/z/7N15tJxVmf3x7w4gYQoiAoKgEkBkDCAoICLaDj9FcULRhhbBsbEFRO12AgRttRVRwRGQoEDj0EA3CrYMzaQiQwiEWQZFQBAZlDAKZP/+eN8ilUuR3CR176k6d3/WuuvWe5K71s5KUsPznvM8NH/O3wB799p9OEwkfQ1YAfhIZxx1O676EOBB2/uWzBcLJmmq7ZtK54hF0x41Pdz2Ke31G2meW/6hbLJYEEk/pcfNDttvLxBnHjUXgSbciHFJq9u+vXSOfpE0FfgZzSi9H5fOEzGSpFVt31k6Rz9JuooejZJrfu6sRftm41rgH4GDgV2Ba2zvUzRYBCDphSOXgCNzTGWwtUdpn+8RHxgkLQFca3u9MslitJ6qabntWpqWV03SOsDxNCc/oGk2/0+2byyXKkZD0shCnYCvDsJE4WqLQACSpgGds+bn2768ZJ5+qv0JvWsn1wrAmsA1ANmNEKX0mC4lYAawOc1z6T3jn6r/0jtgeHX+7iTNsr2ppKVoXvu2Lp0tohdJ59nevnSOfpB0Sq912zuNd5Z+kvQ7289f2F+LwVF70/KJQtLyALbvL50lFt2gvO5V2xNI0j7A+4CT2qXj2iauhxeM1U/TaZ7Q39Ze79au1fKE/npgKZpC16k046ojSrqLZrpUt2czd4z61HFPNDY+XDpALLJH2+9/lbQxcAdNo+iI4iQdzpOPg9XyvAmwAfDe0iHGwNWS3mX7h92Lbf+jawtlioWziu3pXdfHSMoxviGT4s/wkXTAyCWanmrFVVsEoumL8GLbDwBI+g/gApqiQg1qf0K/F/gpzU6gFWnOnf+lbKSY4D5OU2T9uO0rACT93vbaZWP13RVtD4jOLspzaY5kDv2Y+F4krQ7cM3Ia4ZA6QtJKwP7AKcDy7eOIQXDJKNeG1Wzb55YOMQY+BJzUTiCc0a5tSTOY5M3FUsXCqLJpecQQeKDH2uPjnqKHao+DtceJtuqMYGsbZl5se5OyyfpD0lk0O3+6n9D3qKVJmKSLgM/aPk3SW4DPAt+z/a2yyWIia49hfg24BTgQuNx2TXeykXQicCXQGfv7T8A0228pl2rsSDoTWAc40fbHSueJqFk70aZzfOg624/O7/cPE0mPA7OBh4E/Ab8GDrJ9V9FgfSLpFTRN5wGutn1WyTwxerU2LY8YRoNyHKzmItB+wO7Aye3Sm4BjbH+9XKr+qf0JXdKmtmd1XS8HHGD73wrGigBA0k40o3GfZ/tZpfP0k6TLbG+2oLWaSBKwoe2rSmdZHJJWpimYv4S5veI+Zzt3fKM4STvQFJf/QLMlfi1gd9vnFYzVV5Im0eyQWQN4O7Ct7R3LpoqIYdce8d6QeSd//vCpfyIGQbuRYaTP2d6ox/q4qrYIBCBpC5rGydA0x5xZMk9E1EPSMsA6tq8snaWfJF1Ac+TtV+31S4BDbG9TNtnia4s9L6Lp5QRwG3DRyKk3w6pt/nkecFy7tCuwg+1XlksV0ZA0A/hH29e1188HTrA9cmpYNSR9uKJelBFRgKQDgR1oikCnAa8FfmV755K5YsEkTe+1bnuP8c4yUrVFIEk9my4N+04ZSYfN79dt7z1eWcaSpK1pdjptADwNWAK43/aKRYNFVE7SZjR36zv/1+6luVs/66l/avBJejXwbeB6muIPNJMH1wX2sn16qWz9IulK2xuPWLuilmPQMdw6U+sWtDbM2l2inW3+59r+Wck8ETH82hYn04CZtqdJWg04LtPdBp+klQd1N3bNjaFPbb9PBW6k2XpsYNjfbLwRGNlpvEbfBN5B0xx6S+BdzO0jEBFj5472TcYUANv3lQ7UJ98AXmn7D92LktamubO2QYlQfXa6pHcAP2mvdwZ+WTBPRLdLJB3FvDvVqmkMLemLNDsNj2+X9pa0je1PFYwVEcPvIdtzJD3Wvje7k+Y4bQy+30q6jKaP7y8Gaed5tTuBOiTNtL156Rz9Utuf56lIusT2lt13CSfKnz2iJEmX2t6idI5+k3Q9sIHtx0asP42myem6ZZL1j6TZwHLMnTyxBHMnU9j2lCLBIgBJS9NMmnrimD7w7Uom8yFpFrCZ7Tnt9RI0d+6H/eZjDLl258gXgDVsv1bShsA2tr9fOFqMgqRv0/ShfAfwUeB+4LJBOFIU89e2IXglsCewFc1NumNs/65oMOreCdRRW5Wrtj/PU3mw/XB2maQvA7cDkwpningSSVsCf7L9p9JZYr6OBi6W9COa6W4AzwF2Aap4I2x7hdIZIuZjc9uHAoeWDjKGng7c0z7O8fUYFMfQ7ET4dHv9O+DHVPLaVzvbe7UPvyvpf4Epw35Ef6Jod/6cAZwh6eU0O2H3knQ58AnbF5TKVu1OoK5u3IcAT4z9tX1SmUT9Uetd+pHa6Wd/pukH9BGaN1Pftn1D0WARI0j6Ac0x09/Z3qV0nsUl6THgwe4lKtlFImkDmiO13Y2hT7F9dblUERND7e9fJL0T+BJwNs3z5vY0b/J/XDRYTHiSLra9VfeO+tqnftZE0ia2r+i6Xho4yPYnCsaKUWintu4G/BPN59rvA6cAmwE/tb12qWw17wR6Q/v93K7HBoa6CARMk9SrR0c1H9Rar7F9BPAwcFDpMBFPxfbuAJJq2YVxRa3HLm1fA1zTuZa0RQpAEeNGpQOMJdsnSDqHZss/wL/ZvqNgpIiOB9oPo4Ynhq/8rWykWAg/kLSv7fPa3SSHMbf3WAy2C4BjgTfZvrVr/RJJ3y2UCah7J9AWti8tnSMWTe13DGN4ted7dwWm2j64nUT4LNsXFY7WFxOp91aeZyLGj6Sb6NqZ3THsO7Q7JG3fa932eeOdJaKbpC1oJu5uDFwJrALsnCNFw0HSs4CTgTuAKcAHbV9fNlWMhiTZdtvQ27Znl87UUXMRKG/uh1jtbxZjeEn6DjAHeIXtDSStBJxue6sF/OhQkDTV9k2lc4yHiVTwiihN0jE8ua+hbe9ZIE7fSforcB7z7niy7Z0KRYp4gqQlgfVp/n1eZ/vRwpFiIbS7zU+mOcJ+WOk8MTpt39DpwAo0//f+Cuxpe0bRYNRdBJoFvIwR249t39P7J2KQSLob+B+e/GaqijeLMbw6BeYRZ+svtz2tdLZ+aHsc7WP7r+31SsBXa/y/J+lNtv+7dI6xIqlzMBR2VwAAIABJREFU9O1btr9ZNExE5VJUjkEn6ZnAvjT9Ng+3fcsCfiQGQDv50zQTP5ehmfpZUwuQarX1iA/ZPr+93o6mx23xqZE19wRaH5jBiCICMLVMnFhIf6zxQ2dU4dF29G/nbP0qNDuDarFppwAEYPteSVV8sJG0IvD/6GoMLenp3X/emrQ71VYGti6dJULS0b3WK3qtr/OuatTkKOAK4E80PWV6HmGMwZLJn0Pt8U4BCMD2r9oBLMXVXAS6OndkhtpVpQNEPIXDaLbkribp34Gdgc+UjdRXkyStZPteAEnPoILXCknvAg4ETqeZCgbwcuALkg6y/cNi4fpE0mp0Fbhs/9n23cCpBWNFdOwAfJzm5tx/AP9aNE3/rSppv5GLtg8tESaih+fYfhOApLeWDhOjI+nntl9fOkcsknMlfQ84geZGwS7AOW2fLkr2Lx76N/ZRF0nrAqvZ3m3E+kuAO2zfWCZZRMP28ZJmAP/QLr2pnTpVi68CF0j6Kc2HtZ2Bfy8bqS8+Dbxw5K6f9rjbhcDQFoEkbQZ8F1iRuQWuNdseJXtlSEIMiL/aPhFA0leBayqbznckTd+HiIHS+cAJLNPu7BWwXMFIsXDWKB0gFlmnVcSBI9Y3pykKvWJ848xVc0+gybYflrQ8gO37S2eKBZP0c+CTtq8Ysb4J8AXbbyiTLGIuSdOAl7aX59u+vGSefpO0Ec0uGYD/q+GDmqTfAVvZ/tuI9RWBS2yvVybZ4pN0GfAB2xeOWN8a+F4t/apiuEm6EPgxTaHk1cDfgWNs/6BosIjKSTq717rtl/daj8HS1XR+Hmk6H4uj5p1A60o6FngGzYS2vwC7276ycK6Yv9VGFoAAbF8h6XnjHydiXpL2Ad4HnEhzN+04SUfYPrxssv6xfVX7nDkZQNJzbP+xcKzF9e/ApZJOBzrNMJ8DvAr4XLFU/bHcyAIQgO3fSsrd3hgU7wT2Ah6n2WF4D3AokCJQxBhKsWfo/YVml3YMIUk7AhvRvqcGsH1wuUSNmncC/Qb4tO2z2+sdaHaSbFs0WMyXpOuf6o68pBtsrzvemSK6tZ3+t7H9QHu9HHDBIHT67wdJO9G82VgDuBN4Ls2xjY2KBuuD9ujXa+jqmwP8stP/aFhJOgxYh+ZIW6fAtRbwLuD3tv+lVLaIDklb5GhixPiTtCHNsZOfAgcDKwOft31Z0WAxKpk8OLwkfRdYlmZ3/VE0N0Ausv2eosGoeyfQcp0CEIDtc3JHdChcIul9to/sXpT0XpppbxGlieZOdsfjzDuFcNh9jmaa1Jm2N5f0cmC3BfzMwJOkttjzowX8nqG7M2J7b0mvBd7IvAWub9k+rVyyiHkcBWyxwN8VEf32n8D5NP3vPgfMBr4PvLBkqBi1L5YOEItsW9ubSppl+6C2H94vSoeCuotAN0naHzi2vd4NuKlgnhidfYGTJe3K3KLPlsDTgDcXSxUx13TgQkknt9dvonkzVYtHbd8taZKkSbbPlvT10qH64GxJJwL/0320TdLTgO2A3YGzgWPKxFs8tn9B1xsLSc+yfUfBSBEjLdnuxpunaG77nkJ5+krS0b3Wbe853lkiRphk+8OSXmP7+wCSPlk6VIza5HbC6TxqmGo6ATzUfn9Q0hrA3cDqBfM8oeYi0J7AQcBJNN23z2/XYoDZ/jOwbbv7YON2+VTb/1cwVsQTbB8q6RyawgHAHrZnFozUb39tG+qfBxwv6U7ggcKZ+uH/0bwGnCBpbeCvwDLAJJqx8V+v7O/xNLLrIgbL+jQ3d7qLQAamlonTd68Bbqa5+Xhn4SwR3ZaX9BaaQuybaV73phTOFKO3Vddj0zyHmiGeajqB/FzS04GvAJfS/L0dVTZSo9qeQBERY0HSc3qtV9A4GXiix9HDNG8ydqUZO3687buLBusjSUsBzwQeGjkyvhbpIRCDpvZ/k5Im0RSb/wlYApje7tCLKErS9F7rtvcY7yyx6CStQnNiYingcNu3LOBHYoBIWhqYPHJKbSkpAkVELARJnel1U4Ebae/I1NIYeiKQtB2wnu3pkp4JrGD796Vz9ZOkvWx/u3SOiI7ai0AdbRPefwVWsb1j6TwRUQdJ/w1cQXOk6C22ty8cKRag1zE+GIyjfDUfB4uI6Dvbm0B9H2gk/Z5mm2pPtqs4siHpQJo+Y+vT9Hd6GnAc8JKSuRaXJAEvYm5j6BnD2ug6qrUNQHvcFNv3l43TX5LeT9Mj7gbgG5UdL40hJmlN4HDmvs6dD+xj+9ZyqWIRPNf2mwAkvbV0mBiVzlG+twM/aR8PxFG+FIEiIhZNbR+ut+x6LOD/aEZa1ubNwOY0Z7Ox/SdJK5SNtHgkvRr4NnA9zVQwgDWBddsdQacXCxcx17qSjgWeQVO3/Auwu+0rC+fql+/SFIDWAnZo6rKQXaIxAKbTTAh7W3u9W7v2qmKJYtQkdfr7TZa0Oc17tEy8HgK2PwzNDvTO40FRbRFI0mG91m3vPd5ZIqIebXNFgKd3Pcb2SYUi9cXInj+SHqupD1CXv9u2JMMTPZCG3TeAV9r+Q/di2wD7NGCDEqEiRjgC2M/22QCSdmjXti0Zqo/WLh0g4imsYru7L9AxkvYtliYW1lfb73cAh7aPB6KvTIzawN04rrYIBOwIzKa5O/pI4SwRUY83tN/P7XpsmkmEVZA0lRFjnCvyE0nfoynivY9mYtiRhTMtriWBXtv6b6NpIBkxCJbrFIAAbJ9TSRG2Y+De5Ee07pa0G3BCe/1Omr4yMQRs17gre0KQdDjNa8Oa3RtUBmFTSs1FoPWBDwDvA74HHG17TtlIETHsap2m0Ta8NrA0sCzN82d1bB8i6VXAfTSvEwfYPqNwrMV1NHCxpB8BnWkhawHvAL5fLFXEvG6StD/NCHVojqTcVDBPv53KvOObO99zHCxK25OmJ9DX2utfA1W+l6mRpAN6rds+eLyzxEK7pP0+o2iKHqqfDiZpWWAf4I3AIbb/q3CkiKiApBfRvKFaCviU7TMLR1oskp7bPnzY9p+LhomFJmkDmte5TmPo24BTbF9dLlXEXJJWAg4CtqMpjpwPHGT73qLB+qxt0v5KmteG020/VjhSRAwxSbcyt4D3BNtf7fHbI0al2iJQ111taO7GrAg82/YS5VJFRC0knQ98FrgHONL2lvP/iRgEkmYz77ENAbY9pVCkiKiIpK8D02h6djxo+x8LR4oJrj3i/Q1ga5rXvwuAj9iuaSdetWqbRhuDoebjYK8vHSAiqrac7bMAJD1YOkyM2jeAVwD/bvvU0mH6QdLPaBrs/q/tR0f82lTg3cAfbB9dIF7ERLMDsIXtOZJ+WzpMBM1ksG/RTMeE5qjwCcCLiyWKhVHnjo0oquYiUP7DRETfSdqvfbhq+1jMPYITA872ZyStAuzf/v0dYPvXpXMtpvcB+wFfl3QP8BdgMvA84Ebgm7b/p1y8iAllTlcPyr8XTRLRWNb2sV3Xx0n6eLE0sbCmSjpl5KLtnUqEiTrUfBxsDnA9cyeDdbb8p0FfRCwySQf2Wrd90HhniYUnaYuuy7WBA4BbbFexe1TS84DVgYeA39nOLrWIcdB11HRZ4EGa952TbWdCXxQl6T+Ae4Ef0fwb3QVYCfgKgO17yqWLBZH0sl7rts8d7yyxcHoV72AwCng1F4H+GdiJphB0tO3LCkeKiIjCJJ3daz0jWCPG1iC/GY6omaTfz+eXbXvquIWJRSJpNWCr9vIi23eWzBOj0/YPXQH4AvDE0JVBKOBVWwTqkLQR8DFgVds7ls4TEcNN0qxe69llGKVIWsr2oyOaXqv9nqbXMRAkXQ+8d+T6ILwZ7gdJ2/dat33eeGeJiHpIejvNrq1zaF7bXwp8PBOvh4OkHYFPAWcDX7Z9X+FIQMVFoHZE52uAd9GM6Zxu+7SyqSJi2Em6CnjdyHXbNxeIEwtJ0gG91m0fPN5Z+kXSKbZ3kvR5Kmt6HfWQdKntLRb8O4dT26AdYDvgV+1jZ6dTlCZpKeCfgU6h8hzgeyMHCcRgknQ58KrO7p+2r+GZtqeVTRYLQ9I7gX2A/7J9SPE8FReBbgFuBY4F7uis2z6pWKiIGHrti/H2wCO2Hy6dJxaOpI+2D/cFvt5Zt/3VMokWn6SLbL+ofbwKsD+wEXU0vY5KSHocmA08DPwJ+DVwkO27igbrs4xzjkEj6SiaG+I/aJf+CXjc9pN25sXgkXSF7U26ricBl3evxWDqsUN7Ek2vuCXKpWrDVFwEOoYnTwiz7T0LxImISkj6A80T+bLt9wuAfW3fWDJXLJyaPqhJ+pLtT9Te9DqGX/vhZRlgDeDtwLa1HdWvfcdTDB9Jl4/cNdJrLQaTpK8AmwIntEu7ALNs/1u5VDHsqi0CRUSMNUlLA28DPmD7paXzxOjV+EEtTa9j2Ej6sO3DS+foB0n7tQ/3Aw7trNs+tPdPRIwPSZcCb+vcrJI0leZISlWvgTWT9FbgJe3l+bZPLpknRkfSW3qtD8LJpCVLBxgrkqbz5J1AZCdQRPSL7UeA4yTdXzpLjE7bt8PA1O5pRTX07UixJwaZpDcD/2f7b+3104FbyqbqqxXa70d2PY4YBB8HzpZ0E80O5ucC+Tw0RGyfCJxYOkcstCOBkZMxDRQvAlW7E6itmHaYdlJK+58oImKRSdoY2BCY3Fmz/cNyiWK0JL2s13oNE4q6diLMIzsRYhBIusz2ZiPWqjmWGTHI2p3L67eX17U3sWIISHoMeLB7iUz+HAqD/BpX7U6gTrFH0otptuUuBXy6aKiIGHqSDgR2oCkCnQa8lmYSTIpAQ8D2uZKeC6xn+0xJywLFG/T1yf7AzUC2iccgmtRjrbr3oZJeBxxB87zyMdvHF44UE5ykZ7QPb22/Lyfp2zQ71r5m+4IyyWKUrhjUQkIs0LMlfZ2ugQi2ZxTOBFS8E6hD0vnAZ4F7gCNtb1k2UUQMM0lXANOAmbanSVoNOM72qwpHi1GQ9D7g/cAzbK8jaT3gu7b/oXC0xda+0f8k8GLgYNtnFo4U8QRJRwN/Bb7VLn2I5v/hu4uFGgOSLgR2Be4FzkjflShN0iPAbbQ7SNrvq9uePN8fjIFQYw/DiULS7jQ3BDoDEV4PnGD7S0WDUeEdmB6Ws30WgKQHF/SbIyIW4CHbcyQ9JmkKcCewVulQMWofAl4EXAhg+3pJq5aN1B+27wE+LmkN4EBJHwP2t31x4WgRAB+m2a324/b6DJr/j7VZyvYNAOkXFwPi6pE7SSTNLBUmFtqykjanbW3SYfvSQnlilGz/oPta0udpThGkCDRWunojrNo+FvDsgpEiog6XtA1NjwRmAPfTjImP4fCI7b9LzXspSUvSY4jAMOpqeg3Na95zgN9Sz3G3GGK2HwA+UTrHWJF0WPtwzfaxgKkFI0V0LC/pJTS7025rm7NX8bo3QdxO18TBloFXFMgSi8H2Q8BADPGo9jhY27fjSWwfNN5ZIqJOkp4HTLE9q3CUGCVJX6Y5kvIump0Je9HcJR36nnE1N72O4SdpFeBfgY2Yt6l+FR9k2m3/TzLyTnDEeGtvECwBLE9zc+AWmr54zyoaLCKKqbYIFBExFiT1PJedbbnDQdIk4D3Aq2nu1P8SOMoVvBhK+qztz5bOEdGLpNNpjoJ9DPggsDvwF9v/VjRYxAQjaRuaIyknA9/JkeGIiafaIpCks+mx1bGWO04RUUb73NLxQpojYc5zy/CStI7tG0vnWFxpHhmDTNIM2y+UNMv2pu3axba3Kp2tHyTNZt73nRnjHANL0urA02gKsemZGjHBVNsTiOZOk4DjaKY0REQsNttPnOWVNLP7OgafpBOBXW0/LOlpwKeAHYEaPoh2euDNw/bIXgIRJTzafr9d0o4043KfMZ/fP2xuyBjnGCSSJgP70hyBPhL4DLAlcBHwRduPFYwXUT1Jp/Rat73TeGcZqdoikO0ZAJIe6jyOiOiXtjn0UqVzxEL7MXCmpG8B/0Zzo2CbspH6ptPzQQv6jREFfF7SisBHgcOBKcBHykbqq8mSpgGPALe3zXcjSjocmE3TB+hc4HLgK8BO7fea/v9VTdLGwIbM20/th+USxSitBKwAfAH4c+Es86j2OFhHtsdHRD9JuqJ9+CzgANvfKZknFp6kFwH/Dfyz7f8pnadf2p1p2YkQUUB7VHgJYBlgdZpJTHvYvqRosJiwOp+B2l54fwZWsz1HzXjMGfl8NBzaYUc70BSBTgNeC/zK9s4lc8XotDtfPwWcDXzZ9n2FIwEV7wTqOpu9rKT7yNnsiOiP1wNzaM7RP1w6TCycrjHqdwDHdXo8DcLW3D44o3SAiJEkHc58xlHb3nsc44yZkUeDJW0HfJfm+E1ECY8CtIWfW23Paa/d1IFiSOwMTANm2t5D0mo0u5hjCNg+FThV0juB0yX9l+1DSueqtghke4XSGSKiPrZvlrQSsGl73r6zfl7BWDF6nRfeTwC3Al8tmKXfvinpOSMXbf+xRJiIVvdOmIOAA0sFGU+2fyXpg6VzxMQmaUq782CbrrW1mNujKwbfQ20h7zFJU4A7gbVKh4oFGzEwQMAkmh6UKQKNlXar467A2rY/1z7hrW77osLRImKISXovsA+wJnAZsDVwAZDpYMPh18BRwEbAscBvbT9SNlLfXAvcQPNGYypwE82bj01LhoqJzfYPOo8l7dt9XZt22/9GdPXtYN4iWMR4ehftB9ARO5eXBj5QJFEsikvaPpRH0kykvZ/mfWcMuEHelFJtTyBJ36E5svEK2xu0d+5Pr2UUaUSU0fYE2oqmeLCZpBcAX7D9lsLRYhQknQX8lObN1N7A7sCnbJ9WNFgfdPcEknSZ7c1KZ4roVnOfRknfBZYFXk5TaN4ZuMj2e4oGi4hqSHoeMMX2rMJRYhQk9fxsYPuk8c4yUrU7gYAXt83QZgLYvrcdBxwRsTgebseLI2lp29dKWr90qBi1/7B9evv4a5J+DHyNptnisFumfZ1bFniupGOAD6Z3VcS42Nb2ppJm2T5I0leBX5QOFRHDrVchQdK6g1BIiAU6Ehg5Jt5A8b+7motAj0pagnYbpKRVaHYGRUQsjlvbbbn/DZwh6V7g5sKZYpRsn94WSp7fLl1ne5eSmfroeOCW9vEnafoGnAW8pFiimPBG9EToDOuA+gZ2PNR+f1DSGsDdNFPCIiIWx8AWEmKB/mh7j9Iheqn5ONiuwC7AFsAPaLblfsb2T4sGi4hqSHoZsCLwv7b/XjpPLJikHWheE/5A8yF0LWD3Whp7S1oBwPbs9nod2zeWTRVRP0n7A4cD/wB8i+ZD2lG29y8aLCKGWvdR7xguku4E/hN4GPgT8GvbM8qmalRbBAJoe3X8A80b/bNsX1M4UkQMuV7TlyATmIaFpBnAP9q+rr1+PnCC7ReWTbb48m8zYjBIWhqYbPtvpbNExHAb5EJCzJ+k3YElgGWANYDX07zn/FLRYFRcBMqb4YgYC21jaGimL93I3CMNmcA0BNp+HZsuaG0Y5d9mRDmD3AA0IobXIBcSYuFIWgY4zfbLi2epuAg0B7ge6Iz+zZvhiOibbM8dTpKOpukPd1y7tCuwhO09y6Xqr/zbjBh/kh4FrqYZ4ax22TU9t0REeYNUSIjhVXMR6J+BnWgKQUfbvqxwpIioSM2jjmvWHtP4F+Y2Sz4f+LbtR576p4ZL/m1GjL92SuTn2sv9O0dOIyJiYpL0e+YORoC5m1KmFoo0N0itRaAOSRsBHwNWtb1j6TwRMdy6tvwfQvPcAmTLf5SXf5sR5Ul6IXAwTe+Oz9q+rXCkiBhig1xIiPmTtHLX5bI0x/pm2767UKQnVFsEkiTgNcC7gKWA6bZPK5sqIoadpOk9lrPlf0iMGFcNFY2pzr/NiHIkHc7c5xYBLwPWtb1suVQRMewGuZAQoyPp3cBXgEeBQ20fUjZR3UWgW4BbgWOBOzrruSMaETFxpV9ORIyFtnnrk9j+wXhniYj6DGIhIUannUz7auB+4DeDMJF2ydIBxtBZNHdktupaM5AiUET0RXqvDKXJkqbRDA24vaYRzpImA+8BNgImd9azEyhi7Nn+gaSnAS+geb95ne2/F44VEfX4MM3zy/3Ab2iOfsdwUGfnlqQHSoeBiotAtt9dOkNEVE8L/i0xYO4ADqcZtbq6pHuBPWxfUjZWXxwLXEtzFPpgmsln1xRNFDFBSHod8D3gRprXhrUlfcD2L8omi4hKDFwhIeZP0s9obgpMlXQKzWvDhmVTNWo+DvZ84DvAarY3lrQpsJPtzxeOFhGVkPR5258pnSMWnaTtgK/b3rJ0lsXVOeomaZbtTSUtBZxve+vS2SJqJ+la4PW2b2iv1wFOtf2CsskiYph1FRK2B86jKSRsY/uZRYPFAkl6Wa912+eOd5aRai4CnQt8HPhep/+DpCttb1w2WUQMM0mrAc9uL2+z/eeSeWLxSdqyhp1Aki6y/SJJ5wF70ex6uigTRCLGnqSLbW/VdS2a/39bzefHIiLma5ALCTF6klYepGbe1R4HA5a1fVHzGvyEx0qFiYjhJmkz4LvAikBn5O+akv4K7GX70mLhYtQkrQh8luaOmoFzaY5O1eAISSsB+wOnAMsDB5SNFDFhXCLpNOAnNM8tbwMulvQWyGCSiFg03cWeQSskRG+SPmd7//bxi4H/ApaStATwbtunFg0ITCodYAzd1W7FNYCknYHby0aKiCF2DLCP7Q1sv7L9egGwL9BrNHcMpqOB+2g+oL29fVzF35/to2zfa/tc21Ntr2r7u6VzRUwQk4E/04yG3wH4C03vsTcAry8XKyKGkaTPdT1+cTv5+ipJf5G0Y8FosWDdfz9fAN5m+1nAS9vr4mo+DjYVOALYFrgX+D2wm+0/lMwVEcNJ0vW213uKX7vB9rrjnSkWnqTLbG+2oLVhJOklNMfAvknTFHoj4FO2LygaLCIiIhZK9wRaSWcBn7b9W0kvAH5se1rZhPFUOj0aRz7udV1KtTuBbN9k+5XAKsALbG+XAlBELIZfSDpV0i6Stm2/dpF0KvC/pcPFqD3UNoMGniicPFQwTz99EzgH+BlwPnAY8K2SgSImCknPl3SWpCvb600lZXBARCyq7p4mz7D9WwDb1wJzykSKUfJTPO51XUTNO4G+AHzZ9l/b65WAj2aST0QsKkmvBd5IV2No4BTbp5VLFQuj7e30A5reTgLuoTmffXnRYH0gaYbtF0q6zvb67dpA3HGKqF0GkkREP43YCfTE417XMVgkPQ48QPM+cxngwc4vAZNtL1UqW0fNRaAnvfHNf5iIiACQNAXA9n2ls/RL13SwabYvlzQJmJkt4xFjrzMdbMQxgCqOmkbE+BuGQkIMr5qngy0haWnbjwBIWgZYunCmiBhSko4EDrN9RY9fWw7YBXjE9vHjHi5GTdIBI64BsF3DhLDXAXTtaloWeH+5OBETSgaSRETf2F6idIaoV81FoOOBsyR1pr7sQXMEICJiUXwL2F/SJsCVNJNfJgPrAVNopk6lADT43g98rXSIsWD7rhHX9wMXFooTMdF8iGYgyQsk3UYzkGTXspEiIiKerNrjYACS/h/wyvbyDNu/LJknIoafpOWBLYHVaRoKX2P7urKpYrTSIycixoKkZ9m+o90ZOsn27NKZIiIieqm6CBQRMRba46XPSfFn+KQ3XESMhTy3RETEsKj5OFhERN9J2gn4CvA0YO122tTBtncqmyxGaaqkU0Yu1vr3J+n1wDOAc23fXDpPRERERJSVIlBExMI5EHgRcA6A7cskrV00USyMN5YOMFZ6FLcEbEfTl+SR8U8UMaFsKql72qAA255SKlBEREQvE6IIJGkysITtB0pniYih96jtv3WmSrVyrnZI2D63dIYxtAHw3q5rAS+wfVqhPBETyRXpNxYREcOg+iKQpD2ALwOPSjrU9iGlM0XEULtK0j8CS0haD9gb+E3hTBEAs0cWuSSlOW1EREREPGFS6QDj4F+AFwBrA+8snCUiht+HgY1ojtecANwH7Fs0UURjI0k3SLpI0kmS9gQmlw4VMUG8tXSAiIiI0ah+Olj3tAZJ59nevnSmiIgop9bpbpJWBpYAlqe58fE24H3Ay4Grbd9VMF5E1drWA++huUnwRPHV9p7FQkVERPRQ7XEwST+j6dPRmQQjYMOyqSJi2PWaLAX1TpeqjaQ3AIdQ4XQ323e3D+8EbgLOkjSLpgh0V/sVEWPjWOBa4DXAwTQN2a8pmigiIqKHancCSXpZr/XKm4JGxBiTdD6wAvAF4M+d9Ty3DAdJM4BXAOd0mrhKusL2JmWT9YekacBL28vzbV9eMk/ERCFppu3NJc2yvamkpWj+D25dOltERES3ancCAS+3/dnSISKiLrZfKmlH4FPA2cCXbd+3gB+LwVHtdDdJ+9Ac/zqpXTpO0hG2Dy8YK2KieLT9/ldJGwN3AKsWzBMREdFTzY2hh35rf0QMJtun2n4JcBVwuqSPlc4UozbPdDdJh1PPdLf3AC+2fYDtA4CtaYpCETH2jpC0ErA/cApwNc102oiIiIFS83GwW4FDR67bftJaRMRotSO3O0+coimmT7a9RLlUMVqSlgU+Dbya5u/vl8DnbD9cNFgfSLoC2KrzZ2kb1V5cy1G3iIiIiFh8NR8H60xI0YJ+Y0TEaNleoXSGWHS2HwQ+LemL7fX9hSP103TgQkknt9dvAr5fME/EhCHpgF7rtg8e7ywRERHzU/NOoJmdpp8REf0iafte67bPG+8ssfAkbQL8EHhGu3QXsLvtK8ul6h9JWwDbtZfn255ZMk/ERCHpQeAymqNgnf5A2P5qsVARERE91LwT6IzSASKiSh9vv28H/Kp9bCBFoOHwPWA/22cDSNoBOALYtmSoxdEe+/ogsC5wBfBt24+VTRUx4axBMxb+DTSj4o+2PatspIiIiCereSfQ1sBVtme311OADWxfWDZZRNQguw2Hk6TLbU9b0NowkfRjmp0H5wMhsL+tAAAUP0lEQVSvBf5ge9+yqSImprY59H8Am9l+Uek8ERERI9W8E+g7wBZd1/f3WIuIWFR1VtDrd5Ok/YFj2+vdgJsK5umHDTvNnyV9H7iocJ6ICUfSq4F3AUsD/wnsVTZRREREbzUXgeSubU6250iq+c8bEeNA0n7tw1W7Hmfy4PDYEzgIOKm9Pr9dG2bd/UcekzIPIaKA/wUuBW4H9gD2kITtncrGioiImFfNRZGbJO1Ns/sHmjsyw363NyLK60wHO7LrcQwJ2/cCe5fO0WfTJN3XPhawTHstwLanlIsWMWG8vHSAiIiI0ai5J9CqwGHAK9qlM4F9bd9ZLlVERJQk6Wx6HOWz/Yoevz0iIiIioirVFoEiIsaCpFWAfwU2AiZ31lNEGA6SXkizQ+Y4mkk+ANieUSxURERERMQ4mVQ6wFiRtKakkyXd2X6dKGnN0rkiYugdTzP+d22a3jJ/AC4uGShGz/YM25cAD7WPZ6QAFBERERETRbVFIGA6cAqwRvv1s3YtImJxrGz7+8Cjts+1vSdzj53G8Mg22IgYE5ImS1qudI6IiIheai4CrWJ7uu3H2q9jgFVKh4qIodeZxHS7pB0lbQ48o2SgGD1Js9umyZtKuq/rOiJisUnaA7gFuF7Sx0rniYiIGKnm6WB3S9oNOKG9fidwd8E8EVGHz0taEfgocDgwBfhI2UgxWrYz0S0ixtK/AC8A7gd+AxxSNk5ERMS8qm0MLem5NB/QtqHZ9v8bYG/bfywaLCIiipG0Ra9125eOd5aIqI+kS21v0T4+z/b2pTNFRER0q7YIFBExFiTtALyepsfYocDKwCdtn1EyV8yfpA1sXyNpDnA9cBvNlDAAZ7pbRCwOST+juem4PXAezfPLNrafWTRYRETECNUWgSRNp0fjz7aJa0TEIpF0NXA0zZj4dwKzgaNsb1o0WMxX5468pFcC+wMXAV+0fU/haBFRAUkv67Vu+9zxzhIRETE/NfcE+nn7/cs0H9YiIvrh77YPkbSH7bMAJD1WOlQs0NMAbJ8JnCnpLcDPJZ0KHGr7oaLpImLYvdz2Z0uHiIiIWJBqdwJ1SJppe/PSOSKiDpJupTkGtl/7XcC+ttcqGizmS9I7bP9I0n5dy0sCuwGr2n5WoWgRUYHuXkARERGDrOadQB11V7kiYrwdCazQ9R3gqHJxYjRs/6h9OHI62InjnSUiqrTqiCIzALYPLREmIiLiqVS7E0jSFTQFoHWBG2ju1jt9OyKiHyQtD2D7/tJZYuFJWtb2g6VzREQdJN0OfIe5DecBsH1QmUQRERG91VwEem6vdds3j3eWiKiHpI2BY4FntEt3Ae+yfVW5VDFakrYBvg8sb/s5kqYBH7C9V+FoETHE0n4gIiKGxaTSAcaQn+IrImJxHAHsZ/u5tp8LfJTmaFgMh68DrwHuBrB9Oc1I54iIxXFG6QARERGjUXNPoFPb71OBG2mPgwE5DhYRi2M522d3LmyfI2m5koFi4di+RZrnxMbjpbJERDVOkrSC7dkAkqYAG9i+sHCuiIiIeVRbBLK9CWR7bkT03U2S9qc5EgbNdKmbCuaJhXOLpG0BS1oK2Ae4pnCmiBh+3wG6p4Pd32MtIiKiuJqPg3XkCFhE9NOewCrASe3XKu1aDIcPAh8Cng3cBmzWXkdELA65q9Gm7TlUfLM1IiKGV7UvTpLe0j58etdjbJ9UKFJEVMD2vcDenWtJS9p+rGCkWAi27wJ2LZ0jIqpzk6S9aXb/AOxFdolGRMQAqnk62PQey7adO/YRscgk/TPwGeALwO7AesC/2k5z6CEg6ehe63ltiIjFIWlV4DDgFe3SmcC+tu8slyoiIuLJqi0CRUSMBUlXAW8CLgM2BB4DzrS9QdFgMSqSbgNupunp9MSHM9snFgsVERERETFOqu0JJOn5ks6SdGV7vamkz5TOFRFD72Hb1wPX2b7Z9m3Aw6VDxaitBXyeZiz8LsCDKQBFxOKStKakkyXd2X6dKGnN0rkiIiJGqrYIBBwJfBJ4FMD2LOAdRRNFRA1+D2B7CwBJKwBziiaKUbM9x/ZpwOeAB4F/KRwpIuowHTgFWKP9+lm7FhERMVCqPQ4m6WLbW3WPiJd0me3NSmeLiLpIWtr2I6VzxIJJej/Ncb4bgOm2ZxaOFBEV6PUeM+87IyJiEFU7HQy4S9I6tCPiJe0M3F42UkTUQNLGNP2AJnct/7BQnFg436UpAK0F7CAJANublgwVEUPvbkm7ASe01+8E7i6YJyIioqeadwJNBY4AtgXupTnCsavtm4sGi4ihJulAYAeaItBpwGuBX9neuWSuGB1Jz+21nteGiFgc7XPL4cA2NDcgfwPsbfuPRYNFRESMUG0RqEPScsAk27NLZ4mI4SfpCmAaMNP2NEmrAcfZflXhaDFKkrYD1rM9XdIqwPK2f186V0RERETEWKv2OJiklYEDge0AS/oVcLDtbM2NiMXxkO05kh6TNIVmzPhapUPF6LQ7ubYE1qdp2roUcBzwkpK5ImK4SZpO24Kgm+09C8SJiIh4StUWgYAfAecBb22vdwV+DLyyWKKIqMElkp5OM4FwBnA/cEHZSLEQ3gxsDlwKYPtP7YS3iIjF8fP2+5eBfy0ZJCIiYn6qPQ4m6UrbG49Yu8L2JqUyRURdJD0PmGJ7VuEoMUqSLrL9IkmX2t6iPTJ8QRpDR0Q/dE+ljYiIGESTSgcYQ6dLeoekSe3X24Fflg4VEcNP0lskHQp8GFindJ5YKD+R9D3g6ZLeB5xJs6srIqIf6ry7GhER1ah5J9BsYDlgTrs0CXigfWzbU4oEi4ihJunbwLrMHQO8C3Cj7Q+VSxULQ9KrgFcDAn5p+4zCkSJiyLVDA0zz+nADzfOLs8swIiIGTbVFoIiIsSDpWmADt0+ekiYBV9neoGyymB9J6wKr2f71iPXtgNtt31gmWUTUoB0R/yS2bx7vLBEREfNT83EwJO0k6ZD26/Wl80REFW4AntN1vVa7FoPt68B9Pdb/1v5aRMTi8FN8RUREDJRqdwJJ+hKwFXB8u/RO4BLbnyyXKiKGnaRzaZ5bLmqXtgIuoSkmYHunQtFiPiRdbHurp/i1DA2IiMXSHgcDmArcSI6DRUTEgKq5CDQL2Mz2nPZ6CWBmXowjYnFIetn8ft32ueOVJUZP0vW213uKX7vB9rrjnSki6pPpYBERMeiWLB1gjD0duKd9vGLJIBFRB9vnSlqNZgcQwEW27yyZKUblEknvsz3PJDBJ7wVmFMoUEfWp8+5qRERUo+Yi0BeBmZLOptmSuz3wibKRImJYSTrF9k6S3g58BTiH5rnlcEkfs31i0YCxIPsCJ0valblFny2BpwFvLpYqIqog6S3tw6d3Pcb2SYUiRURE9FTtcTAASasz7936O0rmiYjhJem3treWdDnwqs7uH0mrAGfY3qxswhgNSS8HNm4vr7L9fyXzREQdJE3vsWzbe457mIiIiPmotggkaRlgHdtXSnoH8Ezgh7Z7TYeJiJgvSacCHwJOtb1R1/okYJbtjZ/yhyMiIiIiIgZAzUWgXwKrAXcAdwKzgXVtv6ZosIgYSpJeCnyept/DI8AJ7S/tAtxg+8OlskVERFmSng98B1jN9saSNgV2sv35wtEiIiLmUXMR6GqaLf+32H52u3a57Wllk0XEsJK0AfBuYBWafkD3ARcCP+pMIoyIiIlH0rnAx4HvdaaDSboyu0QjImLQ1NwY+lGa6WB3S1qJ5gNbRMQis32NpAOBzjjxG2w/XDJTREQMhGVtXyTN83bzsVJhIiIinkrNRaAVgUtoij+Xtmt1bnuKiDEnaUngC8AewB9pnlvWapuBftr2oyXzRUREUXdJWof2vaaknYHby0aKiIh4smqPg0VE9JOkrwErAB+xPbtdmwIcAjxke5+S+SIiohxJU4EjgG2Be4HfA7vavrlosIiIiBGqLQJJutT2FqVzREQdJF0PPN8jnjQlLQFca3u9MskiImJQSFoOmNS5WRARETFoJpUOMIbSAygi+skjC0Dt4uPkqGlExIQmaWVJhwHnA+dI+oaklUvnioiIGKnmItD6kmZ1fV0haVbpUBExtK6W9K6Ri5J2A64tkCciIgbHj4C/AG8Fdm4f/7hoooiIiB5qPg52FfC6kes5mx0Ri0LSs4GTgIeAGe3ylsAywJtt31YqW0RElNVrHLykK2xvUipTRERELzVPB/t7Cj4R0S9tkefFkl4BbNQun2b7rIKxIiJiMJwu6R3AT9rrnYFfFswTERHRU807gbaz/avSOSIiIiKibpJmA8sBc9qlScAD7WPbnlIkWERExAg19wS6XtL3Jf0CQNKGkt5TOlRERERE1MX2CrYn2V6y/ZrUrq2QAlBERAySmncC/QKYDnza9jRJSwIzczY7IiIiIvpN0k7A9u3lObZ/XjJPRERELzXvBHqm7Z/Qbsu1/RjweNlIEREREVEbSV8C9gGubr/2kfTFsqkiIiKerObG0A9IWhkwgKStgb+VjRQRERERFXodsJntOQCSfgDMBD5ZNFVERMQINReB9gNOAdaR9GtgFZpJDRERERER/fZ04J728Yolg0RERDyVaotAti+V9DJgfUDAdbYfLRwrIiIiIurzRWCmpLNp3nduD3yibKSIiIgnq7kx9H691m0fOt5ZIiIiIqJuklYHtmovL7J9R8k8ERERvdTcGPrjwAo9viIiIiIi+kbSMsDKtk8BlgV2lpTR8BERMXBq3gl0qe0tSueIiIiIiLpJ+iWwGnAHcCcwG1jX9muKBouIiBih2p5AwFRJ/w08DPwJ+LXtEwtnioiIiIj6rAVsDNxi+9kAki4vGykiIuLJai4CvRFYAlgGWAN4r6Ttbe9TNlZEREREVOZRmulgd0taiaY5dERExMCp9jjYSJKWAH5oe9fSWSIiIiKiHpL+AMxh3uKPbU8tkygiIqK3CVEEkvRsYCXbV5bOEhERERERERFRQrXTwSR9RdKdkj4NnA78p6Svlc4VEREREXWRdGnpDBEREaNRc0+gN9M06LsOWJ3mrPasookiIiIiokbpARQREUOh5iLQfbbvlPQH2w8DSHqkdKiIiIiIqM76krpvNoqmJ9CmpQJFRET0UnMR6AXti/G67XcBac4XEREREf32e+ANpUNEREQsSM1FoA1KB4iIiIiICeHvtm8uHSIiImJBqp4OJmka8NL28nzbl5fMExERERH1kbSd7V+VzhEREbEgNU8H2wc4Hli1/TpO0ofLpoqIiIiICl0v6fuSfgEgaUNJ7ykdKiIiYqRqdwK1fYC2sf1Ae70ccEEa9EVEREREP7XFn+nAp21Pk7QkMNP2JoWjRUREzKPanUA0jaAf77p+nIzvjIiIiIj+e6btnwBzAGw/xrzvQyMiIgZCzY2hpwMXSjq5vX4TcHTBPBERERFRpwckrQwYQNLWwN/KRoqIiHiyao+DAUh6IfCS9vJ82zNL5omIiIiI+kjaAjgc2Bi4ElgF2Nn2rKLBIiIiRqi6CDSSpPcDzwL+y/bVpfNERERERB3aPkDr07QfuM72o4UjRUREPEm1RaC2MfQ8S8BUYCvgVtv3jX+qiIiIiKiNpP16rds+dLyzRERE/P/27h3EriqK4/B/mUpMBEV8BiJBfKBoQAyoaJcmELTRRpBExSoiFlZW1hZpLRIDvirFBwpiZRARK1FEECx8RlArgyZDCMvCK04m10TmJrPjme+DYdjnNL963b33OZ0p3wm0IcnOZetK8q4dQAAAnGVPJ3l+dAQAnMmUh0BL3f3t8gdVtTQqBgCAyfqpu58dHQEAZzLlIdD1VXUkyR9JfkzyTpKLxyYBADBBW6vqzSTHkhxO8lF3vz64CQBOMdkhUHdvTJKq2pDk2iQPJtlSVQ8nObRylxAAAKzSffnrKoILk1yd5LGqure7nxybBQAnm+zF0PNU1a4klyb5wBAIAIBzYfYj5Ivd/dDoFgBYbnJDoKp6L8n+JG/5NCcAAGupqq5Jckl3fzG6BQBWumB0wDmwP8mjSb6vqn1VdcvoIAAApquqnquqn6vqmSTvJ3m1qvaN7gKAlSa3E+hvVbU5ye4ke5L8muRAkpe6++jILgAApqWqvk5yV5KvklyV5HiSz7v75qFhALDCFHcC/e2yJFck2ZTklyQ7krw9tAgAgCn6rbt/TvJNdx/r7hNJlkZHAcBKk/s6WFXtTfJIko1JDibZ1t2HZ+++G9kGAMAk3VhVnye5bva/kmwd3AQAp5jcECjJ9iRPdfehOe9uWOsYAAAm76bRAQDwX0z2TiAAAFgrVXVbkntmyw+7+7ORPQAwz5TvBAIAgHOuqp5M8kqSy2d/L1fVE2OrAOBUdgIBAMACZvcA3dndv8/WFyX5uLtvHVsGACezEwgAABZTSU4sW5+YPQOA88oUL4YGAIC1dDDJJ1X1xmx9f5IXBvYAwFyOgwEAwIKq6vYkd8+WH3b3pyN7AGAeQyAAADjLqurxJFcmea27vxzdAwCJ42AAALCQ2cXQJz1KsjXJHUl+WPsiAJjPEAgAABazIcnOZetK8q4dQACcbwyBAABgMUvd/e3yB1W1NCoGAP6NIRAAACzm+qo6kuSPJD8meSfJxWOTAOBUF4wOAACA/7Pu3tjdm5JcneSBJEeTbKmqh6tqy9g6APiHr4MBAMBZVlW7klya5IOVR8UAYBRDIAAAWIWqei/J/iRvdffx0T0AcCaOgwEAwOrsT/Joku+ral9V3TI6CABOx04gAABYQFVtTrI7yZ4kvyY5kOSl7j46sgsAVrITCAAAFnNZkiuSbEryS5IdSd4eWgQAc/hEPAAArEJV7U3ySJKNSQ4m2dbdh2fvvhvZBgDzGAIBAMDqbE/yVHcfmvPuhrWOAYAzcScQAAAAwDrgTiAAAACAdcAQCAAAAGAdMAQCAAAAWAcMgQAAAADWgT8Bvz0ZF3DjfDgAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TOP 5 features\n",
        "sel_ = SelectKBest(f_classif, k=5).fit(X_scaled, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "id": "KSGhE7K5hUqO",
        "outputId": "0c7684ec-af07-4b5a-a3e0-5c6b81fcb9c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Здоровье от 1 до 10', 'Были ли нарушения сна', 'P', 'G',\n",
              "       'Была попытка суицида?'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0FH6fE0hhzK"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OVxUbs4lhFwd"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0morjvDohFyU"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cE49CtiChHBb"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_chi2_scaled # Были ли нарушения сна, Динамека веса за год, Аллергии, ГБ"
      ],
      "metadata": {
        "id": "kK2YEY2VS9kV"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_anova_scaled # Были ли нарушения сна, Аллергии, P, G"
      ],
      "metadata": {
        "id": "aW029ll0S9nm"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many times and which features were the most influential?\n",
        "\n",
        "# Аллергии 4\n",
        "# Были ли нарушения сна  3\n",
        "# P 3\n",
        "# G 3\n",
        "# Динамека веса за год 1 \n",
        "# ГБ 1\n",
        "# Стаж шизофр 1"
      ],
      "metadata": {
        "id": "JGbIT52RS9pu"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "cj_NC7LORQoY",
        "outputId": "84069b2f-ba4f-4ccd-f6f1-404181701d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
            "0    1.0        32.0                                 4.0   \n",
            "1    1.0        26.0                                 2.0   \n",
            "2    1.0        49.0                                 2.0   \n",
            "3    1.0        50.0                                 2.0   \n",
            "4    1.0        39.0                                 2.0   \n",
            "..   ...         ...                                 ...   \n",
            "175  1.0        53.0                                 4.0   \n",
            "176  1.0        36.0                                 4.0   \n",
            "177  0.0        38.0                                 2.0   \n",
            "178  1.0        27.0                                 4.0   \n",
            "179  1.0        36.0                                 4.0   \n",
            "\n",
            "     Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
            "0                            0.0                               0.0   \n",
            "1                            0.0                               0.0   \n",
            "2                            0.0                               0.0   \n",
            "3                            0.0                               0.0   \n",
            "4                            0.0                               0.0   \n",
            "..                           ...                               ...   \n",
            "175                          0.0                               0.0   \n",
            "176                          0.0                               0.0   \n",
            "177                          0.0                               1.0   \n",
            "178                          1.0                               0.0   \n",
            "179                          0.0                               0.0   \n",
            "\n",
            "     Удовлетворенность семеными отношениями  \\\n",
            "0                                       5.0   \n",
            "1                                       5.0   \n",
            "2                                       5.0   \n",
            "3                                       5.0   \n",
            "4                                       5.0   \n",
            "..                                      ...   \n",
            "175                                     3.0   \n",
            "176                                     2.0   \n",
            "177                                     4.0   \n",
            "178                                     2.0   \n",
            "179                                     5.0   \n",
            "\n",
            "     Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
            "0                                          0.0                  7.0   \n",
            "1                                          0.0                 10.0   \n",
            "2                                          1.0                 10.0   \n",
            "3                                          1.0                  7.0   \n",
            "4                                          1.0                  7.0   \n",
            "..                                         ...                  ...   \n",
            "175                                        0.0                  6.0   \n",
            "176                                        1.0                 10.0   \n",
            "177                                        1.0                  4.0   \n",
            "178                                        0.0                  8.0   \n",
            "179                                        1.0                  3.0   \n",
            "\n",
            "     Были ли нарушения сна        ИМТ  Операции  ЧМТ  Насл отягощенность  \\\n",
            "0                      1.0  24.012346       0.0  1.0                 0.0   \n",
            "1                      1.0  20.244898       0.0  0.0                 0.0   \n",
            "2                      0.0  29.752745       0.0  1.0                 0.0   \n",
            "3                      1.0  22.093170       1.0  2.0                 0.0   \n",
            "4                      0.0  20.761246       1.0  2.0                 1.0   \n",
            "..                     ...        ...       ...  ...                 ...   \n",
            "175                    1.0  34.220043       1.0  0.0                 1.0   \n",
            "176                    1.0  18.710949       1.0  2.0                 0.0   \n",
            "177                    1.0  27.434843       1.0  1.0                 1.0   \n",
            "178                    1.0  19.974407       0.0  1.0                 1.0   \n",
            "179                    0.0  28.027681       0.0  2.0                 0.0   \n",
            "\n",
            "         Дебют  Частота госпит  Стаж шизофр     P     N     G  \\\n",
            "0    28.299999             0.0          3.7  11.0  11.0  18.0   \n",
            "1    26.000000             1.0          2.0  10.0  25.0  36.0   \n",
            "2    26.000000             2.0         23.0   9.0  16.0  23.0   \n",
            "3    16.000000             1.0         34.0  13.0  13.0  20.0   \n",
            "4    34.000000             0.0          4.0   9.0  13.0  22.0   \n",
            "..         ...             ...          ...   ...   ...   ...   \n",
            "175  26.000000             0.0         27.0  12.0  16.0  31.0   \n",
            "176  13.000000             2.0         23.0  19.0  26.0  47.0   \n",
            "177  33.000000             2.0          5.0  10.0  10.0  27.0   \n",
            "178  19.000000             0.0          8.0  11.0  18.0  31.0   \n",
            "179  33.000000             1.0          3.0  13.0  21.0  33.0   \n",
            "\n",
            "     Была попытка суицида?  \n",
            "0                      0.0  \n",
            "1                      0.0  \n",
            "2                      0.0  \n",
            "3                      0.0  \n",
            "4                      0.0  \n",
            "..                     ...  \n",
            "175                    0.0  \n",
            "176                    0.0  \n",
            "177                    1.0  \n",
            "178                    0.0  \n",
            "179                    0.0  \n",
            "\n",
            "[180 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "x1gPm1eqRSx8",
        "outputId": "10ac41e1-3f40-4ea2-b821-8bfcf7428706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      1.0\n",
            "1      1.0\n",
            "2      0.0\n",
            "3      1.0\n",
            "4      0.0\n",
            "      ... \n",
            "175    1.0\n",
            "176    0.0\n",
            "177    1.0\n",
            "178    0.0\n",
            "179    0.0\n",
            "Name: psqi больше 5, Length: 180, dtype: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using best features\n",
        "# X = X[['Аллергии', 'Были ли нарушения сна', 'P', 'G']]\n",
        "\n",
        "# X = X[['Забол кожи', 'Были ли нарушения сна', 'Панкреатит', 'ГБ']]\n",
        "\n",
        "# X = X[['Удовлетворенность материальным положением', 'Были ли нарушения сна', 'Забол кожи', 'P', 'G']]\n",
        "\n",
        "# X = X[['Забол кожи', 'Были ли нарушения сна', 'Панкреатит', 'ГБ', 'P']]\n",
        "\n",
        "# X = X[['P', 'G', 'ИМТ', 'Были ли нарушения сна', 'N']]\n",
        "\n",
        "# X = X[['Были ли нарушения сна', 'Забол кожи', 'P']]\n",
        "\n",
        "# X = X[['Были ли нарушения сна', 'Операции', 'P', 'G']]\n",
        "\n",
        "\n",
        "# X = X[['Полных лет', 'Дебют', 'Стаж шизофр', 'P', 'N', 'G']]\n",
        "\n",
        "\n",
        "\n",
        "# X = X[['Была попытка суицида?', 'Дебют', 'Стаж шизофр', 'P', 'N', 'G']]\n",
        "\n",
        "# recursive feature elimination\n",
        "# X = X[['Полных лет', 'Дебют', 'Стаж шизофр', 'N', 'G']]\n",
        "\n",
        "# ANOVA\n",
        "X = X[['Здоровье от 1 до 10', 'Были ли нарушения сна', 'P', 'G', 'Была попытка суицида?']]\n",
        "\n",
        "# chi2\n",
        "# X = X[['Были ли нарушения сна', 'Операции', 'P', 'G', 'Была попытка суицида?']]\n",
        "\n"
      ],
      "metadata": {
        "id": "cA1BbqGaS9ru"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "JoxH9N4PxIe3",
        "outputId": "b8aa6832-731c-4775-d5d2-d6143cc15176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Здоровье от 1 до 10  Были ли нарушения сна     P     G  \\\n",
              "0                    7.0                    1.0  11.0  18.0   \n",
              "1                   10.0                    1.0  10.0  36.0   \n",
              "2                   10.0                    0.0   9.0  23.0   \n",
              "3                    7.0                    1.0  13.0  20.0   \n",
              "4                    7.0                    0.0   9.0  22.0   \n",
              "..                   ...                    ...   ...   ...   \n",
              "175                  6.0                    1.0  12.0  31.0   \n",
              "176                 10.0                    1.0  19.0  47.0   \n",
              "177                  4.0                    1.0  10.0  27.0   \n",
              "178                  8.0                    1.0  11.0  31.0   \n",
              "179                  3.0                    0.0  13.0  33.0   \n",
              "\n",
              "     Была попытка суицида?  \n",
              "0                      0.0  \n",
              "1                      0.0  \n",
              "2                      0.0  \n",
              "3                      0.0  \n",
              "4                      0.0  \n",
              "..                     ...  \n",
              "175                    0.0  \n",
              "176                    0.0  \n",
              "177                    1.0  \n",
              "178                    0.0  \n",
              "179                    0.0  \n",
              "\n",
              "[180 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e568150-f6b9-4710-a512-debce7d3ec40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>P</th>\n",
              "      <th>G</th>\n",
              "      <th>Была попытка суицида?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e568150-f6b9-4710-a512-debce7d3ec40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e568150-f6b9-4710-a512-debce7d3ec40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e568150-f6b9-4710-a512-debce7d3ec40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper functions file\n",
        "import os\n",
        "if not os.path.exists(\"helper_functions.py\"):\n",
        "    print(\"Downloading helper functions...\")\n",
        "    !wget https://raw.githubusercontent.com/Nikitaion/TensorFlowLearning/main/extras/helper_functions.py\n",
        "else:\n",
        "    print(\"Helper functions file already exists, skipping download...\")"
      ],
      "metadata": {
        "id": "ztJnG1gMpQKR",
        "outputId": "31f0ea47-3c67-4b81-ac56-99382ef629a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading helper functions...\n",
            "--2022-09-17 16:04:12--  https://raw.githubusercontent.com/Nikitaion/TensorFlowLearning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-17 16:04:12 (60.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create ModelCheckpoint callback to save model's progress\n",
        "# checkpoint_path = \"model_checkpoints/cp.ckpt\" # saving weights requires \".ckpt\" extension\n",
        "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "#                                                       montior=\"val_accuracy\", # save the model weights with best validation accuracy\n",
        "#                                                       save_best_only=True, # only save the best weights\n",
        "#                                                       save_weights_only=True) # only save model weights (not whole model)\n",
        "#                                                       # verbose=1) # don't print out whether or not model is being saved\n",
        "\n",
        "# Create a function to implment a ModelCheckpoint callback with a specific filename\n",
        "def create_model_checkpoint(model_name, save_path=\"model_experiments\"):\n",
        "  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name),\n",
        "                                            monitor=\"val_accuracy\", # was 'val_loss'\n",
        "                                            verbose=0, #only output a limited amount of text\n",
        "                                            save_best_only=True)\n"
      ],
      "metadata": {
        "id": "1mRN6S7XpPD6"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/valid/test split\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15)\n",
        "\n",
        "\n",
        "# Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "X_train_scaled = minmax_scaler.fit_transform(X_train)\n",
        "X_valid_scaled = minmax_scaler.transform(X_valid)\n",
        "X_test_scaled = minmax_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "EkYpF44DNQjU"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z2UDFlW2VQjH"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVC test\n",
        "from sklearn.svm import LinearSVC\n",
        "lsvc = LinearSVC(verbose=0)\n",
        "print(lsvc)\n"
      ],
      "metadata": {
        "id": "WfVPIUKhVQl0",
        "outputId": "edd85e03-ff27-4321-83c6-15177639b71a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearSVC()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
        "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
        "          verbose=0)\n"
      ],
      "metadata": {
        "id": "rkH2nDFWVZ1u",
        "outputId": "89a4730e-b161-40d6-cf3c-65c31069ae2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc.fit(X_train, y_train)\n",
        "score = lsvc.score(X_train, y_train)\n",
        "print(\"Score: \", score)"
      ],
      "metadata": {
        "id": "aLxy6i-0VQoc",
        "outputId": "5dfa41ca-7e80-4eda-da7a-e73545980159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score:  0.6461538461538462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(lsvc, X_train, y_train, cv=10)\n",
        "print(\"CV average score: %.2f\" % cv_scores.mean())"
      ],
      "metadata": {
        "id": "Q_UxjfdtVpo0",
        "outputId": "eeda7dd2-4cd2-41fa-d255-52601695cc1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV average score: 0.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "ypred = lsvc.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(X_test, y_test)\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "pM_YXgJdVz3a",
        "outputId": "797a2006-0e4b-4a47-96cb-20824506dfee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-5c076d8a5c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass-multioutput and binary targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cr = classification_report(X_train, y_train)\n",
        "print(cr)\n"
      ],
      "metadata": {
        "id": "8eBJBehCWD52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWVCdu65WBRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IhajJ-VgY1hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "# We are going to run it for k = 1 to 15 and will be recording testing accuracy, plotting it, showing confusion matrix and classification report:\n",
        "Range_k = range(1,130)\n",
        "scores = {}\n",
        "scores_list = []\n",
        "for k in Range_k:\n",
        "   classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "   classifier.fit(X_train, y_train)\n",
        "   y_pred = classifier.predict(X_test)\n",
        "   scores[k] = metrics.accuracy_score(y_test,y_pred)\n",
        "   scores_list.append(metrics.accuracy_score(y_test,y_pred))\n",
        "result = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(result)\n",
        "result1 = metrics.classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\",)\n",
        "print (result1)\n"
      ],
      "metadata": {
        "id": "RSLxn85kY1kV",
        "outputId": "22468757-3d11-4acc-aa09-700af3ba642c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 0 12]\n",
            " [ 0 11]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        12\n",
            "         1.0       0.48      1.00      0.65        11\n",
            "\n",
            "    accuracy                           0.48        23\n",
            "   macro avg       0.24      0.50      0.32        23\n",
            "weighted avg       0.23      0.48      0.31        23\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(Range_k,scores_list)\n",
        "plt.xlabel(\"Value of K\")\n",
        "plt.ylabel(\"Accuracy\")\n"
      ],
      "metadata": {
        "id": "LptwTAGvVhoZ",
        "outputId": "5350a5d2-7675-4174-f64d-9fea772a79e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u2JPXNFcZ7AP"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZJZUfx2VhrL"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3dilnjn2Vhte"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model1.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history1 = model1.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=40,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model1.name)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cdqTwvKMbi",
        "outputId": "2b5bc67e-ee4f-4cc5-862b-9b430b85276d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "5/5 [==============================] - 4s 539ms/step - loss: 0.6846 - accuracy: 0.5538 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6649 - accuracy: 0.6154 - val_loss: 0.6837 - val_accuracy: 0.5185\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6591 - accuracy: 0.6154 - val_loss: 0.6893 - val_accuracy: 0.5185\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6467 - accuracy: 0.6154 - val_loss: 0.7024 - val_accuracy: 0.5185\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6547 - accuracy: 0.6154 - val_loss: 0.7010 - val_accuracy: 0.5185\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6454 - accuracy: 0.6154 - val_loss: 0.6674 - val_accuracy: 0.5185\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6403 - accuracy: 0.6154 - val_loss: 0.6680 - val_accuracy: 0.5185\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6455 - accuracy: 0.6154 - val_loss: 0.6697 - val_accuracy: 0.5185\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6376 - accuracy: 0.6154 - val_loss: 0.6433 - val_accuracy: 0.5185\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6358 - accuracy: 0.6154 - val_loss: 0.6382 - val_accuracy: 0.5185\n",
            "Epoch 11/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.6347 - accuracy: 0.6154 - val_loss: 0.6333 - val_accuracy: 0.6667\n",
            "Epoch 12/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6314 - accuracy: 0.6538 - val_loss: 0.6290 - val_accuracy: 0.6667\n",
            "Epoch 13/40\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6257 - accuracy: 0.6615 - val_loss: 0.6281 - val_accuracy: 0.6667\n",
            "Epoch 14/40\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6238 - accuracy: 0.6538 - val_loss: 0.6310 - val_accuracy: 0.6667\n",
            "Epoch 15/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6245 - accuracy: 0.6615 - val_loss: 0.6410 - val_accuracy: 0.6296\n",
            "Epoch 16/40\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6207 - accuracy: 0.6538 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
            "Epoch 17/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6178 - accuracy: 0.6462 - val_loss: 0.6518 - val_accuracy: 0.6667\n",
            "Epoch 18/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.6538 - val_loss: 0.6689 - val_accuracy: 0.6667\n",
            "Epoch 19/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6285 - accuracy: 0.6692 - val_loss: 0.6479 - val_accuracy: 0.6667\n",
            "Epoch 20/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6299 - accuracy: 0.6615 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
            "Epoch 21/40\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.6315 - accuracy: 0.6769 - val_loss: 0.6502 - val_accuracy: 0.7037\n",
            "Epoch 22/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6302 - accuracy: 0.6769 - val_loss: 0.6470 - val_accuracy: 0.5926\n",
            "Epoch 23/40\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6116 - accuracy: 0.6692 - val_loss: 0.6747 - val_accuracy: 0.6667\n",
            "Epoch 24/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6396 - accuracy: 0.6462 - val_loss: 0.6990 - val_accuracy: 0.6296\n",
            "Epoch 25/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6295 - accuracy: 0.6692 - val_loss: 0.6464 - val_accuracy: 0.5926\n",
            "Epoch 26/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6246 - accuracy: 0.6615 - val_loss: 0.6441 - val_accuracy: 0.7037\n",
            "Epoch 27/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6276 - accuracy: 0.6615 - val_loss: 0.6443 - val_accuracy: 0.5926\n",
            "Epoch 28/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6174 - accuracy: 0.6615 - val_loss: 0.6876 - val_accuracy: 0.6667\n",
            "Epoch 29/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6274 - accuracy: 0.6462 - val_loss: 0.7291 - val_accuracy: 0.6296\n",
            "Epoch 30/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6428 - accuracy: 0.6462 - val_loss: 0.6745 - val_accuracy: 0.6667\n",
            "Epoch 31/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6153 - accuracy: 0.6769 - val_loss: 0.6389 - val_accuracy: 0.7037\n",
            "Epoch 32/40\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.6462 - val_loss: 0.6399 - val_accuracy: 0.5926\n",
            "Epoch 33/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6222 - accuracy: 0.6846 - val_loss: 0.6394 - val_accuracy: 0.5926\n",
            "Epoch 34/40\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6100 - accuracy: 0.6846 - val_loss: 0.6547 - val_accuracy: 0.6667\n",
            "Epoch 35/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6174 - accuracy: 0.6615 - val_loss: 0.6898 - val_accuracy: 0.6667\n",
            "Epoch 36/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6351 - accuracy: 0.6538 - val_loss: 0.6929 - val_accuracy: 0.6667\n",
            "Epoch 37/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6394 - accuracy: 0.6538 - val_loss: 0.6981 - val_accuracy: 0.6667\n",
            "Epoch 38/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6306 - accuracy: 0.6538 - val_loss: 0.6733 - val_accuracy: 0.6667\n",
            "Epoch 39/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6169 - accuracy: 0.6615 - val_loss: 0.6613 - val_accuracy: 0.6296\n",
            "Epoch 40/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6135 - accuracy: 0.6692 - val_loss: 0.6509 - val_accuracy: 0.6296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "KRbfjDQWqt0l",
        "outputId": "dc38af23-99de-476a-b020-c6203ffc0624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5792 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5792427659034729, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.models.load_model(f\"/content/model_experiments/{model1.name}\")\n",
        "model1.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQgxT9Qd5r8y",
        "outputId": "eb8e3bf8-77cd-42ac-d8fd-ec23935d56e2"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step - loss: 0.6159 - accuracy: 0.8696\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6159473061561584, 0.8695651888847351]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SowPTdIT6Fwq"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history2 = model2.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=40,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model2.name)])"
      ],
      "metadata": {
        "id": "q9VW_1RycyHm",
        "outputId": "60ebc7f3-3b0d-4884-b9dd-cc0ec64d934f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "5/5 [==============================] - 1s 212ms/step - loss: 0.6803 - accuracy: 0.5385 - val_loss: 0.6863 - val_accuracy: 0.5185\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6606 - accuracy: 0.6154 - val_loss: 0.6812 - val_accuracy: 0.5185\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6603 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6483 - accuracy: 0.6154 - val_loss: 0.7010 - val_accuracy: 0.5185\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6540 - accuracy: 0.6154 - val_loss: 0.7087 - val_accuracy: 0.5185\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6458 - accuracy: 0.6154 - val_loss: 0.6702 - val_accuracy: 0.5185\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6397 - accuracy: 0.6154 - val_loss: 0.6698 - val_accuracy: 0.5185\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6398 - accuracy: 0.6154 - val_loss: 0.6680 - val_accuracy: 0.5185\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6349 - accuracy: 0.6154 - val_loss: 0.6448 - val_accuracy: 0.5185\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6381 - accuracy: 0.6154 - val_loss: 0.6411 - val_accuracy: 0.5185\n",
            "Epoch 11/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6379 - accuracy: 0.6154 - val_loss: 0.6366 - val_accuracy: 0.5185\n",
            "Epoch 12/40\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.6372 - accuracy: 0.6231 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
            "Epoch 13/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.6769 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
            "Epoch 14/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6224 - accuracy: 0.6615 - val_loss: 0.6437 - val_accuracy: 0.6667\n",
            "Epoch 15/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6228 - accuracy: 0.6615 - val_loss: 0.6634 - val_accuracy: 0.6667\n",
            "Epoch 16/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6162 - accuracy: 0.6692 - val_loss: 0.6726 - val_accuracy: 0.6667\n",
            "Epoch 17/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6133 - accuracy: 0.6615 - val_loss: 0.7022 - val_accuracy: 0.6667\n",
            "Epoch 18/40\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 0.6401 - accuracy: 0.6615 - val_loss: 0.6968 - val_accuracy: 0.7037\n",
            "Epoch 19/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6300 - accuracy: 0.6385 - val_loss: 0.6750 - val_accuracy: 0.6296\n",
            "Epoch 20/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6537 - accuracy: 0.6154 - val_loss: 0.6729 - val_accuracy: 0.6296\n",
            "Epoch 21/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6378 - accuracy: 0.6385 - val_loss: 0.6665 - val_accuracy: 0.6296\n",
            "Epoch 22/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6230 - accuracy: 0.6692 - val_loss: 0.6836 - val_accuracy: 0.6296\n",
            "Epoch 23/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.6385 - val_loss: 0.6961 - val_accuracy: 0.6296\n",
            "Epoch 24/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.6615 - val_loss: 0.6717 - val_accuracy: 0.6296\n",
            "Epoch 25/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6244 - accuracy: 0.6462 - val_loss: 0.6539 - val_accuracy: 0.7037\n",
            "Epoch 26/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6319 - accuracy: 0.6846 - val_loss: 0.6542 - val_accuracy: 0.7037\n",
            "Epoch 27/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6200 - accuracy: 0.6692 - val_loss: 0.6699 - val_accuracy: 0.6296\n",
            "Epoch 28/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6293 - accuracy: 0.6615 - val_loss: 0.7566 - val_accuracy: 0.6667\n",
            "Epoch 29/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6425 - accuracy: 0.6538 - val_loss: 0.7106 - val_accuracy: 0.6667\n",
            "Epoch 30/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6177 - accuracy: 0.6769 - val_loss: 0.6560 - val_accuracy: 0.6296\n",
            "Epoch 31/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6117 - accuracy: 0.6538 - val_loss: 0.6456 - val_accuracy: 0.6296\n",
            "Epoch 32/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6302 - accuracy: 0.6462 - val_loss: 0.6441 - val_accuracy: 0.6296\n",
            "Epoch 33/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6071 - accuracy: 0.6923 - val_loss: 0.6755 - val_accuracy: 0.6667\n",
            "Epoch 34/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6138 - accuracy: 0.6538 - val_loss: 0.6707 - val_accuracy: 0.6667\n",
            "Epoch 35/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6165 - accuracy: 0.6615 - val_loss: 0.6801 - val_accuracy: 0.6667\n",
            "Epoch 36/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6206 - accuracy: 0.6538 - val_loss: 0.6822 - val_accuracy: 0.6667\n",
            "Epoch 37/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6270 - accuracy: 0.6615 - val_loss: 0.7151 - val_accuracy: 0.6667\n",
            "Epoch 38/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6246 - accuracy: 0.6615 - val_loss: 0.6999 - val_accuracy: 0.6296\n",
            "Epoch 39/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6139 - accuracy: 0.6846 - val_loss: 0.6869 - val_accuracy: 0.6667\n",
            "Epoch 40/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6093 - accuracy: 0.6692 - val_loss: 0.6656 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npvp-cKs7lwK",
        "outputId": "4c526444-a5f1-4700-d4ee-444cfe74e6fe"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5949 - accuracy: 0.6522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5948721170425415, 0.6521739363670349]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.load_model(f\"/content/model_experiments/{model2.name}\")\n",
        "model2.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "LpO3HR26qyu3",
        "outputId": "018d35c9-bb61-47de-e1fa-237f0e36952a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step - loss: 0.6039 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6039373278617859, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model3.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history3 = model3.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=40,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model3.name)])"
      ],
      "metadata": {
        "id": "2tsjSDV7eP3u",
        "outputId": "40a90541-5782-4b85-996f-188809f69444",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "5/5 [==============================] - 1s 207ms/step - loss: 0.6685 - accuracy: 0.5769 - val_loss: 0.6878 - val_accuracy: 0.5185\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6527 - accuracy: 0.6154 - val_loss: 0.6750 - val_accuracy: 0.5185\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6613 - accuracy: 0.6154 - val_loss: 0.6679 - val_accuracy: 0.5185\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6416 - accuracy: 0.6154 - val_loss: 0.6889 - val_accuracy: 0.5185\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6527 - accuracy: 0.6154 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6407 - accuracy: 0.6154 - val_loss: 0.6582 - val_accuracy: 0.5185\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6414 - accuracy: 0.6154 - val_loss: 0.6616 - val_accuracy: 0.5185\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6422 - accuracy: 0.6154 - val_loss: 0.6735 - val_accuracy: 0.5185\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6349 - accuracy: 0.6154 - val_loss: 0.6501 - val_accuracy: 0.5185\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6377 - accuracy: 0.6154 - val_loss: 0.6574 - val_accuracy: 0.5185\n",
            "Epoch 11/40\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.6253 - accuracy: 0.6308 - val_loss: 0.6639 - val_accuracy: 0.7037\n",
            "Epoch 12/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6259 - accuracy: 0.6538 - val_loss: 0.6467 - val_accuracy: 0.7037\n",
            "Epoch 13/40\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6276 - accuracy: 0.6615 - val_loss: 0.6370 - val_accuracy: 0.6296\n",
            "Epoch 14/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6206 - accuracy: 0.6615 - val_loss: 0.6321 - val_accuracy: 0.6296\n",
            "Epoch 15/40\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6264 - accuracy: 0.6385 - val_loss: 0.6782 - val_accuracy: 0.7037\n",
            "Epoch 16/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6181 - accuracy: 0.6615 - val_loss: 0.6679 - val_accuracy: 0.5926\n",
            "Epoch 17/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6111 - accuracy: 0.6538 - val_loss: 0.7188 - val_accuracy: 0.7037\n",
            "Epoch 18/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6597 - accuracy: 0.6538 - val_loss: 0.7015 - val_accuracy: 0.7037\n",
            "Epoch 19/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6379 - accuracy: 0.6385 - val_loss: 0.6695 - val_accuracy: 0.6296\n",
            "Epoch 20/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6768 - accuracy: 0.5538 - val_loss: 0.6737 - val_accuracy: 0.6296\n",
            "Epoch 21/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6750 - accuracy: 0.5923 - val_loss: 0.6683 - val_accuracy: 0.6296\n",
            "Epoch 22/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6558 - accuracy: 0.6308 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
            "Epoch 23/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6141 - accuracy: 0.6538 - val_loss: 0.6933 - val_accuracy: 0.6296\n",
            "Epoch 24/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6625 - accuracy: 0.6385 - val_loss: 0.7273 - val_accuracy: 0.5185\n",
            "Epoch 25/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6308 - accuracy: 0.6462 - val_loss: 0.6638 - val_accuracy: 0.6667\n",
            "Epoch 26/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6279 - accuracy: 0.6769 - val_loss: 0.6592 - val_accuracy: 0.6667\n",
            "Epoch 27/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6332 - accuracy: 0.6692 - val_loss: 0.6625 - val_accuracy: 0.6667\n",
            "Epoch 28/40\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6218 - accuracy: 0.6615 - val_loss: 0.7183 - val_accuracy: 0.6667\n",
            "Epoch 29/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6268 - accuracy: 0.6538 - val_loss: 0.7600 - val_accuracy: 0.6667\n",
            "Epoch 30/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6383 - accuracy: 0.6615 - val_loss: 0.6782 - val_accuracy: 0.6667\n",
            "Epoch 31/40\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6106 - accuracy: 0.6615 - val_loss: 0.6467 - val_accuracy: 0.6667\n",
            "Epoch 32/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6411 - accuracy: 0.6231 - val_loss: 0.6450 - val_accuracy: 0.6667\n",
            "Epoch 33/40\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6325 - accuracy: 0.6308 - val_loss: 0.6386 - val_accuracy: 0.7037\n",
            "Epoch 34/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6259 - accuracy: 0.6308 - val_loss: 0.6498 - val_accuracy: 0.6667\n",
            "Epoch 35/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6404 - accuracy: 0.6462 - val_loss: 0.6813 - val_accuracy: 0.6667\n",
            "Epoch 36/40\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6553 - accuracy: 0.6538 - val_loss: 0.6660 - val_accuracy: 0.6296\n",
            "Epoch 37/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6284 - accuracy: 0.6462 - val_loss: 0.6717 - val_accuracy: 0.5926\n",
            "Epoch 38/40\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6173 - accuracy: 0.6538 - val_loss: 0.6896 - val_accuracy: 0.6667\n",
            "Epoch 39/40\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6198 - accuracy: 0.6385 - val_loss: 0.7112 - val_accuracy: 0.6667\n",
            "Epoch 40/40\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6187 - accuracy: 0.6538 - val_loss: 0.6883 - val_accuracy: 0.6296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NDBuLs_7nCE",
        "outputId": "aa4cc32b-086a-423b-de20-0cb42d20f3df"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6102 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6101651787757874, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tf.keras.models.load_model(f\"/content/model_experiments/{model3.name}\")\n",
        "model3.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "p6e78-hkq0FB",
        "outputId": "86e90731-60e0-42af-fa40-c4d776f6e72c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 118ms/step - loss: 0.6317 - accuracy: 0.7391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6317034363746643, 0.739130437374115]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model4.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history4 = model4.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model4.name)])"
      ],
      "metadata": {
        "id": "6x7NFRwFeVwx",
        "outputId": "c398b0cb-2a06-4347-dd87-cc8329ee3018",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 212ms/step - loss: 0.6912 - accuracy: 0.5538 - val_loss: 0.6896 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6878 - accuracy: 0.6154 - val_loss: 0.6902 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6859 - accuracy: 0.6154 - val_loss: 0.6879 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6800 - accuracy: 0.6154 - val_loss: 0.6877 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6680 - accuracy: 0.6154 - val_loss: 0.6908 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6578 - accuracy: 0.6154 - val_loss: 0.6958 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6598 - accuracy: 0.6154 - val_loss: 0.7125 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6590 - accuracy: 0.6154 - val_loss: 0.7242 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6572 - accuracy: 0.6154 - val_loss: 0.7073 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6509 - accuracy: 0.6154 - val_loss: 0.6920 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6492 - accuracy: 0.6154 - val_loss: 0.6821 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6492 - accuracy: 0.6154 - val_loss: 0.6744 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6493 - accuracy: 0.6154 - val_loss: 0.6712 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6494 - accuracy: 0.6154 - val_loss: 0.6693 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6483 - accuracy: 0.6154 - val_loss: 0.6673 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6429 - accuracy: 0.6154 - val_loss: 0.6661 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6383 - accuracy: 0.6154 - val_loss: 0.6676 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6378 - accuracy: 0.6154 - val_loss: 0.6755 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6360 - accuracy: 0.6154 - val_loss: 0.6696 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6333 - accuracy: 0.6154 - val_loss: 0.6678 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6306 - accuracy: 0.6154 - val_loss: 0.6604 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6335 - accuracy: 0.6154 - val_loss: 0.6580 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6334 - accuracy: 0.6154 - val_loss: 0.6571 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6318 - accuracy: 0.6154 - val_loss: 0.6595 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6275 - accuracy: 0.6154 - val_loss: 0.6610 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6269 - accuracy: 0.6154 - val_loss: 0.6606 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6255 - accuracy: 0.6154 - val_loss: 0.6637 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6266 - accuracy: 0.6154 - val_loss: 0.6723 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6272 - accuracy: 0.6154 - val_loss: 0.6816 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.6325 - accuracy: 0.6154 - val_loss: 0.6806 - val_accuracy: 0.6296\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.6280 - accuracy: 0.6462 - val_loss: 0.6602 - val_accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6211 - accuracy: 0.6615 - val_loss: 0.6543 - val_accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.6692 - val_loss: 0.6555 - val_accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6200 - accuracy: 0.6615 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6193 - accuracy: 0.6692 - val_loss: 0.6604 - val_accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6212 - accuracy: 0.6615 - val_loss: 0.6700 - val_accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6294 - accuracy: 0.6615 - val_loss: 0.6852 - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6283 - accuracy: 0.6692 - val_loss: 0.6911 - val_accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6311 - accuracy: 0.6615 - val_loss: 0.6947 - val_accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6304 - accuracy: 0.6538 - val_loss: 0.6852 - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6238 - accuracy: 0.6769 - val_loss: 0.6637 - val_accuracy: 0.6667\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6208 - accuracy: 0.6846 - val_loss: 0.6597 - val_accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6233 - accuracy: 0.6769 - val_loss: 0.6591 - val_accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6192 - accuracy: 0.6769 - val_loss: 0.6582 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6153 - accuracy: 0.6769 - val_loss: 0.6608 - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6146 - accuracy: 0.6769 - val_loss: 0.6640 - val_accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6158 - accuracy: 0.6769 - val_loss: 0.6713 - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6140 - accuracy: 0.6692 - val_loss: 0.6792 - val_accuracy: 0.6296\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6141 - accuracy: 0.6769 - val_loss: 0.6679 - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6149 - accuracy: 0.6846 - val_loss: 0.6620 - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6258 - accuracy: 0.6615 - val_loss: 0.6650 - val_accuracy: 0.6296\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6363 - accuracy: 0.6538 - val_loss: 0.6660 - val_accuracy: 0.6667\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6306 - accuracy: 0.6615 - val_loss: 0.6638 - val_accuracy: 0.6667\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6230 - accuracy: 0.6846 - val_loss: 0.6681 - val_accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6168 - accuracy: 0.6769 - val_loss: 0.6775 - val_accuracy: 0.6296\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6153 - accuracy: 0.6769 - val_loss: 0.6808 - val_accuracy: 0.6296\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6164 - accuracy: 0.6769 - val_loss: 0.6819 - val_accuracy: 0.6296\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6120 - accuracy: 0.6769 - val_loss: 0.6647 - val_accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6144 - accuracy: 0.6692 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6164 - accuracy: 0.6692 - val_loss: 0.6552 - val_accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6170 - accuracy: 0.6615 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6166 - accuracy: 0.6846 - val_loss: 0.6468 - val_accuracy: 0.6667\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6241 - accuracy: 0.6692 - val_loss: 0.6509 - val_accuracy: 0.6296\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6328 - accuracy: 0.6615 - val_loss: 0.6535 - val_accuracy: 0.6296\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6304 - accuracy: 0.6615 - val_loss: 0.6523 - val_accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6249 - accuracy: 0.6692 - val_loss: 0.6516 - val_accuracy: 0.6667\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6191 - accuracy: 0.6692 - val_loss: 0.6543 - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6148 - accuracy: 0.6846 - val_loss: 0.6615 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6115 - accuracy: 0.6692 - val_loss: 0.6706 - val_accuracy: 0.6296\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.6692 - val_loss: 0.6734 - val_accuracy: 0.6296\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6119 - accuracy: 0.6692 - val_loss: 0.6678 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6115 - accuracy: 0.6769 - val_loss: 0.6664 - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6119 - accuracy: 0.6692 - val_loss: 0.6730 - val_accuracy: 0.6296\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.6692 - val_loss: 0.6741 - val_accuracy: 0.6296\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6105 - accuracy: 0.6769 - val_loss: 0.6648 - val_accuracy: 0.6667\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6071 - accuracy: 0.6769 - val_loss: 0.6599 - val_accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6164 - accuracy: 0.6846 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6166 - accuracy: 0.6846 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6130 - accuracy: 0.6769 - val_loss: 0.6611 - val_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6083 - accuracy: 0.6846 - val_loss: 0.6704 - val_accuracy: 0.6296\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6077 - accuracy: 0.6769 - val_loss: 0.6769 - val_accuracy: 0.6296\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6101 - accuracy: 0.6538 - val_loss: 0.6917 - val_accuracy: 0.6296\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6119 - accuracy: 0.6692 - val_loss: 0.6962 - val_accuracy: 0.6296\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6124 - accuracy: 0.6769 - val_loss: 0.6919 - val_accuracy: 0.6296\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6084 - accuracy: 0.6615 - val_loss: 0.6834 - val_accuracy: 0.6296\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6091 - accuracy: 0.6692 - val_loss: 0.6766 - val_accuracy: 0.6296\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6051 - accuracy: 0.6692 - val_loss: 0.6809 - val_accuracy: 0.6296\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6078 - accuracy: 0.6692 - val_loss: 0.6866 - val_accuracy: 0.6296\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6074 - accuracy: 0.6692 - val_loss: 0.6898 - val_accuracy: 0.6296\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6122 - accuracy: 0.6769 - val_loss: 0.6958 - val_accuracy: 0.6296\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6074 - accuracy: 0.6846 - val_loss: 0.6779 - val_accuracy: 0.6296\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6038 - accuracy: 0.6769 - val_loss: 0.6726 - val_accuracy: 0.6667\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6018 - accuracy: 0.6769 - val_loss: 0.6670 - val_accuracy: 0.6667\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6021 - accuracy: 0.6769 - val_loss: 0.6678 - val_accuracy: 0.6667\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6020 - accuracy: 0.6769 - val_loss: 0.6659 - val_accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6031 - accuracy: 0.6692 - val_loss: 0.6648 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6030 - accuracy: 0.6769 - val_loss: 0.6614 - val_accuracy: 0.6667\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6042 - accuracy: 0.6692 - val_loss: 0.6619 - val_accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6022 - accuracy: 0.6692 - val_loss: 0.6579 - val_accuracy: 0.6667\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6022 - accuracy: 0.6692 - val_loss: 0.6566 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_-4IBuJ7o6-",
        "outputId": "50b5c4a3-a1b1-4a1c-96b0-a2ff6d596f01"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5838 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5838184356689453, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = tf.keras.models.load_model(f\"/content/model_experiments/{model4.name}\")\n",
        "model4.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "CKJfsbhUq01R",
        "outputId": "bc630cd0-db0c-4622-a1d9-9b9a31d724bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 147ms/step - loss: 0.6290 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.628968358039856, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model5.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history5 = model5.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model5.name)])"
      ],
      "metadata": {
        "id": "9uRfoFpYeXtB",
        "outputId": "dbc552e1-deac-4cf1-9e6d-96c226b8e556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 208ms/step - loss: 0.6878 - accuracy: 0.5462 - val_loss: 0.6869 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6762 - accuracy: 0.6154 - val_loss: 0.6875 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6673 - accuracy: 0.6154 - val_loss: 0.6914 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6501 - accuracy: 0.6154 - val_loss: 0.7148 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.7313 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6501 - accuracy: 0.6154 - val_loss: 0.7040 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6442 - accuracy: 0.6154 - val_loss: 0.7020 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6426 - accuracy: 0.6154 - val_loss: 0.6968 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6381 - accuracy: 0.6154 - val_loss: 0.6727 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6350 - accuracy: 0.6154 - val_loss: 0.6605 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6350 - accuracy: 0.6154 - val_loss: 0.6544 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.6354 - accuracy: 0.6231 - val_loss: 0.6508 - val_accuracy: 0.6296\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6322 - accuracy: 0.6538 - val_loss: 0.6478 - val_accuracy: 0.6296\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6281 - accuracy: 0.6615 - val_loss: 0.6483 - val_accuracy: 0.6296\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6272 - accuracy: 0.6846 - val_loss: 0.6582 - val_accuracy: 0.5926\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.6692 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6227 - accuracy: 0.6615 - val_loss: 0.6630 - val_accuracy: 0.6296\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6269 - accuracy: 0.6538 - val_loss: 0.6798 - val_accuracy: 0.6296\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 0.6241 - accuracy: 0.6615 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.6202 - accuracy: 0.6615 - val_loss: 0.6570 - val_accuracy: 0.7037\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6238 - accuracy: 0.6615 - val_loss: 0.6564 - val_accuracy: 0.7037\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6319 - accuracy: 0.6692 - val_loss: 0.6518 - val_accuracy: 0.7037\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6222 - accuracy: 0.6538 - val_loss: 0.6521 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6193 - accuracy: 0.6615 - val_loss: 0.6671 - val_accuracy: 0.6296\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6175 - accuracy: 0.6538 - val_loss: 0.6666 - val_accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6162 - accuracy: 0.6615 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6124 - accuracy: 0.6538 - val_loss: 0.6594 - val_accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6138 - accuracy: 0.6538 - val_loss: 0.6774 - val_accuracy: 0.6667\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6143 - accuracy: 0.6615 - val_loss: 0.6944 - val_accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6211 - accuracy: 0.6692 - val_loss: 0.6886 - val_accuracy: 0.6667\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6118 - accuracy: 0.6846 - val_loss: 0.6547 - val_accuracy: 0.7037\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6107 - accuracy: 0.6692 - val_loss: 0.6519 - val_accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6104 - accuracy: 0.6692 - val_loss: 0.6572 - val_accuracy: 0.7037\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6081 - accuracy: 0.6615 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6094 - accuracy: 0.6615 - val_loss: 0.6761 - val_accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6178 - accuracy: 0.6692 - val_loss: 0.6927 - val_accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6309 - accuracy: 0.6538 - val_loss: 0.7148 - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6282 - accuracy: 0.6538 - val_loss: 0.7048 - val_accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6176 - accuracy: 0.6615 - val_loss: 0.6896 - val_accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6089 - accuracy: 0.6538 - val_loss: 0.6743 - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6093 - accuracy: 0.6615 - val_loss: 0.6641 - val_accuracy: 0.6667\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6208 - accuracy: 0.6615 - val_loss: 0.6676 - val_accuracy: 0.6296\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6141 - accuracy: 0.6538 - val_loss: 0.6761 - val_accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 0.6538 - val_loss: 0.6767 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.6692 - val_loss: 0.6787 - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6023 - accuracy: 0.6692 - val_loss: 0.6744 - val_accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6031 - accuracy: 0.6692 - val_loss: 0.6840 - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6019 - accuracy: 0.6769 - val_loss: 0.7008 - val_accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5994 - accuracy: 0.6846 - val_loss: 0.6685 - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6088 - accuracy: 0.6308 - val_loss: 0.6644 - val_accuracy: 0.6296\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6324 - accuracy: 0.6154 - val_loss: 0.6655 - val_accuracy: 0.6296\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6352 - accuracy: 0.6000 - val_loss: 0.6629 - val_accuracy: 0.6296\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6177 - accuracy: 0.6231 - val_loss: 0.6750 - val_accuracy: 0.5926\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6189 - accuracy: 0.6846 - val_loss: 0.7297 - val_accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6303 - accuracy: 0.6615 - val_loss: 0.7467 - val_accuracy: 0.6667\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6293 - accuracy: 0.6538 - val_loss: 0.7147 - val_accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6160 - accuracy: 0.6615 - val_loss: 0.6791 - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6003 - accuracy: 0.6846 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6076 - accuracy: 0.6692 - val_loss: 0.6581 - val_accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6069 - accuracy: 0.6538 - val_loss: 0.6695 - val_accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6049 - accuracy: 0.6692 - val_loss: 0.6751 - val_accuracy: 0.6667\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6018 - accuracy: 0.6692 - val_loss: 0.6594 - val_accuracy: 0.6667\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6096 - accuracy: 0.6692 - val_loss: 0.6582 - val_accuracy: 0.5926\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6161 - accuracy: 0.6462 - val_loss: 0.6580 - val_accuracy: 0.6667\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 0.6462 - val_loss: 0.6618 - val_accuracy: 0.6296\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5992 - accuracy: 0.6692 - val_loss: 0.6657 - val_accuracy: 0.6296\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5953 - accuracy: 0.6846 - val_loss: 0.6841 - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6020 - accuracy: 0.6769 - val_loss: 0.7059 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6058 - accuracy: 0.6615 - val_loss: 0.6964 - val_accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6007 - accuracy: 0.6615 - val_loss: 0.6811 - val_accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5943 - accuracy: 0.6769 - val_loss: 0.6686 - val_accuracy: 0.6296\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5972 - accuracy: 0.6692 - val_loss: 0.6683 - val_accuracy: 0.6296\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.6615 - val_loss: 0.6873 - val_accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5992 - accuracy: 0.6615 - val_loss: 0.6874 - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5990 - accuracy: 0.6538 - val_loss: 0.6612 - val_accuracy: 0.6667\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5999 - accuracy: 0.6692 - val_loss: 0.6585 - val_accuracy: 0.5926\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6144 - accuracy: 0.6154 - val_loss: 0.6588 - val_accuracy: 0.5926\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6115 - accuracy: 0.6077 - val_loss: 0.6733 - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5993 - accuracy: 0.6846 - val_loss: 0.6945 - val_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5991 - accuracy: 0.6846 - val_loss: 0.7231 - val_accuracy: 0.6296\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6023 - accuracy: 0.6769 - val_loss: 0.7214 - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6015 - accuracy: 0.6615 - val_loss: 0.7161 - val_accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5976 - accuracy: 0.6615 - val_loss: 0.6983 - val_accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5937 - accuracy: 0.6692 - val_loss: 0.6824 - val_accuracy: 0.6296\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5920 - accuracy: 0.6769 - val_loss: 0.6718 - val_accuracy: 0.6296\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5954 - accuracy: 0.6846 - val_loss: 0.6719 - val_accuracy: 0.5926\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5902 - accuracy: 0.6769 - val_loss: 0.6961 - val_accuracy: 0.6667\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5967 - accuracy: 0.6692 - val_loss: 0.7111 - val_accuracy: 0.6667\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6007 - accuracy: 0.6615 - val_loss: 0.7152 - val_accuracy: 0.6296\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6049 - accuracy: 0.6692 - val_loss: 0.7089 - val_accuracy: 0.6296\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5918 - accuracy: 0.6846 - val_loss: 0.6695 - val_accuracy: 0.6296\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5916 - accuracy: 0.6769 - val_loss: 0.6694 - val_accuracy: 0.6296\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5915 - accuracy: 0.6846 - val_loss: 0.6739 - val_accuracy: 0.6296\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5903 - accuracy: 0.6615 - val_loss: 0.6925 - val_accuracy: 0.6667\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5907 - accuracy: 0.6769 - val_loss: 0.6917 - val_accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5927 - accuracy: 0.6692 - val_loss: 0.6857 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5964 - accuracy: 0.6538 - val_loss: 0.6596 - val_accuracy: 0.6296\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6015 - accuracy: 0.6615 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5980 - accuracy: 0.6692 - val_loss: 0.6514 - val_accuracy: 0.6296\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5909 - accuracy: 0.6692 - val_loss: 0.6618 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gvMvEml7qdi",
        "outputId": "57f91114-fa84-43ae-e013-46235a1ab276"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5684 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.568408191204071, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = tf.keras.models.load_model(f\"/content/model_experiments/{model5.name}\")\n",
        "model5.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "XeQ1W3ycq2Kg",
        "outputId": "46e86891-9933-47ab-983d-46070890ba4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 125ms/step - loss: 0.6265 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6265031695365906, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model6 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model6.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history6 = model6.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model6.name)])"
      ],
      "metadata": {
        "id": "aGjeYTd4eZ7x",
        "outputId": "f3f6c971-5815-4154-b3f9-e3dac52c7d02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 216ms/step - loss: 0.6801 - accuracy: 0.5538 - val_loss: 0.6813 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6598 - accuracy: 0.6154 - val_loss: 0.6788 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6562 - accuracy: 0.6154 - val_loss: 0.6810 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6465 - accuracy: 0.6154 - val_loss: 0.6965 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6494 - accuracy: 0.6154 - val_loss: 0.7122 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6475 - accuracy: 0.6154 - val_loss: 0.6863 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6419 - accuracy: 0.6154 - val_loss: 0.6848 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6412 - accuracy: 0.6154 - val_loss: 0.6813 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6371 - accuracy: 0.6154 - val_loss: 0.6612 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6353 - accuracy: 0.6154 - val_loss: 0.6533 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 1s 200ms/step - loss: 0.6364 - accuracy: 0.6154 - val_loss: 0.6493 - val_accuracy: 0.5926\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.6373 - accuracy: 0.6538 - val_loss: 0.6463 - val_accuracy: 0.6296\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6340 - accuracy: 0.6615 - val_loss: 0.6443 - val_accuracy: 0.6296\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6295 - accuracy: 0.6692 - val_loss: 0.6475 - val_accuracy: 0.6296\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6296 - accuracy: 0.6692 - val_loss: 0.6558 - val_accuracy: 0.5926\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6264 - accuracy: 0.6615 - val_loss: 0.6557 - val_accuracy: 0.6296\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6238 - accuracy: 0.6462 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6296 - accuracy: 0.6538 - val_loss: 0.6672 - val_accuracy: 0.6296\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 0.6264 - accuracy: 0.6538 - val_loss: 0.6443 - val_accuracy: 0.7037\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6239 - accuracy: 0.6538 - val_loss: 0.6462 - val_accuracy: 0.7037\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6271 - accuracy: 0.6615 - val_loss: 0.6493 - val_accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6314 - accuracy: 0.6769 - val_loss: 0.6448 - val_accuracy: 0.7037\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6193 - accuracy: 0.6615 - val_loss: 0.6477 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6213 - accuracy: 0.6538 - val_loss: 0.6690 - val_accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6205 - accuracy: 0.6615 - val_loss: 0.6594 - val_accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6148 - accuracy: 0.6692 - val_loss: 0.6470 - val_accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6111 - accuracy: 0.6769 - val_loss: 0.6502 - val_accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6115 - accuracy: 0.6692 - val_loss: 0.6793 - val_accuracy: 0.6296\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6165 - accuracy: 0.6615 - val_loss: 0.7045 - val_accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6248 - accuracy: 0.6615 - val_loss: 0.6752 - val_accuracy: 0.6667\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6072 - accuracy: 0.6769 - val_loss: 0.6422 - val_accuracy: 0.6296\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6129 - accuracy: 0.6769 - val_loss: 0.6442 - val_accuracy: 0.6296\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6074 - accuracy: 0.6769 - val_loss: 0.6512 - val_accuracy: 0.6296\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6046 - accuracy: 0.6615 - val_loss: 0.6577 - val_accuracy: 0.6296\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6079 - accuracy: 0.6538 - val_loss: 0.6762 - val_accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6160 - accuracy: 0.6615 - val_loss: 0.6888 - val_accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6253 - accuracy: 0.6615 - val_loss: 0.7117 - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6246 - accuracy: 0.6615 - val_loss: 0.6957 - val_accuracy: 0.6296\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6135 - accuracy: 0.6692 - val_loss: 0.6809 - val_accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6061 - accuracy: 0.6769 - val_loss: 0.6649 - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6081 - accuracy: 0.6692 - val_loss: 0.6543 - val_accuracy: 0.6296\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6157 - accuracy: 0.6538 - val_loss: 0.6558 - val_accuracy: 0.6296\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6043 - accuracy: 0.6615 - val_loss: 0.6682 - val_accuracy: 0.6296\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6038 - accuracy: 0.6615 - val_loss: 0.6602 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5999 - accuracy: 0.6692 - val_loss: 0.6492 - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 0.5992 - accuracy: 0.6692 - val_loss: 0.6481 - val_accuracy: 0.7407\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6038 - accuracy: 0.6615 - val_loss: 0.6685 - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6026 - accuracy: 0.6769 - val_loss: 0.7049 - val_accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5987 - accuracy: 0.6692 - val_loss: 0.6523 - val_accuracy: 0.6296\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6333 - accuracy: 0.6538 - val_loss: 0.6818 - val_accuracy: 0.5185\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6756 - accuracy: 0.5385 - val_loss: 0.6823 - val_accuracy: 0.5185\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.5769 - val_loss: 0.6765 - val_accuracy: 0.6296\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6254 - accuracy: 0.6308 - val_loss: 0.6941 - val_accuracy: 0.6296\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6364 - accuracy: 0.6615 - val_loss: 0.7536 - val_accuracy: 0.6296\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6402 - accuracy: 0.6615 - val_loss: 0.7391 - val_accuracy: 0.6296\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6196 - accuracy: 0.6615 - val_loss: 0.7045 - val_accuracy: 0.6296\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6029 - accuracy: 0.6769 - val_loss: 0.6802 - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6014 - accuracy: 0.6615 - val_loss: 0.6660 - val_accuracy: 0.5926\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6136 - accuracy: 0.6692 - val_loss: 0.6648 - val_accuracy: 0.6296\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6115 - accuracy: 0.6692 - val_loss: 0.6746 - val_accuracy: 0.6296\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6083 - accuracy: 0.6692 - val_loss: 0.6784 - val_accuracy: 0.6296\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6033 - accuracy: 0.6692 - val_loss: 0.6637 - val_accuracy: 0.6296\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6192 - accuracy: 0.6462 - val_loss: 0.6656 - val_accuracy: 0.5926\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6261 - accuracy: 0.6462 - val_loss: 0.6643 - val_accuracy: 0.5926\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6126 - accuracy: 0.6308 - val_loss: 0.6673 - val_accuracy: 0.5926\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6007 - accuracy: 0.6692 - val_loss: 0.6762 - val_accuracy: 0.6296\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5967 - accuracy: 0.6692 - val_loss: 0.7057 - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6077 - accuracy: 0.6846 - val_loss: 0.7316 - val_accuracy: 0.6296\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6123 - accuracy: 0.6692 - val_loss: 0.7045 - val_accuracy: 0.5926\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5995 - accuracy: 0.6615 - val_loss: 0.6840 - val_accuracy: 0.6296\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5918 - accuracy: 0.6769 - val_loss: 0.6691 - val_accuracy: 0.7037\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5948 - accuracy: 0.6923 - val_loss: 0.6717 - val_accuracy: 0.7037\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5970 - accuracy: 0.6692 - val_loss: 0.6948 - val_accuracy: 0.5926\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6007 - accuracy: 0.6615 - val_loss: 0.6904 - val_accuracy: 0.5926\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5958 - accuracy: 0.6923 - val_loss: 0.6629 - val_accuracy: 0.6296\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5989 - accuracy: 0.6538 - val_loss: 0.6595 - val_accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6137 - accuracy: 0.6385 - val_loss: 0.6556 - val_accuracy: 0.6296\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6083 - accuracy: 0.6308 - val_loss: 0.6736 - val_accuracy: 0.5926\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5951 - accuracy: 0.6846 - val_loss: 0.6954 - val_accuracy: 0.6296\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5964 - accuracy: 0.6692 - val_loss: 0.7197 - val_accuracy: 0.6296\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5992 - accuracy: 0.6769 - val_loss: 0.7130 - val_accuracy: 0.6296\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5964 - accuracy: 0.6769 - val_loss: 0.7062 - val_accuracy: 0.6296\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5927 - accuracy: 0.6769 - val_loss: 0.6910 - val_accuracy: 0.6296\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5900 - accuracy: 0.6769 - val_loss: 0.6831 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5875 - accuracy: 0.6615 - val_loss: 0.6809 - val_accuracy: 0.5926\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5903 - accuracy: 0.6769 - val_loss: 0.6894 - val_accuracy: 0.6296\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5857 - accuracy: 0.6692 - val_loss: 0.7309 - val_accuracy: 0.6296\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5984 - accuracy: 0.6769 - val_loss: 0.7380 - val_accuracy: 0.6296\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5981 - accuracy: 0.6615 - val_loss: 0.7210 - val_accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5988 - accuracy: 0.6846 - val_loss: 0.7049 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5889 - accuracy: 0.6692 - val_loss: 0.6667 - val_accuracy: 0.6667\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5912 - accuracy: 0.6615 - val_loss: 0.6716 - val_accuracy: 0.6667\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5850 - accuracy: 0.6846 - val_loss: 0.6772 - val_accuracy: 0.6667\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5837 - accuracy: 0.6769 - val_loss: 0.6925 - val_accuracy: 0.5926\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5815 - accuracy: 0.6769 - val_loss: 0.6801 - val_accuracy: 0.6296\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5851 - accuracy: 0.6615 - val_loss: 0.6732 - val_accuracy: 0.6296\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5943 - accuracy: 0.6538 - val_loss: 0.6636 - val_accuracy: 0.6296\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6031 - accuracy: 0.6615 - val_loss: 0.6638 - val_accuracy: 0.6296\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5882 - accuracy: 0.6846 - val_loss: 0.6641 - val_accuracy: 0.6296\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5817 - accuracy: 0.6692 - val_loss: 0.6896 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk7CoEfq7r7I",
        "outputId": "ce862056-307e-46f4-f0c3-825fea0f5d3e"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5461 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5460948348045349, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = tf.keras.models.load_model(f\"/content/model_experiments/{model6.name}\")\n",
        "model6.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "jWwLJ77yq27l",
        "outputId": "dc60113c-c065-489f-af79-7df2a4200628",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step - loss: 0.5765 - accuracy: 0.8261\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5764762163162231, 0.8260869383811951]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model7.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history7 = model7.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model7.name)])"
      ],
      "metadata": {
        "id": "h_ByrY0Cecaw",
        "outputId": "7fb5dc9b-e647-4cea-aff9-4a043cc0f57f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 205ms/step - loss: 0.6926 - accuracy: 0.5846 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6922 - accuracy: 0.6000 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6918 - accuracy: 0.6077 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6913 - accuracy: 0.6154 - val_loss: 0.6915 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6154 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.6154 - val_loss: 0.6907 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.6154 - val_loss: 0.6904 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6889 - accuracy: 0.6154 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6877 - accuracy: 0.6154 - val_loss: 0.6893 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.6154 - val_loss: 0.6888 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6863 - accuracy: 0.6154 - val_loss: 0.6884 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6859 - accuracy: 0.6154 - val_loss: 0.6882 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6854 - accuracy: 0.6154 - val_loss: 0.6880 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6850 - accuracy: 0.6154 - val_loss: 0.6879 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6843 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6830 - accuracy: 0.6154 - val_loss: 0.6870 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6818 - accuracy: 0.6154 - val_loss: 0.6868 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6803 - accuracy: 0.6154 - val_loss: 0.6869 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6783 - accuracy: 0.6154 - val_loss: 0.6871 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6768 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6755 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6745 - accuracy: 0.6154 - val_loss: 0.6872 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6728 - accuracy: 0.6154 - val_loss: 0.6869 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6714 - accuracy: 0.6154 - val_loss: 0.6865 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6693 - accuracy: 0.6154 - val_loss: 0.6861 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6676 - accuracy: 0.6154 - val_loss: 0.6857 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6661 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6640 - accuracy: 0.6154 - val_loss: 0.6850 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6614 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6594 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6579 - accuracy: 0.6154 - val_loss: 0.6848 - val_accuracy: 0.5185\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6568 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6554 - accuracy: 0.6154 - val_loss: 0.6852 - val_accuracy: 0.5185\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6544 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6534 - accuracy: 0.6154 - val_loss: 0.6857 - val_accuracy: 0.5185\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.6864 - val_accuracy: 0.5185\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6507 - accuracy: 0.6154 - val_loss: 0.6886 - val_accuracy: 0.5185\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6502 - accuracy: 0.6154 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6497 - accuracy: 0.6154 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6493 - accuracy: 0.6154 - val_loss: 0.6908 - val_accuracy: 0.5185\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6490 - accuracy: 0.6154 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6487 - accuracy: 0.6154 - val_loss: 0.6898 - val_accuracy: 0.5185\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6484 - accuracy: 0.6154 - val_loss: 0.6895 - val_accuracy: 0.5185\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6481 - accuracy: 0.6154 - val_loss: 0.6894 - val_accuracy: 0.5185\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6479 - accuracy: 0.6154 - val_loss: 0.6888 - val_accuracy: 0.5185\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6476 - accuracy: 0.6154 - val_loss: 0.6890 - val_accuracy: 0.5185\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6472 - accuracy: 0.6154 - val_loss: 0.6893 - val_accuracy: 0.5185\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6470 - accuracy: 0.6154 - val_loss: 0.6883 - val_accuracy: 0.5185\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6468 - accuracy: 0.6154 - val_loss: 0.6866 - val_accuracy: 0.5185\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6467 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6470 - accuracy: 0.6154 - val_loss: 0.6843 - val_accuracy: 0.5185\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6467 - accuracy: 0.6154 - val_loss: 0.6842 - val_accuracy: 0.5185\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6466 - accuracy: 0.6154 - val_loss: 0.6843 - val_accuracy: 0.5185\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6462 - accuracy: 0.6154 - val_loss: 0.6845 - val_accuracy: 0.5185\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6154 - val_loss: 0.6851 - val_accuracy: 0.5185\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6453 - accuracy: 0.6154 - val_loss: 0.6858 - val_accuracy: 0.5185\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6452 - accuracy: 0.6154 - val_loss: 0.6855 - val_accuracy: 0.5185\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6451 - accuracy: 0.6154 - val_loss: 0.6854 - val_accuracy: 0.5185\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6449 - accuracy: 0.6154 - val_loss: 0.6858 - val_accuracy: 0.5185\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6447 - accuracy: 0.6154 - val_loss: 0.6854 - val_accuracy: 0.5185\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6445 - accuracy: 0.6154 - val_loss: 0.6840 - val_accuracy: 0.5185\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6443 - accuracy: 0.6154 - val_loss: 0.6831 - val_accuracy: 0.5185\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6447 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6444 - accuracy: 0.6154 - val_loss: 0.6815 - val_accuracy: 0.5185\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6444 - accuracy: 0.6154 - val_loss: 0.6804 - val_accuracy: 0.5185\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6443 - accuracy: 0.6154 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6441 - accuracy: 0.6154 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6436 - accuracy: 0.6154 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6433 - accuracy: 0.6154 - val_loss: 0.6798 - val_accuracy: 0.5185\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6431 - accuracy: 0.6154 - val_loss: 0.6797 - val_accuracy: 0.5185\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6426 - accuracy: 0.6154 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6425 - accuracy: 0.6154 - val_loss: 0.6807 - val_accuracy: 0.5185\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6419 - accuracy: 0.6154 - val_loss: 0.6814 - val_accuracy: 0.5185\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6419 - accuracy: 0.6154 - val_loss: 0.6817 - val_accuracy: 0.5185\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6418 - accuracy: 0.6154 - val_loss: 0.6817 - val_accuracy: 0.5185\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6418 - accuracy: 0.6154 - val_loss: 0.6806 - val_accuracy: 0.5185\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6415 - accuracy: 0.6154 - val_loss: 0.6806 - val_accuracy: 0.5185\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6412 - accuracy: 0.6154 - val_loss: 0.6803 - val_accuracy: 0.5185\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6411 - accuracy: 0.6154 - val_loss: 0.6804 - val_accuracy: 0.5185\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6410 - accuracy: 0.6154 - val_loss: 0.6806 - val_accuracy: 0.5185\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6410 - accuracy: 0.6154 - val_loss: 0.6812 - val_accuracy: 0.5185\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6408 - accuracy: 0.6154 - val_loss: 0.6819 - val_accuracy: 0.5185\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6406 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6402 - accuracy: 0.6154 - val_loss: 0.6821 - val_accuracy: 0.5185\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6401 - accuracy: 0.6154 - val_loss: 0.6818 - val_accuracy: 0.5185\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6397 - accuracy: 0.6154 - val_loss: 0.6821 - val_accuracy: 0.5185\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6395 - accuracy: 0.6154 - val_loss: 0.6821 - val_accuracy: 0.5185\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6393 - accuracy: 0.6154 - val_loss: 0.6820 - val_accuracy: 0.5185\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6396 - accuracy: 0.6154 - val_loss: 0.6823 - val_accuracy: 0.5185\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6389 - accuracy: 0.6154 - val_loss: 0.6811 - val_accuracy: 0.5185\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6387 - accuracy: 0.6154 - val_loss: 0.6809 - val_accuracy: 0.5185\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6384 - accuracy: 0.6154 - val_loss: 0.6805 - val_accuracy: 0.5185\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6383 - accuracy: 0.6154 - val_loss: 0.6804 - val_accuracy: 0.5185\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6381 - accuracy: 0.6154 - val_loss: 0.6794 - val_accuracy: 0.5185\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6379 - accuracy: 0.6154 - val_loss: 0.6785 - val_accuracy: 0.5185\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6375 - accuracy: 0.6154 - val_loss: 0.6772 - val_accuracy: 0.5185\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6375 - accuracy: 0.6154 - val_loss: 0.6767 - val_accuracy: 0.5185\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6374 - accuracy: 0.6154 - val_loss: 0.6758 - val_accuracy: 0.5185\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6374 - accuracy: 0.6154 - val_loss: 0.6751 - val_accuracy: 0.5185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuSW-3hF7uM4",
        "outputId": "316c7d73-d396-45a0-ed3a-8b9cd34583b2"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6691 - accuracy: 0.4783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6691227555274963, 0.47826087474823]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = tf.keras.models.load_model(f\"/content/model_experiments/{model7.name}\")\n",
        "model7.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "S7rS6N1nq4HX",
        "outputId": "7b0f7325-4b4c-4f29-caa7-cd4256c83db5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 119ms/step - loss: 0.6930 - accuracy: 0.4348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.692970335483551, 0.43478259444236755]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jM1qixAGG_oP"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model8 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model8.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history8 = model8.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model8.name)])"
      ],
      "metadata": {
        "id": "6iqdazWeefng",
        "outputId": "b7485808-6ff6-42ae-b5f3-39de7a581978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 210ms/step - loss: 0.6952 - accuracy: 0.4308 - val_loss: 0.6956 - val_accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6929 - accuracy: 0.5231 - val_loss: 0.6948 - val_accuracy: 0.3333\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 0.6913 - accuracy: 0.5538 - val_loss: 0.6935 - val_accuracy: 0.4815\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.6889 - accuracy: 0.6231 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6866 - accuracy: 0.6154 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6846 - accuracy: 0.6154 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6831 - accuracy: 0.6154 - val_loss: 0.6894 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6811 - accuracy: 0.6154 - val_loss: 0.6886 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6791 - accuracy: 0.6154 - val_loss: 0.6879 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6777 - accuracy: 0.6154 - val_loss: 0.6873 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6760 - accuracy: 0.6154 - val_loss: 0.6867 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6747 - accuracy: 0.6154 - val_loss: 0.6865 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6735 - accuracy: 0.6154 - val_loss: 0.6864 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6718 - accuracy: 0.6154 - val_loss: 0.6865 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6700 - accuracy: 0.6154 - val_loss: 0.6864 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6672 - accuracy: 0.6154 - val_loss: 0.6862 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6643 - accuracy: 0.6154 - val_loss: 0.6869 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6615 - accuracy: 0.6154 - val_loss: 0.6882 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6585 - accuracy: 0.6154 - val_loss: 0.6884 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6571 - accuracy: 0.6154 - val_loss: 0.6893 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6560 - accuracy: 0.6154 - val_loss: 0.6886 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6557 - accuracy: 0.6154 - val_loss: 0.6883 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6548 - accuracy: 0.6154 - val_loss: 0.6882 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6539 - accuracy: 0.6154 - val_loss: 0.6890 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6521 - accuracy: 0.6154 - val_loss: 0.6898 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6511 - accuracy: 0.6154 - val_loss: 0.6902 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6502 - accuracy: 0.6154 - val_loss: 0.6910 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6491 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6474 - accuracy: 0.6154 - val_loss: 0.6956 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6466 - accuracy: 0.6154 - val_loss: 0.6979 - val_accuracy: 0.5185\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6460 - accuracy: 0.6154 - val_loss: 0.6973 - val_accuracy: 0.5185\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6154 - val_loss: 0.6982 - val_accuracy: 0.5185\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6449 - accuracy: 0.6154 - val_loss: 0.6996 - val_accuracy: 0.5185\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6445 - accuracy: 0.6154 - val_loss: 0.6991 - val_accuracy: 0.5185\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6440 - accuracy: 0.6154 - val_loss: 0.6999 - val_accuracy: 0.5185\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6434 - accuracy: 0.6154 - val_loss: 0.7018 - val_accuracy: 0.5185\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6438 - accuracy: 0.6154 - val_loss: 0.7051 - val_accuracy: 0.5185\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6436 - accuracy: 0.6154 - val_loss: 0.7087 - val_accuracy: 0.5185\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6443 - accuracy: 0.6154 - val_loss: 0.7121 - val_accuracy: 0.5185\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6448 - accuracy: 0.6154 - val_loss: 0.7134 - val_accuracy: 0.5185\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6442 - accuracy: 0.6154 - val_loss: 0.7095 - val_accuracy: 0.5185\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6431 - accuracy: 0.6154 - val_loss: 0.7063 - val_accuracy: 0.5185\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6428 - accuracy: 0.6154 - val_loss: 0.7047 - val_accuracy: 0.5185\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6419 - accuracy: 0.6154 - val_loss: 0.7028 - val_accuracy: 0.5185\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6417 - accuracy: 0.6154 - val_loss: 0.7016 - val_accuracy: 0.5185\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6413 - accuracy: 0.6154 - val_loss: 0.6998 - val_accuracy: 0.5185\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6410 - accuracy: 0.6154 - val_loss: 0.6998 - val_accuracy: 0.5185\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6407 - accuracy: 0.6154 - val_loss: 0.7002 - val_accuracy: 0.5185\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6404 - accuracy: 0.6154 - val_loss: 0.6976 - val_accuracy: 0.5185\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6401 - accuracy: 0.6154 - val_loss: 0.6936 - val_accuracy: 0.5185\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6401 - accuracy: 0.6154 - val_loss: 0.6905 - val_accuracy: 0.5185\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6407 - accuracy: 0.6154 - val_loss: 0.6883 - val_accuracy: 0.5185\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6404 - accuracy: 0.6154 - val_loss: 0.6879 - val_accuracy: 0.5185\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6405 - accuracy: 0.6154 - val_loss: 0.6883 - val_accuracy: 0.5185\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6399 - accuracy: 0.6154 - val_loss: 0.6890 - val_accuracy: 0.5185\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6392 - accuracy: 0.6154 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6388 - accuracy: 0.6154 - val_loss: 0.6918 - val_accuracy: 0.5185\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6386 - accuracy: 0.6154 - val_loss: 0.6917 - val_accuracy: 0.5185\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6385 - accuracy: 0.6154 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6383 - accuracy: 0.6154 - val_loss: 0.6931 - val_accuracy: 0.5185\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6381 - accuracy: 0.6154 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6378 - accuracy: 0.6154 - val_loss: 0.6898 - val_accuracy: 0.5185\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6377 - accuracy: 0.6154 - val_loss: 0.6884 - val_accuracy: 0.5185\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6381 - accuracy: 0.6154 - val_loss: 0.6868 - val_accuracy: 0.5185\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6379 - accuracy: 0.6154 - val_loss: 0.6856 - val_accuracy: 0.5185\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6379 - accuracy: 0.6154 - val_loss: 0.6841 - val_accuracy: 0.5185\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6378 - accuracy: 0.6154 - val_loss: 0.6835 - val_accuracy: 0.5185\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6376 - accuracy: 0.6154 - val_loss: 0.6836 - val_accuracy: 0.5185\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6369 - accuracy: 0.6154 - val_loss: 0.6838 - val_accuracy: 0.5185\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6364 - accuracy: 0.6154 - val_loss: 0.6841 - val_accuracy: 0.5185\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6362 - accuracy: 0.6154 - val_loss: 0.6838 - val_accuracy: 0.5185\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6356 - accuracy: 0.6154 - val_loss: 0.6843 - val_accuracy: 0.5185\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6356 - accuracy: 0.6154 - val_loss: 0.6859 - val_accuracy: 0.5185\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6348 - accuracy: 0.6154 - val_loss: 0.6875 - val_accuracy: 0.5185\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6348 - accuracy: 0.6154 - val_loss: 0.6884 - val_accuracy: 0.5185\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6348 - accuracy: 0.6154 - val_loss: 0.6882 - val_accuracy: 0.5185\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6348 - accuracy: 0.6154 - val_loss: 0.6861 - val_accuracy: 0.5185\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6343 - accuracy: 0.6154 - val_loss: 0.6861 - val_accuracy: 0.5185\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6339 - accuracy: 0.6154 - val_loss: 0.6856 - val_accuracy: 0.5185\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6337 - accuracy: 0.6154 - val_loss: 0.6859 - val_accuracy: 0.5185\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6336 - accuracy: 0.6154 - val_loss: 0.6863 - val_accuracy: 0.5185\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.6154 - val_loss: 0.6875 - val_accuracy: 0.5185\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6333 - accuracy: 0.6154 - val_loss: 0.6886 - val_accuracy: 0.5185\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6333 - accuracy: 0.6154 - val_loss: 0.6894 - val_accuracy: 0.5185\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6327 - accuracy: 0.6154 - val_loss: 0.6894 - val_accuracy: 0.5185\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6325 - accuracy: 0.6154 - val_loss: 0.6890 - val_accuracy: 0.5185\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6321 - accuracy: 0.6154 - val_loss: 0.6897 - val_accuracy: 0.5185\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6319 - accuracy: 0.6154 - val_loss: 0.6896 - val_accuracy: 0.5185\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6317 - accuracy: 0.6154 - val_loss: 0.6897 - val_accuracy: 0.5185\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6323 - accuracy: 0.6154 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6312 - accuracy: 0.6154 - val_loss: 0.6875 - val_accuracy: 0.5185\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6307 - accuracy: 0.6154 - val_loss: 0.6867 - val_accuracy: 0.5185\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6303 - accuracy: 0.6154 - val_loss: 0.6859 - val_accuracy: 0.5185\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6302 - accuracy: 0.6154 - val_loss: 0.6859 - val_accuracy: 0.5185\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6298 - accuracy: 0.6154 - val_loss: 0.6846 - val_accuracy: 0.5185\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6297 - accuracy: 0.6154 - val_loss: 0.6832 - val_accuracy: 0.5185\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6293 - accuracy: 0.6154 - val_loss: 0.6809 - val_accuracy: 0.5185\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6292 - accuracy: 0.6154 - val_loss: 0.6800 - val_accuracy: 0.5185\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6290 - accuracy: 0.6154 - val_loss: 0.6782 - val_accuracy: 0.5185\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6291 - accuracy: 0.6154 - val_loss: 0.6772 - val_accuracy: 0.5185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3z1ldA67vxo",
        "outputId": "e574d2dc-94ed-4519-f633-3fcdea7091bb"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6626 - accuracy: 0.4783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6625529527664185, 0.47826087474823]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8 = tf.keras.models.load_model(f\"/content/model_experiments/{model8.name}\")\n",
        "model8.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "HDtXkIhQq43p",
        "outputId": "79315aab-c314-468c-f69a-72e330227653",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step - loss: 0.6927 - accuracy: 0.4783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6926807165145874, 0.47826087474823]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model9 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model9.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history9 = model9.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model9.name)])"
      ],
      "metadata": {
        "id": "IwsQafCPeho4",
        "outputId": "42f51a85-35e2-4708-f850-3ea5378330a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 201ms/step - loss: 0.6899 - accuracy: 0.5462 - val_loss: 0.6909 - val_accuracy: 0.4815\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 0.6843 - accuracy: 0.6077 - val_loss: 0.6893 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6808 - accuracy: 0.6154 - val_loss: 0.6870 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6751 - accuracy: 0.6154 - val_loss: 0.6851 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6698 - accuracy: 0.6154 - val_loss: 0.6839 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6654 - accuracy: 0.6154 - val_loss: 0.6834 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6628 - accuracy: 0.6154 - val_loss: 0.6836 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6586 - accuracy: 0.6154 - val_loss: 0.6843 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6556 - accuracy: 0.6154 - val_loss: 0.6850 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6543 - accuracy: 0.6154 - val_loss: 0.6854 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6528 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.6845 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.6154 - val_loss: 0.6840 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6510 - accuracy: 0.6154 - val_loss: 0.6838 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6507 - accuracy: 0.6154 - val_loss: 0.6837 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6496 - accuracy: 0.6154 - val_loss: 0.6834 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6488 - accuracy: 0.6154 - val_loss: 0.6834 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6481 - accuracy: 0.6154 - val_loss: 0.6842 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6471 - accuracy: 0.6154 - val_loss: 0.6835 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6466 - accuracy: 0.6154 - val_loss: 0.6837 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6462 - accuracy: 0.6154 - val_loss: 0.6824 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6463 - accuracy: 0.6154 - val_loss: 0.6815 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6461 - accuracy: 0.6154 - val_loss: 0.6810 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6457 - accuracy: 0.6154 - val_loss: 0.6819 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6447 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6442 - accuracy: 0.6154 - val_loss: 0.6821 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6438 - accuracy: 0.6154 - val_loss: 0.6825 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6432 - accuracy: 0.6154 - val_loss: 0.6841 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6422 - accuracy: 0.6154 - val_loss: 0.6865 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6418 - accuracy: 0.6154 - val_loss: 0.6887 - val_accuracy: 0.5185\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6418 - accuracy: 0.6154 - val_loss: 0.6881 - val_accuracy: 0.5185\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6414 - accuracy: 0.6154 - val_loss: 0.6891 - val_accuracy: 0.5185\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6411 - accuracy: 0.6154 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6410 - accuracy: 0.6154 - val_loss: 0.6896 - val_accuracy: 0.5185\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6408 - accuracy: 0.6154 - val_loss: 0.6904 - val_accuracy: 0.5185\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.6154 - val_loss: 0.6920 - val_accuracy: 0.5185\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6411 - accuracy: 0.6154 - val_loss: 0.6951 - val_accuracy: 0.5185\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6413 - accuracy: 0.6154 - val_loss: 0.6983 - val_accuracy: 0.5185\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6423 - accuracy: 0.6154 - val_loss: 0.7017 - val_accuracy: 0.5185\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6430 - accuracy: 0.6154 - val_loss: 0.7030 - val_accuracy: 0.5185\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6423 - accuracy: 0.6154 - val_loss: 0.6979 - val_accuracy: 0.5185\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6402 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6393 - accuracy: 0.6154 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6377 - accuracy: 0.6154 - val_loss: 0.6871 - val_accuracy: 0.5185\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6371 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6365 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6360 - accuracy: 0.6154 - val_loss: 0.6816 - val_accuracy: 0.5185\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6355 - accuracy: 0.6154 - val_loss: 0.6819 - val_accuracy: 0.5185\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6351 - accuracy: 0.6154 - val_loss: 0.6789 - val_accuracy: 0.5185\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6347 - accuracy: 0.6154 - val_loss: 0.6747 - val_accuracy: 0.5185\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.6154 - val_loss: 0.6719 - val_accuracy: 0.5185\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6356 - accuracy: 0.6154 - val_loss: 0.6701 - val_accuracy: 0.5185\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6352 - accuracy: 0.6154 - val_loss: 0.6702 - val_accuracy: 0.5185\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6352 - accuracy: 0.6154 - val_loss: 0.6710 - val_accuracy: 0.5185\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6341 - accuracy: 0.6154 - val_loss: 0.6721 - val_accuracy: 0.5185\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6331 - accuracy: 0.6154 - val_loss: 0.6739 - val_accuracy: 0.5185\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6327 - accuracy: 0.6154 - val_loss: 0.6756 - val_accuracy: 0.5185\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6326 - accuracy: 0.6154 - val_loss: 0.6748 - val_accuracy: 0.5185\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6325 - accuracy: 0.6154 - val_loss: 0.6745 - val_accuracy: 0.5185\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6322 - accuracy: 0.6154 - val_loss: 0.6754 - val_accuracy: 0.5185\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6320 - accuracy: 0.6154 - val_loss: 0.6741 - val_accuracy: 0.5185\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6315 - accuracy: 0.6154 - val_loss: 0.6707 - val_accuracy: 0.5185\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6313 - accuracy: 0.6154 - val_loss: 0.6688 - val_accuracy: 0.5185\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6320 - accuracy: 0.6154 - val_loss: 0.6670 - val_accuracy: 0.5185\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.6154 - val_loss: 0.6656 - val_accuracy: 0.5185\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.6316 - accuracy: 0.6077 - val_loss: 0.6639 - val_accuracy: 0.5926\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6316 - accuracy: 0.6154 - val_loss: 0.6632 - val_accuracy: 0.5926\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6311 - accuracy: 0.6231 - val_loss: 0.6635 - val_accuracy: 0.5926\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6300 - accuracy: 0.6308 - val_loss: 0.6638 - val_accuracy: 0.5926\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6292 - accuracy: 0.6538 - val_loss: 0.6640 - val_accuracy: 0.5926\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6289 - accuracy: 0.6538 - val_loss: 0.6638 - val_accuracy: 0.5926\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6281 - accuracy: 0.6538 - val_loss: 0.6644 - val_accuracy: 0.5926\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6280 - accuracy: 0.6462 - val_loss: 0.6667 - val_accuracy: 0.5926\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6270 - accuracy: 0.6077 - val_loss: 0.6686 - val_accuracy: 0.5926\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6270 - accuracy: 0.6077 - val_loss: 0.6690 - val_accuracy: 0.5926\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6269 - accuracy: 0.6154 - val_loss: 0.6682 - val_accuracy: 0.5926\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6269 - accuracy: 0.6538 - val_loss: 0.6656 - val_accuracy: 0.5926\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6263 - accuracy: 0.6538 - val_loss: 0.6657 - val_accuracy: 0.5926\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6257 - accuracy: 0.6538 - val_loss: 0.6651 - val_accuracy: 0.5926\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6255 - accuracy: 0.6615 - val_loss: 0.6656 - val_accuracy: 0.5926\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6253 - accuracy: 0.6615 - val_loss: 0.6663 - val_accuracy: 0.5926\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6253 - accuracy: 0.6538 - val_loss: 0.6681 - val_accuracy: 0.5926\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6251 - accuracy: 0.6462 - val_loss: 0.6699 - val_accuracy: 0.5926\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6251 - accuracy: 0.6615 - val_loss: 0.6708 - val_accuracy: 0.5926\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.6615 - val_loss: 0.6706 - val_accuracy: 0.5926\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6243 - accuracy: 0.6538 - val_loss: 0.6701 - val_accuracy: 0.5926\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6237 - accuracy: 0.6538 - val_loss: 0.6709 - val_accuracy: 0.5926\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6236 - accuracy: 0.6538 - val_loss: 0.6705 - val_accuracy: 0.5926\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6233 - accuracy: 0.6692 - val_loss: 0.6704 - val_accuracy: 0.5926\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6239 - accuracy: 0.6692 - val_loss: 0.6707 - val_accuracy: 0.5926\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.6226 - accuracy: 0.6692 - val_loss: 0.6665 - val_accuracy: 0.6296\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6218 - accuracy: 0.6846 - val_loss: 0.6651 - val_accuracy: 0.6296\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6213 - accuracy: 0.6846 - val_loss: 0.6636 - val_accuracy: 0.6296\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6213 - accuracy: 0.6769 - val_loss: 0.6634 - val_accuracy: 0.6296\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6209 - accuracy: 0.6769 - val_loss: 0.6616 - val_accuracy: 0.6296\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6208 - accuracy: 0.6538 - val_loss: 0.6600 - val_accuracy: 0.6296\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.6615 - val_loss: 0.6578 - val_accuracy: 0.6296\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6208 - accuracy: 0.6615 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6207 - accuracy: 0.6692 - val_loss: 0.6561 - val_accuracy: 0.6296\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6207 - accuracy: 0.6769 - val_loss: 0.6560 - val_accuracy: 0.6296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model9.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd_oLO0b7xF-",
        "outputId": "3ed4aba5-2565-4eaf-bf2f-db094389c96c"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6338 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6338170766830444, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model9 = tf.keras.models.load_model(f\"/content/model_experiments/{model9.name}\")\n",
        "model9.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "PNeldcfCq6b9",
        "outputId": "7d48dda7-a8b1-4616-9100-e441d4fd0821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 118ms/step - loss: 0.6427 - accuracy: 0.6522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6426671743392944, 0.6521739363670349]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLbBeyiit_4Z"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZYMdY3Ht__h"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3jGW7vHzcyKG"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model10 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model10.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history10 = model10.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model10.name)])"
      ],
      "metadata": {
        "id": "en9K52fle0pU",
        "outputId": "5974b719-fa79-4322-c2b7-4b37535d548c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 214ms/step - loss: 0.6926 - accuracy: 0.5846 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6922 - accuracy: 0.6000 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6918 - accuracy: 0.6077 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6913 - accuracy: 0.6154 - val_loss: 0.6915 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6154 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.6154 - val_loss: 0.6907 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.6154 - val_loss: 0.6904 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6889 - accuracy: 0.6154 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6877 - accuracy: 0.6154 - val_loss: 0.6893 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.6154 - val_loss: 0.6888 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6863 - accuracy: 0.6154 - val_loss: 0.6884 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6859 - accuracy: 0.6154 - val_loss: 0.6882 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6854 - accuracy: 0.6154 - val_loss: 0.6880 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6850 - accuracy: 0.6154 - val_loss: 0.6879 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6843 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6830 - accuracy: 0.6154 - val_loss: 0.6870 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6818 - accuracy: 0.6154 - val_loss: 0.6868 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6803 - accuracy: 0.6154 - val_loss: 0.6869 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6783 - accuracy: 0.6154 - val_loss: 0.6871 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6768 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6755 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6745 - accuracy: 0.6154 - val_loss: 0.6872 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6728 - accuracy: 0.6154 - val_loss: 0.6869 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6714 - accuracy: 0.6154 - val_loss: 0.6865 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6693 - accuracy: 0.6154 - val_loss: 0.6861 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6676 - accuracy: 0.6154 - val_loss: 0.6857 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6661 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6640 - accuracy: 0.6154 - val_loss: 0.6850 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6614 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6594 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6579 - accuracy: 0.6154 - val_loss: 0.6848 - val_accuracy: 0.5185\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6568 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6554 - accuracy: 0.6154 - val_loss: 0.6852 - val_accuracy: 0.5185\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6544 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6534 - accuracy: 0.6154 - val_loss: 0.6857 - val_accuracy: 0.5185\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6522 - accuracy: 0.6154 - val_loss: 0.6864 - val_accuracy: 0.5185\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6507 - accuracy: 0.6154 - val_loss: 0.6886 - val_accuracy: 0.5185\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6502 - accuracy: 0.6154 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6497 - accuracy: 0.6154 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6493 - accuracy: 0.6154 - val_loss: 0.6908 - val_accuracy: 0.5185\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6490 - accuracy: 0.6154 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6487 - accuracy: 0.6154 - val_loss: 0.6898 - val_accuracy: 0.5185\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6484 - accuracy: 0.6154 - val_loss: 0.6895 - val_accuracy: 0.5185\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6481 - accuracy: 0.6154 - val_loss: 0.6894 - val_accuracy: 0.5185\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6479 - accuracy: 0.6154 - val_loss: 0.6888 - val_accuracy: 0.5185\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6476 - accuracy: 0.6154 - val_loss: 0.6890 - val_accuracy: 0.5185\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6472 - accuracy: 0.6154 - val_loss: 0.6893 - val_accuracy: 0.5185\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6470 - accuracy: 0.6154 - val_loss: 0.6883 - val_accuracy: 0.5185\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6468 - accuracy: 0.6154 - val_loss: 0.6866 - val_accuracy: 0.5185\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6467 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6470 - accuracy: 0.6154 - val_loss: 0.6843 - val_accuracy: 0.5185\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6467 - accuracy: 0.6154 - val_loss: 0.6842 - val_accuracy: 0.5185\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6466 - accuracy: 0.6154 - val_loss: 0.6843 - val_accuracy: 0.5185\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6462 - accuracy: 0.6154 - val_loss: 0.6845 - val_accuracy: 0.5185\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6154 - val_loss: 0.6851 - val_accuracy: 0.5185\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6453 - accuracy: 0.6154 - val_loss: 0.6858 - val_accuracy: 0.5185\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6452 - accuracy: 0.6154 - val_loss: 0.6855 - val_accuracy: 0.5185\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6451 - accuracy: 0.6154 - val_loss: 0.6854 - val_accuracy: 0.5185\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6449 - accuracy: 0.6154 - val_loss: 0.6858 - val_accuracy: 0.5185\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6447 - accuracy: 0.6154 - val_loss: 0.6854 - val_accuracy: 0.5185\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6445 - accuracy: 0.6154 - val_loss: 0.6840 - val_accuracy: 0.5185\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6443 - accuracy: 0.6154 - val_loss: 0.6831 - val_accuracy: 0.5185\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6447 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6444 - accuracy: 0.6154 - val_loss: 0.6815 - val_accuracy: 0.5185\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6444 - accuracy: 0.6154 - val_loss: 0.6804 - val_accuracy: 0.5185\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6443 - accuracy: 0.6154 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6441 - accuracy: 0.6154 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6436 - accuracy: 0.6154 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6433 - accuracy: 0.6154 - val_loss: 0.6798 - val_accuracy: 0.5185\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6431 - accuracy: 0.6154 - val_loss: 0.6797 - val_accuracy: 0.5185\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6426 - accuracy: 0.6154 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6425 - accuracy: 0.6154 - val_loss: 0.6807 - val_accuracy: 0.5185\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6419 - accuracy: 0.6154 - val_loss: 0.6814 - val_accuracy: 0.5185\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6419 - accuracy: 0.6154 - val_loss: 0.6817 - val_accuracy: 0.5185\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6418 - accuracy: 0.6154 - val_loss: 0.6817 - val_accuracy: 0.5185\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6418 - accuracy: 0.6154 - val_loss: 0.6806 - val_accuracy: 0.5185\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6415 - accuracy: 0.6154 - val_loss: 0.6806 - val_accuracy: 0.5185\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6412 - accuracy: 0.6154 - val_loss: 0.6803 - val_accuracy: 0.5185\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6411 - accuracy: 0.6154 - val_loss: 0.6804 - val_accuracy: 0.5185\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6410 - accuracy: 0.6154 - val_loss: 0.6806 - val_accuracy: 0.5185\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6410 - accuracy: 0.6154 - val_loss: 0.6812 - val_accuracy: 0.5185\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6408 - accuracy: 0.6154 - val_loss: 0.6819 - val_accuracy: 0.5185\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6406 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6402 - accuracy: 0.6154 - val_loss: 0.6821 - val_accuracy: 0.5185\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6401 - accuracy: 0.6154 - val_loss: 0.6818 - val_accuracy: 0.5185\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6397 - accuracy: 0.6154 - val_loss: 0.6821 - val_accuracy: 0.5185\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6395 - accuracy: 0.6154 - val_loss: 0.6821 - val_accuracy: 0.5185\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6393 - accuracy: 0.6154 - val_loss: 0.6820 - val_accuracy: 0.5185\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6396 - accuracy: 0.6154 - val_loss: 0.6823 - val_accuracy: 0.5185\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6389 - accuracy: 0.6154 - val_loss: 0.6811 - val_accuracy: 0.5185\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6387 - accuracy: 0.6154 - val_loss: 0.6809 - val_accuracy: 0.5185\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6384 - accuracy: 0.6154 - val_loss: 0.6805 - val_accuracy: 0.5185\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6383 - accuracy: 0.6154 - val_loss: 0.6804 - val_accuracy: 0.5185\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6381 - accuracy: 0.6154 - val_loss: 0.6794 - val_accuracy: 0.5185\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6379 - accuracy: 0.6154 - val_loss: 0.6785 - val_accuracy: 0.5185\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6375 - accuracy: 0.6154 - val_loss: 0.6772 - val_accuracy: 0.5185\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6375 - accuracy: 0.6154 - val_loss: 0.6767 - val_accuracy: 0.5185\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6374 - accuracy: 0.6154 - val_loss: 0.6758 - val_accuracy: 0.5185\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6374 - accuracy: 0.6154 - val_loss: 0.6751 - val_accuracy: 0.5185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model10.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2fxE1Nm7yn9",
        "outputId": "6205652d-7314-46c2-e2a0-b0820eff7f53"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6691 - accuracy: 0.4783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6691227555274963, 0.47826087474823]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model10 = tf.keras.models.load_model(f\"/content/model_experiments/{model10.name}\")\n",
        "model10.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "lpKDkcyxq8F8",
        "outputId": "804deb30-34e3-4493-9fd6-77cea1213767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 127ms/step - loss: 0.6930 - accuracy: 0.4348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.692970335483551, 0.43478259444236755]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model11 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model11.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history11 = model11.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model11.name)])"
      ],
      "metadata": {
        "id": "d0mJOMoge0ri",
        "outputId": "6b42d7ce-cd96-4c4e-c137-2842b26177ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 1s 36ms/step - loss: 0.6921 - accuracy: 0.5538 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.6154 - val_loss: 0.6917 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.6154 - val_loss: 0.6901 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.6154 - val_loss: 0.6881 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.6154 - val_loss: 0.6878 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.6154 - val_loss: 0.6870 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.6154 - val_loss: 0.6857 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6154 - val_loss: 0.6855 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6154 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6154 - val_loss: 0.6861 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6154 - val_loss: 0.6863 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6154 - val_loss: 0.6864 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6154 - val_loss: 0.6875 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6154 - val_loss: 0.6870 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6154 - val_loss: 0.6833 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6154 - val_loss: 0.6854 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6154 - val_loss: 0.6831 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6154 - val_loss: 0.6821 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6154 - val_loss: 0.6813 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6154 - val_loss: 0.6777 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6154 - val_loss: 0.6799 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6154 - val_loss: 0.6769 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6154 - val_loss: 0.6770 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.6154 - val_loss: 0.6765 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6154 - val_loss: 0.6756 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6154 - val_loss: 0.6740 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6154 - val_loss: 0.6749 - val_accuracy: 0.5185\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6154 - val_loss: 0.6722 - val_accuracy: 0.5185\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6154 - val_loss: 0.6722 - val_accuracy: 0.5185\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6154 - val_loss: 0.6707 - val_accuracy: 0.5185\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6154 - val_loss: 0.6699 - val_accuracy: 0.5185\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6154 - val_loss: 0.6695 - val_accuracy: 0.5185\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6154 - val_loss: 0.6680 - val_accuracy: 0.5185\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.6154 - val_loss: 0.6691 - val_accuracy: 0.5185\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.6154 - val_loss: 0.6666 - val_accuracy: 0.5185\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6154 - val_loss: 0.6661 - val_accuracy: 0.5185\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6154 - val_loss: 0.6672 - val_accuracy: 0.5185\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.6154 - val_loss: 0.6647 - val_accuracy: 0.5185\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6154 - val_loss: 0.6643 - val_accuracy: 0.5185\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.6154 - val_loss: 0.6633 - val_accuracy: 0.5185\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6154 - val_loss: 0.6641 - val_accuracy: 0.5185\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6278 - accuracy: 0.6538 - val_loss: 0.6633 - val_accuracy: 0.5556\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6615 - val_loss: 0.6625 - val_accuracy: 0.5556\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.6538 - val_loss: 0.6615 - val_accuracy: 0.5556\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 0.6271 - accuracy: 0.6538 - val_loss: 0.6617 - val_accuracy: 0.5926\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6538 - val_loss: 0.6622 - val_accuracy: 0.5556\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6538 - val_loss: 0.6614 - val_accuracy: 0.5926\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6260 - accuracy: 0.6538 - val_loss: 0.6600 - val_accuracy: 0.6296\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6260 - accuracy: 0.6538 - val_loss: 0.6586 - val_accuracy: 0.6667\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6538 - val_loss: 0.6615 - val_accuracy: 0.6296\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6615 - val_loss: 0.6626 - val_accuracy: 0.6296\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6615 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.6615 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6615 - val_loss: 0.6574 - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6692 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.6615 - val_loss: 0.6574 - val_accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6615 - val_loss: 0.6581 - val_accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6615 - val_loss: 0.6585 - val_accuracy: 0.6667\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6615 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6615 - val_loss: 0.6582 - val_accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6615 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6692 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.6692 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6615 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6692 - val_loss: 0.6566 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6615 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6615 - val_loss: 0.6566 - val_accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.6615 - val_loss: 0.6579 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.6692 - val_loss: 0.6553 - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.6615 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.6692 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.6692 - val_loss: 0.6556 - val_accuracy: 0.6667\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.6692 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6615 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.6692 - val_loss: 0.6575 - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6692 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6538 - val_loss: 0.6553 - val_accuracy: 0.6667\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.6538 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6615 - val_loss: 0.6574 - val_accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6615 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.6538 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6538 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6538 - val_loss: 0.6545 - val_accuracy: 0.6667\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6538 - val_loss: 0.6553 - val_accuracy: 0.6667\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.6538 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.6538 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.6615 - val_loss: 0.6588 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6538 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6538 - val_loss: 0.6568 - val_accuracy: 0.6667\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.6538 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6615 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.6538 - val_loss: 0.6566 - val_accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6538 - val_loss: 0.6576 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.6538 - val_loss: 0.6560 - val_accuracy: 0.6296\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6538 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6615 - val_loss: 0.6562 - val_accuracy: 0.6296\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6692 - val_loss: 0.6568 - val_accuracy: 0.6296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model11.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "talbzlnM7z6g",
        "outputId": "22cea18f-28c6-4004-ea8e-91571e4affb6"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6134 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6134088039398193, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model11 = tf.keras.models.load_model(f\"/content/model_experiments/{model11.name}\")\n",
        "model11.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "0QMLEXq_q-aZ",
        "outputId": "51bdb71c-febd-41c1-b8a3-753c11f98c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 122ms/step - loss: 0.6405 - accuracy: 0.6522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6405295729637146, 0.6521739363670349]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model12 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model12.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history12 = model12.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=10,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model12.name)])"
      ],
      "metadata": {
        "id": "HOLGhvTfe0t1",
        "outputId": "47143452-58af-460c-fcfe-7bd64b7ff4b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.6519 - accuracy: 0.6154 - val_loss: 0.6797 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.6154 - val_loss: 0.6809 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6154 - val_loss: 0.6829 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.6154 - val_loss: 0.6840 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.6154 - val_loss: 0.6838 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.6154 - val_loss: 0.6842 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6440 - accuracy: 0.6154 - val_loss: 0.6872 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6154 - val_loss: 0.6858 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6154 - val_loss: 0.6840 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6154 - val_loss: 0.6838 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6154 - val_loss: 0.6819 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6154 - val_loss: 0.6817 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6372 - accuracy: 0.6154 - val_loss: 0.6816 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6360 - accuracy: 0.6154 - val_loss: 0.6788 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6361 - accuracy: 0.6154 - val_loss: 0.6761 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6350 - accuracy: 0.6154 - val_loss: 0.6780 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6154 - val_loss: 0.6748 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6154 - val_loss: 0.6751 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.6154 - val_loss: 0.6748 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.6154 - val_loss: 0.6738 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.6322 - accuracy: 0.6154 - val_loss: 0.6692 - val_accuracy: 0.5926\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6154 - val_loss: 0.6711 - val_accuracy: 0.5926\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6154 - val_loss: 0.6689 - val_accuracy: 0.5926\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6154 - val_loss: 0.6687 - val_accuracy: 0.5926\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6385 - val_loss: 0.6684 - val_accuracy: 0.5926\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6462 - val_loss: 0.6682 - val_accuracy: 0.5926\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6462 - val_loss: 0.6666 - val_accuracy: 0.5926\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6692 - val_loss: 0.6671 - val_accuracy: 0.5926\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.6615 - val_loss: 0.6662 - val_accuracy: 0.5926\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.6263 - accuracy: 0.6769 - val_loss: 0.6659 - val_accuracy: 0.6296\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6264 - accuracy: 0.6846 - val_loss: 0.6648 - val_accuracy: 0.6296\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.6769 - val_loss: 0.6641 - val_accuracy: 0.6296\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6250 - accuracy: 0.6769 - val_loss: 0.6640 - val_accuracy: 0.6296\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.6846 - val_loss: 0.6628 - val_accuracy: 0.6296\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6246 - accuracy: 0.7000 - val_loss: 0.6653 - val_accuracy: 0.6296\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.6923 - val_loss: 0.6628 - val_accuracy: 0.6296\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.6769 - val_loss: 0.6624 - val_accuracy: 0.6296\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.6769 - val_loss: 0.6631 - val_accuracy: 0.6296\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6225 - accuracy: 0.6846 - val_loss: 0.6610 - val_accuracy: 0.6296\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.6692 - val_loss: 0.6606 - val_accuracy: 0.6296\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6615 - val_loss: 0.6597 - val_accuracy: 0.6296\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6615 - val_loss: 0.6613 - val_accuracy: 0.6296\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6209 - accuracy: 0.6615 - val_loss: 0.6607 - val_accuracy: 0.6296\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.6615 - val_loss: 0.6601 - val_accuracy: 0.6296\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6200 - accuracy: 0.6615 - val_loss: 0.6595 - val_accuracy: 0.6296\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6200 - accuracy: 0.6615 - val_loss: 0.6590 - val_accuracy: 0.6296\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.6615 - val_loss: 0.6597 - val_accuracy: 0.6296\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.6615 - val_loss: 0.6592 - val_accuracy: 0.6296\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6189 - accuracy: 0.6615 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6615 - val_loss: 0.6562 - val_accuracy: 0.6296\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.6615 - val_loss: 0.6598 - val_accuracy: 0.6296\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.6615 - val_loss: 0.6622 - val_accuracy: 0.6296\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.6615 - val_loss: 0.6555 - val_accuracy: 0.6296\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.6174 - accuracy: 0.6615 - val_loss: 0.6542 - val_accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.6615 - val_loss: 0.6553 - val_accuracy: 0.6296\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.6615 - val_loss: 0.6561 - val_accuracy: 0.6296\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.6615 - val_loss: 0.6552 - val_accuracy: 0.6296\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.6615 - val_loss: 0.6557 - val_accuracy: 0.6296\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6615 - val_loss: 0.6564 - val_accuracy: 0.6296\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.6615 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6615 - val_loss: 0.6562 - val_accuracy: 0.6296\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6149 - accuracy: 0.6615 - val_loss: 0.6529 - val_accuracy: 0.6667\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.6615 - val_loss: 0.6554 - val_accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.6615 - val_loss: 0.6532 - val_accuracy: 0.6667\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.6615 - val_loss: 0.6536 - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6133 - accuracy: 0.6615 - val_loss: 0.6543 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.6692 - val_loss: 0.6521 - val_accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.6692 - val_loss: 0.6537 - val_accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.6692 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6124 - accuracy: 0.6692 - val_loss: 0.6519 - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6692 - val_loss: 0.6541 - val_accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6692 - val_loss: 0.6509 - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.6692 - val_loss: 0.6517 - val_accuracy: 0.6667\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.6692 - val_loss: 0.6539 - val_accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6111 - accuracy: 0.6615 - val_loss: 0.6499 - val_accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.6692 - val_loss: 0.6543 - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.6692 - val_loss: 0.6530 - val_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6083 - accuracy: 0.6615 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.6692 - val_loss: 0.6521 - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6615 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.6538 - val_loss: 0.6523 - val_accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.6615 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 1s 64ms/step - loss: 0.6062 - accuracy: 0.6615 - val_loss: 0.6498 - val_accuracy: 0.7037\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6615 - val_loss: 0.6480 - val_accuracy: 0.7037\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.6615 - val_loss: 0.6501 - val_accuracy: 0.7037\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.6692 - val_loss: 0.6515 - val_accuracy: 0.7037\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.6615 - val_loss: 0.6529 - val_accuracy: 0.7037\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6615 - val_loss: 0.6566 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.6615 - val_loss: 0.6508 - val_accuracy: 0.7037\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.6615 - val_loss: 0.6509 - val_accuracy: 0.7037\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.6615 - val_loss: 0.6519 - val_accuracy: 0.7037\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.6615 - val_loss: 0.6513 - val_accuracy: 0.7037\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6031 - accuracy: 0.6692 - val_loss: 0.6514 - val_accuracy: 0.7037\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.6692 - val_loss: 0.6524 - val_accuracy: 0.7037\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6692 - val_loss: 0.6505 - val_accuracy: 0.7037\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.6615 - val_loss: 0.6509 - val_accuracy: 0.7037\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6023 - accuracy: 0.6538 - val_loss: 0.6499 - val_accuracy: 0.6667\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.6769 - val_loss: 0.6505 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model12.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-hHajVs71Ly",
        "outputId": "5f34353a-09fa-42a2-dcce-5b20f2e8a79a"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5910 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5909890532493591, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model12 = tf.keras.models.load_model(f\"/content/model_experiments/{model12.name}\")\n",
        "model12.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "iB5xbBGeq_Tn",
        "outputId": "6754e9b6-7a53-4c23-a3ea-836704a7e76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step - loss: 0.6010 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.601042628288269, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model13 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model13.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history13 = model13.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=10,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model13.name)])"
      ],
      "metadata": {
        "id": "etsSl4HktL8C",
        "outputId": "a6dfdb1c-a90e-4166-ec82-17a5bfc36d26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.6932 - accuracy: 0.4462 - val_loss: 0.6937 - val_accuracy: 0.4815\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.6868 - accuracy: 0.6077 - val_loss: 0.6909 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.6154 - val_loss: 0.6882 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.6154 - val_loss: 0.6877 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.6154 - val_loss: 0.6881 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.6154 - val_loss: 0.6887 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.6154 - val_loss: 0.6909 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6550 - accuracy: 0.6154 - val_loss: 0.6931 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6512 - accuracy: 0.6154 - val_loss: 0.6945 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.6154 - val_loss: 0.6971 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6154 - val_loss: 0.6975 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.6154 - val_loss: 0.6984 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6154 - val_loss: 0.6999 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6444 - accuracy: 0.6154 - val_loss: 0.7001 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6441 - accuracy: 0.6154 - val_loss: 0.7005 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6428 - accuracy: 0.6154 - val_loss: 0.6975 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6154 - val_loss: 0.6948 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6416 - accuracy: 0.6154 - val_loss: 0.6970 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6407 - accuracy: 0.6154 - val_loss: 0.6938 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.6154 - val_loss: 0.6940 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6154 - val_loss: 0.6934 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6154 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.6154 - val_loss: 0.6876 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.6154 - val_loss: 0.6892 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.6154 - val_loss: 0.6864 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6154 - val_loss: 0.6858 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6154 - val_loss: 0.6850 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6154 - val_loss: 0.6840 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6321 - accuracy: 0.6154 - val_loss: 0.6819 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.6154 - val_loss: 0.6819 - val_accuracy: 0.5185\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.6154 - val_loss: 0.6807 - val_accuracy: 0.5185\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6154 - val_loss: 0.6800 - val_accuracy: 0.5185\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.6154 - val_loss: 0.6785 - val_accuracy: 0.5185\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6284 - accuracy: 0.6154 - val_loss: 0.6778 - val_accuracy: 0.5185\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6154 - val_loss: 0.6774 - val_accuracy: 0.5185\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6154 - val_loss: 0.6761 - val_accuracy: 0.5185\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6273 - accuracy: 0.6154 - val_loss: 0.6788 - val_accuracy: 0.5185\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 1s 62ms/step - loss: 0.6264 - accuracy: 0.6154 - val_loss: 0.6763 - val_accuracy: 0.5556\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.6259 - accuracy: 0.6308 - val_loss: 0.6756 - val_accuracy: 0.5926\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6254 - accuracy: 0.6462 - val_loss: 0.6764 - val_accuracy: 0.5926\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6538 - val_loss: 0.6740 - val_accuracy: 0.5926\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.6244 - accuracy: 0.6538 - val_loss: 0.6730 - val_accuracy: 0.6296\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6615 - val_loss: 0.6716 - val_accuracy: 0.6296\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.6615 - val_loss: 0.6734 - val_accuracy: 0.6296\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6230 - accuracy: 0.6692 - val_loss: 0.6730 - val_accuracy: 0.6296\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6615 - val_loss: 0.6720 - val_accuracy: 0.6296\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6692 - val_loss: 0.6710 - val_accuracy: 0.6296\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6615 - val_loss: 0.6707 - val_accuracy: 0.6296\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6615 - val_loss: 0.6714 - val_accuracy: 0.6296\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.6615 - val_loss: 0.6711 - val_accuracy: 0.6296\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.6538 - val_loss: 0.6694 - val_accuracy: 0.6296\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.6538 - val_loss: 0.6682 - val_accuracy: 0.6296\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.6615 - val_loss: 0.6708 - val_accuracy: 0.6296\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.6538 - val_loss: 0.6736 - val_accuracy: 0.6296\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.6615 - val_loss: 0.6675 - val_accuracy: 0.6296\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.6193 - accuracy: 0.6615 - val_loss: 0.6659 - val_accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.6615 - val_loss: 0.6669 - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6615 - val_loss: 0.6679 - val_accuracy: 0.6296\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.6615 - val_loss: 0.6677 - val_accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6615 - val_loss: 0.6683 - val_accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6615 - val_loss: 0.6696 - val_accuracy: 0.6667\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6167 - accuracy: 0.6615 - val_loss: 0.6676 - val_accuracy: 0.6667\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.6615 - val_loss: 0.6685 - val_accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.6692 - val_loss: 0.6654 - val_accuracy: 0.6667\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.6692 - val_loss: 0.6679 - val_accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.6692 - val_loss: 0.6660 - val_accuracy: 0.6667\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6145 - accuracy: 0.6692 - val_loss: 0.6670 - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.6692 - val_loss: 0.6680 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.6692 - val_loss: 0.6658 - val_accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.6615 - val_loss: 0.6674 - val_accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6140 - accuracy: 0.6692 - val_loss: 0.6703 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6137 - accuracy: 0.6538 - val_loss: 0.6658 - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.6538 - val_loss: 0.6684 - val_accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.6538 - val_loss: 0.6655 - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.6538 - val_loss: 0.6668 - val_accuracy: 0.6667\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6538 - val_loss: 0.6699 - val_accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.6538 - val_loss: 0.6656 - val_accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6124 - accuracy: 0.6538 - val_loss: 0.6707 - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6101 - accuracy: 0.6538 - val_loss: 0.6691 - val_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.6615 - val_loss: 0.6674 - val_accuracy: 0.6667\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.6615 - val_loss: 0.6685 - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.6615 - val_loss: 0.6708 - val_accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6083 - accuracy: 0.6615 - val_loss: 0.6692 - val_accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.6615 - val_loss: 0.6707 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.6075 - accuracy: 0.6615 - val_loss: 0.6669 - val_accuracy: 0.7037\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.6692 - val_loss: 0.6660 - val_accuracy: 0.7037\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6067 - accuracy: 0.6769 - val_loss: 0.6689 - val_accuracy: 0.7037\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6769 - val_loss: 0.6696 - val_accuracy: 0.7037\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6692 - val_loss: 0.6720 - val_accuracy: 0.7037\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6692 - val_loss: 0.6761 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6769 - val_loss: 0.6697 - val_accuracy: 0.7037\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.6692 - val_loss: 0.6700 - val_accuracy: 0.7037\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6769 - val_loss: 0.6723 - val_accuracy: 0.7037\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.6692 - val_loss: 0.6723 - val_accuracy: 0.7037\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6692 - val_loss: 0.6727 - val_accuracy: 0.7037\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.6692 - val_loss: 0.6754 - val_accuracy: 0.7037\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6692 - val_loss: 0.6738 - val_accuracy: 0.7037\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.6692 - val_loss: 0.6745 - val_accuracy: 0.7037\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6019 - accuracy: 0.6692 - val_loss: 0.6739 - val_accuracy: 0.7037\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.6615 - val_loss: 0.6743 - val_accuracy: 0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model13.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTAuxujt72VG",
        "outputId": "6c18906d-650d-40d7-a46d-853338d87a81"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6122 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6122291684150696, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model13 = tf.keras.models.load_model(f\"/content/model_experiments/{model13.name}\")\n",
        "model13.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "FFd7l6LPrAGn",
        "outputId": "8cac7899-62e8-4d93-db27-7301f5baf1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 193ms/step - loss: 0.6197 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6196947693824768, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model14 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model14.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history14 = model14.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=10,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model14.name)])"
      ],
      "metadata": {
        "id": "T3c16NIOtOyF",
        "outputId": "8616b207-d6f5-408d-e00d-133ae7d7e7bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 5s 272ms/step - loss: 0.6837 - accuracy: 0.5769 - val_loss: 0.6845 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6714 - accuracy: 0.6154 - val_loss: 0.6820 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.6632 - accuracy: 0.6154 - val_loss: 0.6816 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.6552 - accuracy: 0.6154 - val_loss: 0.6836 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.6506 - accuracy: 0.6154 - val_loss: 0.6855 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.6472 - accuracy: 0.6154 - val_loss: 0.6877 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6493 - accuracy: 0.6154 - val_loss: 0.6938 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.6444 - accuracy: 0.6154 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 0.6439 - accuracy: 0.6154 - val_loss: 0.6872 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.6428 - accuracy: 0.6154 - val_loss: 0.6870 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6154 - val_loss: 0.6844 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6407 - accuracy: 0.6154 - val_loss: 0.6835 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6400 - accuracy: 0.6154 - val_loss: 0.6844 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.6154 - val_loss: 0.6835 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6154 - val_loss: 0.6830 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6154 - val_loss: 0.6782 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.6154 - val_loss: 0.6742 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6154 - val_loss: 0.6772 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6338 - accuracy: 0.6154 - val_loss: 0.6724 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6325 - accuracy: 0.6154 - val_loss: 0.6726 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.6154 - val_loss: 0.6719 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6154 - val_loss: 0.6703 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6311 - accuracy: 0.6308 - val_loss: 0.6652 - val_accuracy: 0.5926\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6615 - val_loss: 0.6687 - val_accuracy: 0.5926\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6293 - accuracy: 0.6692 - val_loss: 0.6663 - val_accuracy: 0.5926\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6692 - val_loss: 0.6667 - val_accuracy: 0.5926\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.6692 - val_loss: 0.6672 - val_accuracy: 0.5926\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.6275 - accuracy: 0.6538 - val_loss: 0.6669 - val_accuracy: 0.6296\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6846 - val_loss: 0.6646 - val_accuracy: 0.6296\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6846 - val_loss: 0.6657 - val_accuracy: 0.6296\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.6769 - val_loss: 0.6646 - val_accuracy: 0.6296\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6251 - accuracy: 0.6923 - val_loss: 0.6645 - val_accuracy: 0.6296\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.6846 - val_loss: 0.6628 - val_accuracy: 0.6296\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6241 - accuracy: 0.6769 - val_loss: 0.6631 - val_accuracy: 0.6296\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.6846 - val_loss: 0.6638 - val_accuracy: 0.6296\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.6769 - val_loss: 0.6623 - val_accuracy: 0.6296\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.6769 - val_loss: 0.6660 - val_accuracy: 0.6296\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.6769 - val_loss: 0.6622 - val_accuracy: 0.6296\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.6692 - val_loss: 0.6621 - val_accuracy: 0.6296\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6692 - val_loss: 0.6642 - val_accuracy: 0.6296\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6217 - accuracy: 0.6692 - val_loss: 0.6615 - val_accuracy: 0.6296\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.6692 - val_loss: 0.6611 - val_accuracy: 0.6296\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.6615 - val_loss: 0.6601 - val_accuracy: 0.6296\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6615 - val_loss: 0.6629 - val_accuracy: 0.6296\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.6692 - val_loss: 0.6623 - val_accuracy: 0.6296\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.6692 - val_loss: 0.6610 - val_accuracy: 0.6296\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.6615 - val_loss: 0.6596 - val_accuracy: 0.6296\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6615 - val_loss: 0.6586 - val_accuracy: 0.6296\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.6615 - val_loss: 0.6602 - val_accuracy: 0.6296\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.6166 - accuracy: 0.6615 - val_loss: 0.6592 - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.6615 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6166 - accuracy: 0.6692 - val_loss: 0.6537 - val_accuracy: 0.6667\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.6692 - val_loss: 0.6585 - val_accuracy: 0.6667\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6176 - accuracy: 0.6615 - val_loss: 0.6633 - val_accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.6162 - accuracy: 0.6538 - val_loss: 0.6503 - val_accuracy: 0.7037\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6140 - accuracy: 0.6615 - val_loss: 0.6487 - val_accuracy: 0.7037\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.6615 - val_loss: 0.6509 - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6692 - val_loss: 0.6537 - val_accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.6692 - val_loss: 0.6514 - val_accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6107 - accuracy: 0.6538 - val_loss: 0.6515 - val_accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.6615 - val_loss: 0.6534 - val_accuracy: 0.6667\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6099 - accuracy: 0.6692 - val_loss: 0.6497 - val_accuracy: 0.7037\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6099 - accuracy: 0.6538 - val_loss: 0.6527 - val_accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6692 - val_loss: 0.6474 - val_accuracy: 0.7037\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.6615 - val_loss: 0.6515 - val_accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6615 - val_loss: 0.6473 - val_accuracy: 0.7037\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6692 - val_loss: 0.6481 - val_accuracy: 0.7037\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6077 - accuracy: 0.6692 - val_loss: 0.6501 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6692 - val_loss: 0.6461 - val_accuracy: 0.7037\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.6692 - val_loss: 0.6488 - val_accuracy: 0.7037\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.6615 - val_loss: 0.6533 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.6615 - val_loss: 0.6437 - val_accuracy: 0.7037\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6065 - accuracy: 0.6692 - val_loss: 0.6483 - val_accuracy: 0.7037\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6057 - accuracy: 0.6615 - val_loss: 0.6432 - val_accuracy: 0.7037\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6042 - accuracy: 0.6692 - val_loss: 0.6457 - val_accuracy: 0.7037\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6051 - accuracy: 0.6692 - val_loss: 0.6492 - val_accuracy: 0.7037\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.6538 - val_loss: 0.6422 - val_accuracy: 0.7037\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6062 - accuracy: 0.6692 - val_loss: 0.6510 - val_accuracy: 0.7037\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6030 - accuracy: 0.6692 - val_loss: 0.6473 - val_accuracy: 0.7037\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6021 - accuracy: 0.6538 - val_loss: 0.6438 - val_accuracy: 0.7037\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6015 - accuracy: 0.6692 - val_loss: 0.6464 - val_accuracy: 0.7037\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6020 - accuracy: 0.6538 - val_loss: 0.6491 - val_accuracy: 0.7037\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.6692 - val_loss: 0.6461 - val_accuracy: 0.7037\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.6692 - val_loss: 0.6497 - val_accuracy: 0.7037\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.6769 - val_loss: 0.6439 - val_accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6032 - accuracy: 0.6769 - val_loss: 0.6426 - val_accuracy: 0.6667\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6769 - val_loss: 0.6479 - val_accuracy: 0.6667\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.6769 - val_loss: 0.6510 - val_accuracy: 0.7037\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5988 - accuracy: 0.6692 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6615 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6846 - val_loss: 0.6451 - val_accuracy: 0.6667\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.6769 - val_loss: 0.6483 - val_accuracy: 0.6667\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5980 - accuracy: 0.6769 - val_loss: 0.6531 - val_accuracy: 0.6667\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.6769 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5961 - accuracy: 0.6769 - val_loss: 0.6523 - val_accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.6769 - val_loss: 0.6542 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5965 - accuracy: 0.6769 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5968 - accuracy: 0.6769 - val_loss: 0.6523 - val_accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.6769 - val_loss: 0.6514 - val_accuracy: 0.6667\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.6769 - val_loss: 0.6534 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model14.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHC9jAs273i8",
        "outputId": "19522145-60a5-4f1f-a50c-8316bdad453f"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5747 - accuracy: 0.7391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5747423768043518, 0.739130437374115]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model14 = tf.keras.models.load_model(f\"/content/model_experiments/{model14.name}\")\n",
        "model14.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "ey6oyFQIrA1B",
        "outputId": "ac811e1b-fc19-4dff-d41f-d85eb428cb6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 135ms/step - loss: 0.6161 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6161332130432129, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model15 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model15.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history15 = model15.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=10,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model15.name)])"
      ],
      "metadata": {
        "id": "ytfYzYMftS79",
        "outputId": "3beac5dd-36c4-49c4-fc33-c9c0a0346119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 108ms/step - loss: 0.6847 - accuracy: 0.5846 - val_loss: 0.6869 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6652 - accuracy: 0.6154 - val_loss: 0.6872 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6572 - accuracy: 0.6154 - val_loss: 0.6995 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6512 - accuracy: 0.6154 - val_loss: 0.6974 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6491 - accuracy: 0.6154 - val_loss: 0.6887 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6449 - accuracy: 0.6154 - val_loss: 0.6868 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6154 - val_loss: 0.6943 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6154 - val_loss: 0.6785 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6407 - accuracy: 0.6154 - val_loss: 0.6726 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.6154 - val_loss: 0.6764 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6154 - val_loss: 0.6711 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.6328 - accuracy: 0.6231 - val_loss: 0.6676 - val_accuracy: 0.5926\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.6538 - val_loss: 0.6744 - val_accuracy: 0.5926\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.6286 - accuracy: 0.6923 - val_loss: 0.6647 - val_accuracy: 0.6296\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6692 - val_loss: 0.6655 - val_accuracy: 0.6296\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.6251 - accuracy: 0.6615 - val_loss: 0.6579 - val_accuracy: 0.6296\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.6538 - val_loss: 0.6563 - val_accuracy: 0.6296\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6538 - val_loss: 0.6701 - val_accuracy: 0.6296\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.6256 - accuracy: 0.6538 - val_loss: 0.6489 - val_accuracy: 0.7037\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.6769 - val_loss: 0.6600 - val_accuracy: 0.6296\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.6615 - val_loss: 0.6554 - val_accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6196 - accuracy: 0.6615 - val_loss: 0.6478 - val_accuracy: 0.7037\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6209 - accuracy: 0.6538 - val_loss: 0.6419 - val_accuracy: 0.7037\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.6538 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.6769 - val_loss: 0.6378 - val_accuracy: 0.7037\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6538 - val_loss: 0.6528 - val_accuracy: 0.7037\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.6615 - val_loss: 0.6471 - val_accuracy: 0.7037\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.6615 - val_loss: 0.6395 - val_accuracy: 0.7037\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6106 - accuracy: 0.6692 - val_loss: 0.6358 - val_accuracy: 0.7037\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6082 - accuracy: 0.6615 - val_loss: 0.6549 - val_accuracy: 0.7037\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6138 - accuracy: 0.6615 - val_loss: 0.6234 - val_accuracy: 0.7037\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.6615 - val_loss: 0.6347 - val_accuracy: 0.7037\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6692 - val_loss: 0.6308 - val_accuracy: 0.7037\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6013 - accuracy: 0.6692 - val_loss: 0.6324 - val_accuracy: 0.7037\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.6692 - val_loss: 0.6233 - val_accuracy: 0.7037\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.6615 - val_loss: 0.6251 - val_accuracy: 0.7037\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6022 - accuracy: 0.6692 - val_loss: 0.6434 - val_accuracy: 0.7037\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5985 - accuracy: 0.6692 - val_loss: 0.6121 - val_accuracy: 0.7037\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.6692 - val_loss: 0.6251 - val_accuracy: 0.7037\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.6692 - val_loss: 0.6291 - val_accuracy: 0.7037\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.6692 - val_loss: 0.6120 - val_accuracy: 0.7037\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.6692 - val_loss: 0.6121 - val_accuracy: 0.7037\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6615 - val_loss: 0.6471 - val_accuracy: 0.7037\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.6692 - val_loss: 0.6048 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.6769 - val_loss: 0.6176 - val_accuracy: 0.7037\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5865 - accuracy: 0.6692 - val_loss: 0.6128 - val_accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.6692 - val_loss: 0.6326 - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.6692 - val_loss: 0.6203 - val_accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.6769 - val_loss: 0.6412 - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.6769 - val_loss: 0.6165 - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.6769 - val_loss: 0.6265 - val_accuracy: 0.6667\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.6692 - val_loss: 0.6312 - val_accuracy: 0.6667\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.6769 - val_loss: 0.6420 - val_accuracy: 0.6667\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.6769 - val_loss: 0.6220 - val_accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.6923 - val_loss: 0.6073 - val_accuracy: 0.7037\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.6923 - val_loss: 0.6465 - val_accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.6846 - val_loss: 0.6261 - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5839 - accuracy: 0.6692 - val_loss: 0.6329 - val_accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.5714 - accuracy: 0.6769 - val_loss: 0.6111 - val_accuracy: 0.7407\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.6846 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.6923 - val_loss: 0.6247 - val_accuracy: 0.6667\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5718 - accuracy: 0.6923 - val_loss: 0.6226 - val_accuracy: 0.7037\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.6769 - val_loss: 0.6421 - val_accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6692 - val_loss: 0.6140 - val_accuracy: 0.7037\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.6615 - val_loss: 0.6516 - val_accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.7077 - val_loss: 0.6152 - val_accuracy: 0.5926\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.6769 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.6846 - val_loss: 0.6225 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.6923 - val_loss: 0.6537 - val_accuracy: 0.6296\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5705 - accuracy: 0.6923 - val_loss: 0.6627 - val_accuracy: 0.6296\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5681 - accuracy: 0.6923 - val_loss: 0.6466 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.6615 - val_loss: 0.6422 - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5782 - accuracy: 0.6846 - val_loss: 0.6493 - val_accuracy: 0.6296\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7077 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.7077 - val_loss: 0.6440 - val_accuracy: 0.6667\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5634 - accuracy: 0.7077 - val_loss: 0.6350 - val_accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7077 - val_loss: 0.6364 - val_accuracy: 0.7407\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.6769 - val_loss: 0.6497 - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7000 - val_loss: 0.6321 - val_accuracy: 0.7037\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.6923 - val_loss: 0.6326 - val_accuracy: 0.7407\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5615 - accuracy: 0.7077 - val_loss: 0.6461 - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.7000 - val_loss: 0.6423 - val_accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5593 - accuracy: 0.7077 - val_loss: 0.6412 - val_accuracy: 0.7407\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5680 - accuracy: 0.6923 - val_loss: 0.6631 - val_accuracy: 0.6296\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5626 - accuracy: 0.7077 - val_loss: 0.6253 - val_accuracy: 0.6296\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5566 - accuracy: 0.7000 - val_loss: 0.6566 - val_accuracy: 0.6667\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5568 - accuracy: 0.7000 - val_loss: 0.6445 - val_accuracy: 0.7037\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7000 - val_loss: 0.6486 - val_accuracy: 0.6667\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7077 - val_loss: 0.6424 - val_accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5538 - accuracy: 0.7154 - val_loss: 0.6517 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5545 - accuracy: 0.7154 - val_loss: 0.6389 - val_accuracy: 0.7037\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7077 - val_loss: 0.6442 - val_accuracy: 0.7037\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5526 - accuracy: 0.6923 - val_loss: 0.6434 - val_accuracy: 0.7037\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7231 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7231 - val_loss: 0.6423 - val_accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7000 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7231 - val_loss: 0.6342 - val_accuracy: 0.6667\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7154 - val_loss: 0.6283 - val_accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7154 - val_loss: 0.6628 - val_accuracy: 0.6667\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.7308 - val_loss: 0.6429 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model15.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zF-Vflf74n8",
        "outputId": "25a31782-d50e-44ef-ed8a-3961b0acfc69"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5013 - accuracy: 0.8261\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5012883543968201, 0.8260869383811951]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model15 = tf.keras.models.load_model(f\"/content/model_experiments/{model15.name}\")\n",
        "model15.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "hnN5jGe7rBrV",
        "outputId": "a12489ac-966b-4405-8bcf-9f3669987211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 140ms/step - loss: 0.5224 - accuracy: 0.8696\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5224146842956543, 0.8695651888847351]"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aSFXiJDIe0wL"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ndd_Lu6DajLv"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model16 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model16.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0003),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history16 = model16.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model16.name)])"
      ],
      "metadata": {
        "id": "bXvnP0wBajOx",
        "outputId": "fa50d6b9-45e6-4c22-84b8-c035c29a19d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 2s 53ms/step - loss: 0.6892 - accuracy: 0.5846 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.6154 - val_loss: 0.6869 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.6154 - val_loss: 0.6854 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6154 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.6154 - val_loss: 0.6883 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.6154 - val_loss: 0.6910 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6154 - val_loss: 0.6964 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6154 - val_loss: 0.6908 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6154 - val_loss: 0.6889 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.6154 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6154 - val_loss: 0.6885 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6154 - val_loss: 0.6865 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6154 - val_loss: 0.6891 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6154 - val_loss: 0.6872 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6154 - val_loss: 0.6804 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6154 - val_loss: 0.6785 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6154 - val_loss: 0.6829 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6154 - val_loss: 0.6748 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6154 - val_loss: 0.6781 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6154 - val_loss: 0.6755 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6154 - val_loss: 0.6726 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 0.6338 - accuracy: 0.6154 - val_loss: 0.6673 - val_accuracy: 0.5926\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6154 - val_loss: 0.6734 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6154 - val_loss: 0.6669 - val_accuracy: 0.5926\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.6231 - val_loss: 0.6700 - val_accuracy: 0.5926\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6538 - val_loss: 0.6692 - val_accuracy: 0.5926\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6615 - val_loss: 0.6686 - val_accuracy: 0.5926\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6692 - val_loss: 0.6672 - val_accuracy: 0.5926\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.6769 - val_loss: 0.6717 - val_accuracy: 0.5926\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 0.6304 - accuracy: 0.6615 - val_loss: 0.6662 - val_accuracy: 0.6296\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.6769 - val_loss: 0.6681 - val_accuracy: 0.6296\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6846 - val_loss: 0.6660 - val_accuracy: 0.6296\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6846 - val_loss: 0.6676 - val_accuracy: 0.6296\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6846 - val_loss: 0.6679 - val_accuracy: 0.6296\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6615 - val_loss: 0.6664 - val_accuracy: 0.6296\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6692 - val_loss: 0.6713 - val_accuracy: 0.6296\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6769 - val_loss: 0.6638 - val_accuracy: 0.6296\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6692 - val_loss: 0.6647 - val_accuracy: 0.6296\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.6769 - val_loss: 0.6696 - val_accuracy: 0.6296\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6692 - val_loss: 0.6625 - val_accuracy: 0.6296\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6692 - val_loss: 0.6626 - val_accuracy: 0.6296\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6615 - val_loss: 0.6640 - val_accuracy: 0.6296\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.6692 - val_loss: 0.6655 - val_accuracy: 0.6296\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6692 - val_loss: 0.6657 - val_accuracy: 0.6296\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6692 - val_loss: 0.6626 - val_accuracy: 0.6296\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.6615 - val_loss: 0.6626 - val_accuracy: 0.6296\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6615 - val_loss: 0.6630 - val_accuracy: 0.6296\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6615 - val_loss: 0.6648 - val_accuracy: 0.6296\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6615 - val_loss: 0.6626 - val_accuracy: 0.6296\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.6615 - val_loss: 0.6591 - val_accuracy: 0.6296\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.6769 - val_loss: 0.6579 - val_accuracy: 0.6296\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6615 - val_loss: 0.6686 - val_accuracy: 0.6296\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6692 - val_loss: 0.6684 - val_accuracy: 0.6296\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 1s 45ms/step - loss: 0.6206 - accuracy: 0.6462 - val_loss: 0.6500 - val_accuracy: 0.7037\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.6615 - val_loss: 0.6520 - val_accuracy: 0.7037\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.6769 - val_loss: 0.6573 - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.6615 - val_loss: 0.6616 - val_accuracy: 0.6296\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.6615 - val_loss: 0.6530 - val_accuracy: 0.7037\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6692 - val_loss: 0.6543 - val_accuracy: 0.7037\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.6692 - val_loss: 0.6546 - val_accuracy: 0.7037\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6769 - val_loss: 0.6477 - val_accuracy: 0.7037\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.6615 - val_loss: 0.6540 - val_accuracy: 0.7037\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6615 - val_loss: 0.6467 - val_accuracy: 0.7037\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.6615 - val_loss: 0.6545 - val_accuracy: 0.7037\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6538 - val_loss: 0.6436 - val_accuracy: 0.7037\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6538 - val_loss: 0.6474 - val_accuracy: 0.7037\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6615 - val_loss: 0.6473 - val_accuracy: 0.7037\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.6538 - val_loss: 0.6426 - val_accuracy: 0.7037\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6538 - val_loss: 0.6489 - val_accuracy: 0.7037\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.6615 - val_loss: 0.6525 - val_accuracy: 0.7037\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6538 - val_loss: 0.6387 - val_accuracy: 0.7037\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.6538 - val_loss: 0.6438 - val_accuracy: 0.7037\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6615 - val_loss: 0.6380 - val_accuracy: 0.7037\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.6615 - val_loss: 0.6398 - val_accuracy: 0.7037\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6538 - val_loss: 0.6413 - val_accuracy: 0.7037\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6692 - val_loss: 0.6338 - val_accuracy: 0.7037\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.6538 - val_loss: 0.6448 - val_accuracy: 0.7037\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.6538 - val_loss: 0.6337 - val_accuracy: 0.7037\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.6692 - val_loss: 0.6323 - val_accuracy: 0.7037\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6615 - val_loss: 0.6386 - val_accuracy: 0.7037\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.6615 - val_loss: 0.6418 - val_accuracy: 0.7037\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6769 - val_loss: 0.6320 - val_accuracy: 0.7037\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.6692 - val_loss: 0.6403 - val_accuracy: 0.7037\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6615 - val_loss: 0.6265 - val_accuracy: 0.7037\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.6692 - val_loss: 0.6287 - val_accuracy: 0.7037\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.6769 - val_loss: 0.6343 - val_accuracy: 0.7037\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6692 - val_loss: 0.6327 - val_accuracy: 0.7037\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.6769 - val_loss: 0.6290 - val_accuracy: 0.7037\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.6615 - val_loss: 0.6372 - val_accuracy: 0.7037\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.6692 - val_loss: 0.6227 - val_accuracy: 0.7037\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.6692 - val_loss: 0.6320 - val_accuracy: 0.7037\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6769 - val_loss: 0.6284 - val_accuracy: 0.7037\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6692 - val_loss: 0.6316 - val_accuracy: 0.7037\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6692 - val_loss: 0.6280 - val_accuracy: 0.7037\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.6692 - val_loss: 0.6315 - val_accuracy: 0.7037\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.6692 - val_loss: 0.6243 - val_accuracy: 0.7037\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.6692 - val_loss: 0.6255 - val_accuracy: 0.7037\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6692 - val_loss: 0.6255 - val_accuracy: 0.7037\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.6692 - val_loss: 0.6298 - val_accuracy: 0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model16.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "D2ndsxfdatDD",
        "outputId": "19101a29-9458-48e4-bf36-53f73f01d190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5712 - accuracy: 0.7391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5712490081787109, 0.739130437374115]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model16 = tf.keras.models.load_model(f\"/content/model_experiments/{model16.name}\")\n",
        "model16.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "4Sg7wFpWJVC0",
        "outputId": "d1fd580d-4cb1-4f57-9e22-ad2628cb17fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 141ms/step - loss: 0.6298 - accuracy: 0.7391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6297730803489685, 0.739130437374115]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zB-pR3_DJXEk"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model17 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model17.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0003),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history17 = model17.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model17.name)])"
      ],
      "metadata": {
        "id": "6_nOu_7jatHU",
        "outputId": "4452e3b3-c8c0-4c2e-a6eb-f2643ee4c59c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 2s 57ms/step - loss: 0.6921 - accuracy: 0.5000 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.6154 - val_loss: 0.6882 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.6154 - val_loss: 0.6855 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.6154 - val_loss: 0.6850 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6154 - val_loss: 0.6846 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.6154 - val_loss: 0.6852 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6154 - val_loss: 0.6870 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.6154 - val_loss: 0.6875 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6154 - val_loss: 0.6877 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6154 - val_loss: 0.6888 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6154 - val_loss: 0.6890 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6154 - val_loss: 0.6890 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6154 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6154 - val_loss: 0.6907 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6154 - val_loss: 0.6907 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6154 - val_loss: 0.6892 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6154 - val_loss: 0.6883 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6154 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.6154 - val_loss: 0.6877 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6154 - val_loss: 0.6890 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6154 - val_loss: 0.6885 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.6154 - val_loss: 0.6878 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6154 - val_loss: 0.6850 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6154 - val_loss: 0.6872 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6154 - val_loss: 0.6847 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6154 - val_loss: 0.6852 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.6154 - val_loss: 0.6845 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6154 - val_loss: 0.6838 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.6154 - val_loss: 0.6826 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6154 - val_loss: 0.6832 - val_accuracy: 0.5185\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.6154 - val_loss: 0.6812 - val_accuracy: 0.5185\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6154 - val_loss: 0.6812 - val_accuracy: 0.5185\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.6154 - val_loss: 0.6797 - val_accuracy: 0.5185\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6343 - accuracy: 0.6154 - val_loss: 0.6793 - val_accuracy: 0.5185\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6154 - val_loss: 0.6788 - val_accuracy: 0.5185\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6154 - val_loss: 0.6780 - val_accuracy: 0.5185\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.6154 - val_loss: 0.6792 - val_accuracy: 0.5185\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6154 - val_loss: 0.6769 - val_accuracy: 0.5185\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6154 - val_loss: 0.6766 - val_accuracy: 0.5185\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6077 - val_loss: 0.6778 - val_accuracy: 0.5185\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6309 - accuracy: 0.6077 - val_loss: 0.6756 - val_accuracy: 0.5926\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.6000 - val_loss: 0.6750 - val_accuracy: 0.5926\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6154 - val_loss: 0.6740 - val_accuracy: 0.5926\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6154 - val_loss: 0.6744 - val_accuracy: 0.5926\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6538 - val_loss: 0.6742 - val_accuracy: 0.5926\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.6538 - val_loss: 0.6730 - val_accuracy: 0.5926\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6538 - val_loss: 0.6725 - val_accuracy: 0.5926\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6538 - val_loss: 0.6721 - val_accuracy: 0.5926\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6615 - val_loss: 0.6722 - val_accuracy: 0.5926\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6615 - val_loss: 0.6715 - val_accuracy: 0.5926\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 0.6267 - accuracy: 0.6615 - val_loss: 0.6701 - val_accuracy: 0.6296\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6769 - val_loss: 0.6687 - val_accuracy: 0.6296\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6769 - val_loss: 0.6712 - val_accuracy: 0.6296\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6615 - val_loss: 0.6727 - val_accuracy: 0.6296\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6615 - val_loss: 0.6668 - val_accuracy: 0.6296\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.6692 - val_loss: 0.6668 - val_accuracy: 0.6296\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6615 - val_loss: 0.6674 - val_accuracy: 0.6296\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6692 - val_loss: 0.6685 - val_accuracy: 0.6296\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6769 - val_loss: 0.6668 - val_accuracy: 0.6296\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6692 - val_loss: 0.6678 - val_accuracy: 0.6296\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6692 - val_loss: 0.6678 - val_accuracy: 0.6296\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6615 - val_loss: 0.6658 - val_accuracy: 0.6296\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6615 - val_loss: 0.6676 - val_accuracy: 0.6296\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 16ms/step - loss: 0.6230 - accuracy: 0.6538 - val_loss: 0.6647 - val_accuracy: 0.6296\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6223 - accuracy: 0.6538 - val_loss: 0.6666 - val_accuracy: 0.6296\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6538 - val_loss: 0.6639 - val_accuracy: 0.6296\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6538 - val_loss: 0.6645 - val_accuracy: 0.6296\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.6538 - val_loss: 0.6644 - val_accuracy: 0.6296\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.6538 - val_loss: 0.6631 - val_accuracy: 0.6296\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6538 - val_loss: 0.6640 - val_accuracy: 0.6296\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.6214 - accuracy: 0.6538 - val_loss: 0.6657 - val_accuracy: 0.6296\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.6216 - accuracy: 0.6538 - val_loss: 0.6615 - val_accuracy: 0.6296\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.6538 - val_loss: 0.6635 - val_accuracy: 0.6296\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6615 - val_loss: 0.6610 - val_accuracy: 0.6296\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6615 - val_loss: 0.6613 - val_accuracy: 0.6296\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.6615 - val_loss: 0.6620 - val_accuracy: 0.6296\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6692 - val_loss: 0.6590 - val_accuracy: 0.6296\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.6615 - val_loss: 0.6628 - val_accuracy: 0.6296\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.6192 - accuracy: 0.6538 - val_loss: 0.6604 - val_accuracy: 0.6296\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.6186 - accuracy: 0.6615 - val_loss: 0.6587 - val_accuracy: 0.6296\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.6615 - val_loss: 0.6596 - val_accuracy: 0.6296\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6615 - val_loss: 0.6606 - val_accuracy: 0.6296\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6615 - val_loss: 0.6587 - val_accuracy: 0.6296\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.6615 - val_loss: 0.6604 - val_accuracy: 0.6296\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 0.6172 - accuracy: 0.6769 - val_loss: 0.6562 - val_accuracy: 0.7037\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6769 - val_loss: 0.6546 - val_accuracy: 0.7037\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6769 - val_loss: 0.6561 - val_accuracy: 0.7037\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.6692 - val_loss: 0.6561 - val_accuracy: 0.7037\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6692 - val_loss: 0.6563 - val_accuracy: 0.7037\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6615 - val_loss: 0.6598 - val_accuracy: 0.6296\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6769 - val_loss: 0.6546 - val_accuracy: 0.7037\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.6769 - val_loss: 0.6555 - val_accuracy: 0.7037\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.6692 - val_loss: 0.6550 - val_accuracy: 0.7037\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6769 - val_loss: 0.6546 - val_accuracy: 0.7037\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6769 - val_loss: 0.6540 - val_accuracy: 0.7037\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6769 - val_loss: 0.6548 - val_accuracy: 0.7037\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.6769 - val_loss: 0.6532 - val_accuracy: 0.7037\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6769 - val_loss: 0.6532 - val_accuracy: 0.7037\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6769 - val_loss: 0.6518 - val_accuracy: 0.7037\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6692 - val_loss: 0.6520 - val_accuracy: 0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model17.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "0vZZ7o6sayjB",
        "outputId": "895ffe15-b653-433e-abc8-f13ec8772261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6122 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6122463345527649, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model17 = tf.keras.models.load_model(f\"/content/model_experiments/{model17.name}\")\n",
        "model17.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "I6cyip8JJbW-",
        "outputId": "98651070-8b46-4af1-efb0-ce7602e8269f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 127ms/step - loss: 0.6218 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6218386888504028, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MT1OoowIaylx"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model18 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model18.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0003),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history18 = model18.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model18.name)])"
      ],
      "metadata": {
        "id": "w6omLrG8ayx2",
        "outputId": "48a5dddb-0aa7-4cc3-b190-73a3969f1fb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 1s 37ms/step - loss: 0.6923 - accuracy: 0.5154 - val_loss: 0.6913 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.6154 - val_loss: 0.6892 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.6154 - val_loss: 0.6872 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6154 - val_loss: 0.6861 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6154 - val_loss: 0.6840 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.6154 - val_loss: 0.6832 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6154 - val_loss: 0.6829 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6154 - val_loss: 0.6824 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6154 - val_loss: 0.6823 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6154 - val_loss: 0.6824 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6154 - val_loss: 0.6826 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6154 - val_loss: 0.6830 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6154 - val_loss: 0.6837 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.6154 - val_loss: 0.6842 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.6154 - val_loss: 0.6841 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6154 - val_loss: 0.6839 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6154 - val_loss: 0.6852 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.6154 - val_loss: 0.6845 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6154 - val_loss: 0.6854 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6154 - val_loss: 0.6855 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6154 - val_loss: 0.6857 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6154 - val_loss: 0.6846 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6154 - val_loss: 0.6860 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.6154 - val_loss: 0.6850 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6154 - val_loss: 0.6855 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.6154 - val_loss: 0.6854 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6154 - val_loss: 0.6849 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.6154 - val_loss: 0.6845 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6154 - val_loss: 0.6850 - val_accuracy: 0.5185\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.6154 - val_loss: 0.6839 - val_accuracy: 0.5185\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6154 - val_loss: 0.6839 - val_accuracy: 0.5185\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6154 - val_loss: 0.6827 - val_accuracy: 0.5185\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6154 - val_loss: 0.6822 - val_accuracy: 0.5185\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6154 - val_loss: 0.6814 - val_accuracy: 0.5185\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6154 - val_loss: 0.6806 - val_accuracy: 0.5185\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.6154 - val_loss: 0.6807 - val_accuracy: 0.5185\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6154 - val_loss: 0.6792 - val_accuracy: 0.5185\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.6154 - val_loss: 0.6786 - val_accuracy: 0.5185\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6154 - val_loss: 0.6789 - val_accuracy: 0.5185\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6154 - val_loss: 0.6775 - val_accuracy: 0.5185\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6154 - val_loss: 0.6768 - val_accuracy: 0.5185\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6154 - val_loss: 0.6758 - val_accuracy: 0.5185\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6154 - val_loss: 0.6755 - val_accuracy: 0.5185\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6154 - val_loss: 0.6750 - val_accuracy: 0.5185\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6154 - val_loss: 0.6739 - val_accuracy: 0.5185\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6154 - val_loss: 0.6734 - val_accuracy: 0.5185\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6154 - val_loss: 0.6730 - val_accuracy: 0.5185\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6154 - val_loss: 0.6727 - val_accuracy: 0.5185\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6154 - val_loss: 0.6718 - val_accuracy: 0.5185\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.6154 - val_loss: 0.6706 - val_accuracy: 0.5185\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.6154 - val_loss: 0.6687 - val_accuracy: 0.5185\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.6154 - val_loss: 0.6705 - val_accuracy: 0.5185\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6154 - val_loss: 0.6715 - val_accuracy: 0.5185\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6321 - accuracy: 0.6154 - val_loss: 0.6666 - val_accuracy: 0.5926\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6154 - val_loss: 0.6668 - val_accuracy: 0.5926\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6154 - val_loss: 0.6670 - val_accuracy: 0.5926\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6154 - val_loss: 0.6671 - val_accuracy: 0.5926\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6077 - val_loss: 0.6651 - val_accuracy: 0.5926\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6385 - val_loss: 0.6657 - val_accuracy: 0.5926\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6462 - val_loss: 0.6659 - val_accuracy: 0.5926\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.6615 - val_loss: 0.6643 - val_accuracy: 0.5926\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6615 - val_loss: 0.6652 - val_accuracy: 0.5926\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6692 - val_loss: 0.6629 - val_accuracy: 0.5926\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6615 - val_loss: 0.6641 - val_accuracy: 0.5926\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 0.6280 - accuracy: 0.6692 - val_loss: 0.6607 - val_accuracy: 0.6296\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6692 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6615 - val_loss: 0.6610 - val_accuracy: 0.6296\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6846 - val_loss: 0.6602 - val_accuracy: 0.6296\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6769 - val_loss: 0.6610 - val_accuracy: 0.6296\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6769 - val_loss: 0.6613 - val_accuracy: 0.6296\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6846 - val_loss: 0.6580 - val_accuracy: 0.6296\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6846 - val_loss: 0.6595 - val_accuracy: 0.6296\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6846 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.6846 - val_loss: 0.6577 - val_accuracy: 0.6296\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.6846 - val_loss: 0.6580 - val_accuracy: 0.6296\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.6769 - val_loss: 0.6551 - val_accuracy: 0.6296\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.6846 - val_loss: 0.6575 - val_accuracy: 0.6296\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6692 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6692 - val_loss: 0.6543 - val_accuracy: 0.6296\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6692 - val_loss: 0.6549 - val_accuracy: 0.6296\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.6692 - val_loss: 0.6546 - val_accuracy: 0.6296\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6615 - val_loss: 0.6530 - val_accuracy: 0.6296\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6615 - val_loss: 0.6532 - val_accuracy: 0.6296\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.6615 - val_loss: 0.6505 - val_accuracy: 0.6296\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6615 - val_loss: 0.6494 - val_accuracy: 0.6296\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6615 - val_loss: 0.6499 - val_accuracy: 0.6296\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6615 - val_loss: 0.6493 - val_accuracy: 0.6296\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6615 - val_loss: 0.6490 - val_accuracy: 0.6296\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6615 - val_loss: 0.6513 - val_accuracy: 0.6296\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6615 - val_loss: 0.6476 - val_accuracy: 0.6296\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6692 - val_loss: 0.6481 - val_accuracy: 0.6296\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.6615 - val_loss: 0.6475 - val_accuracy: 0.6296\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.6692 - val_loss: 0.6468 - val_accuracy: 0.6296\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6692 - val_loss: 0.6462 - val_accuracy: 0.6296\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6692 - val_loss: 0.6471 - val_accuracy: 0.6296\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6692 - val_loss: 0.6455 - val_accuracy: 0.6296\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6692 - val_loss: 0.6446 - val_accuracy: 0.6296\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6178 - accuracy: 0.6692 - val_loss: 0.6441 - val_accuracy: 0.7037\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6769 - val_loss: 0.6440 - val_accuracy: 0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model18.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "vQ__vw93Jha4",
        "outputId": "446250dc-b4ec-4d62-9605-11d2eddc9816",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6194 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6194218397140503, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model18 = tf.keras.models.load_model(f\"/content/model_experiments/{model18.name}\")\n",
        "model18.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "gJJ51Qqpa5AY",
        "outputId": "4b3326d3-d165-44b3-e6e3-c0db8c15e21c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 122ms/step - loss: 0.6199 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6199381351470947, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DTCg_cOha5DS"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model19 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model19.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0003),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history19 = model19.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model19.name)])"
      ],
      "metadata": {
        "id": "K2TjoYoea5FP",
        "outputId": "ef64d8b1-9d6e-43cd-e524-c9a6c21ae7bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 2s 41ms/step - loss: 0.6684 - accuracy: 0.6154 - val_loss: 0.6793 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6154 - val_loss: 0.6785 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6154 - val_loss: 0.6786 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6154 - val_loss: 0.6794 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.6154 - val_loss: 0.6797 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6154 - val_loss: 0.6808 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6154 - val_loss: 0.6841 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6154 - val_loss: 0.6833 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6154 - val_loss: 0.6829 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6154 - val_loss: 0.6840 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6154 - val_loss: 0.6835 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.6154 - val_loss: 0.6835 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6154 - val_loss: 0.6844 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6154 - val_loss: 0.6845 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6154 - val_loss: 0.6842 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6154 - val_loss: 0.6818 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6154 - val_loss: 0.6801 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6154 - val_loss: 0.6824 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6154 - val_loss: 0.6784 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6154 - val_loss: 0.6796 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.6154 - val_loss: 0.6785 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.6154 - val_loss: 0.6774 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6154 - val_loss: 0.6735 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6154 - val_loss: 0.6764 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.6154 - val_loss: 0.6730 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6154 - val_loss: 0.6737 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6154 - val_loss: 0.6728 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6154 - val_loss: 0.6715 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 1s 36ms/step - loss: 0.6322 - accuracy: 0.6154 - val_loss: 0.6700 - val_accuracy: 0.5926\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6308 - val_loss: 0.6706 - val_accuracy: 0.5926\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6308 - val_loss: 0.6679 - val_accuracy: 0.5926\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.6692 - val_loss: 0.6680 - val_accuracy: 0.5926\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6615 - val_loss: 0.6661 - val_accuracy: 0.5926\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6692 - val_loss: 0.6657 - val_accuracy: 0.5926\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6692 - val_loss: 0.6649 - val_accuracy: 0.5926\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 1s 34ms/step - loss: 0.6290 - accuracy: 0.6692 - val_loss: 0.6638 - val_accuracy: 0.6296\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6846 - val_loss: 0.6649 - val_accuracy: 0.6296\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6846 - val_loss: 0.6618 - val_accuracy: 0.6296\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7000 - val_loss: 0.6612 - val_accuracy: 0.6296\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6846 - val_loss: 0.6627 - val_accuracy: 0.6296\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6769 - val_loss: 0.6596 - val_accuracy: 0.6296\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6769 - val_loss: 0.6591 - val_accuracy: 0.6296\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6692 - val_loss: 0.6581 - val_accuracy: 0.6296\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6692 - val_loss: 0.6588 - val_accuracy: 0.6296\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6769 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6692 - val_loss: 0.6568 - val_accuracy: 0.6296\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6769 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6692 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6692 - val_loss: 0.6570 - val_accuracy: 0.6296\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6692 - val_loss: 0.6561 - val_accuracy: 0.6296\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6692 - val_loss: 0.6542 - val_accuracy: 0.6296\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 1s 58ms/step - loss: 0.6216 - accuracy: 0.6769 - val_loss: 0.6526 - val_accuracy: 0.7037\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6692 - val_loss: 0.6568 - val_accuracy: 0.6296\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6769 - val_loss: 0.6588 - val_accuracy: 0.6296\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6538 - val_loss: 0.6500 - val_accuracy: 0.7037\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.6769 - val_loss: 0.6510 - val_accuracy: 0.7037\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6769 - val_loss: 0.6519 - val_accuracy: 0.7037\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.6692 - val_loss: 0.6536 - val_accuracy: 0.6296\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.6692 - val_loss: 0.6511 - val_accuracy: 0.7037\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6692 - val_loss: 0.6523 - val_accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.6769 - val_loss: 0.6521 - val_accuracy: 0.7037\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6769 - val_loss: 0.6500 - val_accuracy: 0.7037\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.6769 - val_loss: 0.6524 - val_accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.6769 - val_loss: 0.6489 - val_accuracy: 0.7037\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6769 - val_loss: 0.6518 - val_accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6769 - val_loss: 0.6479 - val_accuracy: 0.7037\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6769 - val_loss: 0.6495 - val_accuracy: 0.7037\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.6769 - val_loss: 0.6496 - val_accuracy: 0.7037\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6769 - val_loss: 0.6484 - val_accuracy: 0.7037\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6769 - val_loss: 0.6496 - val_accuracy: 0.7037\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6769 - val_loss: 0.6513 - val_accuracy: 0.7037\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.6692 - val_loss: 0.6462 - val_accuracy: 0.7037\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6692 - val_loss: 0.6490 - val_accuracy: 0.7037\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6692 - val_loss: 0.6456 - val_accuracy: 0.7037\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.6769 - val_loss: 0.6466 - val_accuracy: 0.7037\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6769 - val_loss: 0.6471 - val_accuracy: 0.7037\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.6615 - val_loss: 0.6433 - val_accuracy: 0.7037\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6769 - val_loss: 0.6482 - val_accuracy: 0.7037\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6769 - val_loss: 0.6448 - val_accuracy: 0.7037\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6692 - val_loss: 0.6427 - val_accuracy: 0.7037\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6692 - val_loss: 0.6438 - val_accuracy: 0.7037\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6692 - val_loss: 0.6453 - val_accuracy: 0.7037\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6692 - val_loss: 0.6424 - val_accuracy: 0.7037\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.6692 - val_loss: 0.6457 - val_accuracy: 0.7037\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.6769 - val_loss: 0.6401 - val_accuracy: 0.7037\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6692 - val_loss: 0.6386 - val_accuracy: 0.7037\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.6769 - val_loss: 0.6407 - val_accuracy: 0.7037\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.6692 - val_loss: 0.6404 - val_accuracy: 0.7037\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6692 - val_loss: 0.6403 - val_accuracy: 0.7037\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6769 - val_loss: 0.6451 - val_accuracy: 0.7037\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6692 - val_loss: 0.6374 - val_accuracy: 0.7037\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6692 - val_loss: 0.6393 - val_accuracy: 0.7037\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6692 - val_loss: 0.6387 - val_accuracy: 0.7037\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.6615 - val_loss: 0.6391 - val_accuracy: 0.7037\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6615 - val_loss: 0.6381 - val_accuracy: 0.7037\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.6692 - val_loss: 0.6398 - val_accuracy: 0.7037\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.6692 - val_loss: 0.6372 - val_accuracy: 0.7037\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6692 - val_loss: 0.6374 - val_accuracy: 0.7037\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.6692 - val_loss: 0.6361 - val_accuracy: 0.7037\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6692 - val_loss: 0.6365 - val_accuracy: 0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model19.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "AXRcc8LGJltz",
        "outputId": "a4043850-254d-4a6d-9177-7cf518913621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5981 - accuracy: 0.7391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5981103777885437, 0.739130437374115]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model19 = tf.keras.models.load_model(f\"/content/model_experiments/{model19.name}\")\n",
        "model19.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "NAc3PhNnajRQ",
        "outputId": "3c5b4f3a-c559-48c5-8d32-ebb034ad1d82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 139ms/step - loss: 0.6311 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6311095952987671, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jrFHLXvsJqs4"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_YLE821JpnZ"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model20 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model20.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0003),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history20 = model20.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=20,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model20.name)])"
      ],
      "metadata": {
        "id": "wycpJGLpajTr",
        "outputId": "f3a0ebe4-3c67-4151-b1e9-c25c8f4318ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 2s 166ms/step - loss: 0.6931 - accuracy: 0.5385 - val_loss: 0.6931 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.6154 - val_loss: 0.6931 - val_accuracy: 0.5185\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.6154 - val_loss: 0.6931 - val_accuracy: 0.5185\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6926 - accuracy: 0.6154 - val_loss: 0.6931 - val_accuracy: 0.5185\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6925 - accuracy: 0.6154 - val_loss: 0.6930 - val_accuracy: 0.5185\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.6154 - val_loss: 0.6930 - val_accuracy: 0.5185\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6922 - accuracy: 0.6154 - val_loss: 0.6930 - val_accuracy: 0.5185\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.6154 - val_loss: 0.6930 - val_accuracy: 0.5185\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6919 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6917 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6915 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6914 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6901 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6899 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6895 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6893 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6891 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6890 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6888 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6887 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6885 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6882 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6880 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6875 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6874 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6868 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6865 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6861 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6860 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6859 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6855 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6853 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6853 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6852 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6850 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6849 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6848 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6847 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6845 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6844 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6842 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6839 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6838 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6837 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6836 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6835 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6833 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6832 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6831 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6830 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.6154 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6828 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6827 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6825 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6824 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6822 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6821 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6820 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.6154 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6816 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6811 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6811 - accuracy: 0.6154 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6808 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6807 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6806 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6805 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6804 - accuracy: 0.6154 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6803 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6801 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6800 - accuracy: 0.6154 - val_loss: 0.6929 - val_accuracy: 0.5185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model20.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "VL39O9CUJ0aV",
        "outputId": "5871c4b9-088c-4c4d-9089-87f14ab74d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6983 - accuracy: 0.4783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6982666254043579, 0.47826087474823]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model20 = tf.keras.models.load_model(f\"/content/model_experiments/{model20.name}\")\n",
        "model20.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "27s6h46_ajVd",
        "outputId": "1e598d64-01aa-4202-9842-a823e71df2e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 138ms/step - loss: 0.6932 - accuracy: 0.4783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6931762099266052, 0.47826087474823]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "HwrvwOX0cyMf",
        "outputId": "221c4bd2-9bfa-4aad-d674-dcd740fe75c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1.0\n",
              "1      1.0\n",
              "2      0.0\n",
              "3      1.0\n",
              "4      0.0\n",
              "      ... \n",
              "175    1.0\n",
              "176    0.0\n",
              "177    1.0\n",
              "178    0.0\n",
              "179    0.0\n",
              "Name: psqi больше 5, Length: 180, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGr_oqlJHh4h"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xSCrBKNIHh7K"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "jxDbWXbvvMEV",
        "outputId": "0ae2120b-e75d-4263-e731-0870127d47df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Нарушения сна больше 5'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-3819433a1a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Нарушения сна больше 5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# X = data.drop(columns=['Нарушения сна больше 5'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Пол'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Удовлетворенность семейными отношениями'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ЧМТ'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Стаж шизофр'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Образование'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Насл отягощенность'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'G'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# X = data[[ 'P', 'N', 'G']] # Only with these 3 values we can get very good result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Нарушения сна больше 5'"
          ]
        }
      ],
      "source": [
        "y = data['Нарушения сна больше 5']\n",
        "# X = data.drop(columns=['Нарушения сна больше 5'])\n",
        "# X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование']]\n",
        "X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "# X = data[[ 'P', 'N', 'G']] # Only with these 3 values we can get very good result\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kZTjgK7vMG8"
      },
      "outputs": [],
      "source": [
        "# Scale X from 0 to 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "X_train_scaled = minmax_scaler.fit_transform(X_train)\n",
        "X_valid_scaled = minmax_scaler.transform(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOQOcCCXPrrL"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.003), # lr=0.003\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Create a learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # Learning rate will increase at each epoch\n",
        "\n",
        "history0 = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVMn6WFCPEHX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zFAGeTMPvxf"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXokhoC2PwQk"
      },
      "source": [
        "### Find bels LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH0ZyOMevW6o"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(), # lr=0.003\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Create a learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # Learning rate will increase at each epoch\n",
        "\n",
        "history_lr = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWTprQ0aOC_S"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the learning rate vs loss\n",
        "lrs = 1e-4 * (10 ** (tf.range(100)/20))\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, history_lr.history[\"loss\"]) # lrs - x-axis, history - y-axis\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs. loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPZdm2LqvMQs"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history1 = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJCjkFO-Pb3f"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1n34k49Pebz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqB5o19TPfeV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pofTvAKuPfhO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XzO4JMrPfjd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtdAN5vAPfmH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMlFZkEuPCer"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jzqVz0-vMSw"
      },
      "outputs": [],
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AdEsLsQhl-L"
      },
      "outputs": [],
      "source": [
        "train_data = data[:121] # 70%\n",
        "validation_data = data[121:155] # 20%\n",
        "test_data = data[155:174] # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD1BAgypjWbC"
      },
      "outputs": [],
      "source": [
        "y_train = train_data['Нарушения сна больше 5']\n",
        "y_validation = validation_data['Нарушения сна больше 5']\n",
        "y_test = test_data['Нарушения сна больше 5']\n",
        "\n",
        "X_train = train_data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "X_validation = validation_data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "X_test = test_data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgi-q_Iujyt-"
      },
      "outputs": [],
      "source": [
        "len(y_train), len(y_validation), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w3owV7dhnfn"
      },
      "outputs": [],
      "source": [
        "# y = data['Нарушения сна']\n",
        "# # X = data.drop(columns=['Нарушения сна'])\n",
        "# # X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование']]\n",
        "# # X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "# X = data[[ 'P', 'N', 'G']] # Only with these 3 values we can get very good result\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5EEQckhaLgC"
      },
      "outputs": [],
      "source": [
        "# Scale X from 0 to 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_validation_scaled = scaler.fit_transform(X_validation)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVjPP8UokzzF"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(), # lr=0.03\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_validation_scaled, y_validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc5mFrJQhMsd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEAMkOEmhOE9"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yZGlBKrhNN1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrA_ArvkOh9c"
      },
      "source": [
        "### It is very likely that the model has overfitted. It is necessary to add data augmentation, validation data, visualization\n",
        "Find best lr\n",
        "\n",
        "Вывести наиболее значимые характеристики\n",
        "\n",
        "\n",
        "\n",
        "Check result on different scalers. For example:\n",
        "\n",
        "1) Min Max Scaler (try it)\n",
        "\n",
        "2) Standard Scaler\n",
        "\n",
        "3) Max Abs Scaler\n",
        "\n",
        "4) Robust Scaler\n",
        "\n",
        "5) Quantile Transformer Scaler\n",
        "\n",
        "6) Power Transformer Scaler\n",
        "\n",
        "7) Unit Vector Scaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io90TB1dlcBf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDAqLqo5DT74"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNhuw9AgDT-L"
      },
      "outputs": [],
      "source": [
        "# Let's try to use 'Нарушения сна' as y value\n",
        "data = ds.drop(columns=['Тревога больше 7', 'Madrs больше 6', 'Калгари больше 5'])\n",
        "y = data['Нарушения сна больше 5']\n",
        "# X = data.drop(columns=['Нарушения сна'])\n",
        "X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']] # 'Были ли нарушения сна', \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,)\n",
        "\n",
        "# Scale X from 0 to 1\n",
        "scaler2 = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler2.fit_transform(X_train)\n",
        "X_test_scaled = scaler2.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR0dXD6DEdDg"
      },
      "outputs": [],
      "source": [
        "X_train_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKvqJHX3DWyj"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(), # lr=0.03\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history2 = model2.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGzI7qA1DrxS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "mental_disorders.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}