{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitaion/mental_disorders/blob/main/mental_disorders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xviXFSvcd-gZ",
        "outputId": "569d7e42-d065-4f7f-cf53-4bdefac0fd08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-09 08:12:28--  https://raw.githubusercontent.com/Nikitaion/mental_disorders/main/data/050622_mental_disorders_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21849 (21K) [text/plain]\n",
            "Saving to: ‘ds.csv’\n",
            "\n",
            "\rds.csv                0%[                    ]       0  --.-KB/s               \rds.csv              100%[===================>]  21.34K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-06-09 08:12:29 (30.5 MB/s) - ‘ds.csv’ saved [21849/21849]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Nikitaion/mental_disorders/main/data/050622_mental_disorders_data.csv -O ds.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6YXg1QZeuWS",
        "outputId": "a43b711b-722a-4f7b-e543-40a7297ca8f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import  train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "0lKSFBRwg3oI",
        "outputId": "1ced455d-f530-4a96-d48b-765f253658d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Снинговый номер Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "0            УП-1   М          32                                   4   \n",
              "1            УП-2   М          26                                   2   \n",
              "2            УП-3   М          49                                   2   \n",
              "3            УП-4   М          50                                   2   \n",
              "4            УП-5   М          27                                   2   \n",
              "\n",
              "   Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "0                            0                                 0   \n",
              "1                            0                                 0   \n",
              "2                            0                                 0   \n",
              "3                            0                                 0   \n",
              "4                            1                                 0   \n",
              "\n",
              "   Удовлетворенность семеными отношениями  \\\n",
              "0                                       5   \n",
              "1                                       5   \n",
              "2                                       5   \n",
              "3                                       5   \n",
              "4                                       5   \n",
              "\n",
              "   Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "0                                          0                    7   \n",
              "1                                          0                   10   \n",
              "2                                          1                   10   \n",
              "3                                          1                    7   \n",
              "4                                          1                    9   \n",
              "\n",
              "   Были ли нарушения сна  ...  Дебют  Частота госпит  Стаж шизофр   P   N   G  \\\n",
              "0                      1  ...   28.3               0          3.7  11  11  18   \n",
              "1                      1  ...   26.0               1          2.0  10  25  36   \n",
              "2                      0  ...   26.0               2         23.0   9  16  23   \n",
              "3                      1  ...   16.0               1         34.0  13  13  20   \n",
              "4                      1  ...   21.0               0          6.0   7   9  22   \n",
              "\n",
              "   (СОН)psqi больше 6  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "0                   0                             0   \n",
              "1                   1                             0   \n",
              "2                   0                             0   \n",
              "3                   0                             0   \n",
              "4                   0                             0   \n",
              "\n",
              "   (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "0                          0                            0  \n",
              "1                          1                            1  \n",
              "2                          0                            0  \n",
              "3                          0                            0  \n",
              "4                          0                            0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b927e262-0fe6-4662-a09e-ab2fd7cb5867\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Снинговый номер</th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>...</th>\n",
              "      <th>Дебют</th>\n",
              "      <th>Частота госпит</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>(СОН)psqi больше 6</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>УП-1</td>\n",
              "      <td>М</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>28.3</td>\n",
              "      <td>0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>УП-2</td>\n",
              "      <td>М</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>УП-3</td>\n",
              "      <td>М</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>УП-4</td>\n",
              "      <td>М</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>УП-5</td>\n",
              "      <td>М</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b927e262-0fe6-4662-a09e-ab2fd7cb5867')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b927e262-0fe6-4662-a09e-ab2fd7cb5867 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b927e262-0fe6-4662-a09e-ab2fd7cb5867');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ],
      "source": [
        "ds = pd.read_csv(\"/content/ds.csv\")\n",
        "ds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "ASj1vcYIhAzw",
        "outputId": "6bf37601-1059-4f17-dc10-8fe5acf90d39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Снинговый номер Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "246           УФ-32   М          35                                   3   \n",
              "247           УФ-33   М          57                                   2   \n",
              "248           УФ-34   М          24                                   4   \n",
              "249         УФ-33-2   М          41                                   2   \n",
              "250         УФ-34-2   М          32                                   2   \n",
              "\n",
              "     Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "246                            0                                 0   \n",
              "247                            0                                 0   \n",
              "248                            1                                 0   \n",
              "249                            0                                 0   \n",
              "250                            0                                 0   \n",
              "\n",
              "     Удовлетворенность семеными отношениями  \\\n",
              "246                                       2   \n",
              "247                                       1   \n",
              "248                                       5   \n",
              "249                                       3   \n",
              "250                                       5   \n",
              "\n",
              "     Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "246                                          0                    7   \n",
              "247                                          0                    9   \n",
              "248                                          1                   10   \n",
              "249                                          0                    9   \n",
              "250                                          1                   10   \n",
              "\n",
              "     Были ли нарушения сна  ...  Дебют  Частота госпит  Стаж шизофр   P   N  \\\n",
              "246                      1  ...   19.0               0         16.0  19   8   \n",
              "247                      1  ...   22.0               0         35.0  10  10   \n",
              "248                      1  ...   18.0               0          6.0   7   9   \n",
              "249                      1  ...   28.0               2         13.0  14  13   \n",
              "250                      1  ...   23.0               1          9.0   7  12   \n",
              "\n",
              "      G  (СОН)psqi больше 6  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "246  31                   0                             0   \n",
              "247  23                   0                             0   \n",
              "248  27                   0                             0   \n",
              "249  21                   1                             1   \n",
              "250  28                   0                             0   \n",
              "\n",
              "     (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "246                          1                            1  \n",
              "247                          0                            0  \n",
              "248                          0                            0  \n",
              "249                          1                            0  \n",
              "250                          1                            0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90da2045-485c-4082-9eec-c994db6ad645\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Снинговый номер</th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>...</th>\n",
              "      <th>Дебют</th>\n",
              "      <th>Частота госпит</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>(СОН)psqi больше 6</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>УФ-32</td>\n",
              "      <td>М</td>\n",
              "      <td>35</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>УФ-33</td>\n",
              "      <td>М</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>УФ-34</td>\n",
              "      <td>М</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>УФ-33-2</td>\n",
              "      <td>М</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>УФ-34-2</td>\n",
              "      <td>М</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90da2045-485c-4082-9eec-c994db6ad645')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90da2045-485c-4082-9eec-c994db6ad645 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90da2045-485c-4082-9eec-c994db6ad645');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ],
      "source": [
        "ds.tail()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_N2ueZDTxGN",
        "outputId": "6de3cf0f-93cf-4e0b-daa3-c38435dc0fe0"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 251 entries, 0 to 250\n",
            "Data columns (total 30 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Снинговый номер                            251 non-null    object \n",
            " 1   Пол                                        251 non-null    object \n",
            " 2   Полных лет                                 251 non-null    int64  \n",
            " 3   Образование(0-начальное, 4-высшее)         251 non-null    int64  \n",
            " 4   Род занятий(0-0, работает-1                251 non-null    int64  \n",
            " 5   Семейное положение(0-0, 1-женат)           251 non-null    int64  \n",
            " 6   Удовлетворенность семеными отношениями     251 non-null    int64  \n",
            " 7   Удовлетворенность материальным положением  251 non-null    int64  \n",
            " 8   Здоровье от 1 до 10                        251 non-null    int64  \n",
            " 9   Были ли нарушения сна                      251 non-null    int64  \n",
            " 10  ИМТ                                        251 non-null    float64\n",
            " 11  Операции                                   251 non-null    int64  \n",
            " 12  Аллергии                                   251 non-null    int64  \n",
            " 13  СД                                         251 non-null    int64  \n",
            " 14  Забол кожи                                 251 non-null    int64  \n",
            " 15  ГБ                                         251 non-null    int64  \n",
            " 16  Панкреатит                                 251 non-null    int64  \n",
            " 17  Дисфункция ЖКТ                             251 non-null    int64  \n",
            " 18  ЧМТ                                        251 non-null    int64  \n",
            " 19  Насл отягощенность                         251 non-null    int64  \n",
            " 20  Дебют                                      251 non-null    float64\n",
            " 21  Частота госпит                             251 non-null    int64  \n",
            " 22  Стаж шизофр                                251 non-null    float64\n",
            " 23  P                                          251 non-null    int64  \n",
            " 24  N                                          251 non-null    int64  \n",
            " 25  G                                          251 non-null    int64  \n",
            " 26  (СОН)psqi больше 6                         251 non-null    int64  \n",
            " 27  (ТРЕВОГА)Гаиильтон больше 16               251 non-null    int64  \n",
            " 28  (ДЕПРЕССИЯ)madrs больше 6                  251 non-null    int64  \n",
            " 29  (ДЕПРЕССИЯ)Калгари больше 5                251 non-null    int64  \n",
            "dtypes: float64(3), int64(25), object(2)\n",
            "memory usage: 59.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5kHDI6VTxyX",
        "outputId": "9db271cc-5991-4681-c3f0-06aefc98db79"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Снинговый номер                              0\n",
              "Пол                                          0\n",
              "Полных лет                                   0\n",
              "Образование(0-начальное, 4-высшее)           0\n",
              "Род занятий(0-0, работает-1                  0\n",
              "Семейное положение(0-0, 1-женат)             0\n",
              "Удовлетворенность семеными отношениями       0\n",
              "Удовлетворенность материальным положением    0\n",
              "Здоровье от 1 до 10                          0\n",
              "Были ли нарушения сна                        0\n",
              "ИМТ                                          0\n",
              "Операции                                     0\n",
              "Аллергии                                     0\n",
              "СД                                           0\n",
              "Забол кожи                                   0\n",
              "ГБ                                           0\n",
              "Панкреатит                                   0\n",
              "Дисфункция ЖКТ                               0\n",
              "ЧМТ                                          0\n",
              "Насл отягощенность                           0\n",
              "Дебют                                        0\n",
              "Частота госпит                               0\n",
              "Стаж шизофр                                  0\n",
              "P                                            0\n",
              "N                                            0\n",
              "G                                            0\n",
              "(СОН)psqi больше 6                           0\n",
              "(ТРЕВОГА)Гаиильтон больше 16                 0\n",
              "(ДЕПРЕССИЯ)madrs больше 6                    0\n",
              "(ДЕПРЕССИЯ)Калгари больше 5                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TXPhKu8mT4cS"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "pEJ79uoXQZdV"
      },
      "outputs": [],
      "source": [
        "# drop unnecessary columns\n",
        "ds = ds.drop(columns=['Снинговый номер'])\n",
        "# ds = ds.drop(columns=['Здоровье от 1 до 10', 'Удовлетворенность материальным положением', 'Рост', 'Вес', 'BARS (акатизия)', 'SAS (Экстрапир)', 'AIMS (непр дв)', 'ESS', 'шкала общего клин впечатления', 'шкала соц функционир'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-YpnvKCkznI",
        "outputId": "7830a7ff-b708-4ae0-9ae5-8e89c3ae0afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 251 entries, 0 to 250\n",
            "Data columns (total 29 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Пол                                        251 non-null    object \n",
            " 1   Полных лет                                 251 non-null    int64  \n",
            " 2   Образование(0-начальное, 4-высшее)         251 non-null    int64  \n",
            " 3   Род занятий(0-0, работает-1                251 non-null    int64  \n",
            " 4   Семейное положение(0-0, 1-женат)           251 non-null    int64  \n",
            " 5   Удовлетворенность семеными отношениями     251 non-null    int64  \n",
            " 6   Удовлетворенность материальным положением  251 non-null    int64  \n",
            " 7   Здоровье от 1 до 10                        251 non-null    int64  \n",
            " 8   Были ли нарушения сна                      251 non-null    int64  \n",
            " 9   ИМТ                                        251 non-null    float64\n",
            " 10  Операции                                   251 non-null    int64  \n",
            " 11  Аллергии                                   251 non-null    int64  \n",
            " 12  СД                                         251 non-null    int64  \n",
            " 13  Забол кожи                                 251 non-null    int64  \n",
            " 14  ГБ                                         251 non-null    int64  \n",
            " 15  Панкреатит                                 251 non-null    int64  \n",
            " 16  Дисфункция ЖКТ                             251 non-null    int64  \n",
            " 17  ЧМТ                                        251 non-null    int64  \n",
            " 18  Насл отягощенность                         251 non-null    int64  \n",
            " 19  Дебют                                      251 non-null    float64\n",
            " 20  Частота госпит                             251 non-null    int64  \n",
            " 21  Стаж шизофр                                251 non-null    float64\n",
            " 22  P                                          251 non-null    int64  \n",
            " 23  N                                          251 non-null    int64  \n",
            " 24  G                                          251 non-null    int64  \n",
            " 25  (СОН)psqi больше 6                         251 non-null    int64  \n",
            " 26  (ТРЕВОГА)Гаиильтон больше 16               251 non-null    int64  \n",
            " 27  (ДЕПРЕССИЯ)madrs больше 6                  251 non-null    int64  \n",
            " 28  (ДЕПРЕССИЯ)Калгари больше 5                251 non-null    int64  \n",
            "dtypes: float64(3), int64(25), object(1)\n",
            "memory usage: 57.0+ KB\n"
          ]
        }
      ],
      "source": [
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "DV4Cfa-0wKzw"
      },
      "outputs": [],
      "source": [
        "# Why i did this?\n",
        "# We have one-hot encoding lol -_-\n",
        "\n",
        "def change_value_to_numeric(x):\n",
        "  if type(x) == int or type(x) == float:\n",
        "    return x\n",
        "\n",
        "  x = x.strip().lower() # remove spaces and make lower\n",
        "\n",
        "  if x == \"да\":\n",
        "    return 1\n",
        "  elif x == \"нет\":\n",
        "    return 0\n",
        "  elif x == \"м\":\n",
        "    return 1\n",
        "  elif x == \"ж\":\n",
        "    return 0\n",
        "  \n",
        "  # Род занятий\n",
        "  elif x== \"не работает\":\n",
        "    return 0\n",
        "  elif x == \"работает\":\n",
        "    return 1\n",
        "  elif x == \"учится\":\n",
        "    return 2\n",
        "  elif x == \"пенсионер\":\n",
        "    return 3\n",
        "  \n",
        "  # Семейное положение:\n",
        "  elif x == \"холост\":\n",
        "    return 0 \n",
        "  elif x == \"женат\":\n",
        "    return 1\n",
        "  elif x == \"разведен\":\n",
        "    return 2\n",
        "  elif x == \"вдовец\":\n",
        "    return 3\n",
        "\n",
        "  # Образование:\n",
        "  elif x == \"среднее\":\n",
        "    return 0 \n",
        "  elif x == \"незаконченное высшее\":\n",
        "    return 1\n",
        "  elif x == \"высшее\":\n",
        "    return 2\n",
        "  elif x == \"неполное среднее\":\n",
        "    return 3\n",
        "  elif x == \"начальное\":\n",
        "    return 4\n",
        "\n",
        "  # Динамика веса за год:\n",
        "  elif x == \"стабильный вес\":\n",
        "    return 0 \n",
        "  elif x == \"снижение веса\":\n",
        "    return 1\n",
        "  elif x == \"увеличение веса\":\n",
        "    return 2\n",
        "\n",
        "  # ЧМТ:\n",
        "  elif x == \"нет\":\n",
        "    return 0 \n",
        "  elif x == \"да (без потери сознания)\":\n",
        "    return 1\n",
        "  elif x == \"да (с потерей сознания)\":\n",
        "    return 2\n",
        "\n",
        "  # Преобл синдром:\n",
        "  elif x == \"аффективно-параноидный\":\n",
        "    return 0 \n",
        "  elif x == \"параноидный\":\n",
        "    return 1\n",
        "  elif x == \"галлюцинаторно-параноидный\":\n",
        "    return 2\n",
        "  elif x == \"парафренный\":\n",
        "    return 3\n",
        "  elif x == \"кататонический\":\n",
        "    return 4\n",
        "\n",
        "  return \"NaN\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "psWgB8oSkcF-"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "dB7dnTgpqs_-"
      },
      "outputs": [],
      "source": [
        "# ds.applymap(lambda x: change_value_to_numeric(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "zQnlz8DAnAC3"
      },
      "outputs": [],
      "source": [
        "# ds = ds.applymap(lambda x: change_value_to_numeric(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Пол'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy9-88v9bi2u",
        "outputId": "6776faa6-aa39-4f80-e4a4-74fb804f6e93"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "М    175\n",
              "Ж     76\n",
              "Name: Пол, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Пол'] = np.where(ds['Пол']=='М',1,0)"
      ],
      "metadata": {
        "id": "0HsMmuGXbX0i"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Пол'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTxS-svEbkoK",
        "outputId": "8b95c3a8-c237-4e36-c59b-1377b6174780"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    175\n",
              "0     76\n",
              "Name: Пол, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "eYGpxa6cG2Oi",
        "outputId": "3e09ad23-eeab-49ca-88ec-646499848fea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "0    1          32                                   4   \n",
              "1    1          26                                   2   \n",
              "2    1          49                                   2   \n",
              "3    1          50                                   2   \n",
              "4    1          27                                   2   \n",
              "\n",
              "   Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "0                            0                                 0   \n",
              "1                            0                                 0   \n",
              "2                            0                                 0   \n",
              "3                            0                                 0   \n",
              "4                            1                                 0   \n",
              "\n",
              "   Удовлетворенность семеными отношениями  \\\n",
              "0                                       5   \n",
              "1                                       5   \n",
              "2                                       5   \n",
              "3                                       5   \n",
              "4                                       5   \n",
              "\n",
              "   Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "0                                          0                    7   \n",
              "1                                          0                   10   \n",
              "2                                          1                   10   \n",
              "3                                          1                    7   \n",
              "4                                          1                    9   \n",
              "\n",
              "   Были ли нарушения сна        ИМТ  ...  Дебют  Частота госпит  Стаж шизофр  \\\n",
              "0                      1  24.012346  ...   28.3               0          3.7   \n",
              "1                      1  20.244898  ...   26.0               1          2.0   \n",
              "2                      0  29.752744  ...   26.0               2         23.0   \n",
              "3                      1  22.093170  ...   16.0               1         34.0   \n",
              "4                      1  26.061679  ...   21.0               0          6.0   \n",
              "\n",
              "    P   N   G  (СОН)psqi больше 6  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "0  11  11  18                   0                             0   \n",
              "1  10  25  36                   1                             0   \n",
              "2   9  16  23                   0                             0   \n",
              "3  13  13  20                   0                             0   \n",
              "4   7   9  22                   0                             0   \n",
              "\n",
              "   (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "0                          0                            0  \n",
              "1                          1                            1  \n",
              "2                          0                            0  \n",
              "3                          0                            0  \n",
              "4                          0                            0  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d8cdfb8-4ee2-41cd-9d02-029c90e0627d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>ИМТ</th>\n",
              "      <th>...</th>\n",
              "      <th>Дебют</th>\n",
              "      <th>Частота госпит</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>(СОН)psqi больше 6</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>24.012346</td>\n",
              "      <td>...</td>\n",
              "      <td>28.3</td>\n",
              "      <td>0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>20.244898</td>\n",
              "      <td>...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>29.752744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>22.093170</td>\n",
              "      <td>...</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>26.061679</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d8cdfb8-4ee2-41cd-9d02-029c90e0627d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d8cdfb8-4ee2-41cd-9d02-029c90e0627d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d8cdfb8-4ee2-41cd-9d02-029c90e0627d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ],
      "source": [
        "ds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dNDEEZMXqCI",
        "outputId": "eb63711b-cb70-4885-fcfb-5cce34bbd774"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Пол                                          0\n",
              "Полных лет                                   0\n",
              "Образование(0-начальное, 4-высшее)           0\n",
              "Род занятий(0-0, работает-1                  0\n",
              "Семейное положение(0-0, 1-женат)             0\n",
              "Удовлетворенность семеными отношениями       0\n",
              "Удовлетворенность материальным положением    0\n",
              "Здоровье от 1 до 10                          0\n",
              "Были ли нарушения сна                        0\n",
              "ИМТ                                          0\n",
              "Операции                                     0\n",
              "Аллергии                                     0\n",
              "СД                                           0\n",
              "Забол кожи                                   0\n",
              "ГБ                                           0\n",
              "Панкреатит                                   0\n",
              "Дисфункция ЖКТ                               0\n",
              "ЧМТ                                          0\n",
              "Насл отягощенность                           0\n",
              "Дебют                                        0\n",
              "Частота госпит                               0\n",
              "Стаж шизофр                                  0\n",
              "P                                            0\n",
              "N                                            0\n",
              "G                                            0\n",
              "(СОН)psqi больше 6                           0\n",
              "(ТРЕВОГА)Гаиильтон больше 16                 0\n",
              "(ДЕПРЕССИЯ)madrs больше 6                    0\n",
              "(ДЕПРЕССИЯ)Калгари больше 5                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ],
      "source": [
        "# Check for na values\n",
        "ds.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kak3ZDUIIWNo",
        "outputId": "80d30202-496b-42d9-e565-22761e2f9b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 251 entries, 0 to 250\n",
            "Data columns (total 29 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Пол                                        251 non-null    int64  \n",
            " 1   Полных лет                                 251 non-null    int64  \n",
            " 2   Образование(0-начальное, 4-высшее)         251 non-null    int64  \n",
            " 3   Род занятий(0-0, работает-1                251 non-null    int64  \n",
            " 4   Семейное положение(0-0, 1-женат)           251 non-null    int64  \n",
            " 5   Удовлетворенность семеными отношениями     251 non-null    int64  \n",
            " 6   Удовлетворенность материальным положением  251 non-null    int64  \n",
            " 7   Здоровье от 1 до 10                        251 non-null    int64  \n",
            " 8   Были ли нарушения сна                      251 non-null    int64  \n",
            " 9   ИМТ                                        251 non-null    float64\n",
            " 10  Операции                                   251 non-null    int64  \n",
            " 11  Аллергии                                   251 non-null    int64  \n",
            " 12  СД                                         251 non-null    int64  \n",
            " 13  Забол кожи                                 251 non-null    int64  \n",
            " 14  ГБ                                         251 non-null    int64  \n",
            " 15  Панкреатит                                 251 non-null    int64  \n",
            " 16  Дисфункция ЖКТ                             251 non-null    int64  \n",
            " 17  ЧМТ                                        251 non-null    int64  \n",
            " 18  Насл отягощенность                         251 non-null    int64  \n",
            " 19  Дебют                                      251 non-null    float64\n",
            " 20  Частота госпит                             251 non-null    int64  \n",
            " 21  Стаж шизофр                                251 non-null    float64\n",
            " 22  P                                          251 non-null    int64  \n",
            " 23  N                                          251 non-null    int64  \n",
            " 24  G                                          251 non-null    int64  \n",
            " 25  (СОН)psqi больше 6                         251 non-null    int64  \n",
            " 26  (ТРЕВОГА)Гаиильтон больше 16               251 non-null    int64  \n",
            " 27  (ДЕПРЕССИЯ)madrs больше 6                  251 non-null    int64  \n",
            " 28  (ДЕПРЕССИЯ)Калгари больше 5                251 non-null    int64  \n",
            "dtypes: float64(3), int64(26)\n",
            "memory usage: 57.0 KB\n"
          ]
        }
      ],
      "source": [
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLmf_yhQIdAS",
        "outputId": "46a59174-d89d-4259-f737-fc91fab10be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 251 entries, 0 to 250\n",
            "Data columns (total 29 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Пол                                        251 non-null    float32\n",
            " 1   Полных лет                                 251 non-null    float32\n",
            " 2   Образование(0-начальное, 4-высшее)         251 non-null    float32\n",
            " 3   Род занятий(0-0, работает-1                251 non-null    float32\n",
            " 4   Семейное положение(0-0, 1-женат)           251 non-null    float32\n",
            " 5   Удовлетворенность семеными отношениями     251 non-null    float32\n",
            " 6   Удовлетворенность материальным положением  251 non-null    float32\n",
            " 7   Здоровье от 1 до 10                        251 non-null    float32\n",
            " 8   Были ли нарушения сна                      251 non-null    float32\n",
            " 9   ИМТ                                        251 non-null    float32\n",
            " 10  Операции                                   251 non-null    float32\n",
            " 11  Аллергии                                   251 non-null    float32\n",
            " 12  СД                                         251 non-null    float32\n",
            " 13  Забол кожи                                 251 non-null    float32\n",
            " 14  ГБ                                         251 non-null    float32\n",
            " 15  Панкреатит                                 251 non-null    float32\n",
            " 16  Дисфункция ЖКТ                             251 non-null    float32\n",
            " 17  ЧМТ                                        251 non-null    float32\n",
            " 18  Насл отягощенность                         251 non-null    float32\n",
            " 19  Дебют                                      251 non-null    float32\n",
            " 20  Частота госпит                             251 non-null    float32\n",
            " 21  Стаж шизофр                                251 non-null    float32\n",
            " 22  P                                          251 non-null    float32\n",
            " 23  N                                          251 non-null    float32\n",
            " 24  G                                          251 non-null    float32\n",
            " 25  (СОН)psqi больше 6                         251 non-null    float32\n",
            " 26  (ТРЕВОГА)Гаиильтон больше 16               251 non-null    float32\n",
            " 27  (ДЕПРЕССИЯ)madrs больше 6                  251 non-null    float32\n",
            " 28  (ДЕПРЕССИЯ)Калгари больше 5                251 non-null    float32\n",
            "dtypes: float32(29)\n",
            "memory usage: 28.6 KB\n"
          ]
        }
      ],
      "source": [
        "# turn dataset to float32\n",
        "ds = ds.astype(np.float32)\n",
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Ai6pimUakX",
        "outputId": "42cc7648-2fbc-4c9b-f0a1-234b527176d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    126\n",
              "0.0    125\n",
              "Name: (СОН)psqi больше 6, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ],
      "source": [
        "ds['(СОН)psqi больше 6'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fytj8feUaq7",
        "outputId": "5ae28d4e-e943-42a4-acbe-dab1d3cd4c49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    182\n",
              "1.0     69\n",
              "Name: (ТРЕВОГА)Гаиильтон больше 16, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ],
      "source": [
        "ds['(ТРЕВОГА)Гаиильтон больше 16'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z96bukAkUata",
        "outputId": "f355d31f-c7cf-48b2-a4ed-eb1ca1ed1e77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    155\n",
              "1.0     96\n",
              "Name: (ДЕПРЕССИЯ)madrs больше 6, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ],
      "source": [
        "ds['(ДЕПРЕССИЯ)madrs больше 6'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['(ДЕПРЕССИЯ)Калгари больше 5'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2SUV1exnNuK",
        "outputId": "d613dcd1-7d8f-40c9-ecb6-fd3834a1cdc7"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    185\n",
              "1.0     66\n",
              "Name: (ДЕПРЕССИЯ)Калгари больше 5, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "z0Fx5Wsrk2mi"
      },
      "outputs": [],
      "source": [
        "# Let's try to use '(СОН)psqi больше 6' as y value\n",
        "data = ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "x-rJ0J9gvL8Q"
      },
      "outputs": [],
      "source": [
        "# Create X, y\n",
        "y = data['(СОН)psqi больше 6']\n",
        "X = data.drop(columns=['(СОН)psqi больше 6', '(ТРЕВОГА)Гаиильтон больше 16', '(ДЕПРЕССИЯ)madrs больше 6', '(ДЕПРЕССИЯ)Калгари больше 5'])\n",
        "# X = data.drop(columns=['Нарушения сна больше 5'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find 3 best predictors witn chi square and ANOVA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2 # chi^2\n",
        "from sklearn.feature_selection import f_classif # ANOVA\n",
        "\n",
        "X_chi2 = SelectKBest(chi2, k=5).fit_transform(X, y)\n",
        "X_anova = SelectKBest(f_classif, k=5).fit_transform(X, y)"
      ],
      "metadata": {
        "id": "oW3UvZbiNUcI"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the Top Selected Features\n",
        "\n",
        "https://ml2021.medium.com/chi-square-and-anova-feature-selection-for-ml-5e1063ab0991"
      ],
      "metadata": {
        "id": "8aImEuZChXVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_score = chi2(X, y)\n",
        "f_score\n",
        "# The first array is the F_score , 2nd one is the P_values\n",
        "# the smaller the P value the more significant the difference in the features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3x7wS6Key9P",
        "outputId": "21a39b4a-cba0-4c58-cf8a-ac23c730cb49"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.27004444e-01, 1.41640085e-01, 8.85776705e-02, 1.72557953e+00,\n",
              "        3.87955748e-02, 3.17161211e-03, 2.42740890e+00, 3.07154818e+00,\n",
              "        4.31543488e+00, 3.60816218e+02, 1.49696383e+00, 2.11325714e+00,\n",
              "        6.82708995e-01, 4.46464007e+00, 3.69631111e+00, 4.08528955e+00,\n",
              "        4.39262372e-01, 1.27951917e+00, 1.81534829e-02, 3.11785564e-02,\n",
              "        1.96909626e-01, 7.15919533e-01, 3.44895970e+01, 3.27558783e-02,\n",
              "        2.70985987e+01]),\n",
              " array([6.33753939e-01, 7.06655960e-01, 7.65993200e-01, 1.88976419e-01,\n",
              "        8.43854205e-01, 9.55089222e-01, 1.19229833e-01, 7.96735620e-02,\n",
              "        3.77681162e-02, 1.87005948e-80, 2.21139118e-01, 1.46028215e-01,\n",
              "        4.08655450e-01, 3.46033793e-02, 5.45329075e-02, 4.32580391e-02,\n",
              "        5.07478692e-01, 2.57988457e-01, 8.92821509e-01, 8.59842620e-01,\n",
              "        6.57226956e-01, 3.97485647e-01, 4.28535575e-09, 8.56378682e-01,\n",
              "        1.93338040e-07]))"
            ]
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pvalues = pd.Series(f_score[1])\n",
        "pvalues.index = X.columns\n",
        "pvalues.sort_values(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xp3b1pMe9AS",
        "outputId": "738605e3-d5c5-4984-d1a4-be02a7d523d8"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ИМТ                                          1.870059e-80\n",
              "P                                            4.285356e-09\n",
              "G                                            1.933380e-07\n",
              "Забол кожи                                   3.460338e-02\n",
              "Были ли нарушения сна                        3.776812e-02\n",
              "Панкреатит                                   4.325804e-02\n",
              "ГБ                                           5.453291e-02\n",
              "Здоровье от 1 до 10                          7.967356e-02\n",
              "Удовлетворенность материальным положением    1.192298e-01\n",
              "Аллергии                                     1.460282e-01\n",
              "Род занятий(0-0, работает-1                  1.889764e-01\n",
              "Операции                                     2.211391e-01\n",
              "ЧМТ                                          2.579885e-01\n",
              "Стаж шизофр                                  3.974856e-01\n",
              "СД                                           4.086554e-01\n",
              "Дисфункция ЖКТ                               5.074787e-01\n",
              "Пол                                          6.337539e-01\n",
              "Частота госпит                               6.572270e-01\n",
              "Полных лет                                   7.066560e-01\n",
              "Образование(0-начальное, 4-высшее)           7.659932e-01\n",
              "Семейное положение(0-0, 1-женат)             8.438542e-01\n",
              "N                                            8.563787e-01\n",
              "Дебют                                        8.598426e-01\n",
              "Насл отягощенность                           8.928215e-01\n",
              "Удовлетворенность семеными отношениями       9.550892e-01\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now use the SelectKBest Model with the chi2 classifier to find the best features\n",
        "\n",
        "sel_ = SelectKBest(chi2, k=5).fit(X, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pelM22yef1sD",
        "outputId": "93db2bbc-c531-4103-94c9-5fb187e9caca"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Были ли нарушения сна', 'ИМТ', 'Забол кожи', 'P', 'G'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tra8Cu0Af292"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4TvTeApRfKkw"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "QVqfCfsgQHwV",
        "outputId": "3cfc8b58-33b7-4c85-b45f-4b383474363f"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "0   1.0        32.0                                 4.0   \n",
              "1   1.0        26.0                                 2.0   \n",
              "2   1.0        49.0                                 2.0   \n",
              "3   1.0        50.0                                 2.0   \n",
              "4   1.0        27.0                                 2.0   \n",
              "5   1.0        39.0                                 2.0   \n",
              "6   1.0        23.0                                 3.0   \n",
              "7   1.0        26.0                                 2.0   \n",
              "8   1.0        37.0                                 4.0   \n",
              "9   1.0        31.0                                 2.0   \n",
              "10  1.0        35.0                                 3.0   \n",
              "11  1.0        28.0                                 2.0   \n",
              "12  1.0        31.0                                 3.0   \n",
              "13  1.0        23.0                                 2.0   \n",
              "14  1.0        37.0                                 3.0   \n",
              "15  1.0        39.0                                 3.0   \n",
              "16  1.0        29.0                                 1.0   \n",
              "17  1.0        36.0                                 4.0   \n",
              "18  1.0        33.0                                 3.0   \n",
              "19  1.0        24.0                                 2.0   \n",
              "\n",
              "    Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "0                           0.0                               0.0   \n",
              "1                           0.0                               0.0   \n",
              "2                           0.0                               0.0   \n",
              "3                           0.0                               0.0   \n",
              "4                           1.0                               0.0   \n",
              "5                           0.0                               0.0   \n",
              "6                           0.0                               0.0   \n",
              "7                           1.0                               1.0   \n",
              "8                           0.0                               0.0   \n",
              "9                           0.0                               0.0   \n",
              "10                          0.0                               0.0   \n",
              "11                          1.0                               0.0   \n",
              "12                          0.0                               0.0   \n",
              "13                          0.0                               0.0   \n",
              "14                          1.0                               0.0   \n",
              "15                          1.0                               0.0   \n",
              "16                          0.0                               0.0   \n",
              "17                          0.0                               0.0   \n",
              "18                          1.0                               1.0   \n",
              "19                          1.0                               0.0   \n",
              "\n",
              "    Удовлетворенность семеными отношениями  \\\n",
              "0                                      5.0   \n",
              "1                                      5.0   \n",
              "2                                      5.0   \n",
              "3                                      5.0   \n",
              "4                                      5.0   \n",
              "5                                      5.0   \n",
              "6                                      4.0   \n",
              "7                                      5.0   \n",
              "8                                      5.0   \n",
              "9                                      1.0   \n",
              "10                                     5.0   \n",
              "11                                     5.0   \n",
              "12                                     1.0   \n",
              "13                                     4.0   \n",
              "14                                     5.0   \n",
              "15                                     1.0   \n",
              "16                                     5.0   \n",
              "17                                     1.0   \n",
              "18                                     5.0   \n",
              "19                                     5.0   \n",
              "\n",
              "    Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "0                                         0.0                  7.0   \n",
              "1                                         0.0                 10.0   \n",
              "2                                         1.0                 10.0   \n",
              "3                                         1.0                  7.0   \n",
              "4                                         1.0                  9.0   \n",
              "5                                         1.0                  7.0   \n",
              "6                                         1.0                  7.0   \n",
              "7                                         1.0                 10.0   \n",
              "8                                         1.0                  7.0   \n",
              "9                                         0.0                  7.0   \n",
              "10                                        1.0                  5.0   \n",
              "11                                        0.0                  7.0   \n",
              "12                                        0.0                  3.0   \n",
              "13                                        1.0                  7.0   \n",
              "14                                        0.0                  7.0   \n",
              "15                                        0.0                  1.0   \n",
              "16                                        1.0                 10.0   \n",
              "17                                        0.0                  7.0   \n",
              "18                                        1.0                 10.0   \n",
              "19                                        1.0                  5.0   \n",
              "\n",
              "    Были ли нарушения сна        ИМТ  ...      Дебют  Частота госпит  \\\n",
              "0                     1.0  24.012346  ...  28.299999             0.0   \n",
              "1                     1.0  20.244898  ...  26.000000             1.0   \n",
              "2                     0.0  29.752745  ...  26.000000             2.0   \n",
              "3                     1.0  22.093170  ...  16.000000             1.0   \n",
              "4                     1.0  26.061680  ...  21.000000             0.0   \n",
              "5                     0.0  20.761246  ...  34.000000             0.0   \n",
              "6                     0.0  19.623234  ...  20.000000             0.0   \n",
              "7                     1.0  25.737082  ...  25.000000             2.0   \n",
              "8                     0.0  24.508945  ...  20.000000             2.0   \n",
              "9                     0.0  20.603781  ...  17.000000             2.0   \n",
              "10                    0.0  23.547880  ...  22.799999             2.0   \n",
              "11                    1.0  23.040020  ...  24.030001             0.0   \n",
              "12                    1.0  26.128611  ...  22.000000             1.0   \n",
              "13                    0.0  18.812147  ...  17.330000             0.0   \n",
              "14                    0.0  20.761246  ...  26.000000             2.0   \n",
              "15                    1.0  23.148148  ...  23.000000             2.0   \n",
              "16                    1.0  25.661152  ...  13.000000             2.0   \n",
              "17                    1.0  29.407787  ...  21.000000             2.0   \n",
              "18                    1.0  26.827421  ...  20.000000             0.0   \n",
              "19                    1.0  25.390625  ...  16.000000             0.0   \n",
              "\n",
              "    Стаж шизофр     P     N     G  (СОН)psqi больше 6  \\\n",
              "0          3.70  11.0  11.0  18.0                 0.0   \n",
              "1          2.00  10.0  25.0  36.0                 1.0   \n",
              "2         23.00   9.0  16.0  23.0                 0.0   \n",
              "3         34.00  13.0  13.0  20.0                 0.0   \n",
              "4          6.00   7.0   9.0  22.0                 0.0   \n",
              "5          4.00   9.0  13.0  22.0                 0.0   \n",
              "6          3.00   7.0   9.0  22.0                 1.0   \n",
              "7          1.00   7.0   9.0  21.0                 0.0   \n",
              "8         17.00   9.0  15.0  22.0                 0.0   \n",
              "9         14.00   7.0  14.0  38.0                 1.0   \n",
              "10        12.20  14.0  20.0  40.0                 1.0   \n",
              "11         3.97   7.0  15.0  22.0                 0.0   \n",
              "12         9.00   7.0   7.0  16.0                 0.0   \n",
              "13         5.67  15.0  11.0  28.0                 1.0   \n",
              "14        11.00  18.0   7.0  22.0                 1.0   \n",
              "15        16.00  19.0  13.0  41.0                 1.0   \n",
              "16        16.00  15.0   9.0  26.0                 1.0   \n",
              "17        15.00  11.0  19.0  48.0                 1.0   \n",
              "18        13.00   9.0   7.0  25.0                 1.0   \n",
              "19         8.00  12.0  11.0  23.0                 1.0   \n",
              "\n",
              "    (ТРЕВОГА)Гаиильтон больше 16  (ДЕПРЕССИЯ)madrs больше 6  \\\n",
              "0                            0.0                        0.0   \n",
              "1                            0.0                        1.0   \n",
              "2                            0.0                        0.0   \n",
              "3                            0.0                        0.0   \n",
              "4                            0.0                        0.0   \n",
              "5                            0.0                        0.0   \n",
              "6                            1.0                        1.0   \n",
              "7                            0.0                        0.0   \n",
              "8                            0.0                        0.0   \n",
              "9                            1.0                        1.0   \n",
              "10                           1.0                        1.0   \n",
              "11                           0.0                        0.0   \n",
              "12                           0.0                        0.0   \n",
              "13                           0.0                        0.0   \n",
              "14                           0.0                        0.0   \n",
              "15                           1.0                        1.0   \n",
              "16                           0.0                        0.0   \n",
              "17                           1.0                        1.0   \n",
              "18                           0.0                        1.0   \n",
              "19                           1.0                        1.0   \n",
              "\n",
              "    (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "0                           0.0  \n",
              "1                           1.0  \n",
              "2                           0.0  \n",
              "3                           0.0  \n",
              "4                           0.0  \n",
              "5                           0.0  \n",
              "6                           0.0  \n",
              "7                           0.0  \n",
              "8                           0.0  \n",
              "9                           1.0  \n",
              "10                          0.0  \n",
              "11                          0.0  \n",
              "12                          0.0  \n",
              "13                          0.0  \n",
              "14                          0.0  \n",
              "15                          1.0  \n",
              "16                          0.0  \n",
              "17                          1.0  \n",
              "18                          0.0  \n",
              "19                          1.0  \n",
              "\n",
              "[20 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f383069-940e-479a-af7c-c1b2a579d977\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>ИМТ</th>\n",
              "      <th>...</th>\n",
              "      <th>Дебют</th>\n",
              "      <th>Частота госпит</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>(СОН)psqi больше 6</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.012346</td>\n",
              "      <td>...</td>\n",
              "      <td>28.299999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.70</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.244898</td>\n",
              "      <td>...</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.752745</td>\n",
              "      <td>...</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.093170</td>\n",
              "      <td>...</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.061680</td>\n",
              "      <td>...</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.761246</td>\n",
              "      <td>...</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.623234</td>\n",
              "      <td>...</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.737082</td>\n",
              "      <td>...</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.508945</td>\n",
              "      <td>...</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.603781</td>\n",
              "      <td>...</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.547880</td>\n",
              "      <td>...</td>\n",
              "      <td>22.799999</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.20</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.040020</td>\n",
              "      <td>...</td>\n",
              "      <td>24.030001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.97</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.128611</td>\n",
              "      <td>...</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.812147</td>\n",
              "      <td>...</td>\n",
              "      <td>17.330000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.67</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.761246</td>\n",
              "      <td>...</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.00</td>\n",
              "      <td>18.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.148148</td>\n",
              "      <td>...</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.661152</td>\n",
              "      <td>...</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.407787</td>\n",
              "      <td>...</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.827421</td>\n",
              "      <td>...</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.390625</td>\n",
              "      <td>...</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f383069-940e-479a-af7c-c1b2a579d977')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f383069-940e-479a-af7c-c1b2a579d977 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f383069-940e-479a-af7c-c1b2a579d977');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_chi2 # TOP 3 - ИМТ, P, G. TOP 5 - Были ли нарушения сна, забол кожи и топ3"
      ],
      "metadata": {
        "id": "RKzIBlkeNe7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bc7e50-bb46-4c43-bf4c-65cef8326c5f"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.      , 24.012346,  0.      , 11.      , 18.      ],\n",
              "       [ 1.      , 20.244898,  0.      , 10.      , 36.      ],\n",
              "       [ 0.      , 29.752745,  0.      ,  9.      , 23.      ],\n",
              "       ...,\n",
              "       [ 1.      , 19.883854,  0.      ,  7.      , 27.      ],\n",
              "       [ 1.      , 20.281233,  0.      , 14.      , 21.      ],\n",
              "       [ 1.      , 27.041645,  0.      ,  7.      , 28.      ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA"
      ],
      "metadata": {
        "id": "wVd6jE3hZslG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "univariate = f_classif(X, y)\n",
        "univariate"
      ],
      "metadata": {
        "id": "EUMyT5pBZnG7",
        "outputId": "142d138c-d3ea-436d-c7d0-4c2863490e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([7.4597472e-01, 4.9697403e-02, 2.7459836e-01, 2.1454043e+00,\n",
              "        4.4321254e-02, 5.2437475e-03, 5.6714873e+00, 4.4107866e+00,\n",
              "        1.2540681e+01, 9.5257527e-01, 2.9234118e+00, 2.7139599e+00,\n",
              "        6.9579417e-01, 5.3055286e+00, 4.4397712e+00, 4.6680522e+00,\n",
              "        5.0506049e-01, 1.9037019e+00, 3.4774307e-02, 2.0013262e-02,\n",
              "        2.2143316e-01, 1.1720605e-01, 1.4731611e+01, 1.0824733e-02,\n",
              "        1.0870686e+01], dtype=float32),\n",
              " array([3.8858485e-01, 8.2377344e-01, 6.0072982e-01, 1.4425880e-01,\n",
              "        8.3342922e-01, 9.4233078e-01, 1.7995024e-02, 3.6718566e-02,\n",
              "        4.7517335e-04, 3.3001190e-01, 8.8548832e-02, 1.0073511e-01,\n",
              "        4.0500003e-01, 2.2082373e-02, 3.6111336e-02, 3.1682927e-02,\n",
              "        4.7795010e-01, 1.6890225e-01, 8.5222119e-01, 8.8761443e-01,\n",
              "        6.3836199e-01, 7.3237354e-01, 1.5721924e-04, 9.1721976e-01,\n",
              "        1.1194290e-03], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 2nd values are the PValue and we capture those below\n",
        "univariate = pd.Series(univariate[1])\n",
        "univariate.index = X.columns\n",
        "univariate.sort_values(ascending=False).plot.bar(figsize=(20,6))"
      ],
      "metadata": {
        "id": "b9wq1WrOZzPA",
        "outputId": "d0b72059-d6bc-4376-cb58-3eaa64124148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ffadff34550>"
            ]
          },
          "metadata": {},
          "execution_count": 273
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TOP 5 features\n",
        "sel_ = SelectKBest(f_classif, k=5).fit(X, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "id": "BIbA_QH2aNMQ",
        "outputId": "079ba7e3-cc77-4518-9adb-ebba3fd76bbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Удовлетворенность материальным положением', 'Были ли нарушения сна',\n",
              "       'Забол кожи', 'P', 'G'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I90-1SNSaPPg"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Lmy3RTQzZzxL"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_anova # TOP 3 - Были ли нарушения сна, P, G"
      ],
      "metadata": {
        "id": "RDWO9sN0O0xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d2c2bb-9830-400a-ee87-a2b700c64ab3"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  1.,  0., 11., 18.],\n",
              "       [ 0.,  1.,  0., 10., 36.],\n",
              "       [ 1.,  0.,  0.,  9., 23.],\n",
              "       ...,\n",
              "       [ 1.,  1.,  0.,  7., 27.],\n",
              "       [ 0.,  1.,  0., 14., 21.],\n",
              "       [ 1.,  1.,  0.,  7., 28.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F21u74y3UP6q"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find 4 best predictors witn scalied data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = minmax_scaler.fit_transform(X)\n",
        "X_chi2_scaled = SelectKBest(chi2, k=4).fit_transform(X_scaled, y)\n",
        "X_anova_scaled = SelectKBest(f_classif, k=4).fit_transform(X_scaled, y)"
      ],
      "metadata": {
        "id": "023I6vdtNf5b"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_score_scaled = chi2(X_scaled, y)\n",
        "f_score_scaled\n",
        "# The first array is the F_score , 2nd one is the P_values\n",
        "# the smaller the P value the more significant the difference in the features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14mLv1Rcgpcb",
        "outputId": "2b08e67c-ea76-4af3-9ed0-fb4159338da4"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.27004444e-01, 5.68335249e-03, 2.21444176e-02, 1.72557953e+00,\n",
              "        3.87955748e-02, 1.08429199e-03, 2.42740890e+00, 3.92886765e-01,\n",
              "        4.31543488e+00, 3.63840015e-01, 1.49696383e+00, 2.11325714e+00,\n",
              "        6.82708995e-01, 4.46464007e+00, 3.69631111e+00, 4.08528955e+00,\n",
              "        4.39262372e-01, 6.39759583e-01, 1.81534829e-02, 9.45120725e-04,\n",
              "        9.84548131e-02, 1.82393754e-02, 1.07779990e+00, 1.62168666e-03,\n",
              "        1.21322862e+00]),\n",
              " array([0.63375394, 0.939906  , 0.88170356, 0.18897642, 0.8438542 ,\n",
              "        0.97373153, 0.11922983, 0.53078589, 0.03776812, 0.54638129,\n",
              "        0.22113912, 0.14602821, 0.40865545, 0.03460338, 0.05453291,\n",
              "        0.04325804, 0.50747869, 0.42379787, 0.89282151, 0.97547465,\n",
              "        0.75369186, 0.89256979, 0.29919025, 0.96787773, 0.27069364]))"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pvalues = pd.Series(f_score_scaled[1])\n",
        "pvalues.index = X.columns\n",
        "pvalues.sort_values(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvYgWRBqgtKI",
        "outputId": "148ae963-8626-4c17-cbef-bc06b0810a4f"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Забол кожи                                   0.034603\n",
              "Были ли нарушения сна                        0.037768\n",
              "Панкреатит                                   0.043258\n",
              "ГБ                                           0.054533\n",
              "Удовлетворенность материальным положением    0.119230\n",
              "Аллергии                                     0.146028\n",
              "Род занятий(0-0, работает-1                  0.188976\n",
              "Операции                                     0.221139\n",
              "G                                            0.270694\n",
              "P                                            0.299190\n",
              "СД                                           0.408655\n",
              "ЧМТ                                          0.423798\n",
              "Дисфункция ЖКТ                               0.507479\n",
              "Здоровье от 1 до 10                          0.530786\n",
              "ИМТ                                          0.546381\n",
              "Пол                                          0.633754\n",
              "Частота госпит                               0.753692\n",
              "Семейное положение(0-0, 1-женат)             0.843854\n",
              "Образование(0-начальное, 4-высшее)           0.881704\n",
              "Стаж шизофр                                  0.892570\n",
              "Насл отягощенность                           0.892822\n",
              "Полных лет                                   0.939906\n",
              "N                                            0.967878\n",
              "Удовлетворенность семеными отношениями       0.973732\n",
              "Дебют                                        0.975475\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now use the SelectKBest Model with the chi2 classifier to find the best features\n",
        "\n",
        "sel_ = SelectKBest(chi2, k=5).fit(X_scaled, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm1xMp0jgz-e",
        "outputId": "4b8ed14f-3649-4d7c-9bdc-f345fc4a2812"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Удовлетворенность материальным положением', 'Были ли нарушения сна',\n",
              "       'Забол кожи', 'ГБ', 'Панкреатит'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rOW1fDJzhImX"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA"
      ],
      "metadata": {
        "id": "YBuG7ukDhFuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "univariate_scaled = f_classif(X_scaled, y)\n",
        "univariate_scaled"
      ],
      "metadata": {
        "id": "OwBx45LZhG-8",
        "outputId": "c2f7f041-ea5d-456e-fcc3-727575610a57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([7.4597472e-01, 4.9464326e-02, 2.7459836e-01, 2.1454043e+00,\n",
              "        4.4321254e-02, 5.2437475e-03, 5.6714873e+00, 4.4107189e+00,\n",
              "        1.2540681e+01, 9.5257491e-01, 2.9234118e+00, 2.7139599e+00,\n",
              "        6.9579417e-01, 5.3055286e+00, 4.4397712e+00, 4.6680522e+00,\n",
              "        5.0506049e-01, 1.9037019e+00, 3.4774307e-02, 1.9392692e-02,\n",
              "        2.2143316e-01, 1.1730685e-01, 1.4731611e+01, 1.0777256e-02,\n",
              "        1.0870758e+01], dtype=float32),\n",
              " array([3.8858485e-01, 8.2418036e-01, 6.0072982e-01, 1.4425880e-01,\n",
              "        8.3342922e-01, 9.4233078e-01, 1.7995024e-02, 3.6719996e-02,\n",
              "        4.7517335e-04, 3.3001199e-01, 8.8548832e-02, 1.0073511e-01,\n",
              "        4.0500003e-01, 2.2082373e-02, 3.6111336e-02, 3.1682927e-02,\n",
              "        4.7795010e-01, 1.6890225e-01, 8.5222119e-01, 8.8935912e-01,\n",
              "        6.3836199e-01, 7.3226291e-01, 1.5721924e-04, 9.1740084e-01,\n",
              "        1.1193871e-03], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 2nd values are the PValue and we capture those below\n",
        "univariate_scaled = pd.Series(univariate_scaled[1])\n",
        "univariate_scaled.index = X.columns\n",
        "univariate_scaled.sort_values(ascending=False).plot.bar(figsize=(20,6))"
      ],
      "metadata": {
        "id": "djLNEHfThKKz",
        "outputId": "97b1e666-3785-4972-a67b-a4ccec3ddca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ffade943c10>"
            ]
          },
          "metadata": {},
          "execution_count": 281
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TOP 5 features\n",
        "sel_ = SelectKBest(f_classif, k=5).fit(X_scaled, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "id": "KSGhE7K5hUqO",
        "outputId": "c1ce6270-94a8-43de-b12c-a1bde86f0952",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Удовлетворенность материальным положением', 'Были ли нарушения сна',\n",
              "       'Забол кожи', 'P', 'G'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L0FH6fE0hhzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OVxUbs4lhFwd"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0morjvDohFyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cE49CtiChHBb"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_chi2_scaled # Были ли нарушения сна, Динамека веса за год, Аллергии, ГБ"
      ],
      "metadata": {
        "id": "kK2YEY2VS9kV"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_anova_scaled # Были ли нарушения сна, Аллергии, P, G"
      ],
      "metadata": {
        "id": "aW029ll0S9nm"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many times and which features were the most influential?\n",
        "\n",
        "# Аллергии 4\n",
        "# Были ли нарушения сна  3\n",
        "# P 3\n",
        "# G 3\n",
        "# Динамека веса за год 1 \n",
        "# ГБ 1\n",
        "# Стаж шизофр 1"
      ],
      "metadata": {
        "id": "JGbIT52RS9pu"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using best features\n",
        "# X = X[['Аллергии', 'Были ли нарушения сна', 'P', 'G']]\n",
        "\n",
        "# X = X[['Забол кожи', 'Были ли нарушения сна', 'Панкреатит', 'ГБ']]\n",
        "\n",
        "X = X[['Удовлетворенность материальным положением', 'Были ли нарушения сна', 'Забол кожи', 'P', 'G']]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cA1BbqGaS9ru"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Scaling\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "X_train_scaled = minmax_scaler.fit_transform(X_train)\n",
        "X_valid_scaled = minmax_scaler.transform(X_valid)"
      ],
      "metadata": {
        "id": "EkYpF44DNQjU"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cdqTwvKMbi",
        "outputId": "3ee44763-cfec-4ae4-9c88-89173134cf81"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 30ms/step - loss: 0.6885 - accuracy: 0.5800 - val_loss: 0.6774 - val_accuracy: 0.5686\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6732 - accuracy: 0.6200 - val_loss: 0.6657 - val_accuracy: 0.5686\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6636 - accuracy: 0.6100 - val_loss: 0.6570 - val_accuracy: 0.5686\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6558 - accuracy: 0.6200 - val_loss: 0.6517 - val_accuracy: 0.6078\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6460 - accuracy: 0.6700 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6411 - accuracy: 0.6800 - val_loss: 0.6554 - val_accuracy: 0.6667\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6434 - accuracy: 0.6550 - val_loss: 0.6669 - val_accuracy: 0.5882\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6387 - accuracy: 0.6600 - val_loss: 0.6678 - val_accuracy: 0.6275\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6349 - accuracy: 0.6500 - val_loss: 0.6657 - val_accuracy: 0.6275\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6344 - accuracy: 0.6550 - val_loss: 0.6599 - val_accuracy: 0.6471\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6438 - accuracy: 0.6150 - val_loss: 0.6656 - val_accuracy: 0.6471\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6295 - accuracy: 0.6550 - val_loss: 0.6612 - val_accuracy: 0.6471\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6277 - accuracy: 0.6700 - val_loss: 0.6634 - val_accuracy: 0.6667\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6247 - accuracy: 0.6550 - val_loss: 0.6714 - val_accuracy: 0.6471\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6209 - accuracy: 0.6550 - val_loss: 0.6509 - val_accuracy: 0.6471\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6266 - accuracy: 0.6450 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6214 - accuracy: 0.6450 - val_loss: 0.6627 - val_accuracy: 0.6667\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6160 - accuracy: 0.6400 - val_loss: 0.6522 - val_accuracy: 0.6471\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.6700 - val_loss: 0.6644 - val_accuracy: 0.6275\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6219 - accuracy: 0.6500 - val_loss: 0.6708 - val_accuracy: 0.6471\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6152 - accuracy: 0.6650 - val_loss: 0.6540 - val_accuracy: 0.6667\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6218 - accuracy: 0.6600 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6173 - accuracy: 0.6800 - val_loss: 0.6823 - val_accuracy: 0.6471\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6189 - accuracy: 0.6750 - val_loss: 0.6498 - val_accuracy: 0.6863\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6144 - accuracy: 0.6850 - val_loss: 0.6504 - val_accuracy: 0.6667\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6250 - accuracy: 0.6600 - val_loss: 0.6503 - val_accuracy: 0.6471\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6154 - accuracy: 0.6750 - val_loss: 0.6672 - val_accuracy: 0.6667\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6145 - accuracy: 0.6600 - val_loss: 0.6581 - val_accuracy: 0.6667\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6137 - accuracy: 0.6800 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6130 - accuracy: 0.6750 - val_loss: 0.6825 - val_accuracy: 0.6667\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6097 - accuracy: 0.6850 - val_loss: 0.6495 - val_accuracy: 0.6471\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5986 - accuracy: 0.6900 - val_loss: 0.6652 - val_accuracy: 0.6667\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6182 - accuracy: 0.6800 - val_loss: 0.6814 - val_accuracy: 0.6275\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6082 - accuracy: 0.6900 - val_loss: 0.6440 - val_accuracy: 0.6471\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6050 - accuracy: 0.6850 - val_loss: 0.6601 - val_accuracy: 0.6863\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5992 - accuracy: 0.6950 - val_loss: 0.6416 - val_accuracy: 0.7059\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5977 - accuracy: 0.7000 - val_loss: 0.6554 - val_accuracy: 0.6863\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5924 - accuracy: 0.7000 - val_loss: 0.6494 - val_accuracy: 0.6667\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6199 - accuracy: 0.6800 - val_loss: 0.6492 - val_accuracy: 0.6863\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6129 - accuracy: 0.6800 - val_loss: 0.6437 - val_accuracy: 0.6471\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6163 - accuracy: 0.6600 - val_loss: 0.6329 - val_accuracy: 0.7059\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5970 - accuracy: 0.7000 - val_loss: 0.6547 - val_accuracy: 0.6667\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5998 - accuracy: 0.6800 - val_loss: 0.6433 - val_accuracy: 0.7059\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5982 - accuracy: 0.7000 - val_loss: 0.6485 - val_accuracy: 0.7059\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5917 - accuracy: 0.7200 - val_loss: 0.6470 - val_accuracy: 0.6667\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6004 - accuracy: 0.7000 - val_loss: 0.6521 - val_accuracy: 0.6863\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.6550 - val_loss: 0.6474 - val_accuracy: 0.6667\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6096 - accuracy: 0.6650 - val_loss: 0.6420 - val_accuracy: 0.5882\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5998 - accuracy: 0.6650 - val_loss: 0.6574 - val_accuracy: 0.6863\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.6650 - val_loss: 0.6775 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "q9VW_1RycyHm",
        "outputId": "4a94cc85-1c88-4710-8a52-250b9ff939a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 34ms/step - loss: 0.7038 - accuracy: 0.5550 - val_loss: 0.6869 - val_accuracy: 0.5294\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6845 - accuracy: 0.6400 - val_loss: 0.6820 - val_accuracy: 0.5490\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6679 - accuracy: 0.6200 - val_loss: 0.6662 - val_accuracy: 0.5686\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6550 - accuracy: 0.6300 - val_loss: 0.6609 - val_accuracy: 0.6078\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6367 - accuracy: 0.6700 - val_loss: 0.6664 - val_accuracy: 0.5882\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6322 - accuracy: 0.6700 - val_loss: 0.6739 - val_accuracy: 0.6078\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6337 - accuracy: 0.6600 - val_loss: 0.6815 - val_accuracy: 0.5882\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.6650 - val_loss: 0.6709 - val_accuracy: 0.6471\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6253 - accuracy: 0.6450 - val_loss: 0.6663 - val_accuracy: 0.6471\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.6650 - val_loss: 0.6584 - val_accuracy: 0.6667\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6448 - accuracy: 0.6200 - val_loss: 0.6583 - val_accuracy: 0.6667\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6247 - accuracy: 0.6800 - val_loss: 0.6656 - val_accuracy: 0.6471\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6287 - accuracy: 0.6550 - val_loss: 0.6549 - val_accuracy: 0.6275\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6221 - accuracy: 0.6550 - val_loss: 0.6721 - val_accuracy: 0.6471\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.6450 - val_loss: 0.6533 - val_accuracy: 0.6275\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6281 - accuracy: 0.6550 - val_loss: 0.6508 - val_accuracy: 0.6275\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6209 - accuracy: 0.6700 - val_loss: 0.6622 - val_accuracy: 0.6471\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6170 - accuracy: 0.6550 - val_loss: 0.6494 - val_accuracy: 0.6667\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6182 - accuracy: 0.6850 - val_loss: 0.6618 - val_accuracy: 0.6471\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6188 - accuracy: 0.6600 - val_loss: 0.6629 - val_accuracy: 0.6471\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6118 - accuracy: 0.6550 - val_loss: 0.6463 - val_accuracy: 0.6471\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6182 - accuracy: 0.6750 - val_loss: 0.6632 - val_accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.6400 - val_loss: 0.6503 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.6750 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.6500 - val_loss: 0.6491 - val_accuracy: 0.6667\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6248 - accuracy: 0.6500 - val_loss: 0.6387 - val_accuracy: 0.6275\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6107 - accuracy: 0.6800 - val_loss: 0.6660 - val_accuracy: 0.6667\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6103 - accuracy: 0.6700 - val_loss: 0.6452 - val_accuracy: 0.6863\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6161 - accuracy: 0.6800 - val_loss: 0.6403 - val_accuracy: 0.6863\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6159 - accuracy: 0.6750 - val_loss: 0.6750 - val_accuracy: 0.6275\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6125 - accuracy: 0.6600 - val_loss: 0.6443 - val_accuracy: 0.6667\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6010 - accuracy: 0.6950 - val_loss: 0.6582 - val_accuracy: 0.6667\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6107 - accuracy: 0.6850 - val_loss: 0.6441 - val_accuracy: 0.7059\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6020 - accuracy: 0.7000 - val_loss: 0.6463 - val_accuracy: 0.7059\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6005 - accuracy: 0.7000 - val_loss: 0.6355 - val_accuracy: 0.6667\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6062 - accuracy: 0.6900 - val_loss: 0.6309 - val_accuracy: 0.6863\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5974 - accuracy: 0.6850 - val_loss: 0.6460 - val_accuracy: 0.6863\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5914 - accuracy: 0.7150 - val_loss: 0.6306 - val_accuracy: 0.6863\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6124 - accuracy: 0.6750 - val_loss: 0.6457 - val_accuracy: 0.6863\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5968 - accuracy: 0.7050 - val_loss: 0.6503 - val_accuracy: 0.6667\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.6900 - val_loss: 0.6467 - val_accuracy: 0.6667\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5916 - accuracy: 0.6900 - val_loss: 0.6481 - val_accuracy: 0.6667\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5992 - accuracy: 0.6950 - val_loss: 0.6416 - val_accuracy: 0.6863\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6044 - accuracy: 0.6900 - val_loss: 0.6707 - val_accuracy: 0.6275\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5882 - accuracy: 0.7050 - val_loss: 0.6416 - val_accuracy: 0.7255\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6022 - accuracy: 0.6800 - val_loss: 0.6595 - val_accuracy: 0.6275\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6096 - accuracy: 0.6750 - val_loss: 0.6443 - val_accuracy: 0.6667\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6244 - accuracy: 0.6600 - val_loss: 0.6403 - val_accuracy: 0.7255\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5951 - accuracy: 0.7200 - val_loss: 0.6594 - val_accuracy: 0.6471\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5984 - accuracy: 0.6950 - val_loss: 0.6416 - val_accuracy: 0.7059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "2tsjSDV7eP3u",
        "outputId": "6306c9bf-ece5-47ff-8703-8dcffd02b09d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 29ms/step - loss: 0.7038 - accuracy: 0.5450 - val_loss: 0.6856 - val_accuracy: 0.5882\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6773 - accuracy: 0.5900 - val_loss: 0.6808 - val_accuracy: 0.5294\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6512 - accuracy: 0.6350 - val_loss: 0.6791 - val_accuracy: 0.5686\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6436 - accuracy: 0.6800 - val_loss: 0.6646 - val_accuracy: 0.6275\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6294 - accuracy: 0.6700 - val_loss: 0.6697 - val_accuracy: 0.6471\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6256 - accuracy: 0.6700 - val_loss: 0.6694 - val_accuracy: 0.6275\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6343 - accuracy: 0.6750 - val_loss: 0.6901 - val_accuracy: 0.6078\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.6450 - val_loss: 0.6641 - val_accuracy: 0.6275\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6256 - accuracy: 0.6550 - val_loss: 0.6686 - val_accuracy: 0.6471\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6323 - accuracy: 0.6650 - val_loss: 0.6685 - val_accuracy: 0.6078\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6517 - accuracy: 0.6150 - val_loss: 0.6718 - val_accuracy: 0.5490\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6314 - accuracy: 0.6150 - val_loss: 0.6794 - val_accuracy: 0.6275\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6256 - accuracy: 0.6850 - val_loss: 0.6917 - val_accuracy: 0.6471\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6719 - val_accuracy: 0.6275\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6168 - accuracy: 0.6750 - val_loss: 0.6655 - val_accuracy: 0.6667\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6255 - accuracy: 0.6700 - val_loss: 0.6533 - val_accuracy: 0.6275\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6195 - accuracy: 0.6750 - val_loss: 0.6556 - val_accuracy: 0.6667\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.6800 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.6650 - val_loss: 0.6750 - val_accuracy: 0.6667\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6306 - accuracy: 0.6600 - val_loss: 0.6476 - val_accuracy: 0.6667\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6162 - accuracy: 0.6850 - val_loss: 0.6470 - val_accuracy: 0.6667\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6200 - accuracy: 0.6450 - val_loss: 0.6553 - val_accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6203 - accuracy: 0.6850 - val_loss: 0.6766 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6158 - accuracy: 0.6800 - val_loss: 0.6715 - val_accuracy: 0.6471\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6321 - accuracy: 0.6450 - val_loss: 0.6665 - val_accuracy: 0.6471\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6364 - accuracy: 0.6350 - val_loss: 0.6582 - val_accuracy: 0.6471\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6180 - accuracy: 0.6650 - val_loss: 0.6636 - val_accuracy: 0.6471\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6301 - accuracy: 0.6550 - val_loss: 0.6493 - val_accuracy: 0.6471\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6332 - accuracy: 0.6300 - val_loss: 0.6568 - val_accuracy: 0.6471\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6352 - accuracy: 0.6500 - val_loss: 0.6661 - val_accuracy: 0.6863\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6288 - accuracy: 0.6350 - val_loss: 0.6642 - val_accuracy: 0.5686\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6370 - accuracy: 0.6150 - val_loss: 0.6634 - val_accuracy: 0.5686\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6313 - accuracy: 0.6150 - val_loss: 0.7039 - val_accuracy: 0.6471\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6400 - accuracy: 0.6550 - val_loss: 0.7025 - val_accuracy: 0.6275\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6183 - accuracy: 0.6800 - val_loss: 0.6579 - val_accuracy: 0.6275\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.6650 - val_loss: 0.6243 - val_accuracy: 0.6471\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6224 - accuracy: 0.6800 - val_loss: 0.6303 - val_accuracy: 0.6667\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6139 - accuracy: 0.6500 - val_loss: 0.6417 - val_accuracy: 0.6471\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.6550 - val_loss: 0.6542 - val_accuracy: 0.6667\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6120 - accuracy: 0.6650 - val_loss: 0.6371 - val_accuracy: 0.6863\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6229 - accuracy: 0.6650 - val_loss: 0.6210 - val_accuracy: 0.6667\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6121 - accuracy: 0.6750 - val_loss: 0.6446 - val_accuracy: 0.6863\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6132 - accuracy: 0.6850 - val_loss: 0.6553 - val_accuracy: 0.6667\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6228 - accuracy: 0.6750 - val_loss: 0.6622 - val_accuracy: 0.6667\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6111 - accuracy: 0.6950 - val_loss: 0.6460 - val_accuracy: 0.6471\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6179 - accuracy: 0.6650 - val_loss: 0.6392 - val_accuracy: 0.6863\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6155 - accuracy: 0.6700 - val_loss: 0.6518 - val_accuracy: 0.6667\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.6600 - val_loss: 0.6659 - val_accuracy: 0.6275\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6113 - accuracy: 0.7000 - val_loss: 0.6860 - val_accuracy: 0.6863\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6204 - accuracy: 0.6600 - val_loss: 0.6552 - val_accuracy: 0.6471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "6x7NFRwFeVwx",
        "outputId": "d2a4482b-87e2-401e-c60d-8a9100e04ca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 31ms/step - loss: 0.6845 - accuracy: 0.5950 - val_loss: 0.6786 - val_accuracy: 0.5882\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.6150 - val_loss: 0.6751 - val_accuracy: 0.5686\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6747 - accuracy: 0.6050 - val_loss: 0.6712 - val_accuracy: 0.5882\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6710 - accuracy: 0.6000 - val_loss: 0.6661 - val_accuracy: 0.5490\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6670 - accuracy: 0.6150 - val_loss: 0.6630 - val_accuracy: 0.5686\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6629 - accuracy: 0.6150 - val_loss: 0.6608 - val_accuracy: 0.5686\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6600 - accuracy: 0.6200 - val_loss: 0.6597 - val_accuracy: 0.5686\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6555 - accuracy: 0.6300 - val_loss: 0.6590 - val_accuracy: 0.5490\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6523 - accuracy: 0.6550 - val_loss: 0.6568 - val_accuracy: 0.6078\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6505 - accuracy: 0.6700 - val_loss: 0.6525 - val_accuracy: 0.6471\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6519 - accuracy: 0.6050 - val_loss: 0.6502 - val_accuracy: 0.5686\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6456 - accuracy: 0.6350 - val_loss: 0.6498 - val_accuracy: 0.6275\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6426 - accuracy: 0.6650 - val_loss: 0.6521 - val_accuracy: 0.6667\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6412 - accuracy: 0.6700 - val_loss: 0.6542 - val_accuracy: 0.6471\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6550 - val_loss: 0.6534 - val_accuracy: 0.6471\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6397 - accuracy: 0.6650 - val_loss: 0.6524 - val_accuracy: 0.6078\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6377 - accuracy: 0.6800 - val_loss: 0.6535 - val_accuracy: 0.6667\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6363 - accuracy: 0.6750 - val_loss: 0.6533 - val_accuracy: 0.6667\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6362 - accuracy: 0.6750 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6358 - accuracy: 0.6650 - val_loss: 0.6542 - val_accuracy: 0.6471\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6357 - accuracy: 0.6600 - val_loss: 0.6565 - val_accuracy: 0.6275\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6333 - accuracy: 0.6500 - val_loss: 0.6530 - val_accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6320 - accuracy: 0.6700 - val_loss: 0.6556 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6368 - accuracy: 0.6450 - val_loss: 0.6602 - val_accuracy: 0.6471\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6313 - accuracy: 0.6500 - val_loss: 0.6566 - val_accuracy: 0.6667\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6318 - accuracy: 0.6650 - val_loss: 0.6521 - val_accuracy: 0.6471\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.6500 - val_loss: 0.6511 - val_accuracy: 0.6275\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6298 - accuracy: 0.6450 - val_loss: 0.6546 - val_accuracy: 0.6471\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6295 - accuracy: 0.6550 - val_loss: 0.6547 - val_accuracy: 0.6471\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6306 - accuracy: 0.6600 - val_loss: 0.6518 - val_accuracy: 0.6471\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6290 - accuracy: 0.6600 - val_loss: 0.6486 - val_accuracy: 0.6667\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6258 - accuracy: 0.6550 - val_loss: 0.6494 - val_accuracy: 0.6667\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6268 - accuracy: 0.6550 - val_loss: 0.6472 - val_accuracy: 0.6667\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6267 - accuracy: 0.6600 - val_loss: 0.6429 - val_accuracy: 0.6667\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6255 - accuracy: 0.6600 - val_loss: 0.6436 - val_accuracy: 0.6667\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6234 - accuracy: 0.6750 - val_loss: 0.6368 - val_accuracy: 0.6667\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6232 - accuracy: 0.6700 - val_loss: 0.6353 - val_accuracy: 0.6667\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6223 - accuracy: 0.6800 - val_loss: 0.6348 - val_accuracy: 0.6667\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6226 - accuracy: 0.6500 - val_loss: 0.6307 - val_accuracy: 0.6863\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6269 - accuracy: 0.6350 - val_loss: 0.6317 - val_accuracy: 0.7255\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6234 - accuracy: 0.6600 - val_loss: 0.6322 - val_accuracy: 0.6667\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6194 - accuracy: 0.6750 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6220 - accuracy: 0.6550 - val_loss: 0.6412 - val_accuracy: 0.6667\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.6550 - val_loss: 0.6441 - val_accuracy: 0.6667\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.6600 - val_loss: 0.6330 - val_accuracy: 0.6863\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6201 - accuracy: 0.6700 - val_loss: 0.6304 - val_accuracy: 0.6863\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6200 - accuracy: 0.6600 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.6600 - val_loss: 0.6291 - val_accuracy: 0.6863\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6208 - accuracy: 0.6500 - val_loss: 0.6271 - val_accuracy: 0.6863\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.6700 - val_loss: 0.6294 - val_accuracy: 0.6863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "9uRfoFpYeXtB",
        "outputId": "7c363580-bddc-4dbc-fd87-be5ceb1902b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 28ms/step - loss: 0.7001 - accuracy: 0.5100 - val_loss: 0.6893 - val_accuracy: 0.5294\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6850 - accuracy: 0.5050 - val_loss: 0.6798 - val_accuracy: 0.5490\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6778 - accuracy: 0.6050 - val_loss: 0.6730 - val_accuracy: 0.5882\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6702 - accuracy: 0.6150 - val_loss: 0.6649 - val_accuracy: 0.5686\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6615 - accuracy: 0.6200 - val_loss: 0.6590 - val_accuracy: 0.5686\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6516 - accuracy: 0.6200 - val_loss: 0.6552 - val_accuracy: 0.5490\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6250 - val_loss: 0.6591 - val_accuracy: 0.6471\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.6600 - val_loss: 0.6629 - val_accuracy: 0.6275\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6330 - accuracy: 0.6450 - val_loss: 0.6631 - val_accuracy: 0.6471\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6321 - accuracy: 0.6700 - val_loss: 0.6646 - val_accuracy: 0.6471\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6426 - accuracy: 0.6300 - val_loss: 0.6656 - val_accuracy: 0.5686\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6284 - accuracy: 0.6700 - val_loss: 0.6722 - val_accuracy: 0.6471\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6266 - accuracy: 0.6650 - val_loss: 0.6710 - val_accuracy: 0.6275\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6247 - accuracy: 0.6850 - val_loss: 0.6746 - val_accuracy: 0.6471\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6231 - accuracy: 0.6700 - val_loss: 0.6732 - val_accuracy: 0.6275\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6243 - accuracy: 0.6750 - val_loss: 0.6669 - val_accuracy: 0.5882\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6238 - accuracy: 0.6800 - val_loss: 0.6705 - val_accuracy: 0.6471\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6194 - accuracy: 0.6650 - val_loss: 0.6680 - val_accuracy: 0.6471\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6193 - accuracy: 0.6550 - val_loss: 0.6647 - val_accuracy: 0.6667\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6187 - accuracy: 0.6550 - val_loss: 0.6777 - val_accuracy: 0.6471\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.6500 - val_loss: 0.6755 - val_accuracy: 0.6471\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6189 - accuracy: 0.6500 - val_loss: 0.6656 - val_accuracy: 0.6275\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6135 - accuracy: 0.6800 - val_loss: 0.6866 - val_accuracy: 0.6275\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6241 - accuracy: 0.6600 - val_loss: 0.6773 - val_accuracy: 0.6471\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6132 - accuracy: 0.6600 - val_loss: 0.6690 - val_accuracy: 0.5882\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6269 - accuracy: 0.6150 - val_loss: 0.6640 - val_accuracy: 0.6078\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6123 - accuracy: 0.6850 - val_loss: 0.6742 - val_accuracy: 0.6667\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6170 - accuracy: 0.6650 - val_loss: 0.6795 - val_accuracy: 0.6471\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6141 - accuracy: 0.6850 - val_loss: 0.6620 - val_accuracy: 0.6078\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6120 - accuracy: 0.6800 - val_loss: 0.6742 - val_accuracy: 0.6667\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6100 - accuracy: 0.6800 - val_loss: 0.6657 - val_accuracy: 0.6863\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6057 - accuracy: 0.6950 - val_loss: 0.6703 - val_accuracy: 0.6667\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6063 - accuracy: 0.6750 - val_loss: 0.6718 - val_accuracy: 0.6667\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6040 - accuracy: 0.7000 - val_loss: 0.6730 - val_accuracy: 0.6275\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6041 - accuracy: 0.6950 - val_loss: 0.6774 - val_accuracy: 0.6471\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6033 - accuracy: 0.6800 - val_loss: 0.6613 - val_accuracy: 0.5882\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6038 - accuracy: 0.6750 - val_loss: 0.6710 - val_accuracy: 0.6667\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5971 - accuracy: 0.7050 - val_loss: 0.6574 - val_accuracy: 0.6667\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6058 - accuracy: 0.6700 - val_loss: 0.6533 - val_accuracy: 0.7059\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.6900 - val_loss: 0.6685 - val_accuracy: 0.6863\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5993 - accuracy: 0.7050 - val_loss: 0.6707 - val_accuracy: 0.6667\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5936 - accuracy: 0.7100 - val_loss: 0.6669 - val_accuracy: 0.7059\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5941 - accuracy: 0.7250 - val_loss: 0.6715 - val_accuracy: 0.6667\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 0.7200 - val_loss: 0.6729 - val_accuracy: 0.6667\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5855 - accuracy: 0.7100 - val_loss: 0.6497 - val_accuracy: 0.6863\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5924 - accuracy: 0.6850 - val_loss: 0.6582 - val_accuracy: 0.6863\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5899 - accuracy: 0.7150 - val_loss: 0.6755 - val_accuracy: 0.6667\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.7100 - val_loss: 0.6618 - val_accuracy: 0.6471\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5891 - accuracy: 0.7000 - val_loss: 0.6728 - val_accuracy: 0.6667\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5796 - accuracy: 0.7350 - val_loss: 0.6901 - val_accuracy: 0.6275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "aGjeYTd4eZ7x",
        "outputId": "e860b05e-331f-4da2-c08e-6855eb35deca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 36ms/step - loss: 0.7011 - accuracy: 0.4900 - val_loss: 0.6857 - val_accuracy: 0.5686\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6849 - accuracy: 0.6050 - val_loss: 0.6775 - val_accuracy: 0.5686\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6760 - accuracy: 0.6200 - val_loss: 0.6724 - val_accuracy: 0.5686\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6670 - accuracy: 0.6150 - val_loss: 0.6654 - val_accuracy: 0.5686\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6563 - accuracy: 0.6300 - val_loss: 0.6624 - val_accuracy: 0.5686\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6450 - accuracy: 0.6300 - val_loss: 0.6605 - val_accuracy: 0.5686\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6399 - accuracy: 0.6450 - val_loss: 0.6692 - val_accuracy: 0.6275\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6327 - accuracy: 0.6650 - val_loss: 0.6681 - val_accuracy: 0.5882\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.6950 - val_loss: 0.6692 - val_accuracy: 0.6275\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.6600 - val_loss: 0.6721 - val_accuracy: 0.6275\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6397 - accuracy: 0.6200 - val_loss: 0.6711 - val_accuracy: 0.5882\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6223 - accuracy: 0.6700 - val_loss: 0.6801 - val_accuracy: 0.6471\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6188 - accuracy: 0.6750 - val_loss: 0.6737 - val_accuracy: 0.6078\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6800 - val_loss: 0.6790 - val_accuracy: 0.6471\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6124 - accuracy: 0.6750 - val_loss: 0.6723 - val_accuracy: 0.6078\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6127 - accuracy: 0.6850 - val_loss: 0.6684 - val_accuracy: 0.5882\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6116 - accuracy: 0.6950 - val_loss: 0.6839 - val_accuracy: 0.6471\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6056 - accuracy: 0.6900 - val_loss: 0.6729 - val_accuracy: 0.6078\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6058 - accuracy: 0.7000 - val_loss: 0.6810 - val_accuracy: 0.6275\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.6950 - val_loss: 0.6874 - val_accuracy: 0.6275\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.6700 - val_loss: 0.6752 - val_accuracy: 0.6471\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6062 - accuracy: 0.6700 - val_loss: 0.6684 - val_accuracy: 0.6078\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5962 - accuracy: 0.6950 - val_loss: 0.6963 - val_accuracy: 0.6078\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6041 - accuracy: 0.6800 - val_loss: 0.6717 - val_accuracy: 0.6275\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5977 - accuracy: 0.6850 - val_loss: 0.6672 - val_accuracy: 0.6471\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.6800 - val_loss: 0.6619 - val_accuracy: 0.6275\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6025 - accuracy: 0.6700 - val_loss: 0.6780 - val_accuracy: 0.6471\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.6850 - val_loss: 0.6854 - val_accuracy: 0.6471\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5980 - accuracy: 0.7050 - val_loss: 0.6592 - val_accuracy: 0.6471\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5951 - accuracy: 0.7200 - val_loss: 0.6868 - val_accuracy: 0.6078\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5936 - accuracy: 0.7050 - val_loss: 0.6681 - val_accuracy: 0.6275\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5848 - accuracy: 0.7050 - val_loss: 0.6797 - val_accuracy: 0.6471\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6083 - accuracy: 0.7000 - val_loss: 0.6825 - val_accuracy: 0.6275\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5928 - accuracy: 0.7000 - val_loss: 0.6607 - val_accuracy: 0.6275\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5952 - accuracy: 0.6850 - val_loss: 0.6686 - val_accuracy: 0.6667\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5856 - accuracy: 0.7050 - val_loss: 0.6535 - val_accuracy: 0.6471\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5822 - accuracy: 0.7200 - val_loss: 0.6754 - val_accuracy: 0.6275\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5821 - accuracy: 0.6950 - val_loss: 0.6603 - val_accuracy: 0.6275\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5986 - accuracy: 0.6950 - val_loss: 0.6591 - val_accuracy: 0.6471\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5923 - accuracy: 0.7100 - val_loss: 0.6594 - val_accuracy: 0.6471\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5993 - accuracy: 0.7200 - val_loss: 0.6689 - val_accuracy: 0.6667\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5833 - accuracy: 0.7300 - val_loss: 0.6533 - val_accuracy: 0.6275\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5905 - accuracy: 0.6950 - val_loss: 0.6592 - val_accuracy: 0.6471\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5888 - accuracy: 0.7000 - val_loss: 0.6656 - val_accuracy: 0.6275\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5794 - accuracy: 0.7100 - val_loss: 0.6481 - val_accuracy: 0.6863\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5872 - accuracy: 0.7050 - val_loss: 0.6509 - val_accuracy: 0.6471\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5843 - accuracy: 0.6900 - val_loss: 0.6656 - val_accuracy: 0.6078\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5832 - accuracy: 0.7050 - val_loss: 0.6459 - val_accuracy: 0.6667\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.7100 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5760 - accuracy: 0.7400 - val_loss: 0.6857 - val_accuracy: 0.6471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "h_ByrY0Cecaw",
        "outputId": "97906865-146f-42c8-c089-d2c0de19e23f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 31ms/step - loss: 0.6828 - accuracy: 0.5500 - val_loss: 0.6787 - val_accuracy: 0.5686\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5700 - val_loss: 0.6786 - val_accuracy: 0.5490\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.5850 - val_loss: 0.6783 - val_accuracy: 0.5490\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6815 - accuracy: 0.5750 - val_loss: 0.6780 - val_accuracy: 0.5490\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6811 - accuracy: 0.5750 - val_loss: 0.6776 - val_accuracy: 0.5490\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6807 - accuracy: 0.5800 - val_loss: 0.6772 - val_accuracy: 0.5490\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6805 - accuracy: 0.5800 - val_loss: 0.6769 - val_accuracy: 0.5490\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.5800 - val_loss: 0.6767 - val_accuracy: 0.5294\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6797 - accuracy: 0.6000 - val_loss: 0.6765 - val_accuracy: 0.5098\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.6200 - val_loss: 0.6763 - val_accuracy: 0.5686\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.6150 - val_loss: 0.6759 - val_accuracy: 0.5686\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6785 - accuracy: 0.6150 - val_loss: 0.6756 - val_accuracy: 0.5686\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.6100 - val_loss: 0.6752 - val_accuracy: 0.5686\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6778 - accuracy: 0.6100 - val_loss: 0.6749 - val_accuracy: 0.5686\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.6000 - val_loss: 0.6745 - val_accuracy: 0.5686\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6771 - accuracy: 0.6000 - val_loss: 0.6741 - val_accuracy: 0.5686\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.6050 - val_loss: 0.6737 - val_accuracy: 0.5686\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.6000 - val_loss: 0.6734 - val_accuracy: 0.5686\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6758 - accuracy: 0.6000 - val_loss: 0.6729 - val_accuracy: 0.5686\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6753 - accuracy: 0.6000 - val_loss: 0.6726 - val_accuracy: 0.5686\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6750 - accuracy: 0.6000 - val_loss: 0.6724 - val_accuracy: 0.5882\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6745 - accuracy: 0.6050 - val_loss: 0.6720 - val_accuracy: 0.5882\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6740 - accuracy: 0.6050 - val_loss: 0.6718 - val_accuracy: 0.5686\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6738 - accuracy: 0.6150 - val_loss: 0.6716 - val_accuracy: 0.5686\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6733 - accuracy: 0.6150 - val_loss: 0.6713 - val_accuracy: 0.5686\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.6200 - val_loss: 0.6708 - val_accuracy: 0.5686\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.6150 - val_loss: 0.6703 - val_accuracy: 0.5686\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6718 - accuracy: 0.6200 - val_loss: 0.6700 - val_accuracy: 0.5686\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6713 - accuracy: 0.6200 - val_loss: 0.6697 - val_accuracy: 0.5686\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6709 - accuracy: 0.6200 - val_loss: 0.6695 - val_accuracy: 0.5686\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6704 - accuracy: 0.6200 - val_loss: 0.6693 - val_accuracy: 0.5686\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6700 - accuracy: 0.6200 - val_loss: 0.6691 - val_accuracy: 0.5686\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6697 - accuracy: 0.6200 - val_loss: 0.6687 - val_accuracy: 0.5686\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6693 - accuracy: 0.6200 - val_loss: 0.6683 - val_accuracy: 0.5686\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6689 - accuracy: 0.6200 - val_loss: 0.6681 - val_accuracy: 0.5686\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6684 - accuracy: 0.6200 - val_loss: 0.6678 - val_accuracy: 0.5686\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6680 - accuracy: 0.6200 - val_loss: 0.6673 - val_accuracy: 0.5686\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6675 - accuracy: 0.6200 - val_loss: 0.6668 - val_accuracy: 0.5686\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6669 - accuracy: 0.6200 - val_loss: 0.6662 - val_accuracy: 0.5686\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6667 - accuracy: 0.6200 - val_loss: 0.6656 - val_accuracy: 0.5686\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6661 - accuracy: 0.6200 - val_loss: 0.6649 - val_accuracy: 0.5686\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6660 - accuracy: 0.6200 - val_loss: 0.6644 - val_accuracy: 0.5686\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6653 - accuracy: 0.6200 - val_loss: 0.6644 - val_accuracy: 0.5686\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6648 - accuracy: 0.6200 - val_loss: 0.6643 - val_accuracy: 0.5686\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6643 - accuracy: 0.6200 - val_loss: 0.6639 - val_accuracy: 0.5686\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6639 - accuracy: 0.6200 - val_loss: 0.6634 - val_accuracy: 0.5686\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6635 - accuracy: 0.6150 - val_loss: 0.6632 - val_accuracy: 0.5686\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6631 - accuracy: 0.6150 - val_loss: 0.6625 - val_accuracy: 0.5686\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6627 - accuracy: 0.6200 - val_loss: 0.6622 - val_accuracy: 0.5686\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6625 - accuracy: 0.6200 - val_loss: 0.6617 - val_accuracy: 0.5686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "6iqdazWeefng",
        "outputId": "17fe0823-47ef-4e4b-f139-2bcb5d344fcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 28ms/step - loss: 0.7001 - accuracy: 0.5050 - val_loss: 0.7032 - val_accuracy: 0.4706\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.4550 - val_loss: 0.7003 - val_accuracy: 0.4510\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.4200 - val_loss: 0.6976 - val_accuracy: 0.4510\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6939 - accuracy: 0.4650 - val_loss: 0.6951 - val_accuracy: 0.4118\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.4500 - val_loss: 0.6929 - val_accuracy: 0.5294\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.4950 - val_loss: 0.6907 - val_accuracy: 0.5294\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6893 - accuracy: 0.4950 - val_loss: 0.6888 - val_accuracy: 0.5294\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.4950 - val_loss: 0.6869 - val_accuracy: 0.5294\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6866 - accuracy: 0.4950 - val_loss: 0.6853 - val_accuracy: 0.5294\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.5350 - val_loss: 0.6843 - val_accuracy: 0.5490\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6847 - accuracy: 0.5750 - val_loss: 0.6826 - val_accuracy: 0.5490\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6830 - accuracy: 0.5800 - val_loss: 0.6812 - val_accuracy: 0.5490\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6821 - accuracy: 0.5850 - val_loss: 0.6798 - val_accuracy: 0.5490\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6808 - accuracy: 0.5950 - val_loss: 0.6787 - val_accuracy: 0.5294\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.6100 - val_loss: 0.6776 - val_accuracy: 0.5686\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6790 - accuracy: 0.6150 - val_loss: 0.6761 - val_accuracy: 0.5686\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6775 - accuracy: 0.6150 - val_loss: 0.6751 - val_accuracy: 0.5882\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.6150 - val_loss: 0.6740 - val_accuracy: 0.5882\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6755 - accuracy: 0.6050 - val_loss: 0.6727 - val_accuracy: 0.5882\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6743 - accuracy: 0.6100 - val_loss: 0.6720 - val_accuracy: 0.5686\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6733 - accuracy: 0.6100 - val_loss: 0.6719 - val_accuracy: 0.5490\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6200 - val_loss: 0.6710 - val_accuracy: 0.5686\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6710 - accuracy: 0.6200 - val_loss: 0.6703 - val_accuracy: 0.5686\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6702 - accuracy: 0.6250 - val_loss: 0.6702 - val_accuracy: 0.5686\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6691 - accuracy: 0.6200 - val_loss: 0.6694 - val_accuracy: 0.5686\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6675 - accuracy: 0.6200 - val_loss: 0.6679 - val_accuracy: 0.5686\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6666 - accuracy: 0.6200 - val_loss: 0.6666 - val_accuracy: 0.5686\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6651 - accuracy: 0.6200 - val_loss: 0.6659 - val_accuracy: 0.5686\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6638 - accuracy: 0.6200 - val_loss: 0.6656 - val_accuracy: 0.5686\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6627 - accuracy: 0.6300 - val_loss: 0.6655 - val_accuracy: 0.5686\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6615 - accuracy: 0.6300 - val_loss: 0.6651 - val_accuracy: 0.5686\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6603 - accuracy: 0.6250 - val_loss: 0.6648 - val_accuracy: 0.5686\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6595 - accuracy: 0.6250 - val_loss: 0.6635 - val_accuracy: 0.5686\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6582 - accuracy: 0.6250 - val_loss: 0.6623 - val_accuracy: 0.5686\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6569 - accuracy: 0.6250 - val_loss: 0.6620 - val_accuracy: 0.5686\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6556 - accuracy: 0.6250 - val_loss: 0.6613 - val_accuracy: 0.5686\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6544 - accuracy: 0.6250 - val_loss: 0.6603 - val_accuracy: 0.5686\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6530 - accuracy: 0.6250 - val_loss: 0.6591 - val_accuracy: 0.5686\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6520 - accuracy: 0.6250 - val_loss: 0.6576 - val_accuracy: 0.5686\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.6250 - val_loss: 0.6566 - val_accuracy: 0.5686\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6508 - accuracy: 0.6300 - val_loss: 0.6555 - val_accuracy: 0.5686\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6500 - accuracy: 0.6300 - val_loss: 0.6547 - val_accuracy: 0.5686\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.6250 - val_loss: 0.6549 - val_accuracy: 0.5686\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6472 - accuracy: 0.6300 - val_loss: 0.6562 - val_accuracy: 0.5882\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6462 - accuracy: 0.6450 - val_loss: 0.6554 - val_accuracy: 0.5882\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6451 - accuracy: 0.6500 - val_loss: 0.6542 - val_accuracy: 0.5882\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6443 - accuracy: 0.6400 - val_loss: 0.6540 - val_accuracy: 0.5882\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6435 - accuracy: 0.6350 - val_loss: 0.6527 - val_accuracy: 0.5686\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6429 - accuracy: 0.6300 - val_loss: 0.6520 - val_accuracy: 0.5686\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6430 - accuracy: 0.6250 - val_loss: 0.6513 - val_accuracy: 0.5686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "IwsQafCPeho4",
        "outputId": "9e70f27d-c33c-4d1d-f154-633b477945be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 29ms/step - loss: 0.6983 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.4706\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6944 - accuracy: 0.5300 - val_loss: 0.6897 - val_accuracy: 0.5098\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.5100 - val_loss: 0.6869 - val_accuracy: 0.5490\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6888 - accuracy: 0.5450 - val_loss: 0.6842 - val_accuracy: 0.5490\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6864 - accuracy: 0.5500 - val_loss: 0.6822 - val_accuracy: 0.5686\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.5600 - val_loss: 0.6807 - val_accuracy: 0.5686\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.5650 - val_loss: 0.6801 - val_accuracy: 0.5490\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6810 - accuracy: 0.5950 - val_loss: 0.6795 - val_accuracy: 0.5098\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.6100 - val_loss: 0.6788 - val_accuracy: 0.5686\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.6100 - val_loss: 0.6782 - val_accuracy: 0.5882\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6767 - accuracy: 0.6150 - val_loss: 0.6773 - val_accuracy: 0.5882\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6746 - accuracy: 0.6200 - val_loss: 0.6770 - val_accuracy: 0.5882\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6733 - accuracy: 0.6200 - val_loss: 0.6770 - val_accuracy: 0.5882\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6715 - accuracy: 0.6150 - val_loss: 0.6763 - val_accuracy: 0.5882\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6698 - accuracy: 0.6150 - val_loss: 0.6760 - val_accuracy: 0.5686\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6686 - accuracy: 0.6100 - val_loss: 0.6756 - val_accuracy: 0.5686\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6667 - accuracy: 0.6150 - val_loss: 0.6755 - val_accuracy: 0.5686\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6650 - accuracy: 0.6200 - val_loss: 0.6749 - val_accuracy: 0.5686\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6636 - accuracy: 0.6200 - val_loss: 0.6746 - val_accuracy: 0.5686\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6618 - accuracy: 0.6200 - val_loss: 0.6751 - val_accuracy: 0.5686\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6603 - accuracy: 0.6200 - val_loss: 0.6754 - val_accuracy: 0.5686\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6582 - accuracy: 0.6200 - val_loss: 0.6755 - val_accuracy: 0.5686\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6565 - accuracy: 0.6200 - val_loss: 0.6757 - val_accuracy: 0.5686\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6555 - accuracy: 0.6250 - val_loss: 0.6756 - val_accuracy: 0.5686\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6536 - accuracy: 0.6200 - val_loss: 0.6751 - val_accuracy: 0.5686\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6513 - accuracy: 0.6250 - val_loss: 0.6750 - val_accuracy: 0.5686\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6503 - accuracy: 0.6200 - val_loss: 0.6753 - val_accuracy: 0.5686\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6482 - accuracy: 0.6250 - val_loss: 0.6741 - val_accuracy: 0.5686\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6457 - accuracy: 0.6250 - val_loss: 0.6730 - val_accuracy: 0.5686\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6445 - accuracy: 0.6600 - val_loss: 0.6720 - val_accuracy: 0.5490\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6431 - accuracy: 0.6700 - val_loss: 0.6729 - val_accuracy: 0.5294\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6415 - accuracy: 0.6800 - val_loss: 0.6726 - val_accuracy: 0.5490\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6406 - accuracy: 0.6900 - val_loss: 0.6718 - val_accuracy: 0.5490\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6388 - accuracy: 0.6700 - val_loss: 0.6712 - val_accuracy: 0.5294\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6372 - accuracy: 0.6800 - val_loss: 0.6721 - val_accuracy: 0.5490\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6357 - accuracy: 0.6900 - val_loss: 0.6722 - val_accuracy: 0.5294\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6346 - accuracy: 0.6750 - val_loss: 0.6713 - val_accuracy: 0.5294\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6332 - accuracy: 0.6700 - val_loss: 0.6713 - val_accuracy: 0.5686\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6323 - accuracy: 0.6500 - val_loss: 0.6712 - val_accuracy: 0.5490\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6330 - accuracy: 0.6500 - val_loss: 0.6713 - val_accuracy: 0.5490\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6322 - accuracy: 0.6450 - val_loss: 0.6691 - val_accuracy: 0.5686\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6304 - accuracy: 0.6700 - val_loss: 0.6684 - val_accuracy: 0.5490\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6298 - accuracy: 0.6850 - val_loss: 0.6707 - val_accuracy: 0.5686\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6293 - accuracy: 0.6950 - val_loss: 0.6745 - val_accuracy: 0.6078\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6284 - accuracy: 0.6800 - val_loss: 0.6744 - val_accuracy: 0.5686\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6271 - accuracy: 0.6900 - val_loss: 0.6733 - val_accuracy: 0.5882\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6266 - accuracy: 0.7000 - val_loss: 0.6745 - val_accuracy: 0.5490\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6264 - accuracy: 0.6800 - val_loss: 0.6739 - val_accuracy: 0.5294\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6268 - accuracy: 0.6700 - val_loss: 0.6746 - val_accuracy: 0.5490\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6266 - accuracy: 0.6650 - val_loss: 0.6740 - val_accuracy: 0.5294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3jGW7vHzcyKG"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "en9K52fle0pU",
        "outputId": "0ade69f9-c976-4e0e-d16d-cdc63359fa24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 29ms/step - loss: 0.6828 - accuracy: 0.5500 - val_loss: 0.6787 - val_accuracy: 0.5686\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5700 - val_loss: 0.6786 - val_accuracy: 0.5490\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.5850 - val_loss: 0.6783 - val_accuracy: 0.5490\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6815 - accuracy: 0.5750 - val_loss: 0.6780 - val_accuracy: 0.5490\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6811 - accuracy: 0.5750 - val_loss: 0.6776 - val_accuracy: 0.5490\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6807 - accuracy: 0.5800 - val_loss: 0.6772 - val_accuracy: 0.5490\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6805 - accuracy: 0.5800 - val_loss: 0.6769 - val_accuracy: 0.5490\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.5800 - val_loss: 0.6767 - val_accuracy: 0.5294\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6797 - accuracy: 0.6000 - val_loss: 0.6765 - val_accuracy: 0.5098\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6794 - accuracy: 0.6200 - val_loss: 0.6763 - val_accuracy: 0.5686\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.6150 - val_loss: 0.6759 - val_accuracy: 0.5686\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.6150 - val_loss: 0.6756 - val_accuracy: 0.5686\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.6100 - val_loss: 0.6752 - val_accuracy: 0.5686\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6778 - accuracy: 0.6100 - val_loss: 0.6749 - val_accuracy: 0.5686\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.6000 - val_loss: 0.6745 - val_accuracy: 0.5686\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6771 - accuracy: 0.6000 - val_loss: 0.6741 - val_accuracy: 0.5686\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6765 - accuracy: 0.6050 - val_loss: 0.6737 - val_accuracy: 0.5686\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6761 - accuracy: 0.6000 - val_loss: 0.6734 - val_accuracy: 0.5686\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6758 - accuracy: 0.6000 - val_loss: 0.6729 - val_accuracy: 0.5686\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6753 - accuracy: 0.6000 - val_loss: 0.6726 - val_accuracy: 0.5686\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6750 - accuracy: 0.6000 - val_loss: 0.6724 - val_accuracy: 0.5882\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6745 - accuracy: 0.6050 - val_loss: 0.6720 - val_accuracy: 0.5882\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6740 - accuracy: 0.6050 - val_loss: 0.6718 - val_accuracy: 0.5686\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6738 - accuracy: 0.6150 - val_loss: 0.6716 - val_accuracy: 0.5686\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6733 - accuracy: 0.6150 - val_loss: 0.6713 - val_accuracy: 0.5686\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.6200 - val_loss: 0.6708 - val_accuracy: 0.5686\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6723 - accuracy: 0.6150 - val_loss: 0.6703 - val_accuracy: 0.5686\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6718 - accuracy: 0.6200 - val_loss: 0.6700 - val_accuracy: 0.5686\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6713 - accuracy: 0.6200 - val_loss: 0.6697 - val_accuracy: 0.5686\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6709 - accuracy: 0.6200 - val_loss: 0.6695 - val_accuracy: 0.5686\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6704 - accuracy: 0.6200 - val_loss: 0.6693 - val_accuracy: 0.5686\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6700 - accuracy: 0.6200 - val_loss: 0.6691 - val_accuracy: 0.5686\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6697 - accuracy: 0.6200 - val_loss: 0.6687 - val_accuracy: 0.5686\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6693 - accuracy: 0.6200 - val_loss: 0.6683 - val_accuracy: 0.5686\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6689 - accuracy: 0.6200 - val_loss: 0.6681 - val_accuracy: 0.5686\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6684 - accuracy: 0.6200 - val_loss: 0.6678 - val_accuracy: 0.5686\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6680 - accuracy: 0.6200 - val_loss: 0.6673 - val_accuracy: 0.5686\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6675 - accuracy: 0.6200 - val_loss: 0.6668 - val_accuracy: 0.5686\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6669 - accuracy: 0.6200 - val_loss: 0.6662 - val_accuracy: 0.5686\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6667 - accuracy: 0.6200 - val_loss: 0.6656 - val_accuracy: 0.5686\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6661 - accuracy: 0.6200 - val_loss: 0.6649 - val_accuracy: 0.5686\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6660 - accuracy: 0.6200 - val_loss: 0.6644 - val_accuracy: 0.5686\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6653 - accuracy: 0.6200 - val_loss: 0.6644 - val_accuracy: 0.5686\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6648 - accuracy: 0.6200 - val_loss: 0.6643 - val_accuracy: 0.5686\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6643 - accuracy: 0.6200 - val_loss: 0.6639 - val_accuracy: 0.5686\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6639 - accuracy: 0.6200 - val_loss: 0.6634 - val_accuracy: 0.5686\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6635 - accuracy: 0.6150 - val_loss: 0.6632 - val_accuracy: 0.5686\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.6150 - val_loss: 0.6625 - val_accuracy: 0.5686\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6627 - accuracy: 0.6200 - val_loss: 0.6622 - val_accuracy: 0.5686\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6625 - accuracy: 0.6200 - val_loss: 0.6617 - val_accuracy: 0.5686\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6621 - accuracy: 0.6200 - val_loss: 0.6614 - val_accuracy: 0.5686\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6616 - accuracy: 0.6200 - val_loss: 0.6612 - val_accuracy: 0.5686\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6613 - accuracy: 0.6150 - val_loss: 0.6610 - val_accuracy: 0.5686\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6611 - accuracy: 0.6150 - val_loss: 0.6607 - val_accuracy: 0.5686\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6605 - accuracy: 0.6150 - val_loss: 0.6603 - val_accuracy: 0.5686\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6600 - accuracy: 0.6150 - val_loss: 0.6598 - val_accuracy: 0.5686\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6597 - accuracy: 0.6150 - val_loss: 0.6596 - val_accuracy: 0.5686\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6593 - accuracy: 0.6150 - val_loss: 0.6596 - val_accuracy: 0.5686\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6590 - accuracy: 0.6150 - val_loss: 0.6596 - val_accuracy: 0.5686\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6585 - accuracy: 0.6150 - val_loss: 0.6592 - val_accuracy: 0.5686\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6581 - accuracy: 0.6150 - val_loss: 0.6590 - val_accuracy: 0.5686\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6576 - accuracy: 0.6150 - val_loss: 0.6585 - val_accuracy: 0.5686\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6573 - accuracy: 0.6150 - val_loss: 0.6582 - val_accuracy: 0.5686\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6568 - accuracy: 0.6150 - val_loss: 0.6577 - val_accuracy: 0.5686\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6564 - accuracy: 0.6150 - val_loss: 0.6571 - val_accuracy: 0.5686\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6559 - accuracy: 0.6150 - val_loss: 0.6569 - val_accuracy: 0.5686\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6554 - accuracy: 0.6150 - val_loss: 0.6567 - val_accuracy: 0.5686\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6550 - accuracy: 0.6150 - val_loss: 0.6564 - val_accuracy: 0.5686\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.6150 - val_loss: 0.6561 - val_accuracy: 0.5686\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6543 - accuracy: 0.6150 - val_loss: 0.6556 - val_accuracy: 0.5686\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6538 - accuracy: 0.6200 - val_loss: 0.6554 - val_accuracy: 0.5686\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6535 - accuracy: 0.6250 - val_loss: 0.6550 - val_accuracy: 0.5686\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6531 - accuracy: 0.6300 - val_loss: 0.6548 - val_accuracy: 0.5686\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.6300 - val_loss: 0.6543 - val_accuracy: 0.5686\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6524 - accuracy: 0.6350 - val_loss: 0.6542 - val_accuracy: 0.5686\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6520 - accuracy: 0.6300 - val_loss: 0.6541 - val_accuracy: 0.5686\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.6350 - val_loss: 0.6537 - val_accuracy: 0.5686\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6514 - accuracy: 0.6250 - val_loss: 0.6536 - val_accuracy: 0.5686\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6511 - accuracy: 0.6300 - val_loss: 0.6537 - val_accuracy: 0.5686\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6509 - accuracy: 0.6300 - val_loss: 0.6536 - val_accuracy: 0.5490\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6503 - accuracy: 0.6250 - val_loss: 0.6531 - val_accuracy: 0.5490\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.6300 - val_loss: 0.6527 - val_accuracy: 0.5686\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6499 - accuracy: 0.6300 - val_loss: 0.6524 - val_accuracy: 0.5686\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6496 - accuracy: 0.6300 - val_loss: 0.6524 - val_accuracy: 0.5686\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6493 - accuracy: 0.6250 - val_loss: 0.6521 - val_accuracy: 0.5686\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6491 - accuracy: 0.6250 - val_loss: 0.6519 - val_accuracy: 0.5686\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6490 - accuracy: 0.6300 - val_loss: 0.6519 - val_accuracy: 0.5686\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6485 - accuracy: 0.6250 - val_loss: 0.6515 - val_accuracy: 0.5490\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6481 - accuracy: 0.6350 - val_loss: 0.6511 - val_accuracy: 0.5882\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6450 - val_loss: 0.6508 - val_accuracy: 0.6078\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6476 - accuracy: 0.6550 - val_loss: 0.6504 - val_accuracy: 0.6275\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6473 - accuracy: 0.6500 - val_loss: 0.6506 - val_accuracy: 0.6471\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6469 - accuracy: 0.6500 - val_loss: 0.6507 - val_accuracy: 0.6275\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6468 - accuracy: 0.6600 - val_loss: 0.6509 - val_accuracy: 0.5882\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6463 - accuracy: 0.6700 - val_loss: 0.6509 - val_accuracy: 0.5882\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6462 - accuracy: 0.6700 - val_loss: 0.6508 - val_accuracy: 0.6078\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6458 - accuracy: 0.6800 - val_loss: 0.6508 - val_accuracy: 0.6275\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6456 - accuracy: 0.6750 - val_loss: 0.6504 - val_accuracy: 0.6078\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6454 - accuracy: 0.6750 - val_loss: 0.6500 - val_accuracy: 0.6275\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6453 - accuracy: 0.6850 - val_loss: 0.6502 - val_accuracy: 0.6471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "d0mJOMoge0ri",
        "outputId": "c3e42d78-174e-4963-edc3-bccecd8d89de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 1s 7ms/step - loss: 0.6831 - accuracy: 0.5700 - val_loss: 0.6788 - val_accuracy: 0.5490\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.5850 - val_loss: 0.6782 - val_accuracy: 0.5098\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.6150 - val_loss: 0.6775 - val_accuracy: 0.5490\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.6100 - val_loss: 0.6764 - val_accuracy: 0.5490\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6050 - val_loss: 0.6753 - val_accuracy: 0.5882\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.6050 - val_loss: 0.6743 - val_accuracy: 0.5686\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.6200 - val_loss: 0.6733 - val_accuracy: 0.5686\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.6200 - val_loss: 0.6720 - val_accuracy: 0.5686\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.6250 - val_loss: 0.6697 - val_accuracy: 0.5686\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6250 - val_loss: 0.6674 - val_accuracy: 0.5490\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6250 - val_loss: 0.6657 - val_accuracy: 0.5686\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6200 - val_loss: 0.6641 - val_accuracy: 0.5686\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6250 - val_loss: 0.6636 - val_accuracy: 0.5686\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6300 - val_loss: 0.6649 - val_accuracy: 0.5686\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6200 - val_loss: 0.6638 - val_accuracy: 0.5686\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6400 - val_loss: 0.6571 - val_accuracy: 0.6863\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6650 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6600 - val_loss: 0.6542 - val_accuracy: 0.6667\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.6550 - val_loss: 0.6531 - val_accuracy: 0.6667\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.6650 - val_loss: 0.6528 - val_accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6650 - val_loss: 0.6535 - val_accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6650 - val_loss: 0.6531 - val_accuracy: 0.6667\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6500 - val_loss: 0.6548 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.6700 - val_loss: 0.6554 - val_accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6650 - val_loss: 0.6549 - val_accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6600 - val_loss: 0.6547 - val_accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6700 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6600 - val_loss: 0.6576 - val_accuracy: 0.6667\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6650 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6750 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6600 - val_loss: 0.6573 - val_accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.6750 - val_loss: 0.6574 - val_accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.6800 - val_loss: 0.6587 - val_accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6850 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6900 - val_loss: 0.6594 - val_accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.6850 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6750 - val_loss: 0.6575 - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6900 - val_loss: 0.6589 - val_accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6850 - val_loss: 0.6577 - val_accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.6750 - val_loss: 0.6581 - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6900 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6750 - val_loss: 0.6576 - val_accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6850 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.6900 - val_loss: 0.6581 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6900 - val_loss: 0.6568 - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6800 - val_loss: 0.6553 - val_accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6850 - val_loss: 0.6576 - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6900 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6800 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6850 - val_loss: 0.6573 - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6900 - val_loss: 0.6585 - val_accuracy: 0.6667\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6900 - val_loss: 0.6573 - val_accuracy: 0.6667\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6900 - val_loss: 0.6575 - val_accuracy: 0.6667\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6850 - val_loss: 0.6581 - val_accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.6800 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6900 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.6900 - val_loss: 0.6572 - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6900 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6950 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6650 - val_loss: 0.6543 - val_accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6900 - val_loss: 0.6579 - val_accuracy: 0.6471\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6900 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6850 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6800 - val_loss: 0.6552 - val_accuracy: 0.6667\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6850 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6900 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.6850 - val_loss: 0.6544 - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6900 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6950 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6700 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.6900 - val_loss: 0.6539 - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6850 - val_loss: 0.6540 - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6850 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.6850 - val_loss: 0.6536 - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.6950 - val_loss: 0.6547 - val_accuracy: 0.6667\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6850 - val_loss: 0.6535 - val_accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6800 - val_loss: 0.6529 - val_accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.6850 - val_loss: 0.6530 - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.6900 - val_loss: 0.6542 - val_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6900 - val_loss: 0.6534 - val_accuracy: 0.6667\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6850 - val_loss: 0.6529 - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6850 - val_loss: 0.6532 - val_accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6900 - val_loss: 0.6524 - val_accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6850 - val_loss: 0.6535 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6800 - val_loss: 0.6533 - val_accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6800 - val_loss: 0.6544 - val_accuracy: 0.6667\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6750 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.6900 - val_loss: 0.6547 - val_accuracy: 0.6667\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6900 - val_loss: 0.6540 - val_accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6850 - val_loss: 0.6540 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6800 - val_loss: 0.6520 - val_accuracy: 0.6667\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.6750 - val_loss: 0.6527 - val_accuracy: 0.6667\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6750 - val_loss: 0.6531 - val_accuracy: 0.6667\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6950 - val_loss: 0.6554 - val_accuracy: 0.6471\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6800 - val_loss: 0.6541 - val_accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6900 - val_loss: 0.6537 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6850 - val_loss: 0.6543 - val_accuracy: 0.6667\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6800 - val_loss: 0.6529 - val_accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6850 - val_loss: 0.6537 - val_accuracy: 0.6667\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6950 - val_loss: 0.6547 - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "HOLGhvTfe0t1",
        "outputId": "431646ae-f706-4393-bd07-1115893487da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 1s 7ms/step - loss: 0.6823 - accuracy: 0.5800 - val_loss: 0.6783 - val_accuracy: 0.6078\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.6050 - val_loss: 0.6771 - val_accuracy: 0.5490\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.6150 - val_loss: 0.6765 - val_accuracy: 0.5490\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.6050 - val_loss: 0.6739 - val_accuracy: 0.5686\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.6200 - val_loss: 0.6732 - val_accuracy: 0.5686\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.6200 - val_loss: 0.6710 - val_accuracy: 0.5686\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6300 - val_loss: 0.6717 - val_accuracy: 0.5686\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.6250 - val_loss: 0.6709 - val_accuracy: 0.5686\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6250 - val_loss: 0.6685 - val_accuracy: 0.5686\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6200 - val_loss: 0.6678 - val_accuracy: 0.5686\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6250 - val_loss: 0.6678 - val_accuracy: 0.5686\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.6450 - val_loss: 0.6665 - val_accuracy: 0.5686\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6250 - val_loss: 0.6657 - val_accuracy: 0.5686\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6350 - val_loss: 0.6674 - val_accuracy: 0.5686\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6350 - val_loss: 0.6663 - val_accuracy: 0.5686\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6550 - val_loss: 0.6629 - val_accuracy: 0.5686\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6750 - val_loss: 0.6659 - val_accuracy: 0.5882\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6750 - val_loss: 0.6660 - val_accuracy: 0.5882\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6700 - val_loss: 0.6613 - val_accuracy: 0.5686\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.6800 - val_loss: 0.6648 - val_accuracy: 0.6078\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6800 - val_loss: 0.6647 - val_accuracy: 0.6078\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.6800 - val_loss: 0.6647 - val_accuracy: 0.5686\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.6950 - val_loss: 0.6669 - val_accuracy: 0.6275\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6850 - val_loss: 0.6666 - val_accuracy: 0.5882\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6750 - val_loss: 0.6658 - val_accuracy: 0.5882\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6650 - val_loss: 0.6672 - val_accuracy: 0.5882\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6950 - val_loss: 0.6711 - val_accuracy: 0.6275\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6850 - val_loss: 0.6708 - val_accuracy: 0.6471\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6950 - val_loss: 0.6702 - val_accuracy: 0.6275\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.6850 - val_loss: 0.6720 - val_accuracy: 0.6275\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.7000 - val_loss: 0.6749 - val_accuracy: 0.6275\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6850 - val_loss: 0.6771 - val_accuracy: 0.6471\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6850 - val_loss: 0.6780 - val_accuracy: 0.6471\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6900 - val_loss: 0.6743 - val_accuracy: 0.6275\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6800 - val_loss: 0.6782 - val_accuracy: 0.6471\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6850 - val_loss: 0.6738 - val_accuracy: 0.6078\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6900 - val_loss: 0.6782 - val_accuracy: 0.6471\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.6750 - val_loss: 0.6800 - val_accuracy: 0.6471\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6850 - val_loss: 0.6798 - val_accuracy: 0.6275\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6800 - val_loss: 0.6817 - val_accuracy: 0.6275\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6800 - val_loss: 0.6757 - val_accuracy: 0.6275\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6950 - val_loss: 0.6833 - val_accuracy: 0.6471\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6800 - val_loss: 0.6807 - val_accuracy: 0.6471\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7000 - val_loss: 0.6834 - val_accuracy: 0.6471\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.6900 - val_loss: 0.6818 - val_accuracy: 0.6275\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6950 - val_loss: 0.6760 - val_accuracy: 0.6078\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.7100 - val_loss: 0.6837 - val_accuracy: 0.6471\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6900 - val_loss: 0.6838 - val_accuracy: 0.6471\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.6850 - val_loss: 0.6788 - val_accuracy: 0.5882\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.7250 - val_loss: 0.6863 - val_accuracy: 0.6471\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.6900 - val_loss: 0.6899 - val_accuracy: 0.6275\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7100 - val_loss: 0.6836 - val_accuracy: 0.6471\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7000 - val_loss: 0.6847 - val_accuracy: 0.6471\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.6900 - val_loss: 0.6880 - val_accuracy: 0.6471\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7100 - val_loss: 0.6799 - val_accuracy: 0.6275\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7100 - val_loss: 0.6811 - val_accuracy: 0.6275\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7100 - val_loss: 0.6871 - val_accuracy: 0.6471\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.7100 - val_loss: 0.6857 - val_accuracy: 0.6471\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7050 - val_loss: 0.6884 - val_accuracy: 0.6471\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6900 - val_loss: 0.6837 - val_accuracy: 0.6275\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7000 - val_loss: 0.6908 - val_accuracy: 0.6471\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7150 - val_loss: 0.6871 - val_accuracy: 0.6471\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7100 - val_loss: 0.6885 - val_accuracy: 0.6275\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.7050 - val_loss: 0.6866 - val_accuracy: 0.6275\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7050 - val_loss: 0.6879 - val_accuracy: 0.6471\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7100 - val_loss: 0.6884 - val_accuracy: 0.6275\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7150 - val_loss: 0.6872 - val_accuracy: 0.6275\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7050 - val_loss: 0.6888 - val_accuracy: 0.6275\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.7200 - val_loss: 0.6868 - val_accuracy: 0.6275\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7000 - val_loss: 0.6953 - val_accuracy: 0.6275\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.7250 - val_loss: 0.6893 - val_accuracy: 0.6275\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.7200 - val_loss: 0.6936 - val_accuracy: 0.6275\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7100 - val_loss: 0.6895 - val_accuracy: 0.6275\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7200 - val_loss: 0.6889 - val_accuracy: 0.6275\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7100 - val_loss: 0.6899 - val_accuracy: 0.6275\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7200 - val_loss: 0.6875 - val_accuracy: 0.6078\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7150 - val_loss: 0.6883 - val_accuracy: 0.6275\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7150 - val_loss: 0.6914 - val_accuracy: 0.6275\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7200 - val_loss: 0.6920 - val_accuracy: 0.6275\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7250 - val_loss: 0.6922 - val_accuracy: 0.6275\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7250 - val_loss: 0.6930 - val_accuracy: 0.6078\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7050 - val_loss: 0.6949 - val_accuracy: 0.6078\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.7200 - val_loss: 0.6925 - val_accuracy: 0.6275\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7150 - val_loss: 0.6955 - val_accuracy: 0.6078\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7200 - val_loss: 0.6900 - val_accuracy: 0.6275\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7200 - val_loss: 0.6974 - val_accuracy: 0.6275\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6850 - val_loss: 0.6979 - val_accuracy: 0.6275\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7100 - val_loss: 0.7004 - val_accuracy: 0.6471\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7200 - val_loss: 0.6944 - val_accuracy: 0.6078\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7150 - val_loss: 0.6914 - val_accuracy: 0.6078\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7100 - val_loss: 0.6878 - val_accuracy: 0.6078\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7100 - val_loss: 0.6952 - val_accuracy: 0.6078\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7050 - val_loss: 0.6945 - val_accuracy: 0.6078\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7050 - val_loss: 0.6983 - val_accuracy: 0.6078\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.7150 - val_loss: 0.6948 - val_accuracy: 0.6078\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7250 - val_loss: 0.6927 - val_accuracy: 0.5882\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7250 - val_loss: 0.6980 - val_accuracy: 0.6275\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.7200 - val_loss: 0.6930 - val_accuracy: 0.5882\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7200 - val_loss: 0.6944 - val_accuracy: 0.5882\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7000 - val_loss: 0.6926 - val_accuracy: 0.5882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "etsSl4HktL8C",
        "outputId": "104962d5-d7ca-45c6-e033-f6d380139cb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 1s 7ms/step - loss: 0.6903 - accuracy: 0.5300 - val_loss: 0.6887 - val_accuracy: 0.5882\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5700 - val_loss: 0.6863 - val_accuracy: 0.5882\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5700 - val_loss: 0.6844 - val_accuracy: 0.5490\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.6050 - val_loss: 0.6815 - val_accuracy: 0.5294\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.6050 - val_loss: 0.6812 - val_accuracy: 0.5294\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.6000 - val_loss: 0.6800 - val_accuracy: 0.5294\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.6100 - val_loss: 0.6824 - val_accuracy: 0.5882\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6050 - val_loss: 0.6811 - val_accuracy: 0.5882\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6250 - val_loss: 0.6815 - val_accuracy: 0.5686\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6250 - val_loss: 0.6837 - val_accuracy: 0.5686\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6300 - val_loss: 0.6872 - val_accuracy: 0.5882\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6450 - val_loss: 0.6872 - val_accuracy: 0.5882\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6500 - val_loss: 0.6912 - val_accuracy: 0.5882\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6350 - val_loss: 0.6948 - val_accuracy: 0.5882\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6550 - val_loss: 0.6955 - val_accuracy: 0.5882\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.6400 - val_loss: 0.6952 - val_accuracy: 0.5882\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.6450 - val_loss: 0.6996 - val_accuracy: 0.5882\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6500 - val_loss: 0.7010 - val_accuracy: 0.5882\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6400 - val_loss: 0.6994 - val_accuracy: 0.5882\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6400 - val_loss: 0.6993 - val_accuracy: 0.5882\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6450 - val_loss: 0.7017 - val_accuracy: 0.5882\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6450 - val_loss: 0.7030 - val_accuracy: 0.5882\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6450 - val_loss: 0.7051 - val_accuracy: 0.5882\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6450 - val_loss: 0.7022 - val_accuracy: 0.5882\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6450 - val_loss: 0.7041 - val_accuracy: 0.6078\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6400 - val_loss: 0.7022 - val_accuracy: 0.6078\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6450 - val_loss: 0.7066 - val_accuracy: 0.6078\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6450 - val_loss: 0.7093 - val_accuracy: 0.5882\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.6450 - val_loss: 0.7046 - val_accuracy: 0.6078\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6450 - val_loss: 0.7073 - val_accuracy: 0.5882\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6400 - val_loss: 0.7077 - val_accuracy: 0.5882\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6450 - val_loss: 0.7072 - val_accuracy: 0.5882\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6450 - val_loss: 0.7092 - val_accuracy: 0.5882\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6450 - val_loss: 0.7044 - val_accuracy: 0.6275\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6450 - val_loss: 0.7095 - val_accuracy: 0.5882\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6350 - val_loss: 0.7004 - val_accuracy: 0.6471\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6650 - val_loss: 0.7025 - val_accuracy: 0.6275\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6450 - val_loss: 0.7106 - val_accuracy: 0.5882\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6500 - val_loss: 0.7046 - val_accuracy: 0.6471\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.6500 - val_loss: 0.7050 - val_accuracy: 0.6275\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6600 - val_loss: 0.6984 - val_accuracy: 0.6471\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.6750 - val_loss: 0.7114 - val_accuracy: 0.5882\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6500 - val_loss: 0.7021 - val_accuracy: 0.6471\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6500 - val_loss: 0.7045 - val_accuracy: 0.6275\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6550 - val_loss: 0.6975 - val_accuracy: 0.6471\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6550 - val_loss: 0.6920 - val_accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.6450 - val_loss: 0.7025 - val_accuracy: 0.6471\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6500 - val_loss: 0.7017 - val_accuracy: 0.6471\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.6700 - val_loss: 0.6954 - val_accuracy: 0.6471\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6650 - val_loss: 0.7023 - val_accuracy: 0.6471\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6550 - val_loss: 0.7073 - val_accuracy: 0.6078\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6700 - val_loss: 0.6989 - val_accuracy: 0.6471\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6400 - val_loss: 0.6959 - val_accuracy: 0.6471\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6550 - val_loss: 0.6998 - val_accuracy: 0.6471\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6800 - val_loss: 0.6880 - val_accuracy: 0.6471\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6750 - val_loss: 0.6925 - val_accuracy: 0.6471\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6750 - val_loss: 0.6971 - val_accuracy: 0.6471\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6800 - val_loss: 0.6934 - val_accuracy: 0.6471\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.6600 - val_loss: 0.6932 - val_accuracy: 0.6471\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6600 - val_loss: 0.6900 - val_accuracy: 0.6471\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.6500 - val_loss: 0.6989 - val_accuracy: 0.6471\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6950 - val_loss: 0.6903 - val_accuracy: 0.6471\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.6800 - val_loss: 0.6885 - val_accuracy: 0.6471\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6650 - val_loss: 0.6852 - val_accuracy: 0.6275\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6800 - val_loss: 0.6890 - val_accuracy: 0.6471\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6650 - val_loss: 0.6836 - val_accuracy: 0.6471\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.6900 - val_loss: 0.6887 - val_accuracy: 0.6471\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6750 - val_loss: 0.6851 - val_accuracy: 0.6471\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.6800 - val_loss: 0.6806 - val_accuracy: 0.6078\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.6750 - val_loss: 0.7038 - val_accuracy: 0.6471\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6700 - val_loss: 0.6854 - val_accuracy: 0.6275\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7000 - val_loss: 0.6908 - val_accuracy: 0.6471\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6750 - val_loss: 0.6840 - val_accuracy: 0.6275\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6950 - val_loss: 0.6832 - val_accuracy: 0.6471\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6650 - val_loss: 0.6804 - val_accuracy: 0.6275\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.7000 - val_loss: 0.6745 - val_accuracy: 0.6078\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.7050 - val_loss: 0.6821 - val_accuracy: 0.6275\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7000 - val_loss: 0.6845 - val_accuracy: 0.6471\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.6850 - val_loss: 0.6852 - val_accuracy: 0.6471\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6900 - val_loss: 0.6778 - val_accuracy: 0.6078\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.6950 - val_loss: 0.6803 - val_accuracy: 0.6275\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.6800 - val_loss: 0.6826 - val_accuracy: 0.6275\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.6850 - val_loss: 0.6789 - val_accuracy: 0.6275\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.6850 - val_loss: 0.6822 - val_accuracy: 0.6275\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6750 - val_loss: 0.6781 - val_accuracy: 0.6275\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.7000 - val_loss: 0.6885 - val_accuracy: 0.6275\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.6650 - val_loss: 0.6867 - val_accuracy: 0.6471\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7000 - val_loss: 0.6928 - val_accuracy: 0.6471\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7000 - val_loss: 0.6729 - val_accuracy: 0.6275\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6900 - val_loss: 0.6704 - val_accuracy: 0.6078\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6850 - val_loss: 0.6678 - val_accuracy: 0.6078\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.6950 - val_loss: 0.6735 - val_accuracy: 0.6471\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7050 - val_loss: 0.6800 - val_accuracy: 0.6471\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7050 - val_loss: 0.6855 - val_accuracy: 0.6275\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7000 - val_loss: 0.6829 - val_accuracy: 0.6471\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7000 - val_loss: 0.6770 - val_accuracy: 0.6275\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7050 - val_loss: 0.6790 - val_accuracy: 0.6471\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6900 - val_loss: 0.6763 - val_accuracy: 0.6275\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7200 - val_loss: 0.6770 - val_accuracy: 0.6275\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6900 - val_loss: 0.6743 - val_accuracy: 0.6078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "T3c16NIOtOyF",
        "outputId": "0ab754e0-42cc-4130-afdb-0760d3243dcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 1s 7ms/step - loss: 0.6898 - accuracy: 0.5750 - val_loss: 0.6837 - val_accuracy: 0.5686\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6300 - val_loss: 0.6805 - val_accuracy: 0.5686\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6400 - val_loss: 0.6769 - val_accuracy: 0.5490\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6300 - val_loss: 0.6747 - val_accuracy: 0.5686\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6200 - val_loss: 0.6737 - val_accuracy: 0.5686\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.6250 - val_loss: 0.6709 - val_accuracy: 0.5686\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6400 - val_loss: 0.6832 - val_accuracy: 0.5098\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.6500 - val_loss: 0.6792 - val_accuracy: 0.5490\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.6450 - val_loss: 0.6769 - val_accuracy: 0.5294\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6600 - val_loss: 0.6764 - val_accuracy: 0.5490\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.6550 - val_loss: 0.6938 - val_accuracy: 0.5882\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.6850 - val_loss: 0.6777 - val_accuracy: 0.5490\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6500 - val_loss: 0.6885 - val_accuracy: 0.5882\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6600 - val_loss: 0.6859 - val_accuracy: 0.5882\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6900 - val_loss: 0.6869 - val_accuracy: 0.6078\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6650 - val_loss: 0.6779 - val_accuracy: 0.5882\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.6800 - val_loss: 0.6805 - val_accuracy: 0.5882\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.6850 - val_loss: 0.6880 - val_accuracy: 0.6078\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6850 - val_loss: 0.6790 - val_accuracy: 0.5882\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6700 - val_loss: 0.6723 - val_accuracy: 0.5882\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6700 - val_loss: 0.6778 - val_accuracy: 0.5882\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6850 - val_loss: 0.6843 - val_accuracy: 0.6078\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6850 - val_loss: 0.6876 - val_accuracy: 0.6078\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6800 - val_loss: 0.6771 - val_accuracy: 0.5686\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6400 - val_loss: 0.6774 - val_accuracy: 0.5686\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6450 - val_loss: 0.6978 - val_accuracy: 0.6078\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6850 - val_loss: 0.6808 - val_accuracy: 0.5882\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.6650 - val_loss: 0.6878 - val_accuracy: 0.5882\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6500 - val_loss: 0.6900 - val_accuracy: 0.6078\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.6950 - val_loss: 0.6833 - val_accuracy: 0.5882\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.7150 - val_loss: 0.7016 - val_accuracy: 0.6078\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6700 - val_loss: 0.6897 - val_accuracy: 0.5882\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6950 - val_loss: 0.6986 - val_accuracy: 0.6078\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7000 - val_loss: 0.6842 - val_accuracy: 0.5882\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6950 - val_loss: 0.6896 - val_accuracy: 0.5686\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.6800 - val_loss: 0.6864 - val_accuracy: 0.5686\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7100 - val_loss: 0.6947 - val_accuracy: 0.5882\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6950 - val_loss: 0.6937 - val_accuracy: 0.5882\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.6950 - val_loss: 0.7030 - val_accuracy: 0.5490\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6400 - val_loss: 0.7231 - val_accuracy: 0.5882\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6850 - val_loss: 0.6767 - val_accuracy: 0.5882\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6850 - val_loss: 0.7225 - val_accuracy: 0.6078\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6750 - val_loss: 0.6797 - val_accuracy: 0.5686\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6850 - val_loss: 0.6996 - val_accuracy: 0.5686\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7250 - val_loss: 0.6945 - val_accuracy: 0.5882\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7100 - val_loss: 0.6826 - val_accuracy: 0.5882\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.7050 - val_loss: 0.6954 - val_accuracy: 0.5882\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7100 - val_loss: 0.6940 - val_accuracy: 0.5882\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6850 - val_loss: 0.6914 - val_accuracy: 0.5686\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7300 - val_loss: 0.7139 - val_accuracy: 0.5686\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6750 - val_loss: 0.7113 - val_accuracy: 0.5686\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7050 - val_loss: 0.7137 - val_accuracy: 0.5686\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7100 - val_loss: 0.6912 - val_accuracy: 0.5882\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6650 - val_loss: 0.6955 - val_accuracy: 0.5686\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7000 - val_loss: 0.6910 - val_accuracy: 0.5686\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7150 - val_loss: 0.6972 - val_accuracy: 0.5686\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7250 - val_loss: 0.7034 - val_accuracy: 0.5686\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7100 - val_loss: 0.7103 - val_accuracy: 0.5686\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.7300 - val_loss: 0.6994 - val_accuracy: 0.5490\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6700 - val_loss: 0.7144 - val_accuracy: 0.5686\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.7000 - val_loss: 0.7070 - val_accuracy: 0.5490\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.7150 - val_loss: 0.7155 - val_accuracy: 0.5686\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7100 - val_loss: 0.7029 - val_accuracy: 0.5686\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.7000 - val_loss: 0.6973 - val_accuracy: 0.5686\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.7450 - val_loss: 0.7060 - val_accuracy: 0.5686\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7250 - val_loss: 0.6956 - val_accuracy: 0.5686\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7100 - val_loss: 0.7195 - val_accuracy: 0.5490\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.7100 - val_loss: 0.7016 - val_accuracy: 0.5686\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.7100 - val_loss: 0.6995 - val_accuracy: 0.5686\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6850 - val_loss: 0.7459 - val_accuracy: 0.6078\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7150 - val_loss: 0.6971 - val_accuracy: 0.5686\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7100 - val_loss: 0.7274 - val_accuracy: 0.5294\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7200 - val_loss: 0.7009 - val_accuracy: 0.5686\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7150 - val_loss: 0.7196 - val_accuracy: 0.5490\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7100 - val_loss: 0.6974 - val_accuracy: 0.5882\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7050 - val_loss: 0.7081 - val_accuracy: 0.5490\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7250 - val_loss: 0.7159 - val_accuracy: 0.5490\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7250 - val_loss: 0.7292 - val_accuracy: 0.5294\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7050 - val_loss: 0.7259 - val_accuracy: 0.5490\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7050 - val_loss: 0.7083 - val_accuracy: 0.5882\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.7150 - val_loss: 0.7194 - val_accuracy: 0.5490\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7100 - val_loss: 0.7398 - val_accuracy: 0.5098\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7050 - val_loss: 0.7117 - val_accuracy: 0.5490\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6950 - val_loss: 0.7182 - val_accuracy: 0.5098\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7150 - val_loss: 0.7206 - val_accuracy: 0.5490\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7100 - val_loss: 0.7306 - val_accuracy: 0.5294\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7000 - val_loss: 0.7451 - val_accuracy: 0.5490\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7100 - val_loss: 0.7205 - val_accuracy: 0.5294\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7150 - val_loss: 0.7179 - val_accuracy: 0.5098\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7100 - val_loss: 0.7057 - val_accuracy: 0.6078\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.7000 - val_loss: 0.7191 - val_accuracy: 0.5294\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.6900 - val_loss: 0.7061 - val_accuracy: 0.5490\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7150 - val_loss: 0.7161 - val_accuracy: 0.5490\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7150 - val_loss: 0.7265 - val_accuracy: 0.5294\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7050 - val_loss: 0.7279 - val_accuracy: 0.5490\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7200 - val_loss: 0.7167 - val_accuracy: 0.5686\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7100 - val_loss: 0.7184 - val_accuracy: 0.5490\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7200 - val_loss: 0.7247 - val_accuracy: 0.5686\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7150 - val_loss: 0.7054 - val_accuracy: 0.6078\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.6950 - val_loss: 0.7033 - val_accuracy: 0.6078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "ytfYzYMftS79",
        "outputId": "01608de4-dffa-4c63-949a-c5da68e4965d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 1s 8ms/step - loss: 0.6955 - accuracy: 0.5050 - val_loss: 0.6938 - val_accuracy: 0.4706\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5750 - val_loss: 0.6936 - val_accuracy: 0.5882\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.6300 - val_loss: 0.6898 - val_accuracy: 0.5098\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6150 - val_loss: 0.7114 - val_accuracy: 0.5882\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6350 - val_loss: 0.7162 - val_accuracy: 0.5294\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6350 - val_loss: 0.7079 - val_accuracy: 0.5490\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6800 - val_loss: 0.7018 - val_accuracy: 0.5490\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6500 - val_loss: 0.7116 - val_accuracy: 0.5882\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6800 - val_loss: 0.6967 - val_accuracy: 0.5882\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6600 - val_loss: 0.6894 - val_accuracy: 0.5490\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6450 - val_loss: 0.7097 - val_accuracy: 0.5882\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6700 - val_loss: 0.6901 - val_accuracy: 0.6471\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6800 - val_loss: 0.7188 - val_accuracy: 0.6078\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.6500 - val_loss: 0.6853 - val_accuracy: 0.6275\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7000 - val_loss: 0.7091 - val_accuracy: 0.6275\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6900 - val_loss: 0.6876 - val_accuracy: 0.6667\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.7050 - val_loss: 0.6876 - val_accuracy: 0.6275\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6900 - val_loss: 0.6987 - val_accuracy: 0.6667\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6950 - val_loss: 0.6698 - val_accuracy: 0.6275\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6750 - val_loss: 0.6729 - val_accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6900 - val_loss: 0.6719 - val_accuracy: 0.6275\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.7100 - val_loss: 0.6829 - val_accuracy: 0.6275\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7050 - val_loss: 0.7085 - val_accuracy: 0.6471\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7050 - val_loss: 0.6770 - val_accuracy: 0.6275\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6650 - val_loss: 0.6974 - val_accuracy: 0.6078\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6500 - val_loss: 0.7139 - val_accuracy: 0.6471\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7150 - val_loss: 0.7104 - val_accuracy: 0.6275\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6900 - val_loss: 0.6991 - val_accuracy: 0.5882\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.6750 - val_loss: 0.6991 - val_accuracy: 0.6471\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7100 - val_loss: 0.6850 - val_accuracy: 0.6471\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7100 - val_loss: 0.6776 - val_accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.6850 - val_loss: 0.6877 - val_accuracy: 0.6863\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7000 - val_loss: 0.6840 - val_accuracy: 0.6471\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7050 - val_loss: 0.6902 - val_accuracy: 0.6863\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7150 - val_loss: 0.6573 - val_accuracy: 0.6275\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7200 - val_loss: 0.6554 - val_accuracy: 0.6275\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7000 - val_loss: 0.6903 - val_accuracy: 0.6471\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7100 - val_loss: 0.6959 - val_accuracy: 0.6471\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7100 - val_loss: 0.7235 - val_accuracy: 0.6078\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7000 - val_loss: 0.6941 - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.6950 - val_loss: 0.6990 - val_accuracy: 0.5882\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7150 - val_loss: 0.7278 - val_accuracy: 0.6275\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7150 - val_loss: 0.7133 - val_accuracy: 0.5882\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7350 - val_loss: 0.7316 - val_accuracy: 0.5882\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7300 - val_loss: 0.6731 - val_accuracy: 0.6471\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7400 - val_loss: 0.7130 - val_accuracy: 0.5882\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7100 - val_loss: 0.7191 - val_accuracy: 0.5686\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.6900 - val_loss: 0.7482 - val_accuracy: 0.6471\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7250 - val_loss: 0.7471 - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7350 - val_loss: 0.7587 - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7250 - val_loss: 0.7517 - val_accuracy: 0.6275\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7100 - val_loss: 0.7809 - val_accuracy: 0.6471\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6950 - val_loss: 0.7116 - val_accuracy: 0.5686\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7200 - val_loss: 0.6977 - val_accuracy: 0.6275\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7150 - val_loss: 0.7522 - val_accuracy: 0.5882\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7500 - val_loss: 0.7541 - val_accuracy: 0.6078\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7350 - val_loss: 0.7712 - val_accuracy: 0.5490\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7250 - val_loss: 0.7961 - val_accuracy: 0.6471\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7350 - val_loss: 0.7655 - val_accuracy: 0.5490\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7500 - val_loss: 0.8052 - val_accuracy: 0.6471\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7500 - val_loss: 0.7369 - val_accuracy: 0.6863\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7300 - val_loss: 0.7535 - val_accuracy: 0.6471\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7400 - val_loss: 0.7545 - val_accuracy: 0.5882\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7300 - val_loss: 0.7752 - val_accuracy: 0.5686\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7350 - val_loss: 0.7592 - val_accuracy: 0.5882\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7350 - val_loss: 0.7928 - val_accuracy: 0.5490\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7200 - val_loss: 0.7708 - val_accuracy: 0.6078\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7350 - val_loss: 0.7719 - val_accuracy: 0.5490\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7350 - val_loss: 0.7818 - val_accuracy: 0.5882\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7600 - val_loss: 0.7868 - val_accuracy: 0.6275\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7500 - val_loss: 0.7834 - val_accuracy: 0.6471\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7500 - val_loss: 0.8100 - val_accuracy: 0.6078\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7300 - val_loss: 0.8163 - val_accuracy: 0.5490\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7300 - val_loss: 0.7852 - val_accuracy: 0.6078\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7350 - val_loss: 0.8054 - val_accuracy: 0.5294\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7300 - val_loss: 0.7975 - val_accuracy: 0.6078\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7450 - val_loss: 0.8665 - val_accuracy: 0.5686\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7150 - val_loss: 0.7684 - val_accuracy: 0.6078\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7150 - val_loss: 0.8741 - val_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7400 - val_loss: 0.8145 - val_accuracy: 0.6471\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7450 - val_loss: 0.8396 - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7400 - val_loss: 0.7664 - val_accuracy: 0.5882\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7100 - val_loss: 0.8521 - val_accuracy: 0.5882\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7100 - val_loss: 0.8604 - val_accuracy: 0.5882\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7500 - val_loss: 0.8474 - val_accuracy: 0.6471\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7350 - val_loss: 0.9019 - val_accuracy: 0.6275\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7400 - val_loss: 0.8710 - val_accuracy: 0.5882\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7050 - val_loss: 0.8605 - val_accuracy: 0.6275\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7250 - val_loss: 0.8415 - val_accuracy: 0.6275\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7300 - val_loss: 0.8357 - val_accuracy: 0.5490\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7400 - val_loss: 0.8272 - val_accuracy: 0.6078\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7250 - val_loss: 0.8766 - val_accuracy: 0.6275\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7550 - val_loss: 0.8698 - val_accuracy: 0.6078\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7400 - val_loss: 0.8795 - val_accuracy: 0.5686\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7400 - val_loss: 0.8896 - val_accuracy: 0.6471\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7450 - val_loss: 0.8895 - val_accuracy: 0.6078\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7250 - val_loss: 0.9293 - val_accuracy: 0.5686\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7500 - val_loss: 0.9428 - val_accuracy: 0.6471\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7100 - val_loss: 0.9075 - val_accuracy: 0.5686\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7450 - val_loss: 0.9419 - val_accuracy: 0.5686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aSFXiJDIe0wL"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HwrvwOX0cyMf"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sGr_oqlJHh4h"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xSCrBKNIHh7K"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "jxDbWXbvvMEV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "85e00f8c-9d79-4ebf-a980-589f06ddab2f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Нарушения сна больше 5'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-237-3819433a1a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Нарушения сна больше 5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# X = data.drop(columns=['Нарушения сна больше 5'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Пол'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Удовлетворенность семейными отношениями'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ЧМТ'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Стаж шизофр'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Образование'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Насл отягощенность'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'G'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# X = data[[ 'P', 'N', 'G']] # Only with these 3 values we can get very good result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Нарушения сна больше 5'"
          ]
        }
      ],
      "source": [
        "y = data['Нарушения сна больше 5']\n",
        "# X = data.drop(columns=['Нарушения сна больше 5'])\n",
        "# X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование']]\n",
        "X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "# X = data[[ 'P', 'N', 'G']] # Only with these 3 values we can get very good result\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kZTjgK7vMG8"
      },
      "outputs": [],
      "source": [
        "# Scale X from 0 to 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "X_train_scaled = minmax_scaler.fit_transform(X_train)\n",
        "X_valid_scaled = minmax_scaler.transform(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOQOcCCXPrrL"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.003), # lr=0.003\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Create a learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # Learning rate will increase at each epoch\n",
        "\n",
        "history0 = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVMn6WFCPEHX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zFAGeTMPvxf"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXokhoC2PwQk"
      },
      "source": [
        "### Find bels LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH0ZyOMevW6o"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(), # lr=0.003\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Create a learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # Learning rate will increase at each epoch\n",
        "\n",
        "history_lr = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWTprQ0aOC_S"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the learning rate vs loss\n",
        "lrs = 1e-4 * (10 ** (tf.range(100)/20))\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, history_lr.history[\"loss\"]) # lrs - x-axis, history - y-axis\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs. loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPZdm2LqvMQs"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history1 = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJCjkFO-Pb3f"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1n34k49Pebz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqB5o19TPfeV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pofTvAKuPfhO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XzO4JMrPfjd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtdAN5vAPfmH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMlFZkEuPCer"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jzqVz0-vMSw"
      },
      "outputs": [],
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AdEsLsQhl-L"
      },
      "outputs": [],
      "source": [
        "train_data = data[:121] # 70%\n",
        "validation_data = data[121:155] # 20%\n",
        "test_data = data[155:174] # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD1BAgypjWbC"
      },
      "outputs": [],
      "source": [
        "y_train = train_data['Нарушения сна больше 5']\n",
        "y_validation = validation_data['Нарушения сна больше 5']\n",
        "y_test = test_data['Нарушения сна больше 5']\n",
        "\n",
        "X_train = train_data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "X_validation = validation_data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "X_test = test_data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgi-q_Iujyt-"
      },
      "outputs": [],
      "source": [
        "len(y_train), len(y_validation), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w3owV7dhnfn"
      },
      "outputs": [],
      "source": [
        "# y = data['Нарушения сна']\n",
        "# # X = data.drop(columns=['Нарушения сна'])\n",
        "# # X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование']]\n",
        "# # X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "# X = data[[ 'P', 'N', 'G']] # Only with these 3 values we can get very good result\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5EEQckhaLgC"
      },
      "outputs": [],
      "source": [
        "# Scale X from 0 to 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_validation_scaled = scaler.fit_transform(X_validation)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVjPP8UokzzF"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(), # lr=0.03\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_validation_scaled, y_validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc5mFrJQhMsd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEAMkOEmhOE9"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yZGlBKrhNN1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrA_ArvkOh9c"
      },
      "source": [
        "### It is very likely that the model has overfitted. It is necessary to add data augmentation, validation data, visualization\n",
        "Find best lr\n",
        "\n",
        "Вывести наиболее значимые характеристики\n",
        "\n",
        "\n",
        "\n",
        "Check result on different scalers. For example:\n",
        "\n",
        "1) Min Max Scaler (try it)\n",
        "\n",
        "2) Standard Scaler\n",
        "\n",
        "3) Max Abs Scaler\n",
        "\n",
        "4) Robust Scaler\n",
        "\n",
        "5) Quantile Transformer Scaler\n",
        "\n",
        "6) Power Transformer Scaler\n",
        "\n",
        "7) Unit Vector Scaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io90TB1dlcBf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDAqLqo5DT74"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNhuw9AgDT-L"
      },
      "outputs": [],
      "source": [
        "# Let's try to use 'Нарушения сна' as y value\n",
        "data = ds.drop(columns=['Тревога больше 7', 'Madrs больше 6', 'Калгари больше 5'])\n",
        "y = data['Нарушения сна больше 5']\n",
        "# X = data.drop(columns=['Нарушения сна'])\n",
        "X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']] # 'Были ли нарушения сна', \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,)\n",
        "\n",
        "# Scale X from 0 to 1\n",
        "scaler2 = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler2.fit_transform(X_train)\n",
        "X_test_scaled = scaler2.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR0dXD6DEdDg"
      },
      "outputs": [],
      "source": [
        "X_train_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKvqJHX3DWyj"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(), # lr=0.03\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history2 = model2.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGzI7qA1DrxS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "mental_disorders.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+Bvt8NHHk+YHVS1e6F6bU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}