{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitaion/mental_disorders/blob/main/mental_disorders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 915,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xviXFSvcd-gZ",
        "outputId": "fa941879-3d3a-4691-d718-6b139ea7b40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-12 07:34:11--  https://raw.githubusercontent.com/Nikitaion/mental_disorders/main/data/290622_mental_disorders_data_without_somatika.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13658 (13K) [text/plain]\n",
            "Saving to: ‘ds.csv’\n",
            "\n",
            "\rds.csv                0%[                    ]       0  --.-KB/s               \rds.csv              100%[===================>]  13.34K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-12 07:34:11 (27.7 MB/s) - ‘ds.csv’ saved [13658/13658]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Nikitaion/mental_disorders/main/data/290622_mental_disorders_data_without_somatika.csv -O ds.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 916,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6YXg1QZeuWS",
        "outputId": "6531ab9b-e25f-4a67-d8cc-9a3187c31b29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import  train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 917,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "0lKSFBRwg3oI",
        "outputId": "1f9f14ae-967a-4f1a-e8ed-08032fbdc35c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Снинговый номер Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "0            УП-1   М          32                                   4   \n",
              "1            УП-2   М          26                                   2   \n",
              "2            УП-3   М          49                                   2   \n",
              "3            УП-4   М          50                                   2   \n",
              "4            УП-6   М          39                                   2   \n",
              "\n",
              "   Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "0                            0                                 0   \n",
              "1                            0                                 0   \n",
              "2                            0                                 0   \n",
              "3                            0                                 0   \n",
              "4                            0                                 0   \n",
              "\n",
              "   Удовлетворенность семеными отношениями  \\\n",
              "0                                       5   \n",
              "1                                       5   \n",
              "2                                       5   \n",
              "3                                       5   \n",
              "4                                       5   \n",
              "\n",
              "   Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "0                                          0                    7   \n",
              "1                                          0                   10   \n",
              "2                                          1                   10   \n",
              "3                                          1                    7   \n",
              "4                                          1                    7   \n",
              "\n",
              "   Были ли нарушения сна  ...  Частота госпит  Стаж шизофр   P   N   G  PSQI  \\\n",
              "0                      1  ...               0          3.7  11  11  18     6   \n",
              "1                      1  ...               1          2.0  10  25  36     8   \n",
              "2                      0  ...               2         23.0   9  16  23     3   \n",
              "3                      1  ...               1         34.0  13  13  20     6   \n",
              "4                      0  ...               0          4.0   9  13  22     4   \n",
              "\n",
              "   psqi больше 5  (ТРЕВОГА)Гаиильтон больше 16  (ДЕПРЕССИЯ)madrs больше 6  \\\n",
              "0              1                             0                          0   \n",
              "1              1                             0                          1   \n",
              "2              0                             0                          0   \n",
              "3              1                             0                          0   \n",
              "4              0                             0                          0   \n",
              "\n",
              "   (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "0                            0  \n",
              "1                            1  \n",
              "2                            0  \n",
              "3                            0  \n",
              "4                            0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90eb7080-a32a-40cf-a4fa-d807fd495005\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Снинговый номер</th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>...</th>\n",
              "      <th>Частота госпит</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>PSQI</th>\n",
              "      <th>psqi больше 5</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>УП-1</td>\n",
              "      <td>М</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>УП-2</td>\n",
              "      <td>М</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>УП-3</td>\n",
              "      <td>М</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>УП-4</td>\n",
              "      <td>М</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>УП-6</td>\n",
              "      <td>М</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90eb7080-a32a-40cf-a4fa-d807fd495005')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90eb7080-a32a-40cf-a4fa-d807fd495005 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90eb7080-a32a-40cf-a4fa-d807fd495005');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 917
        }
      ],
      "source": [
        "ds = pd.read_csv(\"/content/ds.csv\")\n",
        "ds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 918,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "ASj1vcYIhAzw",
        "outputId": "ec7de39c-e45c-4646-a36a-d9acd7a8aa8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Снинговый номер Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "170           УФ-32   М          35                                   3   \n",
              "171           УФ-33   М          57                                   2   \n",
              "172           УФ-34   М          24                                   4   \n",
              "173         УФ-33-2   М          41                                   2   \n",
              "174         УФ-34-2   М          32                                   2   \n",
              "\n",
              "     Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "170                            0                                 0   \n",
              "171                            0                                 0   \n",
              "172                            1                                 0   \n",
              "173                            0                                 0   \n",
              "174                            0                                 0   \n",
              "\n",
              "     Удовлетворенность семеными отношениями  \\\n",
              "170                                       2   \n",
              "171                                       1   \n",
              "172                                       5   \n",
              "173                                       3   \n",
              "174                                       5   \n",
              "\n",
              "     Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "170                                          0                    7   \n",
              "171                                          0                    9   \n",
              "172                                          1                   10   \n",
              "173                                          0                    9   \n",
              "174                                          1                   10   \n",
              "\n",
              "     Были ли нарушения сна  ...  Частота госпит  Стаж шизофр   P   N   G  \\\n",
              "170                      1  ...               0         16.0  19   8  31   \n",
              "171                      1  ...               0         35.0  10  10  23   \n",
              "172                      1  ...               0          6.0   7   9  27   \n",
              "173                      1  ...               2         13.0  14  13  21   \n",
              "174                      1  ...               1          9.0   7  12  28   \n",
              "\n",
              "     PSQI  psqi больше 5  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "170     5              0                             0   \n",
              "171     5              0                             0   \n",
              "172     5              0                             0   \n",
              "173     9              1                             1   \n",
              "174     6              1                             0   \n",
              "\n",
              "     (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "170                          1                            1  \n",
              "171                          0                            0  \n",
              "172                          0                            0  \n",
              "173                          1                            0  \n",
              "174                          1                            0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d3d6748-f151-44cd-b2fc-190929fbf1e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Снинговый номер</th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>...</th>\n",
              "      <th>Частота госпит</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>PSQI</th>\n",
              "      <th>psqi больше 5</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>УФ-32</td>\n",
              "      <td>М</td>\n",
              "      <td>35</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>УФ-33</td>\n",
              "      <td>М</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>УФ-34</td>\n",
              "      <td>М</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>УФ-33-2</td>\n",
              "      <td>М</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>УФ-34-2</td>\n",
              "      <td>М</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d3d6748-f151-44cd-b2fc-190929fbf1e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d3d6748-f151-44cd-b2fc-190929fbf1e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d3d6748-f151-44cd-b2fc-190929fbf1e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 918
        }
      ],
      "source": [
        "ds.tail()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_N2ueZDTxGN",
        "outputId": "d62cbdd9-941c-4adb-c6a5-3081f3786732"
      },
      "execution_count": 781,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 175 entries, 0 to 174\n",
            "Data columns (total 25 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Снинговый номер                            175 non-null    object \n",
            " 1   Пол                                        175 non-null    object \n",
            " 2   Полных лет                                 175 non-null    int64  \n",
            " 3   Образование(0-начальное, 4-высшее)         175 non-null    int64  \n",
            " 4   Род занятий(0-0, работает-1                175 non-null    int64  \n",
            " 5   Семейное положение(0-0, 1-женат)           175 non-null    int64  \n",
            " 6   Удовлетворенность семеными отношениями     175 non-null    int64  \n",
            " 7   Удовлетворенность материальным положением  175 non-null    int64  \n",
            " 8   Здоровье от 1 до 10                        175 non-null    int64  \n",
            " 9   Были ли нарушения сна                      175 non-null    int64  \n",
            " 10  ИМТ                                        175 non-null    float64\n",
            " 11  Операции                                   175 non-null    int64  \n",
            " 12  ЧМТ                                        175 non-null    int64  \n",
            " 13  Насл отягощенность                         175 non-null    int64  \n",
            " 14  Дебют                                      175 non-null    float64\n",
            " 15  Частота госпит                             175 non-null    int64  \n",
            " 16  Стаж шизофр                                175 non-null    float64\n",
            " 17  P                                          175 non-null    int64  \n",
            " 18  N                                          175 non-null    int64  \n",
            " 19  G                                          175 non-null    int64  \n",
            " 20  PSQI                                       175 non-null    int64  \n",
            " 21  psqi больше 5                              175 non-null    int64  \n",
            " 22  (ТРЕВОГА)Гаиильтон больше 16               175 non-null    int64  \n",
            " 23  (ДЕПРЕССИЯ)madrs больше 6                  175 non-null    int64  \n",
            " 24  (ДЕПРЕССИЯ)Калгари больше 5                175 non-null    int64  \n",
            "dtypes: float64(3), int64(20), object(2)\n",
            "memory usage: 34.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ydmKTum1euwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FV4kacAYeuzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[['N', 'PSQI']]"
      ],
      "metadata": {
        "id": "E1-ZYGviVJA_",
        "outputId": "1492a8ea-10bd-44cc-b7aa-27ddae33ec44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 920,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      N  PSQI\n",
              "0    11     6\n",
              "1    25     8\n",
              "2    16     3\n",
              "3    13     6\n",
              "4    13     4\n",
              "..   ..   ...\n",
              "170   8     5\n",
              "171  10     5\n",
              "172   9     5\n",
              "173  13     9\n",
              "174  12     6\n",
              "\n",
              "[175 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-759f3d90-402f-4639-989c-c1e402b60423\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N</th>\n",
              "      <th>PSQI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-759f3d90-402f-4639-989c-c1e402b60423')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-759f3d90-402f-4639-989c-c1e402b60423 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-759f3d90-402f-4639-989c-c1e402b60423');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 920
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp\n",
        "tfp.stats.correlation(ds['PSQI'], ds['N'])"
      ],
      "metadata": {
        "id": "MryEqya5VJDa",
        "outputId": "55c000a3-0ddd-45da-f046-7a66c28e27f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": 924,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-924-48dc3684d902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PSQI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/stats/sample_stats.py\u001b[0m in \u001b[0;36mcorrelation\u001b[0;34m(x, y, sample_axis, event_axis, keepdims, name)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;31m# difficulties with the various options for sample/event axis kwargs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/stats/sample_stats.py\u001b[0m in \u001b[0;36mstddev\u001b[0;34m(x, sample_axis, keepdims, name)\u001b[0m\n\u001b[1;32m    600\u001b[0m   \"\"\"\n\u001b[1;32m    601\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'stddev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int64 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2oclsp8-VJF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UgENhvX1VJJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5kHDI6VTxyX",
        "outputId": "7075f603-6b40-4dfa-9ae2-6675ff135d15"
      },
      "execution_count": 782,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Снинговый номер                              0\n",
              "Пол                                          0\n",
              "Полных лет                                   0\n",
              "Образование(0-начальное, 4-высшее)           0\n",
              "Род занятий(0-0, работает-1                  0\n",
              "Семейное положение(0-0, 1-женат)             0\n",
              "Удовлетворенность семеными отношениями       0\n",
              "Удовлетворенность материальным положением    0\n",
              "Здоровье от 1 до 10                          0\n",
              "Были ли нарушения сна                        0\n",
              "ИМТ                                          0\n",
              "Операции                                     0\n",
              "ЧМТ                                          0\n",
              "Насл отягощенность                           0\n",
              "Дебют                                        0\n",
              "Частота госпит                               0\n",
              "Стаж шизофр                                  0\n",
              "P                                            0\n",
              "N                                            0\n",
              "G                                            0\n",
              "PSQI                                         0\n",
              "psqi больше 5                                0\n",
              "(ТРЕВОГА)Гаиильтон больше 16                 0\n",
              "(ДЕПРЕССИЯ)madrs больше 6                    0\n",
              "(ДЕПРЕССИЯ)Калгари больше 5                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 782
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TXPhKu8mT4cS"
      },
      "execution_count": 782,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 783,
      "metadata": {
        "id": "pEJ79uoXQZdV"
      },
      "outputs": [],
      "source": [
        "# drop unnecessary columns\n",
        "ds = ds.drop(columns=['Снинговый номер'])\n",
        "# ds = ds.drop(columns=['Здоровье от 1 до 10', 'Удовлетворенность материальным положением', 'Рост', 'Вес', 'BARS (акатизия)', 'SAS (Экстрапир)', 'AIMS (непр дв)', 'ESS', 'шкала общего клин впечатления', 'шкала соц функционир'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 784,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-YpnvKCkznI",
        "outputId": "a050c493-b6cf-4e06-fdd5-67238f566ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 175 entries, 0 to 174\n",
            "Data columns (total 24 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Пол                                        175 non-null    object \n",
            " 1   Полных лет                                 175 non-null    int64  \n",
            " 2   Образование(0-начальное, 4-высшее)         175 non-null    int64  \n",
            " 3   Род занятий(0-0, работает-1                175 non-null    int64  \n",
            " 4   Семейное положение(0-0, 1-женат)           175 non-null    int64  \n",
            " 5   Удовлетворенность семеными отношениями     175 non-null    int64  \n",
            " 6   Удовлетворенность материальным положением  175 non-null    int64  \n",
            " 7   Здоровье от 1 до 10                        175 non-null    int64  \n",
            " 8   Были ли нарушения сна                      175 non-null    int64  \n",
            " 9   ИМТ                                        175 non-null    float64\n",
            " 10  Операции                                   175 non-null    int64  \n",
            " 11  ЧМТ                                        175 non-null    int64  \n",
            " 12  Насл отягощенность                         175 non-null    int64  \n",
            " 13  Дебют                                      175 non-null    float64\n",
            " 14  Частота госпит                             175 non-null    int64  \n",
            " 15  Стаж шизофр                                175 non-null    float64\n",
            " 16  P                                          175 non-null    int64  \n",
            " 17  N                                          175 non-null    int64  \n",
            " 18  G                                          175 non-null    int64  \n",
            " 19  PSQI                                       175 non-null    int64  \n",
            " 20  psqi больше 5                              175 non-null    int64  \n",
            " 21  (ТРЕВОГА)Гаиильтон больше 16               175 non-null    int64  \n",
            " 22  (ДЕПРЕССИЯ)madrs больше 6                  175 non-null    int64  \n",
            " 23  (ДЕПРЕССИЯ)Калгари больше 5                175 non-null    int64  \n",
            "dtypes: float64(3), int64(20), object(1)\n",
            "memory usage: 32.9+ KB\n"
          ]
        }
      ],
      "source": [
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "psWgB8oSkcF-"
      },
      "execution_count": 784,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Пол'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy9-88v9bi2u",
        "outputId": "e154c1bc-a7d8-4906-a3d8-3236488cd4dd"
      },
      "execution_count": 785,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "М    132\n",
              "Ж     43\n",
              "Name: Пол, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 785
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Пол'] = np.where(ds['Пол']=='М',1,0)"
      ],
      "metadata": {
        "id": "0HsMmuGXbX0i"
      },
      "execution_count": 786,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Пол'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTxS-svEbkoK",
        "outputId": "594187a3-ec37-473e-811b-3d28a9de4adf"
      },
      "execution_count": 787,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    132\n",
              "0     43\n",
              "Name: Пол, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 787
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 788,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "eYGpxa6cG2Oi",
        "outputId": "2e4abfa2-352b-4e78-a337-df9e5ebd8dd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "0    1          32                                   4   \n",
              "1    1          26                                   2   \n",
              "2    1          49                                   2   \n",
              "3    1          50                                   2   \n",
              "4    1          39                                   2   \n",
              "\n",
              "   Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "0                            0                                 0   \n",
              "1                            0                                 0   \n",
              "2                            0                                 0   \n",
              "3                            0                                 0   \n",
              "4                            0                                 0   \n",
              "\n",
              "   Удовлетворенность семеными отношениями  \\\n",
              "0                                       5   \n",
              "1                                       5   \n",
              "2                                       5   \n",
              "3                                       5   \n",
              "4                                       5   \n",
              "\n",
              "   Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "0                                          0                    7   \n",
              "1                                          0                   10   \n",
              "2                                          1                   10   \n",
              "3                                          1                    7   \n",
              "4                                          1                    7   \n",
              "\n",
              "   Были ли нарушения сна        ИМТ  ...  Частота госпит  Стаж шизофр   P   N  \\\n",
              "0                      1  24.012346  ...               0          3.7  11  11   \n",
              "1                      1  20.244898  ...               1          2.0  10  25   \n",
              "2                      0  29.752744  ...               2         23.0   9  16   \n",
              "3                      1  22.093170  ...               1         34.0  13  13   \n",
              "4                      0  20.761246  ...               0          4.0   9  13   \n",
              "\n",
              "    G  PSQI  psqi больше 5  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "0  18     6              1                             0   \n",
              "1  36     8              1                             0   \n",
              "2  23     3              0                             0   \n",
              "3  20     6              1                             0   \n",
              "4  22     4              0                             0   \n",
              "\n",
              "   (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "0                          0                            0  \n",
              "1                          1                            1  \n",
              "2                          0                            0  \n",
              "3                          0                            0  \n",
              "4                          0                            0  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2a1e4ed-2b42-4ac2-8006-de042ca3718a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>ИМТ</th>\n",
              "      <th>...</th>\n",
              "      <th>Частота госпит</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>PSQI</th>\n",
              "      <th>psqi больше 5</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>24.012346</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>20.244898</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>29.752744</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>22.093170</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>20.761246</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2a1e4ed-2b42-4ac2-8006-de042ca3718a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2a1e4ed-2b42-4ac2-8006-de042ca3718a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2a1e4ed-2b42-4ac2-8006-de042ca3718a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 788
        }
      ],
      "source": [
        "ds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 789,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dNDEEZMXqCI",
        "outputId": "d9185011-5719-46ac-c3cc-3836bd3b38c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Пол                                          0\n",
              "Полных лет                                   0\n",
              "Образование(0-начальное, 4-высшее)           0\n",
              "Род занятий(0-0, работает-1                  0\n",
              "Семейное положение(0-0, 1-женат)             0\n",
              "Удовлетворенность семеными отношениями       0\n",
              "Удовлетворенность материальным положением    0\n",
              "Здоровье от 1 до 10                          0\n",
              "Были ли нарушения сна                        0\n",
              "ИМТ                                          0\n",
              "Операции                                     0\n",
              "ЧМТ                                          0\n",
              "Насл отягощенность                           0\n",
              "Дебют                                        0\n",
              "Частота госпит                               0\n",
              "Стаж шизофр                                  0\n",
              "P                                            0\n",
              "N                                            0\n",
              "G                                            0\n",
              "PSQI                                         0\n",
              "psqi больше 5                                0\n",
              "(ТРЕВОГА)Гаиильтон больше 16                 0\n",
              "(ДЕПРЕССИЯ)madrs больше 6                    0\n",
              "(ДЕПРЕССИЯ)Калгари больше 5                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 789
        }
      ],
      "source": [
        "# Check for na values\n",
        "ds.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 790,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kak3ZDUIIWNo",
        "outputId": "d174a187-33a1-47bf-dfbc-304b2678ad00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 175 entries, 0 to 174\n",
            "Data columns (total 24 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Пол                                        175 non-null    int64  \n",
            " 1   Полных лет                                 175 non-null    int64  \n",
            " 2   Образование(0-начальное, 4-высшее)         175 non-null    int64  \n",
            " 3   Род занятий(0-0, работает-1                175 non-null    int64  \n",
            " 4   Семейное положение(0-0, 1-женат)           175 non-null    int64  \n",
            " 5   Удовлетворенность семеными отношениями     175 non-null    int64  \n",
            " 6   Удовлетворенность материальным положением  175 non-null    int64  \n",
            " 7   Здоровье от 1 до 10                        175 non-null    int64  \n",
            " 8   Были ли нарушения сна                      175 non-null    int64  \n",
            " 9   ИМТ                                        175 non-null    float64\n",
            " 10  Операции                                   175 non-null    int64  \n",
            " 11  ЧМТ                                        175 non-null    int64  \n",
            " 12  Насл отягощенность                         175 non-null    int64  \n",
            " 13  Дебют                                      175 non-null    float64\n",
            " 14  Частота госпит                             175 non-null    int64  \n",
            " 15  Стаж шизофр                                175 non-null    float64\n",
            " 16  P                                          175 non-null    int64  \n",
            " 17  N                                          175 non-null    int64  \n",
            " 18  G                                          175 non-null    int64  \n",
            " 19  PSQI                                       175 non-null    int64  \n",
            " 20  psqi больше 5                              175 non-null    int64  \n",
            " 21  (ТРЕВОГА)Гаиильтон больше 16               175 non-null    int64  \n",
            " 22  (ДЕПРЕССИЯ)madrs больше 6                  175 non-null    int64  \n",
            " 23  (ДЕПРЕССИЯ)Калгари больше 5                175 non-null    int64  \n",
            "dtypes: float64(3), int64(21)\n",
            "memory usage: 32.9 KB\n"
          ]
        }
      ],
      "source": [
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 791,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLmf_yhQIdAS",
        "outputId": "bd0b1dc5-c449-40c4-fe8d-4b7b34b7e11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 175 entries, 0 to 174\n",
            "Data columns (total 24 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   Пол                                        175 non-null    float32\n",
            " 1   Полных лет                                 175 non-null    float32\n",
            " 2   Образование(0-начальное, 4-высшее)         175 non-null    float32\n",
            " 3   Род занятий(0-0, работает-1                175 non-null    float32\n",
            " 4   Семейное положение(0-0, 1-женат)           175 non-null    float32\n",
            " 5   Удовлетворенность семеными отношениями     175 non-null    float32\n",
            " 6   Удовлетворенность материальным положением  175 non-null    float32\n",
            " 7   Здоровье от 1 до 10                        175 non-null    float32\n",
            " 8   Были ли нарушения сна                      175 non-null    float32\n",
            " 9   ИМТ                                        175 non-null    float32\n",
            " 10  Операции                                   175 non-null    float32\n",
            " 11  ЧМТ                                        175 non-null    float32\n",
            " 12  Насл отягощенность                         175 non-null    float32\n",
            " 13  Дебют                                      175 non-null    float32\n",
            " 14  Частота госпит                             175 non-null    float32\n",
            " 15  Стаж шизофр                                175 non-null    float32\n",
            " 16  P                                          175 non-null    float32\n",
            " 17  N                                          175 non-null    float32\n",
            " 18  G                                          175 non-null    float32\n",
            " 19  PSQI                                       175 non-null    float32\n",
            " 20  psqi больше 5                              175 non-null    float32\n",
            " 21  (ТРЕВОГА)Гаиильтон больше 16               175 non-null    float32\n",
            " 22  (ДЕПРЕССИЯ)madrs больше 6                  175 non-null    float32\n",
            " 23  (ДЕПРЕССИЯ)Калгари больше 5                175 non-null    float32\n",
            "dtypes: float32(24)\n",
            "memory usage: 16.5 KB\n"
          ]
        }
      ],
      "source": [
        "# turn dataset to float32\n",
        "ds = ds.astype(np.float32)\n",
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 792,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Ai6pimUakX",
        "outputId": "9d24c8c2-206e-46a4-ecb7-682a8ea40311"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    103\n",
              "0.0     72\n",
              "Name: psqi больше 5, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 792
        }
      ],
      "source": [
        "ds['psqi больше 5'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 793,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fytj8feUaq7",
        "outputId": "c4ae6cc0-2df4-4573-d945-20d76e2ded0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    135\n",
              "1.0     40\n",
              "Name: (ТРЕВОГА)Гаиильтон больше 16, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 793
        }
      ],
      "source": [
        "ds['(ТРЕВОГА)Гаиильтон больше 16'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 794,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z96bukAkUata",
        "outputId": "c9385a8f-73e5-49d3-c7b5-6aef1ec91db2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    116\n",
              "1.0     59\n",
              "Name: (ДЕПРЕССИЯ)madrs больше 6, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 794
        }
      ],
      "source": [
        "ds['(ДЕПРЕССИЯ)madrs больше 6'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['(ДЕПРЕССИЯ)Калгари больше 5'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2SUV1exnNuK",
        "outputId": "0d88479c-c530-4ec3-ed6c-f21b6d34e27f"
      },
      "execution_count": 795,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    136\n",
              "1.0     39\n",
              "Name: (ДЕПРЕССИЯ)Калгари больше 5, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 795
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 796,
      "metadata": {
        "id": "z0Fx5Wsrk2mi"
      },
      "outputs": [],
      "source": [
        "# Let's try to use 'psqi больше 5' as y value\n",
        "data = ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 797,
      "metadata": {
        "id": "x-rJ0J9gvL8Q"
      },
      "outputs": [],
      "source": [
        "# Create X, y\n",
        "y = data['psqi больше 5']\n",
        "X = data.drop(columns=['PSQI', 'psqi больше 5', '(ТРЕВОГА)Гаиильтон больше 16', '(ДЕПРЕССИЯ)madrs больше 6', '(ДЕПРЕССИЯ)Калгари больше 5'])\n",
        "# X = data.drop(columns=['Нарушения сна больше 5'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JV3JWvaa8vS2"
      },
      "execution_count": 797,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "I1vVG5N_8vWH",
        "outputId": "d738af38-9a38-4352-d3ff-4a936f65d01a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 798,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Пол', 'Полных лет', 'Образование(0-начальное, 4-высшее)',\n",
              "       'Род занятий(0-0, работает-1', 'Семейное положение(0-0, 1-женат)',\n",
              "       'Удовлетворенность семеными отношениями',\n",
              "       'Удовлетворенность материальным положением', 'Здоровье от 1 до 10',\n",
              "       'Были ли нарушения сна', 'ИМТ', 'Операции', 'ЧМТ', 'Насл отягощенность',\n",
              "       'Дебют', 'Частота госпит', 'Стаж шизофр', 'P', 'N', 'G'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 798
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Пол'].plot.hist()"
      ],
      "metadata": {
        "id": "TvFjqRJs9FKq",
        "outputId": "e2422208-35b3-4e9e-be8f-9e686cf0302e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 799,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f66319c6bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 799
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Полных лет'].plot.hist()"
      ],
      "metadata": {
        "id": "cSzNKuAE8vY0",
        "outputId": "8364a4fc-dbe3-4dd1-b2ee-6125af7f6171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 800,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f663570b490>"
            ]
          },
          "metadata": {},
          "execution_count": 800
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Образование(0-начальное, 4-высшее)'].plot.hist()"
      ],
      "metadata": {
        "id": "rS7RThGt8vbA",
        "outputId": "7e9ec51a-9a63-4608-f76b-bb17c59889b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 801,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6631c86f90>"
            ]
          },
          "metadata": {},
          "execution_count": 801
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQmklEQVR4nO3de7BdZX3G8e8DwQLeUJMiJWCwMipVqDEiHUZLoU5RFGilFMdLoGhar1g6I8g4YjvTGZxpRbQXTcE2eCuIVhCwHUTU6R8GE6Ryk5JB0CBIvBFURor++sdeeXua5pCV5Oy9zuX7mdlz1uXde/3evDl5si57rVQVkiQB7DZ0AZKk2cNQkCQ1hoIkqTEUJEmNoSBJahYNXcCuWLx4cS1btmzoMiRpTlm/fv33q2rJttbN6VBYtmwZ69atG7oMSZpTktw93ToPH0mSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJKaOf2NZs0dy86+apDt3nXecYNsV5qr3FOQJDWGgiSpMRQkSY2hIElqDAVJUjO2UEjykST3J7l5yrInJ7kmyR3dzyd1y5PkA0k2JPlGkuXjqkuSNL1x7in8M3DsVsvOBq6tqoOBa7t5gJcCB3evVcA/jLEuSdI0xhYKVfUV4IdbLT4BWNNNrwFOnLL84hr5KrBPkv3GVZskadsmfU5h36q6t5u+D9i3m94f+M6Udhu7ZZKkCRrsRHNVFVA7+r4kq5KsS7Ju06ZNY6hMkhauSYfC97YcFup+3t8tvwc4YEq7pd2y/6eqVlfViqpasWTJkrEWK0kLzaRD4QpgZTe9Erh8yvLXdVchHQE8MOUwkyRpQsZ2Q7wknwSOAhYn2QicC5wHXJrkdOBu4OSu+dXAy4ANwM+A08ZVlyRpemMLhap61TSrjtlG2wLePK5aJEn9+I1mSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSc0goZDkz5LckuTmJJ9MsmeSg5KsTbIhySVJHjNEbZK0kE08FJLsD7wNWFFVzwF2B04B3gucX1XPAH4EnD7p2iRpoRvq8NEiYK8ki4C9gXuBo4HLuvVrgBMHqk2SFqyJh0JV3QP8NfBtRmHwALAe+HFVPdI12wjsv633J1mVZF2SdZs2bZpEyZK0YAxx+OhJwAnAQcCvAY8Fju37/qpaXVUrqmrFkiVLxlSlJC1MQxw++l3gW1W1qar+G/gMcCSwT3c4CWApcM8AtUnSgjZEKHwbOCLJ3kkCHAPcClwHnNS1WQlcPkBtkrSgDXFOYS2jE8o3ADd1NawGzgLOTLIBeApw0aRrk6SFbtH2m8y8qjoXOHerxXcChw9QjiSp4zeaJUmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkppeoZDkueMuRJI0vL57Cn+f5Pokb0ryxLFWJEkaTK9QqKoXAa8GDgDWJ/lEkpeMtTJJ0sT1PqdQVXcA7wLOAn4b+ECSbyb5g3EVJ0marL7nFA5Ncj5wG3A08IqqenY3ff4Y65MkTdCinu0+CFwInFNVD21ZWFXfTfKusVQmSZq4vqFwHPBQVf0CIMluwJ5V9bOq+ujYqpMkTVTfcwpfAPaaMr93t0ySNI/0DYU9q+onW2a66b3HU5IkaSh9Q+GnSZZvmUnyfOChR2kvSZqD+p5TeDvwqSTfBQI8Ffijnd1okn0Ynbh+DlDAHwO3A5cAy4C7gJOr6kc7uw1J0o7r++W1rwHPAt4I/Cnw7KpavwvbvQD4t6p6FnAYo0tdzwauraqDgWu7eUnSBPXdUwB4AaP/xS8Cliehqi7e0Q12t8l4MXAqQFU9DDyc5ATgqK7ZGuBLjL4oJ0makF6hkOSjwK8DNwK/6BYXsMOhABwEbAL+KclhwHrgDGDfqrq3a3MfsO80tawCVgEceOCBO7F5SdJ0+u4prAAOqaqaoW0uB95aVWuTXMBWh4qqqpJsc1tVtRpYDbBixYqZqEeS1Ol79dHNjE4uz4SNwMaqWtvNX8YoJL6XZD+A7uf9M7Q9SVJPffcUFgO3Jrke+PmWhVV1/I5usKruS/KdJM+sqtuBY4Bbu9dK4Lzu5+U7+tmSpF3TNxTeM8PbfSvw8SSPAe4ETmO013JpktOBu4GTZ3ibkqTt6BUKVfXlJE8DDq6qLyTZG9h9ZzdaVTcyOk+xtWN29jMlSbuu762z38Do2P+Hu0X7A58dV1GSpGH0PdH8ZuBIYDO0B+786riKkiQNo28o/Lz7khkASRYx+p6CJGke6RsKX05yDrBX92zmTwGfG19ZkqQh9A2Fsxl9C/km4E+Aqxk9r1mSNI/0vfrol8A/di9J0jzV995H32Ib5xCq6ukzXpEkaTA7cu+jLfYE/hB48syXI0kaUt/nKfxgyuueqno/cNyYa5MkTVjfw0fLp8zuxmjPYUeexSBJmgP6/sP+N1OmH6F7XOaMVyNJGlTfq49+Z9yFSJKG1/fw0ZmPtr6q3jcz5UiShrQjVx+9ALiim38FcD1wxziKkiQNo28oLAWWV9WDAEneA1xVVa8ZV2GSpMnre5uLfYGHp8w/3C2TJM0jffcULgauT/Kv3fyJwJrxlCRJGkrfq4/+KsnngRd1i06rqq+PryxJ0hD6Hj4C2BvYXFUXABuTHDSmmiRJA+n7OM5zgbOAd3aL9gA+Nq6iJEnD6Lun8PvA8cBPAarqu8Djx1WUJGkYfUPh4aoquttnJ3ns+EqSJA2lbyhcmuTDwD5J3gB8AR+4I0nzznavPkoS4BLgWcBm4JnAu6vqmjHXJkmasO2GQlVVkqur6rmAQSBJ81jfw0c3JHnBWCuRJA2u7zeaXwi8JsldjK5ACqOdiEPHVZgkafIeNRSSHFhV3wZ+b0L1SJIGtL09hc8yujvq3Uk+XVWvnERRkqRhbO+cQqZMP32chUiShre9UKhppiVJ89D2QuGwJJuTPAgc2k1vTvJgks27suEkuyf5epIru/mDkqxNsiHJJUkesyufL0nacY8aClW1e1U9oaoeX1WLuukt80/YxW2fAdw2Zf69wPlV9QzgR8Dpu/j5kqQdtCO3zp4xSZYCxwEXdvMBjgYu65qsYfQgH0nSBA0SCsD7gXcAv+zmnwL8uKoe6eY3Avtv641JViVZl2Tdpk2bxl+pJC0gEw+FJC8H7q+q9Tvz/qpaXVUrqmrFkiVLZrg6SVrY+n6jeSYdCRyf5GXAnsATgAsY3YF1Ube3sBS4Z4DaJGlBm/ieQlW9s6qWVtUy4BTgi1X1auA64KSu2Urg8knXJkkL3VDnFLblLODMJBsYnWO4aOB6JGnBGeLwUVNVXwK+1E3fCRw+ZD2StNDNpj0FSdLADAVJUjPo4SNJmsuWnX3VYNu+67zjxvK57ilIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGZzRL88xQzw0e1zODNVnuKUiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqJh4KSQ5Icl2SW5PckuSMbvmTk1yT5I7u55MmXZskLXRD7Ck8Avx5VR0CHAG8OckhwNnAtVV1MHBtNy9JmqCJh0JV3VtVN3TTDwK3AfsDJwBrumZrgBMnXZskLXSDnlNIsgx4HrAW2Leq7u1W3QfsO817ViVZl2Tdpk2bJlKnJC0Ug4VCkscBnwbeXlWbp66rqgJqW++rqtVVtaKqVixZsmQClUrSwjFIKCTZg1EgfLyqPtMt/l6S/br1+wH3D1GbJC1kQ1x9FOAi4Laqet+UVVcAK7vplcDlk65Nkha6IW6dfSTwWuCmJDd2y84BzgMuTXI6cDdw8gC1SdKCNvFQqKr/ADLN6mMmWYsk6f/yG82SpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNUM8o3lWWHb2VYNt+67zjhts25L0aNxTkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqZlUoJDk2ye1JNiQ5e+h6JGmhmTWhkGR34O+AlwKHAK9KcsiwVUnSwjJrQgE4HNhQVXdW1cPAvwAnDFyTJC0oqaqhawAgyUnAsVX1+m7+tcALq+otW7VbBazqZp8J3L6Tm1wMfH8n3zvb2JfZZ770A+zLbLUrfXlaVS3Z1oo595CdqloNrN7Vz0myrqpWzEBJg7Mvs8986QfYl9lqXH2ZTYeP7gEOmDK/tFsmSZqQ2RQKXwMOTnJQkscApwBXDFyTJC0os+bwUVU9kuQtwL8DuwMfqapbxrjJXT4ENYvYl9lnvvQD7MtsNZa+zJoTzZKk4c2mw0eSpIEZCpKkZl6HQpKPJLk/yc3TrE+SD3S31fhGkuWTrrGvHn05KskDSW7sXu+edI19JTkgyXVJbk1yS5IzttFm1o9Nz37MiXFJsmeS65P8Z9eXv9hGm19Jckk3JmuTLJt8pdvXsy+nJtk0ZVxeP0StfSTZPcnXk1y5jXUzPyZVNW9fwIuB5cDN06x/GfB5IMARwNqha96FvhwFXDl0nT37sh+wvJt+PPBfwCFzbWx69mNOjEv35/y4bnoPYC1wxFZt3gR8qJs+Bbhk6Lp3oS+nAn87dK09+3Mm8Ilt/T0ax5jM6z2FqvoK8MNHaXICcHGNfBXYJ8l+k6lux/Toy5xRVfdW1Q3d9IPAbcD+WzWb9WPTsx9zQvfn/JNudo/utfVVKCcAa7rpy4BjkmRCJfbWsy9zQpKlwHHAhdM0mfExmdeh0MP+wHemzG9kjv5Sd36r22X+fJLfGLqYPrrd3ecx+t/cVHNqbB6lHzBHxqU7THEjcD9wTVVNOyZV9QjwAPCUyVbZT4++ALyyOzR5WZIDtrF+Nng/8A7gl9Osn/ExWeihMJ/cwOh+JocBHwQ+O3A925XkccCngbdX1eah69lZ2+nHnBmXqvpFVf0mo7sJHJ7kOUPXtLN69OVzwLKqOhS4hv/93/askeTlwP1VtX6S213ooTBvbq1RVZu37DJX1dXAHkkWD1zWtJLswegf0o9X1We20WROjM32+jHXxgWgqn4MXAccu9WqNiZJFgFPBH4w2ep2zHR9qaofVNXPu9kLgedPurYejgSOT3IXo7tGH53kY1u1mfExWeihcAXwuu5KlyOAB6rq3qGL2hlJnrrlWGKSwxmN7az8he3qvAi4rareN02zWT82ffoxV8YlyZIk+3TTewEvAb65VbMrgJXd9EnAF6s7wzmb9OnLVuenjmd0PmhWqap3VtXSqlrG6CTyF6vqNVs1m/ExmTW3uRiHJJ9kdPXH4iQbgXMZnXSiqj4EXM3oKpcNwM+A04apdPt69OUk4I1JHgEeAk6Zjb+wnSOB1wI3dcd9Ac4BDoQ5NTZ9+jFXxmU/YE1GD7vaDbi0qq5M8pfAuqq6glEAfjTJBkYXPZwyXLmPqk9f3pbkeOARRn05dbBqd9C4x8TbXEiSmoV++EiSNIWhIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNf8DhkWwVzMdP0cAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Удовлетворенность семеными отношениями'].plot.hist()"
      ],
      "metadata": {
        "id": "qcJXSM9x9KeR",
        "outputId": "f608a939-0e6a-4f80-d5f8-52073bc3588e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 802,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6639214590>"
            ]
          },
          "metadata": {},
          "execution_count": 802
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Удовлетворенность материальным положением'].plot.hist()"
      ],
      "metadata": {
        "id": "ZaW99Tv29M2p",
        "outputId": "25fc9659-3867-4395-a4b3-6659baf18c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 803,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f66338a08d0>"
            ]
          },
          "metadata": {},
          "execution_count": 803
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Здоровье от 1 до 10'].plot.hist()"
      ],
      "metadata": {
        "id": "t9RAlre-9NDZ",
        "outputId": "60d9441a-830a-4b5e-d74f-a3ef8c93b53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 804,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6633e9a5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 804
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Были ли нарушения сна'].plot.hist()"
      ],
      "metadata": {
        "id": "vHaj2_J99NR3",
        "outputId": "910a4809-f0ec-46d1-f964-08ca2a96674f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 805,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6635f83dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 805
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['ИМТ'].plot.hist()"
      ],
      "metadata": {
        "id": "1xC2ChxODvpM",
        "outputId": "aba4b736-f750-40f2-8434-56847d471bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 806,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f663a5be9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 806
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASLElEQVR4nO3df6xfdX3H8efLigN/DZAr6yi1KERCVAq7Vo2aIBsbE6eQOSdRwxZi1Umi0amFGMVlJphM0S3OWAWpzh8gqDBgPyqgzMSAt1ChgAbEulErrVMCGAMrvPfH9zRey/3x7Y/z/XLv5/lIvuk5n+8597w/OfC6537Or1QVkqR2PGHcBUiSRsvgl6TGGPyS1BiDX5IaY/BLUmOeOO4ChnHIIYfUihUrxl2GJC0oGzZs+HlVTezaviCCf8WKFUxNTY27DElaUJL8ZKZ2h3okqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxC+LOXS0MK9ZcNbZtbz7vlLFtW1poPOKXpMb0HvxJliS5OcmV3fwRSW5IcleSi5M8qe8aJEm/MYoj/ncAd0yb/whwflUdCfwSOHMENUiSOr0Gf5JlwCnAZ7v5ACcCl3aLrANO7bMGSdJv6/uI/+PAe4FHu/lnAPdV1Y5u/h7gsJlWTLI6yVSSqe3bt/dcpiS1o7fgT/IqYFtVbdiT9atqbVVNVtXkxMRj3iMgSdpDfV7O+VLg1UleCewPPB34BHBgkid2R/3LgC091iBJ2kVvR/xVdXZVLauqFcDrgWur6g3AdcBru8XOAC7vqwZJ0mON4zr+9wHvSnIXgzH/C8ZQgyQ1ayR37lbVt4BvddN3A6tGsV1J0mN5564kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTF9vmx9/yQ3Jvl+ktuSfKhrvyjJj5Ns7D4r+6pBkvRYfb6B6yHgxKp6MMl+wHeS/Fv33Xuq6tIety1JmkVvwV9VBTzYze7Xfaqv7UmShtPrO3eTLAE2AEcCn6yqG5K8Dfhwkg8A1wBrquqhGdZdDawGWL58eZ9lLjor1lw17hIkPY71enK3qh6pqpXAMmBVkucBZwNHAy8EDgbeN8u6a6tqsqomJyYm+ixTkpoykqt6quo+4Drg5KraWgMPAZ8DVo2iBknSQJ9X9UwkObCbPgA4CfhBkqVdW4BTgU191SBJeqw+x/iXAuu6cf4nAJdU1ZVJrk0yAQTYCLy1xxokSbvo86qeW4DjZmg/sa9tSpLm5527ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmF4fyyyNyrgeRb35vFPGsl1pb3jEL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhrT56sX909yY5LvJ7ktyYe69iOS3JDkriQXJ3lSXzVIkh6rzyP+h4ATq+pYYCVwcpIXAx8Bzq+qI4FfAmf2WIMkaRe9BX8NPNjN7td9CjgRuLRrX8fgheuSpBHpdYw/yZIkG4FtwHrgR8B9VbWjW+Qe4LBZ1l2dZCrJ1Pbt2/ssU5Ka0mvwV9UjVbUSWAasAo7ejXXXVtVkVU1OTEz0VqMktWYkV/VU1X3AdcBLgAOT7HxG0DJgyyhqkCQN9HlVz0SSA7vpA4CTgDsY/AJ4bbfYGcDlfdUgSXqsPp/OuRRYl2QJg18wl1TVlUluB76S5O+Bm4ELeqxBkrSL3oK/qm4Bjpuh/W4G4/2SpDHwzl1JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1Jihgj/J8/suRJI0GsMe8f9zkhuT/E2S3+21IklSr4YK/qp6OfAG4HBgQ5IvJTlprnWSHJ7kuiS3J7ktyTu69nOTbEmysfu8cq97IUka2tBv4KqqO5O8H5gC/hE4LkmAc6rqazOssgN4d1XdlORpDH5hrO++O7+q/mFvi5ck7b6hgj/JC4C/Bk4B1gN/1gX67wPfBR4T/FW1FdjaTT+Q5A7gsH1VuCRpzww7xv9PwE3AsVX19qq6CaCqfgq8f76Vk6xg8P7dG7qms5LckuTCJAftdtWSpD02bPCfAnypqn4NkOQJSZ4MUFVfmGvFJE8FLgPeWVX3A58CngOsZPAXwUdnWW91kqkkU9u3bx+yTEnSfIYN/m8CB0ybf3LXNqck+zEI/S/uPA9QVfdW1SNV9SjwGWDVTOtW1dqqmqyqyYmJiSHLlCTNZ9jg37+qHtw5000/ea4VuhO/FwB3VNXHprUvnbbYacCm4cuVJO2tYa/q+VWS43eO7Sf5A+DX86zzUuBNwK1JNnZt5wCnJ1kJFLAZeMtuVy1J2mPDBv87ga8m+SkQ4PeAv5xrhar6Trfsrq7erQolSfvUUMFfVd9LcjTw3K7ph1X1f/2VJUnqy9A3cAEvBFZ06xyfhKr6fC9VSZJ6M+wNXF9gcAnmRuCRrrkAg1+SFphhj/gngWOqqvosRpLUv2Ev59zE4ISuJGmBG/aI/xDg9iQ3Ag/tbKyqV/dSlSSpN8MG/7l9FiFJGp1hL+f8dpJnAUdV1Te75/Qs6bc0SVIfhn314puBS4FPd02HAd/oqyhJUn+GPbn7dgaPYLgfBi9lAZ7ZV1GSpP4MG/wPVdXDO2eSPJHBdfySpAVm2OD/dpJzgAO6d+1+FfjX/sqSJPVl2OBfA2wHbmXwNM2rGeLNW5Kkx59hr+rZ+dKUz/RbjiSpb8M+q+fHzDCmX1XP3ucVSZJ6tTvP6tlpf+AvgIP3fTmSpL4NNcZfVf877bOlqj7O4AXskqQFZtihnuOnzT6BwV8Ac66b5HAGj20+lMEw0dqq+kSSg4GLGTzbfzPwuqr65W5XLknaI8MO9Xx02vQOusCeZ50dwLur6qYkTwM2JFkP/BVwTVWdl2QNgyuG3rdbVUuS9tiwV/W8Ynd/cFVtBbZ20w8kuYPBox5eA5zQLbYO+BYGvySNzLBDPe+a6/uq+tg8668AjgNuAA7tfikA/IzBUNBM66wGVgMsX758mDIlSUMY9gauSeBtDI7YDwPeChwPPK37zCrJU4HLgHdW1f3Tv+ve6DXjox+qam1VTVbV5MTExJBlSpLmM+wY/zLg+Kp6ACDJucBVVfXGuVZKsh+D0P9iVX2ta743ydKq2ppkKbBtz0qXJO2JYY/4DwUenjb/MLMM0eyUJMAFwB27DAVdAZzRTZ8BXD5kDZKkfWDYI/7PAzcm+Xo3fyqDE7NzeSnwJuDWJBu7tnOA84BLkpwJ/IT5rw6SJO1DGQyzD7Hg4Fr+l3ez11fVzb1VtYvJycmampoa1eb2mRVrrhp3CVrENp/nPZSaW5INVTW5a/uwQz0ATwbur6pPAPckOWKfVSdJGplhX734QQbX2p/dNe0H/EtfRUmS+jPsEf9pwKuBXwFU1U+Z5zJOSdLj07DB//D0a+6TPKW/kiRJfRo2+C9J8mngwCRvBr6JL2WRpAVp3ss5u+vxLwaOBu4Hngt8oKrW91ybJKkH8wZ/VVWSq6vq+YBhL0kL3LBDPTcleWGvlUiSRmLYO3dfBLwxyWYGV/aEwR8DL+irMElSP+Z7i9byqvpv4E9GVI8kqWfzHfF/g8FTOX+S5LKq+vNRFCVJ6s98Y/yZNv3sPguRJI3GfMFfs0xLkhao+YZ6jk1yP4Mj/wO6afjNyd2n91qdJGmfmzP4q2rJqAqRtHvG9dhvHwe98O3OY5klSYtAb8Gf5MIk25JsmtZ2bpItSTZ2n1f2tX1J0sz6POK/CDh5hvbzq2pl97m6x+1LkmbQW/BX1fXAL/r6+ZKkPTOOMf6zktzSDQUdNNtCSVYnmUoytX379lHWJ0mL2qiD/1PAc4CVwFbgo7MtWFVrq2qyqiYnJiZGVZ8kLXojDf6qureqHqmqRxm8yGXVKLcvSRpx8CdZOm32NGDTbMtKkvox7GOZd1uSLwMnAIckuQf4IHBCkpUMHv+wGXhLX9uXJM2st+CvqtNnaL6gr+1JkobjnbuS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMb0FvxJLkyyLcmmaW0HJ1mf5M7u34P62r4kaWZ9HvFfBJy8S9sa4JqqOgq4ppuXJI1Qb8FfVdcDv9il+TXAum56HXBqX9uXJM1s1GP8h1bV1m76Z8Chsy2YZHWSqSRT27dvH011ktSAsZ3craoCao7v11bVZFVNTkxMjLAySVrcRh389yZZCtD9u23E25ek5o06+K8AzuimzwAuH/H2Jal5fV7O+WXgu8Bzk9yT5EzgPOCkJHcCf9TNS5JG6Il9/eCqOn2Wr/6wr21KkubnnbuS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktSY3u7clbQ4rVhz1di2vfm8U8a27cXEI35JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmLFczplkM/AA8Aiwo6omx1GHJLVonNfxv6Kqfj7G7UtSkxzqkaTGjCv4C/jPJBuSrB5TDZLUpHEN9bysqrYkeSawPskPqur66Qt0vxBWAyxfvnwcNUrSojSWI/6q2tL9uw34OrBqhmXWVtVkVU1OTEyMukRJWrRGHvxJnpLkaTungT8GNo26Dklq1TiGeg4Fvp5k5/a/VFX/PoY6JKlJIw/+qrobOHbU25UkDXg5pyQ1xuCXpMYY/JLUGINfkhpj8EtSY3zZuqQFY1wvel9sL3n3iF+SGmPwS1JjDH5JaozBL0mNWfQnd8d1MkiSHq884pekxhj8ktQYg1+SGmPwS1JjFv3JXUnaW+O8SKSPu4Y94pekxowl+JOcnOSHSe5KsmYcNUhSq8bxsvUlwCeBPwWOAU5Pcsyo65CkVo3jiH8VcFdV3V1VDwNfAV4zhjokqUnjOLl7GPA/0+bvAV6060JJVgOru9kHk/xwBLUBHAL8fETbGpcW+gj2czFpoY8wQz/zkb36ec+aqfFxe1VPVa0F1o56u0mmqmpy1NsdpRb6CPZzMWmhjzC6fo5jqGcLcPi0+WVdmyRpBMYR/N8DjkpyRJInAa8HrhhDHZLUpJEP9VTVjiRnAf8BLAEurKrbRl3HHEY+vDQGLfQR7Odi0kIfYUT9TFWNYjuSpMcJ79yVpMYY/JLUmGaDP8mFSbYl2TSt7dwkW5Js7D6vHGeN+0KSw5Ncl+T2JLcleUfXfnCS9Unu7P49aNy17qk5+rio9meS/ZPcmOT7XT8/1LUfkeSG7hEoF3cXTSxYc/TzoiQ/nrY/V4671r2VZEmSm5Nc2c2PZF82G/zARcDJM7SfX1Uru8/VI66pDzuAd1fVMcCLgbd3j8hYA1xTVUcB13TzC9VsfYTFtT8fAk6sqmOBlcDJSV4MfIRBP48EfgmcOcYa94XZ+gnwnmn7c+P4Stxn3gHcMW1+JPuy2eCvquuBX4y7jr5V1daquqmbfoDBf2SHMXhMxrpusXXAqeOpcO/N0cdFpQYe7Gb36z4FnAhc2rUv6H0Jc/ZzUUmyDDgF+Gw3H0a0L5sN/jmcleSWbihowQ5/zCTJCuA44Abg0Kra2n31M+DQMZW1T+3SR1hk+7MbGtgIbAPWAz8C7quqHd0i97AIfunt2s+q2rk/P9ztz/OT/M4YS9wXPg68F3i0m38GI9qXBv9v+xTwHAZ/Xm4FPjrecvadJE8FLgPeWVX3T/+uBtf0Lvgjqhn6uOj2Z1U9UlUrGdzxvgo4eswl9WLXfiZ5HnA2g/6+EDgYeN8YS9wrSV4FbKuqDePYvsE/TVXd2/0H9yjwGQb/Yy14SfZjEIhfrKqvdc33Jlnafb+UwZHVgjVTHxfr/gSoqvuA64CXAAcm2Xkz5qJ6BMq0fp7cDelVVT0EfI6FvT9fCrw6yWYGTyg+EfgEI9qXBv80O4OwcxqwabZlF4pu3PAC4I6q+ti0r64AzuimzwAuH3Vt+8psfVxs+zPJRJIDu+kDgJMYnM+4Dnhtt9iC3pcwaz9/MO1AJQzGvhfs/qyqs6tqWVWtYPDYmmur6g2MaF82e+duki8DJzB4DOq9wAe7+ZUMhj02A2+ZNg6+ICV5GfBfwK38ZizxHAZj4JcAy4GfAK+rqgV5snuOPp7OItqfSV7A4ITfEgYHbZdU1d8leTaDo8aDgZuBN3ZHxQvSHP28FpgAAmwE3jrtJPCCleQE4G+r6lWj2pfNBr8ktcqhHklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGvP/M7Jo7EvQpQ0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Операции'].plot.hist()"
      ],
      "metadata": {
        "id": "QKyiTn8z8vdN",
        "outputId": "1aecc5ab-731a-4173-cfe3-8dc1297ede73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 807,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6635109fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 807
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X['Аллергии'].plot.hist()"
      ],
      "metadata": {
        "id": "9mM7BGvI9N5N"
      },
      "execution_count": 808,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X['Забол кожи'].plot.hist()"
      ],
      "metadata": {
        "id": "9OIttp848vfV"
      },
      "execution_count": 809,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X['ГБ'].plot.hist()"
      ],
      "metadata": {
        "id": "UQSDw5Sj9P2P"
      },
      "execution_count": 810,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X['Панкреатит'].plot.hist()"
      ],
      "metadata": {
        "id": "IkrDKxnY9P4y"
      },
      "execution_count": 811,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X['Дисфункция ЖКТ'].plot.hist()"
      ],
      "metadata": {
        "id": "fe_keiy09P7M"
      },
      "execution_count": 812,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['ЧМТ'].plot.hist()"
      ],
      "metadata": {
        "id": "loEyKK3y9P9v",
        "outputId": "951c4594-11ac-4028-e68f-3374ed867ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 813,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6635b7d2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 813
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Насл отягощенность'].plot.hist()"
      ],
      "metadata": {
        "id": "lB6JgIeJ9QAB",
        "outputId": "237b01a9-c651-4c0c-8e94-6e2e5d67467f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 814,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f66344656d0>"
            ]
          },
          "metadata": {},
          "execution_count": 814
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Дебют'].plot.hist()"
      ],
      "metadata": {
        "id": "73hXHFoX9QCa",
        "outputId": "764438e4-f359-4a6f-900e-dea1ecdd1fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 815,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6634484c90>"
            ]
          },
          "metadata": {},
          "execution_count": 815
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQhklEQVR4nO3dfYxldX3H8feHBwuoKSLrlrDgoBIpqYp0QA3aKhZLiwK2lmrVbBri2hQTjKayEFMx0QT/ULRNa13Fsj4CPiAU1IorakwacFdQnjQgLi0rsOsDAayBLnz7xz2jwzI7e2eZc8/s/t6vZHLPOffeOZ/8NvuZM78595xUFZKkduwxdABJ0mRZ/JLUGItfkhpj8UtSYyx+SWrMXkMHGMeBBx5YU1NTQ8eQpF3Khg0bflZVy7bdvksU/9TUFOvXrx86hiTtUpLcMdd2p3okqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4Jakxu8Qnd6UdmVp95SD73XjeSYPsV3o8POKXpMZY/JLUGItfkhpj8UtSY3r9426SjcD9wMPA1qqaTnIAcDEwBWwETquqX/aZQ5L0W5M44n9ZVR1VVdPd+mpgXVUdDqzr1iVJEzLEVM8pwNpueS1w6gAZJKlZfRd/AV9LsiHJqm7b8qq6q1u+G1g+1xuTrEqyPsn6LVu29BxTktrR9we4XlxVm5I8DbgqyQ9nP1lVlaTmemNVrQHWAExPT8/5GknSwvV6xF9Vm7rHzcClwLHAPUkOAugeN/eZQZL0aL0Vf5InJnnyzDLwCuBG4HJgZfeylcBlfWWQJD1Wn1M9y4FLk8zs5zNV9dUk3wUuSXI6cAdwWo8ZJEnb6K34q+p24HlzbP858PK+9itJmp+f3JWkxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9Jjen71otqyNTqK4eOIGkMHvFLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUmN6LP8meSa5LckW3fliSa5LcluTiJE/oO4Mk6bcmccR/JnDLrPX3AedX1bOAXwKnTyCDJKnTa/EnWQGcBHysWw9wPPD57iVrgVP7zCBJerS+j/g/CLwDeKRbfypwb1Vt7dbvBA7uOYMkaZbeij/JK4HNVbVhJ9+/Ksn6JOu3bNmyyOkkqV19HvEfB5ycZCNwEaMpng8B+yeZucn7CmDTXG+uqjVVNV1V08uWLesxpiS1pbfir6qzq2pFVU0BrwW+UVWvB64GXtO9bCVwWV8ZJEmPNcR5/GcBb0tyG6M5/wsGyCBJzdprxy95/Krqm8A3u+XbgWMnsV9J0mP5yV1JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjZnIJRuk3dXU6isH2/fG804abN/atXnEL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNWas4k/ynL6DSJImY9wj/n9Ncm2Sv0/yu70mkiT1aqzir6qXAK8HDgE2JPlMkhN6TSZJ6sXYc/xVdSvwTuAs4I+Bf0rywyR/0Vc4SdLiG3eO/7lJzgduAY4HXlVVv98tn99jPknSIhv3Riz/DHwMOKeqfj2zsap+muSdvSSTJPVi3OI/Cfh1VT0MkGQPYJ+q+t+q+mRv6SRJi27cOf6vA/vOWt+v2yZJ2sWMW/z7VNUDMyvd8n79RJIk9Wnc4v9VkqNnVpL8IfDreV5Pkn26c/+/n+SmJO/uth+W5JoktyW5OMkTdj6+JGmhxp3jfyvwuSQ/BQL8HvDXO3jPg8DxVfVAkr2B7yT5CvA24PyquijJvwGnAx/eufiSpIUaq/ir6rtJjgCe3W36UVX93w7eU8DM9NDe3VcxOgX0b7rta4FzsfglaWLGPeIHOAaY6t5zdBKq6hPzvSHJnsAG4FnAvwA/Bu6tqq3dS+4EDt7Oe1cBqwAOPfTQBcSUJM1nrOJP8kngmcD1wMPd5gLmLf7u9M+jkuwPXAocMW6wqloDrAGYnp6ucd8nSZrfuEf808CR3fTNglXVvUmuBl4E7J9kr+6ofwWwaWe+pyRp54x7Vs+NjP6gO7Yky7ojfZLsC5zA6JIPVwOv6V62ErhsId9XkvT4jHvEfyBwc5JrGZ2tA0BVnTzPew4C1nbz/HsAl1TVFUluBi5K8h7gOuCCnYsuSdoZ4xb/uQv9xlX1A+D5c2y/HTh2od9PkrQ4xj2d81tJng4cXlVfT7IfsGe/0SRJfRj3ssxvAj4PfKTbdDDwpb5CSZL6M+4fd88AjgPug9/clOVpfYWSJPVn3OJ/sKoemllJshej8/glSbuYcYv/W0nOAfbt7rX7OeA/+oslSerLuMW/GtgC3AC8Gfgyo/vvSpJ2MeOe1fMI8NHuS5K0Cxv3Wj0/YY45/ap6xqInkiT1aiHX6pmxD/BXwAGLH0eS1Lex5vir6uezvjZV1QcZ3YBdkrSLGXeq5+hZq3sw+g1gIdfylyQtEeOW9/tnLW8FNgKnLXoaSVLvxj2r52V9B5EkTca4Uz1vm+/5qvrA4sSRJPVtIWf1HANc3q2/CrgWuLWPUJKk/oxb/CuAo6vqfoAk5wJXVtUb+gomSerHuJdsWA48NGv9oW6bJGkXM+4R/yeAa5Nc2q2fCqztJ5IkqU/jntXz3iRfAV7Sbfrbqrquv1iSpL6MO9UDsB9wX1V9CLgzyWE9ZZIk9WjcWy++CzgLOLvbtDfwqb5CSZL6M+4R/6uBk4FfAVTVT4En9xVKktSfcYv/oaoqukszJ3lif5EkSX0at/gvSfIRYP8kbwK+jjdlkaRd0g7P6kkS4GLgCOA+4NnAP1bVVT1nkyT1YIfFX1WV5MtV9RzAspekXdy4Uz3fS3JMr0kkSRMx7id3XwC8IclGRmf2hNEvA8/tK5gkqR/zFn+SQ6vqv4E/nVAeSVLPdnTE/yVGV+W8I8kXquovJxFKktSfHc3xZ9byM/oMIkmajB0Vf21neYeSHJLk6iQ3J7kpyZnd9gOSXJXk1u7xKQsNLUnaeTsq/ucluS/J/cBzu+X7ktyf5L4dvHcr8PaqOhJ4IXBGkiOB1cC6qjocWNetS5ImZN45/qrac2e/cVXdBdzVLd+f5BbgYOAU4KXdy9YC32R0AThJ0gQs5LLMOy3JFPB84BpgefdDAeButnMnrySrkqxPsn7Lli2TiClJTei9+JM8CfgC8NaqetT00OwLv22rqtZU1XRVTS9btqzvmJLUjF6LP8nejEr/01X1xW7zPUkO6p4/CNjcZwZJ0qP1Vvzdxd0uAG6pqg/MeupyYGW3vBK4rK8MkqTHGveSDTvjOOCNwA1Jru+2nQOcx+gyz6cDdwCn9ZhBkrSN3oq/qr7Doz8ANtvL+9qvJGl+EzmrR5K0dFj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktSYvYYOoMU3tfrKoSNoAob6d9543kmD7FeLxyN+SWqMxS9JjbH4JakxFr8kNaa34k/y8SSbk9w4a9sBSa5Kcmv3+JS+9i9JmlufR/wXAidus201sK6qDgfWdeuSpAnqrfir6tvAL7bZfAqwtlteC5za1/4lSXOb9Bz/8qq6q1u+G1i+vRcmWZVkfZL1W7ZsmUw6SWrAYH/craoCap7n11TVdFVNL1u2bILJJGn3NunivyfJQQDd4+YJ71+Smjfp4r8cWNktrwQum/D+Jal5fZ7O+Vngv4BnJ7kzyenAecAJSW4F/qRblyRNUG8Xaauq123nqZf3tU9J0o75yV1JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGO+5K2lBhryns/f7XRwe8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY3xWj2SdhlDXidoCH1dm8gjfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGrPbn8c/1Hm/3htU0lLlEb8kNcbil6TGWPyS1Jjdfo5/KK1dU0TSrmOQI/4kJyb5UZLbkqweIoMktWrixZ9kT+BfgD8DjgRel+TISeeQpFYNccR/LHBbVd1eVQ8BFwGnDJBDkpo0xBz/wcD/zFq/E3jBti9KsgpY1a0+kORHO7m/A4Gf7eR7+2SuhTHXwphrYZZkrrzvced6+lwbl+wfd6tqDbDm8X6fJOuranoRIi0qcy2MuRbGXAvTWq4hpno2AYfMWl/RbZMkTcAQxf9d4PAkhyV5AvBa4PIBckhSkyY+1VNVW5O8BfhPYE/g41V1U4+7fNzTRT0x18KYa2HMtTBN5UpV9fF9JUlLlJdskKTGWPyS1JjduviTbExyQ5Lrk6wfMMfHk2xOcuOsbQckuSrJrd3jU5ZIrnOTbOrG7Pokfz5ArkOSXJ3k5iQ3JTmz2z7omM2Ta9AxS7JPkmuTfL/L9e5u+2FJrukujXJxdzLFUsh1YZKfzBqvoyaZa1a+PZNcl+SKbn3Q8Zon16KP125d/J2XVdVRA5+jeyFw4jbbVgPrqupwYF23PmkX8thcAOd3Y3ZUVX15wpkAtgJvr6ojgRcCZ3SX9Rh6zLaXC4YdsweB46vqecBRwIlJXgi8r8v1LOCXwOlLJBfAP8war+snnGvGmcAts9aHHq8Z2+aCRR6vFop/cFX1beAX22w+BVjbLa8FTp1oKLaba3BVdVdVfa9bvp/Rf4KDGXjM5sk1qBp5oFvdu/sq4Hjg8932IcZre7kGl2QFcBLwsW49DDxec+Xqy+5e/AV8LcmG7hIQS8nyqrqrW74bWD5kmG28JckPuqmgiU9BzZZkCng+cA1LaMy2yQUDj1k3PXA9sBm4CvgxcG9Vbe1ecicD/JDaNldVzYzXe7vxOj/J70w6F/BB4B3AI936U1kC4zVHrhmLOl67e/G/uKqOZnQl0DOS/NHQgeZSo3Nql8SREPBh4JmMfjW/C3j/UEGSPAn4AvDWqrpv9nNDjtkcuQYfs6p6uKqOYvRJ+GOBIyadYS7b5kryB8DZjPIdAxwAnDXJTEleCWyuqg2T3O+OzJNr0cdrty7+qtrUPW4GLmX0H2KpuCfJQQDd4+aB8wBQVfd0/1kfAT7KQGOWZG9G5frpqvpit3nwMZsr11IZsy7LvcDVwIuA/ZPMfEhz0EujzMp1YjdlVlX1IPDvTH68jgNOTrKR0dWBjwc+xPDj9ZhcST7Vx3jttsWf5IlJnjyzDLwCuHH+d03U5cDKbnklcNmAWX5jplg7r2aAMevmWy8AbqmqD8x6atAx216uoccsybIk+3fL+wInMPr7w9XAa7qXDTFec+X64awf3mE0jz7R8aqqs6tqRVVNMbpkzDeq6vUMPF7byfWGPsZryV6dcxEsBy4djRV7AZ+pqq8OESTJZ4GXAgcmuRN4F3AecEmS04E7gNOWSK6XdqeLFbARePOkczE68nkjcEM3PwxwDsOP2fZyvW7gMTsIWJvRTY72AC6pqiuS3AxclOQ9wHWMfmgthVzfSLIMCHA98HcTzrU9ZzHseG3Ppxd7vLxkgyQ1Zred6pEkzc3il6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY35fxQZ8ZpxuJCZAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Частота госпит'].plot.hist()"
      ],
      "metadata": {
        "id": "dfRTqleE9QFD",
        "outputId": "13df1f45-d51c-49b3-b33e-e3cc8ceff659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 816,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6639cbb7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 816
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Стаж шизофр'].plot.hist()"
      ],
      "metadata": {
        "id": "MPLll8-L9u8u",
        "outputId": "6e81d1fe-1dac-4254-9c57-0fb399a3d7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 817,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6631c36e10>"
            ]
          },
          "metadata": {},
          "execution_count": 817
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['P'].plot.hist()"
      ],
      "metadata": {
        "id": "WR2YxXxd9u_V",
        "outputId": "986c9985-bca5-486d-98f8-5991ba75ac4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 818,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6631f96f90>"
            ]
          },
          "metadata": {},
          "execution_count": 818
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['N'].plot.hist()"
      ],
      "metadata": {
        "id": "n15glR8-9vB2",
        "outputId": "bd04890b-da68-4388-8c36-f8cbda1b0158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 819,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6631c66fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 819
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['G'].plot.hist()"
      ],
      "metadata": {
        "id": "jNFwr3Rt9vEi",
        "outputId": "0e8a00cd-51ee-4058-d922-bb6e9a22342e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 820,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6635ac9c10>"
            ]
          },
          "metadata": {},
          "execution_count": 820
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.min()"
      ],
      "metadata": {
        "id": "SjbyFES59vHG",
        "outputId": "e0b18056-f64e-4031-ed01-bca29c6716e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 821,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Пол                                           0.000000\n",
              "Полных лет                                   19.000000\n",
              "Образование(0-начальное, 4-высшее)            1.000000\n",
              "Род занятий(0-0, работает-1                   0.000000\n",
              "Семейное положение(0-0, 1-женат)              0.000000\n",
              "Удовлетворенность семеными отношениями        1.000000\n",
              "Удовлетворенность материальным положением     0.000000\n",
              "Здоровье от 1 до 10                           1.000000\n",
              "Были ли нарушения сна                         0.000000\n",
              "ИМТ                                          14.005112\n",
              "Операции                                      0.000000\n",
              "ЧМТ                                           0.000000\n",
              "Насл отягощенность                            0.000000\n",
              "Дебют                                         5.000000\n",
              "Частота госпит                                0.000000\n",
              "Стаж шизофр                                   0.500000\n",
              "P                                             7.000000\n",
              "N                                             5.000000\n",
              "G                                            16.000000\n",
              "dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 821
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.max()"
      ],
      "metadata": {
        "id": "Ov1NYpWJ9vLD",
        "outputId": "fb4a0c4c-6158-456c-c3fc-dea592eb48e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 822,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Пол                                           1.000000\n",
              "Полных лет                                   67.000000\n",
              "Образование(0-начальное, 4-высшее)            4.000000\n",
              "Род занятий(0-0, работает-1                   1.000000\n",
              "Семейное положение(0-0, 1-женат)              1.000000\n",
              "Удовлетворенность семеными отношениями        5.000000\n",
              "Удовлетворенность материальным положением     1.000000\n",
              "Здоровье от 1 до 10                          10.000000\n",
              "Были ли нарушения сна                         1.000000\n",
              "ИМТ                                          40.404041\n",
              "Операции                                      1.000000\n",
              "ЧМТ                                           2.000000\n",
              "Насл отягощенность                            1.000000\n",
              "Дебют                                        45.000000\n",
              "Частота госпит                                2.000000\n",
              "Стаж шизофр                                  41.000000\n",
              "P                                            32.000000\n",
              "N                                            37.000000\n",
              "G                                            56.000000\n",
              "dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 822
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z8MPctJWaFgp"
      },
      "execution_count": 822,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eoSFxsKXaFjZ"
      },
      "execution_count": 822,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ld02q8uCaFlZ"
      },
      "execution_count": 822,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recursive feature elimination (feature selection)"
      ],
      "metadata": {
        "id": "6__3yeowZurC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        " \n",
        "lr = LinearRegression()\n",
        "#select 5 the most informative features\n",
        "rfe = RFE(lr, n_features_to_select=5) \n",
        "selector = rfe.fit(X,y)\n",
        "selector.support_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZgqfNgPZutk",
        "outputId": "aea7d980-b012-402c-a3c5-45f4cde71e26"
      },
      "execution_count": 823,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False, False, False, False, False, False,  True,\n",
              "       False, False, False, False,  True, False,  True, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {},
          "execution_count": 823
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selector.ranking_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5e_Fa3NZuv8",
        "outputId": "072a5ad4-0a35-4eb4-9e3d-78a1ce2676c5"
      },
      "execution_count": 824,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1, 13,  2,  3, 12,  4,  8,  1, 10,  5, 14, 11,  1, 15,  1,  9,\n",
              "        7,  6])"
            ]
          },
          "metadata": {},
          "execution_count": 824
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = minmax_scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "IZm5ISGTZuyJ"
      },
      "execution_count": 825,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "#select 5 the most informative features\n",
        "rfe = RFE(lr, n_features_to_select=5) \n",
        "selector = rfe.fit(X_scaled,y)\n",
        "X.columns[selector.support_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEhomgyhZu0m",
        "outputId": "07f07098-1f61-48e1-c664-f5221871fa9f"
      },
      "execution_count": 826,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Полных лет', 'Дебют', 'Стаж шизофр', 'N', 'G'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 826
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selector.ranking_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WMVWWaOZu3j",
        "outputId": "8ac856eb-7f59-4093-842f-0919226e85ef"
      },
      "execution_count": 827,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4,  1, 12,  7,  6, 11,  9,  8,  3,  5, 10, 14, 13,  1, 15,  1,  2,\n",
              "        1,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 827
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[False,  Полных лет, False, False, False, False, False, False, False,\n",
        "       False, False, False, False,  Дебют, False,  Стаж шизофр, False,  N,\n",
        "        G])\n",
        "\n",
        "Полных лет, G, N, Стаж шизофр, Дебют"
      ],
      "metadata": {
        "id": "E6kRoWoDdrY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "#select 5 the most informative features\n",
        "rfe = RFE(lr, n_features_to_select=3) \n",
        "selector = rfe.fit(X_scaled,y)\n",
        "\n",
        "X.columns[selector.support_]\n",
        "# Полных лет Стаж шизофр, Дебют"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUvPGl25drvw",
        "outputId": "125d33e1-4bed-4f8c-d38d-b24363e3330a"
      },
      "execution_count": 828,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Полных лет', 'Дебют', 'Стаж шизофр'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 828
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selector.ranking_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmaSGWsydryY",
        "outputId": "4be9e601-dd93-4a40-f51e-1482eea195e7"
      },
      "execution_count": 829,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  1, 14,  9,  8, 13, 11, 10,  5,  7, 12, 16, 15,  1, 17,  1,  4,\n",
              "        3,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 829
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_s14onwvdr00"
      },
      "execution_count": 829,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V4VkmXfGJU73"
      },
      "execution_count": 829,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ridge regression"
      ],
      "metadata": {
        "id": "bWVE9lVYJU-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "clf = Ridge(alpha=1.0)\n",
        "clf.fit(X_scaled, y)\n",
        "clf.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu1WF01jdr3X",
        "outputId": "67da23f1-2bd2-47c8-e770-1763fcebac65"
      },
      "execution_count": 830,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.22916175, -0.04521506,  0.00620389, -0.13925803,  0.16084182,\n",
              "        0.02381083, -0.0730864 , -0.09515555,  0.26708284, -0.13483925,\n",
              "        0.03858924,  0.00110342,  0.01082914,  0.03102849,  0.00272879,\n",
              "       -0.06005502,  0.2771904 , -0.3858557 ,  0.4021952 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 830
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNlDvdjDdr6q",
        "outputId": "5610050c-d6d0-4c11-e1d5-65a90fd034cc"
      },
      "execution_count": 831,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34553903"
            ]
          },
          "metadata": {},
          "execution_count": 831
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RLA1NUAJKHvd"
      },
      "execution_count": 831,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YBl9ZGQpZu59"
      },
      "execution_count": 831,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LASSO regression (feature selection)"
      ],
      "metadata": {
        "id": "SkuZbKUBBkOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso"
      ],
      "metadata": {
        "id": "qRuBoZdY7yy9"
      },
      "execution_count": 832,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DG_91ub87y1z"
      },
      "execution_count": 833,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "                     ('scaler',StandardScaler()),\n",
        "                     ('model',Lasso())\n",
        "])\n"
      ],
      "metadata": {
        "id": "0BjWX-gC7_TQ"
      },
      "execution_count": 834,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = GridSearchCV(pipeline,\n",
        "                      {'model__alpha':np.arange(0.1,10,0.1)},\n",
        "                      cv = 5, scoring=\"neg_mean_squared_error\",verbose=3\n",
        "                      )"
      ],
      "metadata": {
        "id": "P4DMl7uv8Bt6"
      },
      "execution_count": 835,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "-I6VjLFw8DqO",
        "outputId": "10d4204a-c8cf-461f-ba7e-04d7443fd1df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 836,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 99 candidates, totalling 495 fits\n",
            "[CV 1/5] END .................model__alpha=0.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.1;, score=-0.248 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.1;, score=-0.212 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.2;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.2;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.2;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.2;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.2;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .model__alpha=0.30000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .model__alpha=0.30000000000000004;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .model__alpha=0.30000000000000004;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .model__alpha=0.30000000000000004;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .model__alpha=0.30000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.4;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.4;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.4;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.4;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.4;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.5;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.5;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.5;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.5;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.5;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=0.7000000000000001;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=0.7000000000000001;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=0.7000000000000001;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=0.7000000000000001;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=0.7000000000000001;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.8;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.8;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.8;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.8;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.8;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=0.9;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=0.9;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=0.9;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=0.9;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=0.9;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=1.0;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=1.0;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=1.0;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=1.0;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=1.0;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=1.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=1.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=1.1;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=1.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=1.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.2000000000000002;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.2000000000000002;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.2000000000000002;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.2000000000000002;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.2000000000000002;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.3000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.3000000000000003;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.3000000000000003;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.3000000000000003;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.3000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.4000000000000001;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.4000000000000001;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.4000000000000001;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.4000000000000001;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.4000000000000001;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.5000000000000002;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.5000000000000002;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.5000000000000002;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.5000000000000002;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.5000000000000002;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=1.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=1.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=1.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=1.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=1.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.7000000000000002;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.7000000000000002;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.7000000000000002;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.7000000000000002;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.7000000000000002;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.8000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.8000000000000003;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.8000000000000003;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.8000000000000003;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.8000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=1.9000000000000001;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=1.9000000000000001;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=1.9000000000000001;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=1.9000000000000001;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=1.9000000000000001;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.0;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.0;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.0;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.0;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.0;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.1;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.2;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.2;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.2;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.2;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.2;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.3000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.3000000000000003;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.3000000000000003;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.3000000000000003;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.3000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.4000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.4000000000000004;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.4000000000000004;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.4000000000000004;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.4000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.5000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.5000000000000004;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.5000000000000004;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.5000000000000004;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.5000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=2.7;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=2.7;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=2.7;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=2.7;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=2.7;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.8000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.8000000000000003;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.8000000000000003;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.8000000000000003;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.8000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=2.9000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=2.9000000000000004;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=2.9000000000000004;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=2.9000000000000004;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=2.9000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.0000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.0000000000000004;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.0000000000000004;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.0000000000000004;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.0000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=3.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=3.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=3.1;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=3.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=3.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=3.2;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=3.2;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=3.2;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=3.2;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=3.2;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.3000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.3000000000000003;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.3000000000000003;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.3000000000000003;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.3000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.4000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.4000000000000004;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.4000000000000004;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.4000000000000004;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.4000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.5000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.5000000000000004;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.5000000000000004;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.5000000000000004;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.5000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=3.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=3.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=3.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=3.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=3.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=3.7;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=3.7;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=3.7;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=3.7;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=3.7;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.8000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.8000000000000003;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.8000000000000003;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.8000000000000003;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.8000000000000003;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=3.9000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=3.9000000000000004;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=3.9000000000000004;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=3.9000000000000004;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=3.9000000000000004;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.0;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.0;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.0;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.0;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.0;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.1;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.2;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.2;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.2;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.2;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.2;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.3;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.3;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.3;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.3;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.3;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ..model__alpha=4.3999999999999995;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ..model__alpha=4.3999999999999995;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ..model__alpha=4.3999999999999995;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ..model__alpha=4.3999999999999995;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ..model__alpha=4.3999999999999995;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.5;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.5;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.5;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.5;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.5;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.7;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.7;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.7;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.7;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.7;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.8;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.8;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.8;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.8;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.8;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=4.9;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=4.9;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=4.9;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=4.9;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=4.9;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.0;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.0;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.0;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.0;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.0;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.1;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.2;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.2;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.2;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.2;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.2;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.3;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.3;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.3;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.3;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.3;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.4;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.4;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.4;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.4;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.4;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.5;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.5;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.5;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.5;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.5;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.7;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.7;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.7;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.7;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.7;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.8;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.8;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.8;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.8;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.8;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=5.9;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=5.9;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=5.9;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=5.9;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=5.9;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.0;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.0;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.0;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.0;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.0;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.1;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.2;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.2;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.2;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.2;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.2;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.3;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.3;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.3;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.3;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.3;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.4;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.4;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.4;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.4;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.4;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.5;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.5;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.5;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.5;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.5;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.7;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.7;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.7;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.7;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.7;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.8;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.8;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.8;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.8;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.8;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=6.9;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=6.9;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=6.9;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=6.9;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=6.9;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.0;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.0;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.0;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.0;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.0;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.1;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.2;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.2;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.2;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.2;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.2;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.3;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.3;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.3;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.3;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.3;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.4;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.4;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.4;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.4;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.4;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.5;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.5;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.5;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.5;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.5;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.7;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.7;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.7;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.7;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.7;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.8;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.8;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.8;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.8;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.8;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=7.9;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=7.9;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=7.9;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=7.9;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=7.9;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.0;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.0;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.0;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.0;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.0;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.1;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.2;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.2;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.2;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.2;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.2;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.3;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.3;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.3;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.3;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.3;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.4;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.4;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.4;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.4;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.4;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.5;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.5;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.5;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.5;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.5;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.7;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.7;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.7;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.7;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.7;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.8;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.8;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.8;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.8;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.8;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=8.9;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=8.9;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=8.9;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=8.9;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=8.9;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.0;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.0;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.0;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.0;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.0;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.1;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.1;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.1;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.1;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.1;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.2;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.2;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.2;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.2;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.2;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.3;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.3;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.3;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.3;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.3;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.4;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.4;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.4;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.4;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.4;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.5;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.5;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.5;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.5;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.5;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.6;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.6;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.6;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.6;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.6;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END ...model__alpha=9.700000000000001;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END ...model__alpha=9.700000000000001;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END ...model__alpha=9.700000000000001;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END ...model__alpha=9.700000000000001;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END ...model__alpha=9.700000000000001;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.8;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.8;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.8;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.8;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.8;, score=-0.260 total time=   0.0s\n",
            "[CV 1/5] END .................model__alpha=9.9;, score=-0.260 total time=   0.0s\n",
            "[CV 2/5] END .................model__alpha=9.9;, score=-0.218 total time=   0.0s\n",
            "[CV 3/5] END .................model__alpha=9.9;, score=-0.249 total time=   0.0s\n",
            "[CV 4/5] END .................model__alpha=9.9;, score=-0.213 total time=   0.0s\n",
            "[CV 5/5] END .................model__alpha=9.9;, score=-0.260 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                                       ('model', Lasso())]),\n",
              "             param_grid={'model__alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
              "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6,\n",
              "       2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9,\n",
              "       4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. , 5.1, 5.2,\n",
              "       5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6. , 6.1, 6.2, 6.3, 6.4, 6.5,\n",
              "       6.6, 6.7, 6.8, 6.9, 7. , 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8,\n",
              "       7.9, 8. , 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9. , 9.1,\n",
              "       9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9])},\n",
              "             scoring='neg_mean_squared_error', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 836
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search.best_params_\n"
      ],
      "metadata": {
        "id": "467Y8gXz8Kqb",
        "outputId": "ecd7aad5-9e8d-47e6-8c45-de31bc63a2d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 837,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model__alpha': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 837
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients = search.best_estimator_.named_steps['model'].coef_\n"
      ],
      "metadata": {
        "id": "r5ZsQXb78Py9"
      },
      "execution_count": 838,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients"
      ],
      "metadata": {
        "id": "c6v7Dm-q8RPP",
        "outputId": "74d6d92d-6b7b-4aee-91d2-fa28414c55dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 839,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
              "        0.        , -0.        , -0.        ,  0.00213946,  0.        ,\n",
              "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
              "        0.        ,  0.        , -0.        ,  0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 839
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importance = np.abs(coefficients)\n",
        "importance"
      ],
      "metadata": {
        "id": "Qaa48PUw8T4V",
        "outputId": "131d417c-67cf-4a8e-bdb8-d5960d4c725d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 840,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00213946, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 840
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(['Пол', 'Полных лет', 'Образование(0-начальное, 4-высшее)',\n",
        "       'Род занятий(0-0, работает-1', 'Семейное положение(0-0, 1-женат)',\n",
        "       'Удовлетворенность семеными отношениями', 'Здоровье от 1 до 10', 'Были ли нарушения сна', 'ИМТ', 'Операции',\n",
        "       'Удовлетворенность материальным положением','ЧМТ',\n",
        "       'Насл отягощенность', 'Дебют', 'Частота госпит', 'Стаж шизофр', 'P',\n",
        "       'N', 'G'])[importance > 0]\n"
      ],
      "metadata": {
        "id": "Crjl4-ak8VZF",
        "outputId": "3665659f-1916-4894-dd91-40c6c1704067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 841,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ИМТ'], dtype='<U41')"
            ]
          },
          "metadata": {},
          "execution_count": 841
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(['Пол', 'Полных лет', 'Образование(0-начальное, 4-высшее)',\n",
        "       'Род занятий(0-0, работает-1', 'Семейное положение(0-0, 1-женат)',\n",
        "       'Удовлетворенность семеными отношениями', 'Здоровье от 1 до 10', 'Были ли нарушения сна', 'ИМТ', 'Операции',\n",
        "       'Удовлетворенность материальным положением','ЧМТ',\n",
        "       'Насл отягощенность', 'Дебют', 'Частота госпит', 'Стаж шизофр', 'P',\n",
        "       'N', 'G'])[importance == 0]\n"
      ],
      "metadata": {
        "id": "VpSqwmgK8XI8",
        "outputId": "32b4f8e1-065e-4cec-bc9c-9970e0996a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 842,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Пол', 'Полных лет', 'Образование(0-начальное, 4-высшее)',\n",
              "       'Род занятий(0-0, работает-1', 'Семейное положение(0-0, 1-женат)',\n",
              "       'Удовлетворенность семеными отношениями', 'Здоровье от 1 до 10',\n",
              "       'Были ли нарушения сна', 'Операции',\n",
              "       'Удовлетворенность материальным положением', 'ЧМТ',\n",
              "       'Насл отягощенность', 'Дебют', 'Частота госпит', 'Стаж шизофр',\n",
              "       'P', 'N', 'G'], dtype='<U41')"
            ]
          },
          "metadata": {},
          "execution_count": 842
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fyb98Ux-9IQl"
      },
      "execution_count": 842,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "load_diabetes()['feature_names']\n"
      ],
      "metadata": {
        "id": "oT2xQzDP8Ktb",
        "outputId": "a3756b7f-c61a-40fb-b9cd-e34ded2b0ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 843,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
            ]
          },
          "metadata": {},
          "execution_count": 843
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tIun2lrs8Kvo"
      },
      "execution_count": 843,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FVw800PA8Kyb"
      },
      "execution_count": 843,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qV4qLhq_8K16"
      },
      "execution_count": 843,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8b-nuu2-8E0_"
      },
      "execution_count": 843,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nvDEcbsU7y4A"
      },
      "execution_count": 843,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0KJDyl-A7y6U"
      },
      "execution_count": 843,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XndBQbwQ7y8e"
      },
      "execution_count": 843,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "It37YfGRBkQf"
      },
      "execution_count": 843,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find 3 best predictors witn chi square and ANOVA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2 # chi^2\n",
        "from sklearn.feature_selection import f_classif # ANOVA\n",
        "\n",
        "X_chi2 = SelectKBest(chi2, k=5).fit_transform(X, y)\n",
        "X_anova = SelectKBest(f_classif, k=5).fit_transform(X, y)"
      ],
      "metadata": {
        "id": "oW3UvZbiNUcI"
      },
      "execution_count": 844,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the Top Selected Features\n",
        "\n",
        "https://ml2021.medium.com/chi-square-and-anova-feature-selection-for-ml-5e1063ab0991"
      ],
      "metadata": {
        "id": "8aImEuZChXVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_score = chi2(X, y)\n",
        "f_score\n",
        "# The first array is the F_score , 2nd one is the P_values\n",
        "# the smaller the P value the more significant the difference in the features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3x7wS6Key9P",
        "outputId": "ff8f7619-bf98-4fcd-f55a-a44693f41a44"
      },
      "execution_count": 845,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([8.81632874e-01, 3.74369494e-01, 7.66156713e-06, 2.06719560e-01,\n",
              "        1.45127179e-01, 6.05965998e-03, 7.04258205e-01, 2.79589522e+00,\n",
              "        4.99920218e+00, 1.04374187e-02, 1.13012241e+00, 7.47643030e-01,\n",
              "        2.75761783e-01, 5.57276766e-01, 1.48905613e-01, 2.30464656e-05,\n",
              "        1.69809484e+01, 8.69360186e-01, 1.93603187e+01]),\n",
              " array([3.47754838e-01, 5.40632100e-01, 9.97791495e-01, 6.49350820e-01,\n",
              "        7.03236185e-01, 9.37952291e-01, 4.01356564e-01, 9.45059716e-02,\n",
              "        2.53590056e-02, 9.18626751e-01, 2.87749230e-01, 3.87223489e-01,\n",
              "        5.99492646e-01, 4.55359561e-01, 6.99583395e-01, 9.96169631e-01,\n",
              "        3.77567873e-05, 3.51132497e-01, 1.08232811e-05]))"
            ]
          },
          "metadata": {},
          "execution_count": 845
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pvalues = pd.Series(f_score[1])\n",
        "pvalues.index = X.columns\n",
        "pvalues.sort_values(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xp3b1pMe9AS",
        "outputId": "033fafc2-ec84-4cf9-885a-fa83428bcdbf"
      },
      "execution_count": 846,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "G                                            0.000011\n",
              "P                                            0.000038\n",
              "Были ли нарушения сна                        0.025359\n",
              "Здоровье от 1 до 10                          0.094506\n",
              "Операции                                     0.287749\n",
              "Пол                                          0.347755\n",
              "N                                            0.351132\n",
              "ЧМТ                                          0.387223\n",
              "Удовлетворенность материальным положением    0.401357\n",
              "Дебют                                        0.455360\n",
              "Полных лет                                   0.540632\n",
              "Насл отягощенность                           0.599493\n",
              "Род занятий(0-0, работает-1                  0.649351\n",
              "Частота госпит                               0.699583\n",
              "Семейное положение(0-0, 1-женат)             0.703236\n",
              "ИМТ                                          0.918627\n",
              "Удовлетворенность семеными отношениями       0.937952\n",
              "Стаж шизофр                                  0.996170\n",
              "Образование(0-начальное, 4-высшее)           0.997791\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 846
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now use the SelectKBest Model with the chi2 classifier to find the best features\n",
        "\n",
        "sel_ = SelectKBest(chi2, k=5).fit(X, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pelM22yef1sD",
        "outputId": "9a37bd1d-78cd-49aa-b1b1-83c89f533b86"
      },
      "execution_count": 847,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Здоровье от 1 до 10', 'Были ли нарушения сна', 'Операции', 'P', 'G'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 847
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tra8Cu0Af292"
      },
      "execution_count": 847,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4TvTeApRfKkw"
      },
      "execution_count": 847,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "QVqfCfsgQHwV",
        "outputId": "b723cd22-072a-492a-f297-974973b5ead0"
      },
      "execution_count": 848,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Пол  Полных лет  Образование(0-начальное, 4-высшее)  \\\n",
              "0   1.0        32.0                                 4.0   \n",
              "1   1.0        26.0                                 2.0   \n",
              "2   1.0        49.0                                 2.0   \n",
              "3   1.0        50.0                                 2.0   \n",
              "4   1.0        39.0                                 2.0   \n",
              "5   1.0        26.0                                 2.0   \n",
              "6   1.0        35.0                                 3.0   \n",
              "7   1.0        31.0                                 3.0   \n",
              "8   1.0        23.0                                 2.0   \n",
              "9   1.0        37.0                                 3.0   \n",
              "10  1.0        39.0                                 3.0   \n",
              "11  1.0        29.0                                 1.0   \n",
              "12  1.0        36.0                                 4.0   \n",
              "13  1.0        33.0                                 3.0   \n",
              "14  1.0        24.0                                 2.0   \n",
              "15  1.0        54.0                                 4.0   \n",
              "16  1.0        32.0                                 2.0   \n",
              "17  1.0        29.0                                 2.0   \n",
              "18  1.0        49.0                                 2.0   \n",
              "19  1.0        34.0                                 2.0   \n",
              "\n",
              "    Род занятий(0-0, работает-1  Семейное положение(0-0, 1-женат)  \\\n",
              "0                           0.0                               0.0   \n",
              "1                           0.0                               0.0   \n",
              "2                           0.0                               0.0   \n",
              "3                           0.0                               0.0   \n",
              "4                           0.0                               0.0   \n",
              "5                           1.0                               1.0   \n",
              "6                           0.0                               0.0   \n",
              "7                           0.0                               0.0   \n",
              "8                           0.0                               0.0   \n",
              "9                           1.0                               0.0   \n",
              "10                          1.0                               0.0   \n",
              "11                          0.0                               0.0   \n",
              "12                          0.0                               0.0   \n",
              "13                          1.0                               1.0   \n",
              "14                          1.0                               0.0   \n",
              "15                          0.0                               0.0   \n",
              "16                          0.0                               0.0   \n",
              "17                          0.0                               0.0   \n",
              "18                          0.0                               0.0   \n",
              "19                          1.0                               0.0   \n",
              "\n",
              "    Удовлетворенность семеными отношениями  \\\n",
              "0                                      5.0   \n",
              "1                                      5.0   \n",
              "2                                      5.0   \n",
              "3                                      5.0   \n",
              "4                                      5.0   \n",
              "5                                      5.0   \n",
              "6                                      5.0   \n",
              "7                                      1.0   \n",
              "8                                      4.0   \n",
              "9                                      5.0   \n",
              "10                                     1.0   \n",
              "11                                     5.0   \n",
              "12                                     1.0   \n",
              "13                                     5.0   \n",
              "14                                     5.0   \n",
              "15                                     2.0   \n",
              "16                                     5.0   \n",
              "17                                     4.0   \n",
              "18                                     4.0   \n",
              "19                                     4.0   \n",
              "\n",
              "    Удовлетворенность материальным положением  Здоровье от 1 до 10  \\\n",
              "0                                         0.0                  7.0   \n",
              "1                                         0.0                 10.0   \n",
              "2                                         1.0                 10.0   \n",
              "3                                         1.0                  7.0   \n",
              "4                                         1.0                  7.0   \n",
              "5                                         1.0                 10.0   \n",
              "6                                         1.0                  5.0   \n",
              "7                                         0.0                  3.0   \n",
              "8                                         1.0                  7.0   \n",
              "9                                         0.0                  7.0   \n",
              "10                                        0.0                  1.0   \n",
              "11                                        1.0                 10.0   \n",
              "12                                        0.0                  7.0   \n",
              "13                                        1.0                 10.0   \n",
              "14                                        1.0                  5.0   \n",
              "15                                        0.0                  5.0   \n",
              "16                                        1.0                  9.0   \n",
              "17                                        1.0                 10.0   \n",
              "18                                        0.0                 10.0   \n",
              "19                                        0.0                 10.0   \n",
              "\n",
              "    Были ли нарушения сна        ИМТ  ...  Частота госпит  Стаж шизофр     P  \\\n",
              "0                     1.0  24.012346  ...             0.0         3.70  11.0   \n",
              "1                     1.0  20.244898  ...             1.0         2.00  10.0   \n",
              "2                     0.0  29.752745  ...             2.0        23.00   9.0   \n",
              "3                     1.0  22.093170  ...             1.0        34.00  13.0   \n",
              "4                     0.0  20.761246  ...             0.0         4.00   9.0   \n",
              "5                     1.0  25.737082  ...             2.0         1.00   7.0   \n",
              "6                     0.0  23.547880  ...             2.0        12.20  14.0   \n",
              "7                     1.0  26.128611  ...             1.0         9.00   7.0   \n",
              "8                     0.0  18.812147  ...             0.0         5.67  15.0   \n",
              "9                     0.0  20.761246  ...             2.0        11.00  18.0   \n",
              "10                    1.0  23.148148  ...             2.0        16.00  19.0   \n",
              "11                    1.0  25.661152  ...             2.0        16.00  15.0   \n",
              "12                    1.0  29.407787  ...             2.0        15.00  11.0   \n",
              "13                    1.0  26.827421  ...             0.0        13.00   9.0   \n",
              "14                    1.0  25.390625  ...             0.0         8.00  12.0   \n",
              "15                    0.0  29.411764  ...             2.0        19.00  14.0   \n",
              "16                    0.0  22.724403  ...             2.0        17.00   8.0   \n",
              "17                    0.0  21.877550  ...             2.0        11.00   8.0   \n",
              "18                    0.0  24.092970  ...             2.0        20.00   7.0   \n",
              "19                    1.0  22.386314  ...             2.0        17.00  13.0   \n",
              "\n",
              "       N     G  PSQI  psqi больше 5  (ТРЕВОГА)Гаиильтон больше 16  \\\n",
              "0   11.0  18.0   6.0            1.0                           0.0   \n",
              "1   25.0  36.0   8.0            1.0                           0.0   \n",
              "2   16.0  23.0   3.0            0.0                           0.0   \n",
              "3   13.0  20.0   6.0            1.0                           0.0   \n",
              "4   13.0  22.0   4.0            0.0                           0.0   \n",
              "5    9.0  21.0   1.0            0.0                           0.0   \n",
              "6   20.0  40.0   8.0            1.0                           1.0   \n",
              "7    7.0  16.0   6.0            1.0                           0.0   \n",
              "8   11.0  28.0   8.0            1.0                           0.0   \n",
              "9    7.0  22.0   7.0            1.0                           0.0   \n",
              "10  13.0  41.0  11.0            1.0                           1.0   \n",
              "11   9.0  26.0   8.0            1.0                           0.0   \n",
              "12  19.0  48.0  10.0            1.0                           1.0   \n",
              "13   7.0  25.0  10.0            1.0                           0.0   \n",
              "14  11.0  23.0   7.0            1.0                           1.0   \n",
              "15  11.0  31.0   5.0            0.0                           0.0   \n",
              "16   9.0  22.0   3.0            0.0                           0.0   \n",
              "17   9.0  24.0   4.0            0.0                           0.0   \n",
              "18   7.0  18.0   2.0            0.0                           0.0   \n",
              "19  12.0  28.0   8.0            1.0                           0.0   \n",
              "\n",
              "    (ДЕПРЕССИЯ)madrs больше 6  (ДЕПРЕССИЯ)Калгари больше 5  \n",
              "0                         0.0                          0.0  \n",
              "1                         1.0                          1.0  \n",
              "2                         0.0                          0.0  \n",
              "3                         0.0                          0.0  \n",
              "4                         0.0                          0.0  \n",
              "5                         0.0                          0.0  \n",
              "6                         1.0                          0.0  \n",
              "7                         0.0                          0.0  \n",
              "8                         0.0                          0.0  \n",
              "9                         0.0                          0.0  \n",
              "10                        1.0                          1.0  \n",
              "11                        0.0                          0.0  \n",
              "12                        1.0                          1.0  \n",
              "13                        1.0                          0.0  \n",
              "14                        1.0                          1.0  \n",
              "15                        0.0                          0.0  \n",
              "16                        0.0                          0.0  \n",
              "17                        0.0                          0.0  \n",
              "18                        0.0                          0.0  \n",
              "19                        1.0                          1.0  \n",
              "\n",
              "[20 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-344551fa-c649-4ab6-989d-4b39fe76226e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Пол</th>\n",
              "      <th>Полных лет</th>\n",
              "      <th>Образование(0-начальное, 4-высшее)</th>\n",
              "      <th>Род занятий(0-0, работает-1</th>\n",
              "      <th>Семейное положение(0-0, 1-женат)</th>\n",
              "      <th>Удовлетворенность семеными отношениями</th>\n",
              "      <th>Удовлетворенность материальным положением</th>\n",
              "      <th>Здоровье от 1 до 10</th>\n",
              "      <th>Были ли нарушения сна</th>\n",
              "      <th>ИМТ</th>\n",
              "      <th>...</th>\n",
              "      <th>Частота госпит</th>\n",
              "      <th>Стаж шизофр</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>G</th>\n",
              "      <th>PSQI</th>\n",
              "      <th>psqi больше 5</th>\n",
              "      <th>(ТРЕВОГА)Гаиильтон больше 16</th>\n",
              "      <th>(ДЕПРЕССИЯ)madrs больше 6</th>\n",
              "      <th>(ДЕПРЕССИЯ)Калгари больше 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.012346</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.70</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.244898</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.752745</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.093170</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.761246</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.737082</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.547880</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.20</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.128611</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.812147</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.67</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.761246</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.00</td>\n",
              "      <td>18.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.148148</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.661152</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.407787</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.827421</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.390625</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.411764</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.724403</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.00</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.877550</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.00</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.092970</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.386314</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-344551fa-c649-4ab6-989d-4b39fe76226e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-344551fa-c649-4ab6-989d-4b39fe76226e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-344551fa-c649-4ab6-989d-4b39fe76226e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 848
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_chi2 # TOP 3 - ИМТ, P, G. TOP 5 - Были ли нарушения сна, забол кожи и топ3"
      ],
      "metadata": {
        "id": "RKzIBlkeNe7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db8590b-2bf9-4e1a-ddb8-4addbb239af6"
      },
      "execution_count": 849,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.,  1.,  0., 11., 18.],\n",
              "       [10.,  1.,  0., 10., 36.],\n",
              "       [10.,  0.,  0.,  9., 23.],\n",
              "       [ 7.,  1.,  1., 13., 20.],\n",
              "       [ 7.,  0.,  1.,  9., 22.],\n",
              "       [10.,  1.,  0.,  7., 21.],\n",
              "       [ 5.,  0.,  1., 14., 40.],\n",
              "       [ 3.,  1.,  0.,  7., 16.],\n",
              "       [ 7.,  0.,  1., 15., 28.],\n",
              "       [ 7.,  0.,  0., 18., 22.],\n",
              "       [ 1.,  1.,  1., 19., 41.],\n",
              "       [10.,  1.,  0., 15., 26.],\n",
              "       [ 7.,  1.,  1., 11., 48.],\n",
              "       [10.,  1.,  1.,  9., 25.],\n",
              "       [ 5.,  1.,  1., 12., 23.],\n",
              "       [ 5.,  0.,  0., 14., 31.],\n",
              "       [ 9.,  0.,  0.,  8., 22.],\n",
              "       [10.,  0.,  1.,  8., 24.],\n",
              "       [10.,  0.,  1.,  7., 18.],\n",
              "       [10.,  1.,  1., 13., 28.],\n",
              "       [ 9.,  1.,  0.,  8., 20.],\n",
              "       [10.,  0.,  0.,  7., 16.],\n",
              "       [ 4.,  1.,  1.,  8., 22.],\n",
              "       [10.,  0.,  0.,  8., 25.],\n",
              "       [ 5.,  1.,  0., 22., 37.],\n",
              "       [ 7.,  1.,  0., 11., 35.],\n",
              "       [ 7.,  0.,  0., 15., 31.],\n",
              "       [ 7.,  1.,  1., 13., 23.],\n",
              "       [ 9.,  1.,  1., 13., 30.],\n",
              "       [ 9.,  1.,  1., 10., 25.],\n",
              "       [ 9.,  0.,  1., 11., 18.],\n",
              "       [ 5.,  0.,  1., 13., 24.],\n",
              "       [ 2.,  0.,  0., 10., 31.],\n",
              "       [ 9.,  0.,  1., 13., 27.],\n",
              "       [10.,  1.,  1., 14., 27.],\n",
              "       [ 8.,  1.,  1.,  8., 28.],\n",
              "       [ 8.,  1.,  1., 12., 23.],\n",
              "       [ 7.,  1.,  1., 10., 29.],\n",
              "       [ 1.,  0.,  0., 22., 43.],\n",
              "       [ 7.,  1.,  1., 18., 33.],\n",
              "       [ 9.,  1.,  0., 17., 25.],\n",
              "       [ 9.,  0.,  0., 20., 30.],\n",
              "       [ 8.,  1.,  1., 17., 19.],\n",
              "       [10.,  0.,  0.,  9., 21.],\n",
              "       [10.,  1.,  1., 22., 36.],\n",
              "       [10.,  0.,  1., 11., 24.],\n",
              "       [ 9.,  1.,  0., 11., 22.],\n",
              "       [ 9.,  0.,  1.,  7., 16.],\n",
              "       [ 8.,  1.,  0., 10., 34.],\n",
              "       [10.,  0.,  1.,  7., 18.],\n",
              "       [ 8.,  0.,  1., 20., 35.],\n",
              "       [10.,  1.,  0., 18., 25.],\n",
              "       [10.,  0.,  1.,  7., 22.],\n",
              "       [10.,  0.,  1., 12., 25.],\n",
              "       [10.,  0.,  0.,  7., 22.],\n",
              "       [10.,  1.,  1., 11., 28.],\n",
              "       [10.,  1.,  1.,  7., 18.],\n",
              "       [10.,  0.,  0.,  9., 19.],\n",
              "       [10.,  0.,  0.,  7., 18.],\n",
              "       [ 6.,  0.,  0., 10., 21.],\n",
              "       [ 8.,  0.,  1.,  9., 18.],\n",
              "       [10.,  1.,  0.,  7., 18.],\n",
              "       [ 6.,  1.,  1., 17., 34.],\n",
              "       [ 9.,  1.,  1., 15., 20.],\n",
              "       [10.,  0.,  0., 11., 29.],\n",
              "       [ 6.,  1.,  1., 20., 32.],\n",
              "       [10.,  1.,  0., 15., 42.],\n",
              "       [ 3.,  1.,  1., 10., 26.],\n",
              "       [ 8.,  1.,  0., 10., 26.],\n",
              "       [ 7.,  1.,  1., 15., 31.],\n",
              "       [ 7.,  0.,  0.,  7., 23.],\n",
              "       [ 2.,  1.,  0.,  7., 30.],\n",
              "       [10.,  1.,  0.,  7., 24.],\n",
              "       [ 9.,  1.,  0.,  9., 18.],\n",
              "       [ 9.,  1.,  1.,  7., 18.],\n",
              "       [10.,  0.,  0., 16., 29.],\n",
              "       [ 6.,  0.,  0., 18., 32.],\n",
              "       [ 7.,  0.,  1.,  7., 25.],\n",
              "       [ 3.,  1.,  0., 28., 43.],\n",
              "       [ 8.,  0.,  0., 10., 21.],\n",
              "       [10.,  1.,  0.,  9., 27.],\n",
              "       [ 8.,  1.,  1., 14., 26.],\n",
              "       [10.,  1.,  0., 11., 28.],\n",
              "       [10.,  0.,  1.,  7., 24.],\n",
              "       [10.,  1.,  1.,  7., 16.],\n",
              "       [10.,  1.,  1.,  7., 16.],\n",
              "       [ 8.,  1.,  0.,  8., 23.],\n",
              "       [ 9.,  1.,  0.,  7., 24.],\n",
              "       [10.,  1.,  0.,  7., 18.],\n",
              "       [10.,  1.,  1.,  7., 21.],\n",
              "       [ 5.,  1.,  1.,  7., 18.],\n",
              "       [10.,  0.,  0., 17., 34.],\n",
              "       [ 5.,  0.,  1., 21., 28.],\n",
              "       [10.,  1.,  0.,  7., 30.],\n",
              "       [10.,  1.,  1.,  7., 16.],\n",
              "       [ 3.,  1.,  1., 14., 25.],\n",
              "       [10.,  0.,  0.,  7., 16.],\n",
              "       [ 7.,  0.,  0., 14., 20.],\n",
              "       [10.,  1.,  1., 20., 22.],\n",
              "       [10.,  0.,  0., 10., 26.],\n",
              "       [ 8.,  1.,  1.,  9., 17.],\n",
              "       [ 7.,  1.,  0.,  9., 18.],\n",
              "       [10.,  0.,  0.,  7., 18.],\n",
              "       [10.,  0.,  0.,  7., 18.],\n",
              "       [ 5.,  1.,  1., 25., 16.],\n",
              "       [ 9.,  1.,  1., 15., 18.],\n",
              "       [ 9.,  1.,  0., 10., 20.],\n",
              "       [ 8.,  0.,  0., 15., 35.],\n",
              "       [ 9.,  0.,  0., 15., 31.],\n",
              "       [ 9.,  1.,  1., 14., 30.],\n",
              "       [ 9.,  0.,  0.,  7., 16.],\n",
              "       [10.,  1.,  0.,  7., 20.],\n",
              "       [ 3.,  0.,  1., 13., 25.],\n",
              "       [ 9.,  1.,  1.,  7., 20.],\n",
              "       [ 8.,  1.,  0.,  7., 19.],\n",
              "       [ 5.,  1.,  1.,  9., 30.],\n",
              "       [ 7.,  0.,  0.,  9., 25.],\n",
              "       [10.,  0.,  0.,  7., 22.],\n",
              "       [10.,  1.,  0.,  7., 19.],\n",
              "       [10.,  1.,  1.,  9., 29.],\n",
              "       [ 7.,  1.,  0., 15., 30.],\n",
              "       [ 8.,  0.,  0., 10., 19.],\n",
              "       [ 6.,  1.,  0., 16., 33.],\n",
              "       [ 5.,  1.,  0., 14., 38.],\n",
              "       [ 9.,  1.,  1., 10., 29.],\n",
              "       [ 5.,  1.,  0., 20., 44.],\n",
              "       [ 8.,  1.,  0., 25., 49.],\n",
              "       [ 8.,  0.,  0., 11., 24.],\n",
              "       [ 5.,  1.,  0., 10., 33.],\n",
              "       [ 7.,  1.,  1.,  8., 25.],\n",
              "       [ 7.,  0.,  1.,  9., 32.],\n",
              "       [ 7.,  1.,  1., 11., 28.],\n",
              "       [ 8.,  1.,  0.,  9., 31.],\n",
              "       [ 7.,  0.,  0., 25., 44.],\n",
              "       [ 5.,  1.,  0., 16., 39.],\n",
              "       [10.,  0.,  0., 18., 25.],\n",
              "       [ 6.,  0.,  0.,  9., 26.],\n",
              "       [ 5.,  1.,  1., 24., 44.],\n",
              "       [10.,  1.,  0., 14., 35.],\n",
              "       [ 8.,  1.,  0., 10., 38.],\n",
              "       [ 5.,  1.,  0., 15., 34.],\n",
              "       [ 8.,  1.,  0.,  7., 28.],\n",
              "       [ 7.,  0.,  0., 15., 33.],\n",
              "       [ 5.,  0.,  1., 12., 28.],\n",
              "       [ 8.,  1.,  0., 17., 28.],\n",
              "       [10.,  1.,  0.,  9., 24.],\n",
              "       [ 8.,  1.,  0., 17., 25.],\n",
              "       [ 5.,  0.,  0., 24., 42.],\n",
              "       [ 6.,  1.,  0., 11., 35.],\n",
              "       [ 9.,  0.,  0.,  9., 36.],\n",
              "       [ 1.,  1.,  1., 20., 41.],\n",
              "       [ 8.,  1.,  1., 17., 23.],\n",
              "       [ 7.,  1.,  0., 11., 34.],\n",
              "       [ 1.,  0.,  1., 21., 52.],\n",
              "       [ 8.,  0.,  0.,  7., 22.],\n",
              "       [ 8.,  0.,  0.,  9., 21.],\n",
              "       [ 9.,  1.,  0., 20., 46.],\n",
              "       [ 7.,  1.,  1., 11., 29.],\n",
              "       [ 5.,  1.,  1., 18., 41.],\n",
              "       [ 3.,  0.,  1., 26., 38.],\n",
              "       [ 4.,  1.,  0., 21., 49.],\n",
              "       [10.,  1.,  1.,  7., 22.],\n",
              "       [ 6.,  1.,  1.,  8., 17.],\n",
              "       [10.,  1.,  1.,  9., 16.],\n",
              "       [ 9.,  1.,  1., 18., 16.],\n",
              "       [10.,  0.,  1.,  7., 16.],\n",
              "       [10.,  1.,  1., 18., 21.],\n",
              "       [ 6.,  0.,  0., 32., 56.],\n",
              "       [ 9.,  0.,  1., 25., 32.],\n",
              "       [10.,  1.,  0.,  7., 16.],\n",
              "       [ 7.,  1.,  1., 19., 31.],\n",
              "       [ 9.,  1.,  1., 10., 23.],\n",
              "       [10.,  1.,  0.,  7., 27.],\n",
              "       [ 9.,  1.,  1., 14., 21.],\n",
              "       [10.,  1.,  1.,  7., 28.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 849
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA"
      ],
      "metadata": {
        "id": "wVd6jE3hZslG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "univariate = f_classif(X, y)\n",
        "univariate"
      ],
      "metadata": {
        "id": "EUMyT5pBZnG7",
        "outputId": "cacdc5f1-f139-4149-b810-e04394ed66ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 850,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3.6212697e+00, 1.1628228e-01, 0.0000000e+00, 2.4870960e-01,\n",
              "        1.6109158e-01, 1.0520712e-02, 1.7331967e+00, 4.1912050e+00,\n",
              "        1.3949199e+01, 1.1808826e-02, 2.1281385e+00, 1.0316648e+00,\n",
              "        5.0901812e-01, 3.2690009e-01, 1.6404298e-01, 3.6380683e-05,\n",
              "        7.6243281e+00, 2.7182183e-01, 7.7019234e+00], dtype=float32),\n",
              " array([5.8706161e-02, 7.3351598e-01, 1.0000000e+00, 6.1861867e-01,\n",
              "        6.8864882e-01, 9.1842264e-01, 1.8974462e-01, 4.2146448e-02,\n",
              "        2.5474589e-04, 9.1359144e-01, 1.4642949e-01, 3.1118634e-01,\n",
              "        4.7652555e-01, 5.6823230e-01, 6.8596160e-01, 9.9519444e-01,\n",
              "        6.3802483e-03, 6.0277903e-01, 6.1230245e-03], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 850
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 2nd values are the PValue and we capture those below\n",
        "univariate = pd.Series(univariate[1])\n",
        "univariate.index = X.columns\n",
        "univariate.sort_values(ascending=False).plot.bar(figsize=(20,6))"
      ],
      "metadata": {
        "id": "b9wq1WrOZzPA",
        "outputId": "d4f581b1-3dcc-4232-f618-36263128566d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "execution_count": 851,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6634231250>"
            ]
          },
          "metadata": {},
          "execution_count": 851
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TOP 5 features\n",
        "sel_ = SelectKBest(f_classif, k=5).fit(X, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "id": "BIbA_QH2aNMQ",
        "outputId": "4714e4b2-e615-42ce-dc02-0b8a26135dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 852,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Пол', 'Здоровье от 1 до 10', 'Были ли нарушения сна', 'P', 'G'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 852
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I90-1SNSaPPg"
      },
      "execution_count": 852,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Lmy3RTQzZzxL"
      },
      "execution_count": 852,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_anova # TOP 3 - Были ли нарушения сна, P, G"
      ],
      "metadata": {
        "id": "RDWO9sN0O0xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f12a118-8986-44c8-cb08-1a98d5251968"
      },
      "execution_count": 853,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  7.,  1., 11., 18.],\n",
              "       [ 1., 10.,  1., 10., 36.],\n",
              "       [ 1., 10.,  0.,  9., 23.],\n",
              "       [ 1.,  7.,  1., 13., 20.],\n",
              "       [ 1.,  7.,  0.,  9., 22.],\n",
              "       [ 1., 10.,  1.,  7., 21.],\n",
              "       [ 1.,  5.,  0., 14., 40.],\n",
              "       [ 1.,  3.,  1.,  7., 16.],\n",
              "       [ 1.,  7.,  0., 15., 28.],\n",
              "       [ 1.,  7.,  0., 18., 22.],\n",
              "       [ 1.,  1.,  1., 19., 41.],\n",
              "       [ 1., 10.,  1., 15., 26.],\n",
              "       [ 1.,  7.,  1., 11., 48.],\n",
              "       [ 1., 10.,  1.,  9., 25.],\n",
              "       [ 1.,  5.,  1., 12., 23.],\n",
              "       [ 1.,  5.,  0., 14., 31.],\n",
              "       [ 1.,  9.,  0.,  8., 22.],\n",
              "       [ 1., 10.,  0.,  8., 24.],\n",
              "       [ 1., 10.,  0.,  7., 18.],\n",
              "       [ 1., 10.,  1., 13., 28.],\n",
              "       [ 1.,  9.,  1.,  8., 20.],\n",
              "       [ 1., 10.,  0.,  7., 16.],\n",
              "       [ 1.,  4.,  1.,  8., 22.],\n",
              "       [ 1., 10.,  0.,  8., 25.],\n",
              "       [ 1.,  5.,  1., 22., 37.],\n",
              "       [ 1.,  7.,  1., 11., 35.],\n",
              "       [ 1.,  7.,  0., 15., 31.],\n",
              "       [ 1.,  7.,  1., 13., 23.],\n",
              "       [ 1.,  9.,  1., 13., 30.],\n",
              "       [ 1.,  9.,  1., 10., 25.],\n",
              "       [ 1.,  9.,  0., 11., 18.],\n",
              "       [ 1.,  5.,  0., 13., 24.],\n",
              "       [ 1.,  2.,  0., 10., 31.],\n",
              "       [ 1.,  9.,  0., 13., 27.],\n",
              "       [ 1., 10.,  1., 14., 27.],\n",
              "       [ 1.,  8.,  1.,  8., 28.],\n",
              "       [ 1.,  8.,  1., 12., 23.],\n",
              "       [ 1.,  7.,  1., 10., 29.],\n",
              "       [ 0.,  1.,  0., 22., 43.],\n",
              "       [ 0.,  7.,  1., 18., 33.],\n",
              "       [ 0.,  9.,  1., 17., 25.],\n",
              "       [ 0.,  9.,  0., 20., 30.],\n",
              "       [ 0.,  8.,  1., 17., 19.],\n",
              "       [ 0., 10.,  0.,  9., 21.],\n",
              "       [ 0., 10.,  1., 22., 36.],\n",
              "       [ 0., 10.,  0., 11., 24.],\n",
              "       [ 0.,  9.,  1., 11., 22.],\n",
              "       [ 0.,  9.,  0.,  7., 16.],\n",
              "       [ 0.,  8.,  1., 10., 34.],\n",
              "       [ 1., 10.,  0.,  7., 18.],\n",
              "       [ 1.,  8.,  0., 20., 35.],\n",
              "       [ 1., 10.,  1., 18., 25.],\n",
              "       [ 1., 10.,  0.,  7., 22.],\n",
              "       [ 1., 10.,  0., 12., 25.],\n",
              "       [ 1., 10.,  0.,  7., 22.],\n",
              "       [ 1., 10.,  1., 11., 28.],\n",
              "       [ 1., 10.,  1.,  7., 18.],\n",
              "       [ 1., 10.,  0.,  9., 19.],\n",
              "       [ 1., 10.,  0.,  7., 18.],\n",
              "       [ 1.,  6.,  0., 10., 21.],\n",
              "       [ 1.,  8.,  0.,  9., 18.],\n",
              "       [ 1., 10.,  1.,  7., 18.],\n",
              "       [ 1.,  6.,  1., 17., 34.],\n",
              "       [ 1.,  9.,  1., 15., 20.],\n",
              "       [ 1., 10.,  0., 11., 29.],\n",
              "       [ 1.,  6.,  1., 20., 32.],\n",
              "       [ 1., 10.,  1., 15., 42.],\n",
              "       [ 0.,  3.,  1., 10., 26.],\n",
              "       [ 1.,  8.,  1., 10., 26.],\n",
              "       [ 0.,  7.,  1., 15., 31.],\n",
              "       [ 1.,  7.,  0.,  7., 23.],\n",
              "       [ 0.,  2.,  1.,  7., 30.],\n",
              "       [ 0., 10.,  1.,  7., 24.],\n",
              "       [ 0.,  9.,  1.,  9., 18.],\n",
              "       [ 0.,  9.,  1.,  7., 18.],\n",
              "       [ 0., 10.,  0., 16., 29.],\n",
              "       [ 0.,  6.,  0., 18., 32.],\n",
              "       [ 0.,  7.,  0.,  7., 25.],\n",
              "       [ 0.,  3.,  1., 28., 43.],\n",
              "       [ 1.,  8.,  0., 10., 21.],\n",
              "       [ 1., 10.,  1.,  9., 27.],\n",
              "       [ 0.,  8.,  1., 14., 26.],\n",
              "       [ 0., 10.,  1., 11., 28.],\n",
              "       [ 0., 10.,  0.,  7., 24.],\n",
              "       [ 0., 10.,  1.,  7., 16.],\n",
              "       [ 0., 10.,  1.,  7., 16.],\n",
              "       [ 0.,  8.,  1.,  8., 23.],\n",
              "       [ 0.,  9.,  1.,  7., 24.],\n",
              "       [ 0., 10.,  1.,  7., 18.],\n",
              "       [ 0., 10.,  1.,  7., 21.],\n",
              "       [ 0.,  5.,  1.,  7., 18.],\n",
              "       [ 0., 10.,  0., 17., 34.],\n",
              "       [ 1.,  5.,  0., 21., 28.],\n",
              "       [ 0., 10.,  1.,  7., 30.],\n",
              "       [ 1., 10.,  1.,  7., 16.],\n",
              "       [ 1.,  3.,  1., 14., 25.],\n",
              "       [ 0., 10.,  0.,  7., 16.],\n",
              "       [ 1.,  7.,  0., 14., 20.],\n",
              "       [ 1., 10.,  1., 20., 22.],\n",
              "       [ 1., 10.,  0., 10., 26.],\n",
              "       [ 1.,  8.,  1.,  9., 17.],\n",
              "       [ 1.,  7.,  1.,  9., 18.],\n",
              "       [ 1., 10.,  0.,  7., 18.],\n",
              "       [ 1., 10.,  0.,  7., 18.],\n",
              "       [ 1.,  5.,  1., 25., 16.],\n",
              "       [ 1.,  9.,  1., 15., 18.],\n",
              "       [ 1.,  9.,  1., 10., 20.],\n",
              "       [ 1.,  8.,  0., 15., 35.],\n",
              "       [ 1.,  9.,  0., 15., 31.],\n",
              "       [ 1.,  9.,  1., 14., 30.],\n",
              "       [ 1.,  9.,  0.,  7., 16.],\n",
              "       [ 1., 10.,  1.,  7., 20.],\n",
              "       [ 1.,  3.,  0., 13., 25.],\n",
              "       [ 1.,  9.,  1.,  7., 20.],\n",
              "       [ 1.,  8.,  1.,  7., 19.],\n",
              "       [ 1.,  5.,  1.,  9., 30.],\n",
              "       [ 1.,  7.,  0.,  9., 25.],\n",
              "       [ 1., 10.,  0.,  7., 22.],\n",
              "       [ 1., 10.,  1.,  7., 19.],\n",
              "       [ 1., 10.,  1.,  9., 29.],\n",
              "       [ 1.,  7.,  1., 15., 30.],\n",
              "       [ 0.,  8.,  0., 10., 19.],\n",
              "       [ 0.,  6.,  1., 16., 33.],\n",
              "       [ 1.,  5.,  1., 14., 38.],\n",
              "       [ 1.,  9.,  1., 10., 29.],\n",
              "       [ 1.,  5.,  1., 20., 44.],\n",
              "       [ 1.,  8.,  1., 25., 49.],\n",
              "       [ 1.,  8.,  0., 11., 24.],\n",
              "       [ 1.,  5.,  1., 10., 33.],\n",
              "       [ 1.,  7.,  1.,  8., 25.],\n",
              "       [ 1.,  7.,  0.,  9., 32.],\n",
              "       [ 1.,  7.,  1., 11., 28.],\n",
              "       [ 1.,  8.,  1.,  9., 31.],\n",
              "       [ 1.,  7.,  0., 25., 44.],\n",
              "       [ 0.,  5.,  1., 16., 39.],\n",
              "       [ 1., 10.,  0., 18., 25.],\n",
              "       [ 1.,  6.,  0.,  9., 26.],\n",
              "       [ 1.,  5.,  1., 24., 44.],\n",
              "       [ 1., 10.,  1., 14., 35.],\n",
              "       [ 1.,  8.,  1., 10., 38.],\n",
              "       [ 1.,  5.,  1., 15., 34.],\n",
              "       [ 1.,  8.,  1.,  7., 28.],\n",
              "       [ 1.,  7.,  0., 15., 33.],\n",
              "       [ 1.,  5.,  0., 12., 28.],\n",
              "       [ 1.,  8.,  1., 17., 28.],\n",
              "       [ 1., 10.,  1.,  9., 24.],\n",
              "       [ 1.,  8.,  1., 17., 25.],\n",
              "       [ 1.,  5.,  0., 24., 42.],\n",
              "       [ 1.,  6.,  1., 11., 35.],\n",
              "       [ 1.,  9.,  0.,  9., 36.],\n",
              "       [ 1.,  1.,  1., 20., 41.],\n",
              "       [ 1.,  8.,  1., 17., 23.],\n",
              "       [ 1.,  7.,  1., 11., 34.],\n",
              "       [ 1.,  1.,  0., 21., 52.],\n",
              "       [ 1.,  8.,  0.,  7., 22.],\n",
              "       [ 1.,  8.,  0.,  9., 21.],\n",
              "       [ 1.,  9.,  1., 20., 46.],\n",
              "       [ 1.,  7.,  1., 11., 29.],\n",
              "       [ 0.,  5.,  1., 18., 41.],\n",
              "       [ 0.,  3.,  0., 26., 38.],\n",
              "       [ 0.,  4.,  1., 21., 49.],\n",
              "       [ 0., 10.,  1.,  7., 22.],\n",
              "       [ 0.,  6.,  1.,  8., 17.],\n",
              "       [ 0., 10.,  1.,  9., 16.],\n",
              "       [ 1.,  9.,  1., 18., 16.],\n",
              "       [ 1., 10.,  0.,  7., 16.],\n",
              "       [ 1., 10.,  1., 18., 21.],\n",
              "       [ 1.,  6.,  0., 32., 56.],\n",
              "       [ 1.,  9.,  0., 25., 32.],\n",
              "       [ 1., 10.,  1.,  7., 16.],\n",
              "       [ 1.,  7.,  1., 19., 31.],\n",
              "       [ 1.,  9.,  1., 10., 23.],\n",
              "       [ 1., 10.,  1.,  7., 27.],\n",
              "       [ 1.,  9.,  1., 14., 21.],\n",
              "       [ 1., 10.,  1.,  7., 28.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 853
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F21u74y3UP6q"
      },
      "execution_count": 853,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find 4 best predictors witn scalied data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = minmax_scaler.fit_transform(X)\n",
        "X_chi2_scaled = SelectKBest(chi2, k=4).fit_transform(X_scaled, y)\n",
        "X_anova_scaled = SelectKBest(f_classif, k=4).fit_transform(X_scaled, y)"
      ],
      "metadata": {
        "id": "023I6vdtNf5b"
      },
      "execution_count": 854,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MUHcI8Zz8msw"
      },
      "execution_count": 854,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w4TOf6Gl8nDv"
      },
      "execution_count": 854,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hknAxieW8nHC"
      },
      "execution_count": 854,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_score_scaled = chi2(X_scaled, y)\n",
        "f_score_scaled\n",
        "# The first array is the F_score , 2nd one is the P_values\n",
        "# the smaller the P value the more significant the difference in the features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14mLv1Rcgpcb",
        "outputId": "c9dd8633-c639-4fcc-fcf9-2f80a8408a76"
      },
      "execution_count": 855,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([8.81632874e-01, 1.50330947e-02, 4.24027991e-06, 2.06719560e-01,\n",
              "        1.45127179e-01, 2.05485415e-03, 7.04258205e-01, 3.56339576e-01,\n",
              "        4.99920218e+00, 9.13889215e-04, 1.13012241e+00, 3.73821515e-01,\n",
              "        2.75761783e-01, 1.77243336e-02, 7.44528063e-02, 5.87319075e-07,\n",
              "        1.56535759e+00, 4.29520792e-02, 1.19095746e+00]),\n",
              " array([0.34775484, 0.90241631, 0.998357  , 0.64935082, 0.70323619,\n",
              "        0.96384388, 0.40135656, 0.5505462 , 0.02535901, 0.97588314,\n",
              "        0.28774923, 0.54092855, 0.59949265, 0.89408838, 0.78496052,\n",
              "        0.99938853, 0.21088249, 0.83581553, 0.27513651]))"
            ]
          },
          "metadata": {},
          "execution_count": 855
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pvalues = pd.Series(f_score_scaled[1])\n",
        "pvalues.index = X.columns\n",
        "pvalues.sort_values(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvYgWRBqgtKI",
        "outputId": "30f20f62-0397-4200-f563-c5a992c10611"
      },
      "execution_count": 856,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Были ли нарушения сна                        0.025359\n",
              "P                                            0.210882\n",
              "G                                            0.275137\n",
              "Операции                                     0.287749\n",
              "Пол                                          0.347755\n",
              "Удовлетворенность материальным положением    0.401357\n",
              "ЧМТ                                          0.540929\n",
              "Здоровье от 1 до 10                          0.550546\n",
              "Насл отягощенность                           0.599493\n",
              "Род занятий(0-0, работает-1                  0.649351\n",
              "Семейное положение(0-0, 1-женат)             0.703236\n",
              "Частота госпит                               0.784961\n",
              "N                                            0.835816\n",
              "Дебют                                        0.894088\n",
              "Полных лет                                   0.902416\n",
              "Удовлетворенность семеными отношениями       0.963844\n",
              "ИМТ                                          0.975883\n",
              "Образование(0-начальное, 4-высшее)           0.998357\n",
              "Стаж шизофр                                  0.999389\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 856
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now use the SelectKBest Model with the chi2 classifier to find the best features\n",
        "\n",
        "sel_ = SelectKBest(chi2, k=5).fit(X_scaled, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm1xMp0jgz-e",
        "outputId": "068147d1-f7b4-416c-a3e8-0c077c77d79e"
      },
      "execution_count": 857,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Пол', 'Были ли нарушения сна', 'Операции', 'P', 'G'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 857
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rOW1fDJzhImX"
      },
      "execution_count": 857,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA"
      ],
      "metadata": {
        "id": "YBuG7ukDhFuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "univariate_scaled = f_classif(X_scaled, y)\n",
        "univariate_scaled"
      ],
      "metadata": {
        "id": "OwBx45LZhG-8",
        "outputId": "b24f8e83-fcdc-4fb9-e333-1f51c7036c4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 858,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 3.62126970e+00,  1.16262905e-01,  0.00000000e+00,  2.48709604e-01,\n",
              "         1.61091581e-01,  1.05766766e-02,  1.73319674e+00,  4.19083738e+00,\n",
              "         1.39491987e+01,  1.14049437e-02,  2.12813854e+00,  1.03166485e+00,\n",
              "         5.09018123e-01,  3.27133834e-01,  1.64042979e-01, -2.91374363e-05,\n",
              "         7.62430048e+00,  2.71821856e-01,  7.70179749e+00], dtype=float32),\n",
              " array([5.8706161e-02, 7.3353732e-01, 1.0000000e+00, 6.1861867e-01,\n",
              "        6.8864882e-01, 9.1820669e-01, 1.8974462e-01, 4.2155363e-02,\n",
              "        2.5474589e-04, 9.1507620e-01, 1.4642949e-01, 3.1118634e-01,\n",
              "        4.7652555e-01, 5.6809413e-01, 6.8596160e-01,           nan,\n",
              "        6.3803419e-03, 6.0277903e-01, 6.1234334e-03], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 858
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 2nd values are the PValue and we capture those below\n",
        "univariate_scaled = pd.Series(univariate_scaled[1])\n",
        "univariate_scaled.index = X.columns\n",
        "univariate_scaled.sort_values(ascending=False).plot.bar(figsize=(20,6))"
      ],
      "metadata": {
        "id": "djLNEHfThKKz",
        "outputId": "9daa3fd1-7238-4f98-b373-a4b25efb3a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "execution_count": 859,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f663836ebd0>"
            ]
          },
          "metadata": {},
          "execution_count": 859
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TOP 5 features\n",
        "sel_ = SelectKBest(f_classif, k=5).fit(X_scaled, y)\n",
        "X.columns[sel_.get_support()]"
      ],
      "metadata": {
        "id": "KSGhE7K5hUqO",
        "outputId": "fccd9236-3fac-41cb-e5ad-a9503e39b3c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 860,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Пол', 'Здоровье от 1 до 10', 'Были ли нарушения сна', 'P', 'G'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 860
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L0FH6fE0hhzK"
      },
      "execution_count": 860,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OVxUbs4lhFwd"
      },
      "execution_count": 860,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0morjvDohFyU"
      },
      "execution_count": 860,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cE49CtiChHBb"
      },
      "execution_count": 860,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_chi2_scaled # Были ли нарушения сна, Динамека веса за год, Аллергии, ГБ"
      ],
      "metadata": {
        "id": "kK2YEY2VS9kV"
      },
      "execution_count": 861,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_anova_scaled # Были ли нарушения сна, Аллергии, P, G"
      ],
      "metadata": {
        "id": "aW029ll0S9nm"
      },
      "execution_count": 862,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many times and which features were the most influential?\n",
        "\n",
        "# Аллергии 4\n",
        "# Были ли нарушения сна  3\n",
        "# P 3\n",
        "# G 3\n",
        "# Динамека веса за год 1 \n",
        "# ГБ 1\n",
        "# Стаж шизофр 1"
      ],
      "metadata": {
        "id": "JGbIT52RS9pu"
      },
      "execution_count": 863,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using best features\n",
        "# X = X[['Аллергии', 'Были ли нарушения сна', 'P', 'G']]\n",
        "\n",
        "# X = X[['Забол кожи', 'Были ли нарушения сна', 'Панкреатит', 'ГБ']]\n",
        "\n",
        "# X = X[['Удовлетворенность материальным положением', 'Были ли нарушения сна', 'Забол кожи', 'P', 'G']]\n",
        "\n",
        "# X = X[['Забол кожи', 'Были ли нарушения сна', 'Панкреатит', 'ГБ', 'P']]\n",
        "\n",
        "# X = X[['P', 'G', 'ИМТ', 'Были ли нарушения сна', 'N']]\n",
        "\n",
        "# X = X[['Были ли нарушения сна', 'Забол кожи', 'P']]\n",
        "\n",
        "# X = X[['Были ли нарушения сна', 'Операции', 'P', 'G']]\n",
        "\n",
        "# X = X[['Полных лет', 'Дебют', 'Стаж шизофр', 'N', 'G']]\n",
        "\n",
        "X = X[['Полных лет', 'Дебют', 'Стаж шизофр', 'P', 'N', 'G']]"
      ],
      "metadata": {
        "id": "cA1BbqGaS9ru"
      },
      "execution_count": 864,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper functions file\n",
        "import os\n",
        "if not os.path.exists(\"helper_functions.py\"):\n",
        "    print(\"Downloading helper functions...\")\n",
        "    !wget https://raw.githubusercontent.com/Nikitaion/TensorFlowLearning/main/extras/helper_functions.py\n",
        "else:\n",
        "    print(\"Helper functions file already exists, skipping download...\")"
      ],
      "metadata": {
        "id": "ztJnG1gMpQKR",
        "outputId": "b9c0da6d-b91b-4571-b7c7-547ffa43f6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 865,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions file already exists, skipping download...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create ModelCheckpoint callback to save model's progress\n",
        "# checkpoint_path = \"model_checkpoints/cp.ckpt\" # saving weights requires \".ckpt\" extension\n",
        "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "#                                                       montior=\"val_accuracy\", # save the model weights with best validation accuracy\n",
        "#                                                       save_best_only=True, # only save the best weights\n",
        "#                                                       save_weights_only=True) # only save model weights (not whole model)\n",
        "#                                                       # verbose=1) # don't print out whether or not model is being saved\n",
        "\n",
        "# Create a function to implment a ModelCheckpoint callback with a specific filename\n",
        "def create_model_checkpoint(model_name, save_path=\"model_experiments\"):\n",
        "  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name),\n",
        "                                            monitor=\"val_accuracy\", # was 'val_loss'\n",
        "                                            verbose=0, #only output a limited amount of text\n",
        "                                            save_best_only=True)\n"
      ],
      "metadata": {
        "id": "1mRN6S7XpPD6"
      },
      "execution_count": 866,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/valid/test split\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15)\n",
        "\n",
        "\n",
        "# Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "X_train_scaled = minmax_scaler.fit_transform(X_train)\n",
        "X_valid_scaled = minmax_scaler.transform(X_valid)\n",
        "X_test_scaled = minmax_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "EkYpF44DNQjU"
      },
      "execution_count": 867,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model1.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history1 = model1.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=22,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model1.name)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cdqTwvKMbi",
        "outputId": "77d89e24-135a-4a43-f333-af5be4c78f0e"
      },
      "execution_count": 868,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n",
            "1/4 [======>.......................] - ETA: 1s - loss: 0.6919 - accuracy: 0.6250INFO:tensorflow:Assets written to: model_experiments/sequential_75/assets\n",
            "4/4 [==============================] - 1s 302ms/step - loss: 0.6873 - accuracy: 0.6000 - val_loss: 0.6750 - val_accuracy: 0.6296\n",
            "Epoch 2/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.5760 - val_loss: 0.6619 - val_accuracy: 0.6296\n",
            "Epoch 3/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5760 - val_loss: 0.6615 - val_accuracy: 0.6296\n",
            "Epoch 4/22\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6785 - accuracy: 0.5760 - val_loss: 0.6604 - val_accuracy: 0.6296\n",
            "Epoch 5/22\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6788 - accuracy: 0.5760 - val_loss: 0.6608 - val_accuracy: 0.6296\n",
            "Epoch 6/22\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5760 - val_loss: 0.6590 - val_accuracy: 0.6296\n",
            "Epoch 7/22\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6769 - accuracy: 0.5760 - val_loss: 0.6601 - val_accuracy: 0.6296\n",
            "Epoch 8/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.5760 - val_loss: 0.6592 - val_accuracy: 0.6296\n",
            "Epoch 9/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6752 - accuracy: 0.5760 - val_loss: 0.6585 - val_accuracy: 0.6296\n",
            "Epoch 10/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6727 - accuracy: 0.5760 - val_loss: 0.6547 - val_accuracy: 0.6296\n",
            "Epoch 11/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6724 - accuracy: 0.5760 - val_loss: 0.6498 - val_accuracy: 0.6296\n",
            "Epoch 12/22\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6701 - accuracy: 0.5760 - val_loss: 0.6482 - val_accuracy: 0.6296\n",
            "Epoch 13/22\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6671 - accuracy: 0.5760 - val_loss: 0.6466 - val_accuracy: 0.6296\n",
            "Epoch 14/22\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6658 - accuracy: 0.5760 - val_loss: 0.6435 - val_accuracy: 0.6296\n",
            "Epoch 15/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6617 - accuracy: 0.5760 - val_loss: 0.6412 - val_accuracy: 0.6296\n",
            "Epoch 16/22\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6607 - accuracy: 0.5760 - val_loss: 0.6364 - val_accuracy: 0.6296\n",
            "Epoch 17/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6570 - accuracy: 0.5760 - val_loss: 0.6336 - val_accuracy: 0.6296\n",
            "Epoch 18/22\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6551 - accuracy: 0.5760 - val_loss: 0.6313 - val_accuracy: 0.6296\n",
            "Epoch 19/22\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6546 - accuracy: 0.5840 - val_loss: 0.6309 - val_accuracy: 0.6296\n",
            "Epoch 20/22\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6540 - accuracy: 0.6320 - val_loss: 0.6310 - val_accuracy: 0.6296\n",
            "Epoch 21/22\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6456 - accuracy: 0.5938INFO:tensorflow:Assets written to: model_experiments/sequential_75/assets\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.6512 - accuracy: 0.6320 - val_loss: 0.6297 - val_accuracy: 0.6667\n",
            "Epoch 22/22\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6564 - accuracy: 0.6562INFO:tensorflow:Assets written to: model_experiments/sequential_75/assets\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.6662 - accuracy: 0.5920 - val_loss: 0.6258 - val_accuracy: 0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "KRbfjDQWqt0l",
        "outputId": "f94885a9-fe9f-4d0b-a290-84a531b0ab6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 869,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step - loss: 16.9139 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[16.913942337036133, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 869
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.models.load_model(f\"/content/model_experiments/{model1.name}\")\n",
        "model1.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQgxT9Qd5r8y",
        "outputId": "a07a5519-1187-4e36-b094-8f0a33a2b6d7"
      },
      "execution_count": 870,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 153ms/step - loss: 16.9139 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[16.913942337036133, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 870
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SowPTdIT6Fwq"
      },
      "execution_count": 870,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history2 = model2.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=19,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model2.name)])"
      ],
      "metadata": {
        "id": "q9VW_1RycyHm",
        "outputId": "372820d5-214c-4ed4-d07c-c2ce2bf40665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 871,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/19\n",
            "1/4 [======>.......................] - ETA: 1s - loss: 0.6915 - accuracy: 0.4688INFO:tensorflow:Assets written to: model_experiments/sequential_76/assets\n",
            "4/4 [==============================] - 1s 303ms/step - loss: 0.6819 - accuracy: 0.5600 - val_loss: 0.6527 - val_accuracy: 0.6296\n",
            "Epoch 2/19\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7041 - accuracy: 0.5760 - val_loss: 0.6552 - val_accuracy: 0.6296\n",
            "Epoch 3/19\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5760 - val_loss: 0.6715 - val_accuracy: 0.6296\n",
            "Epoch 4/19\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6821 - accuracy: 0.5760 - val_loss: 0.6785 - val_accuracy: 0.6296\n",
            "Epoch 5/19\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5520 - val_loss: 0.6754 - val_accuracy: 0.6296\n",
            "Epoch 6/19\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5760 - val_loss: 0.6640 - val_accuracy: 0.6296\n",
            "Epoch 7/19\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6731 - accuracy: 0.5760 - val_loss: 0.6596 - val_accuracy: 0.6296\n",
            "Epoch 8/19\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6717 - accuracy: 0.5760 - val_loss: 0.6529 - val_accuracy: 0.6296\n",
            "Epoch 9/19\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6668 - accuracy: 0.5600 - val_loss: 0.6475 - val_accuracy: 0.6296\n",
            "Epoch 10/19\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6503 - accuracy: 0.6250INFO:tensorflow:Assets written to: model_experiments/sequential_76/assets\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.6573 - accuracy: 0.5600 - val_loss: 0.6445 - val_accuracy: 0.7037\n",
            "Epoch 11/19\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6578 - accuracy: 0.5680 - val_loss: 0.6407 - val_accuracy: 0.5926\n",
            "Epoch 12/19\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6589 - accuracy: 0.6160 - val_loss: 0.6415 - val_accuracy: 0.5185\n",
            "Epoch 13/19\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6566 - accuracy: 0.6000 - val_loss: 0.6393 - val_accuracy: 0.6296\n",
            "Epoch 14/19\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6487 - accuracy: 0.6080 - val_loss: 0.6344 - val_accuracy: 0.5926\n",
            "Epoch 15/19\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6432 - accuracy: 0.6080 - val_loss: 0.6343 - val_accuracy: 0.5556\n",
            "Epoch 16/19\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6406 - accuracy: 0.6240 - val_loss: 0.6318 - val_accuracy: 0.5926\n",
            "Epoch 17/19\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6389 - accuracy: 0.6160 - val_loss: 0.6337 - val_accuracy: 0.5926\n",
            "Epoch 18/19\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6341 - accuracy: 0.6240 - val_loss: 0.6232 - val_accuracy: 0.6667\n",
            "Epoch 19/19\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6330 - accuracy: 0.6240 - val_loss: 0.6287 - val_accuracy: 0.6296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npvp-cKs7lwK",
        "outputId": "5bfdc94d-c30e-4851-85b8-d896c6ed9b14"
      },
      "execution_count": 872,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 1.4204 - accuracy: 0.6522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4203765392303467, 0.6521739363670349]"
            ]
          },
          "metadata": {},
          "execution_count": 872
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.load_model(f\"/content/model_experiments/{model2.name}\")\n",
        "model2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "LpO3HR26qyu3",
        "outputId": "30cc265c-271f-41e3-e7fc-e8823e54b044",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 873,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 128ms/step - loss: 4.1842 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.184155464172363, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 873
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model3.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history3 = model3.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=22,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model3.name)])"
      ],
      "metadata": {
        "id": "2tsjSDV7eP3u",
        "outputId": "1722513e-6ee6-4223-b2a0-50cc2c5a6153",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 874,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n",
            "1/4 [======>.......................] - ETA: 1s - loss: 0.6885 - accuracy: 0.6562INFO:tensorflow:Assets written to: model_experiments/sequential_77/assets\n",
            "4/4 [==============================] - 1s 290ms/step - loss: 0.6933 - accuracy: 0.5360 - val_loss: 0.6586 - val_accuracy: 0.6296\n",
            "Epoch 2/22\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.5760 - val_loss: 0.6519 - val_accuracy: 0.6296\n",
            "Epoch 3/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5840 - val_loss: 0.6744 - val_accuracy: 0.5926\n",
            "Epoch 4/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.5840 - val_loss: 0.6725 - val_accuracy: 0.6296\n",
            "Epoch 5/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.5760 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 6/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5760 - val_loss: 0.6505 - val_accuracy: 0.6296\n",
            "Epoch 7/22\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6713 - accuracy: 0.5760 - val_loss: 0.6470 - val_accuracy: 0.6296\n",
            "Epoch 8/22\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6705 - accuracy: 0.5760 - val_loss: 0.6398 - val_accuracy: 0.6296\n",
            "Epoch 9/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6656 - accuracy: 0.5760 - val_loss: 0.6345 - val_accuracy: 0.6296\n",
            "Epoch 10/22\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6542 - accuracy: 0.5760 - val_loss: 0.6356 - val_accuracy: 0.6296\n",
            "Epoch 11/22\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6597 - accuracy: 0.5760 - val_loss: 0.6299 - val_accuracy: 0.6296\n",
            "Epoch 12/22\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6209 - accuracy: 0.5938INFO:tensorflow:Assets written to: model_experiments/sequential_77/assets\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.6525 - accuracy: 0.5840 - val_loss: 0.6331 - val_accuracy: 0.7037\n",
            "Epoch 13/22\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6441 - accuracy: 0.7188INFO:tensorflow:Assets written to: model_experiments/sequential_77/assets\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.6531 - accuracy: 0.5920 - val_loss: 0.6237 - val_accuracy: 0.7407\n",
            "Epoch 14/22\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6503 - accuracy: 0.5680 - val_loss: 0.6255 - val_accuracy: 0.6667\n",
            "Epoch 15/22\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6326 - accuracy: 0.6480 - val_loss: 0.6426 - val_accuracy: 0.5185\n",
            "Epoch 16/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6384 - accuracy: 0.6640 - val_loss: 0.6281 - val_accuracy: 0.6667\n",
            "Epoch 17/22\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6318 - accuracy: 0.6240 - val_loss: 0.6314 - val_accuracy: 0.7037\n",
            "Epoch 18/22\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6230 - accuracy: 0.6400 - val_loss: 0.6323 - val_accuracy: 0.7037\n",
            "Epoch 19/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6181 - accuracy: 0.6480 - val_loss: 0.6446 - val_accuracy: 0.5926\n",
            "Epoch 20/22\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6140 - accuracy: 0.6720 - val_loss: 0.6247 - val_accuracy: 0.7407\n",
            "Epoch 21/22\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6069 - accuracy: 0.6480 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
            "Epoch 22/22\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6389 - accuracy: 0.6160 - val_loss: 0.6613 - val_accuracy: 0.5926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NDBuLs_7nCE",
        "outputId": "418c7ef3-db91-481f-8c7b-7be6fea38d6f"
      },
      "execution_count": 875,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 4.0169 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.016941070556641, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 875
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tf.keras.models.load_model(f\"/content/model_experiments/{model3.name}\")\n",
        "model3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "p6e78-hkq0FB",
        "outputId": "f46d7315-0eeb-47b8-805c-b5e73453968e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 876,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 132ms/step - loss: 6.6751 - accuracy: 0.6522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.675061225891113, 0.6521739363670349]"
            ]
          },
          "metadata": {},
          "execution_count": 876
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model4.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history4 = model4.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model4.name)])"
      ],
      "metadata": {
        "id": "6x7NFRwFeVwx",
        "outputId": "b9458d5b-4a33-4b5c-bfdd-9c87847012aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 877,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/4 [======>.......................] - ETA: 1s - loss: 0.6919 - accuracy: 0.6250INFO:tensorflow:Assets written to: model_experiments/sequential_78/assets\n",
            "4/4 [==============================] - 1s 295ms/step - loss: 0.6907 - accuracy: 0.6000 - val_loss: 0.6874 - val_accuracy: 0.6296\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6874 - accuracy: 0.5760 - val_loss: 0.6798 - val_accuracy: 0.6296\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5760 - val_loss: 0.6746 - val_accuracy: 0.6296\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5760 - val_loss: 0.6688 - val_accuracy: 0.6296\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6769 - accuracy: 0.5760 - val_loss: 0.6658 - val_accuracy: 0.6296\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5760 - val_loss: 0.6633 - val_accuracy: 0.6296\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5760 - val_loss: 0.6623 - val_accuracy: 0.6296\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6766 - accuracy: 0.5760 - val_loss: 0.6618 - val_accuracy: 0.6296\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6758 - accuracy: 0.5760 - val_loss: 0.6622 - val_accuracy: 0.6296\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6742 - accuracy: 0.5760 - val_loss: 0.6617 - val_accuracy: 0.6296\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6737 - accuracy: 0.5760 - val_loss: 0.6606 - val_accuracy: 0.6296\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6728 - accuracy: 0.5760 - val_loss: 0.6598 - val_accuracy: 0.6296\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6719 - accuracy: 0.5760 - val_loss: 0.6585 - val_accuracy: 0.6296\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6713 - accuracy: 0.5760 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6696 - accuracy: 0.5760 - val_loss: 0.6564 - val_accuracy: 0.6296\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6688 - accuracy: 0.5760 - val_loss: 0.6551 - val_accuracy: 0.6296\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6674 - accuracy: 0.5760 - val_loss: 0.6543 - val_accuracy: 0.6296\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6658 - accuracy: 0.5760 - val_loss: 0.6526 - val_accuracy: 0.6296\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6644 - accuracy: 0.5760 - val_loss: 0.6509 - val_accuracy: 0.6296\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6625 - accuracy: 0.5760 - val_loss: 0.6505 - val_accuracy: 0.6296\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6600 - accuracy: 0.5760 - val_loss: 0.6501 - val_accuracy: 0.6296\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6623 - accuracy: 0.5760 - val_loss: 0.6473 - val_accuracy: 0.6296\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6584 - accuracy: 0.5760 - val_loss: 0.6457 - val_accuracy: 0.6296\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6561 - accuracy: 0.5760 - val_loss: 0.6453 - val_accuracy: 0.6296\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6527 - accuracy: 0.5760 - val_loss: 0.6439 - val_accuracy: 0.6296\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6539 - accuracy: 0.5760 - val_loss: 0.6427 - val_accuracy: 0.6296\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6489 - accuracy: 0.5760 - val_loss: 0.6418 - val_accuracy: 0.6296\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6473 - accuracy: 0.5760 - val_loss: 0.6411 - val_accuracy: 0.6296\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6472 - accuracy: 0.5760 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6443 - accuracy: 0.5760 - val_loss: 0.6388 - val_accuracy: 0.6296\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6456 - accuracy: 0.5760 - val_loss: 0.6428 - val_accuracy: 0.6296\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6422 - accuracy: 0.5680 - val_loss: 0.6402 - val_accuracy: 0.6296\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6389 - accuracy: 0.6160 - val_loss: 0.6392 - val_accuracy: 0.5926\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6397 - accuracy: 0.6400 - val_loss: 0.6401 - val_accuracy: 0.5556\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6360 - accuracy: 0.6480 - val_loss: 0.6412 - val_accuracy: 0.6296\n",
            "Epoch 36/100\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6455 - accuracy: 0.5625INFO:tensorflow:Assets written to: model_experiments/sequential_78/assets\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.6347 - accuracy: 0.6400 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6329 - accuracy: 0.6480 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6325 - accuracy: 0.6480 - val_loss: 0.6416 - val_accuracy: 0.5556\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6296 - accuracy: 0.6480 - val_loss: 0.6391 - val_accuracy: 0.5926\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6279 - accuracy: 0.6480 - val_loss: 0.6378 - val_accuracy: 0.5556\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6257 - accuracy: 0.6640 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6250 - accuracy: 0.6320 - val_loss: 0.6393 - val_accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6243 - accuracy: 0.6400 - val_loss: 0.6431 - val_accuracy: 0.5926\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6250 - accuracy: 0.6960 - val_loss: 0.6483 - val_accuracy: 0.5185\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6231 - accuracy: 0.6720 - val_loss: 0.6462 - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6244 - accuracy: 0.6480 - val_loss: 0.6499 - val_accuracy: 0.6296\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6193 - accuracy: 0.6720 - val_loss: 0.6550 - val_accuracy: 0.5556\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6218 - accuracy: 0.6640 - val_loss: 0.6588 - val_accuracy: 0.5185\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6193 - accuracy: 0.6640 - val_loss: 0.6529 - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6204 - accuracy: 0.6880 - val_loss: 0.6552 - val_accuracy: 0.5926\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6148 - accuracy: 0.6720 - val_loss: 0.6573 - val_accuracy: 0.5926\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6161 - accuracy: 0.6640 - val_loss: 0.6607 - val_accuracy: 0.5926\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6158 - accuracy: 0.6640 - val_loss: 0.6598 - val_accuracy: 0.5926\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6134 - accuracy: 0.6640 - val_loss: 0.6584 - val_accuracy: 0.5556\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6144 - accuracy: 0.6640 - val_loss: 0.6630 - val_accuracy: 0.6296\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6127 - accuracy: 0.6800 - val_loss: 0.6680 - val_accuracy: 0.5185\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6169 - accuracy: 0.6640 - val_loss: 0.6683 - val_accuracy: 0.5185\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6160 - accuracy: 0.6560 - val_loss: 0.6671 - val_accuracy: 0.5185\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6142 - accuracy: 0.6640 - val_loss: 0.6597 - val_accuracy: 0.6296\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6160 - accuracy: 0.6640 - val_loss: 0.6651 - val_accuracy: 0.6296\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6144 - accuracy: 0.6480 - val_loss: 0.6741 - val_accuracy: 0.4815\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6154 - accuracy: 0.6320 - val_loss: 0.6762 - val_accuracy: 0.4815\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6113 - accuracy: 0.6800 - val_loss: 0.6763 - val_accuracy: 0.5185\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6138 - accuracy: 0.6560 - val_loss: 0.6702 - val_accuracy: 0.6296\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6110 - accuracy: 0.6640 - val_loss: 0.6722 - val_accuracy: 0.4815\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6128 - accuracy: 0.6400 - val_loss: 0.6778 - val_accuracy: 0.4815\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6114 - accuracy: 0.6560 - val_loss: 0.6807 - val_accuracy: 0.5185\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6099 - accuracy: 0.6720 - val_loss: 0.6762 - val_accuracy: 0.5926\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6107 - accuracy: 0.6720 - val_loss: 0.6742 - val_accuracy: 0.6296\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6104 - accuracy: 0.6480 - val_loss: 0.6761 - val_accuracy: 0.4815\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6134 - accuracy: 0.6560 - val_loss: 0.6719 - val_accuracy: 0.4815\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6156 - accuracy: 0.6480 - val_loss: 0.6710 - val_accuracy: 0.6296\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6102 - accuracy: 0.6720 - val_loss: 0.6781 - val_accuracy: 0.4815\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6095 - accuracy: 0.6640 - val_loss: 0.6734 - val_accuracy: 0.5185\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6082 - accuracy: 0.6880 - val_loss: 0.6729 - val_accuracy: 0.4815\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6093 - accuracy: 0.6720 - val_loss: 0.6767 - val_accuracy: 0.4815\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6169 - accuracy: 0.6560 - val_loss: 0.6755 - val_accuracy: 0.4815\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6098 - accuracy: 0.6560 - val_loss: 0.6778 - val_accuracy: 0.6296\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6173 - accuracy: 0.6400 - val_loss: 0.6845 - val_accuracy: 0.5926\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6075 - accuracy: 0.6560 - val_loss: 0.6868 - val_accuracy: 0.4815\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6138 - accuracy: 0.6320 - val_loss: 0.6893 - val_accuracy: 0.4815\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6123 - accuracy: 0.6240 - val_loss: 0.6844 - val_accuracy: 0.5926\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6099 - accuracy: 0.6640 - val_loss: 0.6791 - val_accuracy: 0.6296\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6115 - accuracy: 0.6720 - val_loss: 0.6830 - val_accuracy: 0.5185\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6112 - accuracy: 0.6480 - val_loss: 0.6809 - val_accuracy: 0.5926\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6084 - accuracy: 0.6720 - val_loss: 0.6849 - val_accuracy: 0.4815\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6109 - accuracy: 0.6560 - val_loss: 0.6817 - val_accuracy: 0.4815\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6063 - accuracy: 0.6880 - val_loss: 0.6781 - val_accuracy: 0.6296\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6139 - accuracy: 0.6400 - val_loss: 0.6769 - val_accuracy: 0.6296\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6165 - accuracy: 0.6400 - val_loss: 0.6854 - val_accuracy: 0.4815\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6104 - accuracy: 0.6480 - val_loss: 0.6838 - val_accuracy: 0.5185\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6207 - accuracy: 0.6400 - val_loss: 0.6790 - val_accuracy: 0.6296\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6106 - accuracy: 0.6640 - val_loss: 0.6828 - val_accuracy: 0.5185\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6135 - accuracy: 0.6560 - val_loss: 0.6875 - val_accuracy: 0.4815\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6137 - accuracy: 0.6480 - val_loss: 0.6760 - val_accuracy: 0.5185\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6378 - accuracy: 0.6160 - val_loss: 0.6804 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6155 - accuracy: 0.6480 - val_loss: 0.6838 - val_accuracy: 0.5185\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6070 - accuracy: 0.6800 - val_loss: 0.6887 - val_accuracy: 0.4815\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6129 - accuracy: 0.6320 - val_loss: 0.6892 - val_accuracy: 0.4815\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6097 - accuracy: 0.6800 - val_loss: 0.6817 - val_accuracy: 0.5926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_-4IBuJ7o6-",
        "outputId": "a6681661-178b-4c77-d810-fa5e8e799c9f"
      },
      "execution_count": 878,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6983 - accuracy: 0.4348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6983448266983032, 0.43478259444236755]"
            ]
          },
          "metadata": {},
          "execution_count": 878
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = tf.keras.models.load_model(f\"/content/model_experiments/{model4.name}\")\n",
        "model4.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "CKJfsbhUq01R",
        "outputId": "48dfd3c8-9af9-443e-c223-ab26dacdb6cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 879,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 127ms/step - loss: 3.1820 - accuracy: 0.6957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.182018995285034, 0.695652186870575]"
            ]
          },
          "metadata": {},
          "execution_count": 879
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model5.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history5 = model5.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model5.name)])"
      ],
      "metadata": {
        "id": "9uRfoFpYeXtB",
        "outputId": "34f466f8-9fcf-473f-f6d8-dac4bf66fefc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 880,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1/4 [======>.......................] - ETA: 1s - loss: 0.6915 - accuracy: 0.4688INFO:tensorflow:Assets written to: model_experiments/sequential_79/assets\n",
            "4/4 [==============================] - 1s 299ms/step - loss: 0.6907 - accuracy: 0.5600 - val_loss: 0.6769 - val_accuracy: 0.6296\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6844 - accuracy: 0.5760 - val_loss: 0.6649 - val_accuracy: 0.6296\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6785 - accuracy: 0.5760 - val_loss: 0.6624 - val_accuracy: 0.6296\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5760 - val_loss: 0.6598 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5760 - val_loss: 0.6592 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5760 - val_loss: 0.6577 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5760 - val_loss: 0.6580 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6764 - accuracy: 0.5760 - val_loss: 0.6576 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6757 - accuracy: 0.5760 - val_loss: 0.6575 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6736 - accuracy: 0.5760 - val_loss: 0.6558 - val_accuracy: 0.6296\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6728 - accuracy: 0.5760 - val_loss: 0.6528 - val_accuracy: 0.6296\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6710 - accuracy: 0.5760 - val_loss: 0.6508 - val_accuracy: 0.6296\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6697 - accuracy: 0.5760 - val_loss: 0.6487 - val_accuracy: 0.6296\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6689 - accuracy: 0.5760 - val_loss: 0.6458 - val_accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6664 - accuracy: 0.5760 - val_loss: 0.6434 - val_accuracy: 0.6296\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6654 - accuracy: 0.5760 - val_loss: 0.6405 - val_accuracy: 0.6296\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6636 - accuracy: 0.5760 - val_loss: 0.6385 - val_accuracy: 0.6296\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6620 - accuracy: 0.5760 - val_loss: 0.6354 - val_accuracy: 0.6296\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6608 - accuracy: 0.5760 - val_loss: 0.6333 - val_accuracy: 0.6296\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6591 - accuracy: 0.5760 - val_loss: 0.6308 - val_accuracy: 0.6296\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6569 - accuracy: 0.5760 - val_loss: 0.6291 - val_accuracy: 0.6296\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6620 - accuracy: 0.5760 - val_loss: 0.6254 - val_accuracy: 0.6296\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6565 - accuracy: 0.5840 - val_loss: 0.6295 - val_accuracy: 0.6296\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6543 - accuracy: 0.6160 - val_loss: 0.6288 - val_accuracy: 0.5926\n",
            "Epoch 25/150\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6471 - accuracy: 0.7188INFO:tensorflow:Assets written to: model_experiments/sequential_79/assets\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.6510 - accuracy: 0.6400 - val_loss: 0.6228 - val_accuracy: 0.6667\n",
            "Epoch 26/150\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.5483 - accuracy: 0.7812INFO:tensorflow:Assets written to: model_experiments/sequential_79/assets\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.6534 - accuracy: 0.6480 - val_loss: 0.6194 - val_accuracy: 0.7037\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6480 - accuracy: 0.6160 - val_loss: 0.6220 - val_accuracy: 0.6667\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6459 - accuracy: 0.6400 - val_loss: 0.6237 - val_accuracy: 0.5926\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6463 - accuracy: 0.6320 - val_loss: 0.6234 - val_accuracy: 0.5926\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6452 - accuracy: 0.6560 - val_loss: 0.6170 - val_accuracy: 0.6296\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6465 - accuracy: 0.6320 - val_loss: 0.6201 - val_accuracy: 0.6667\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6410 - accuracy: 0.6720 - val_loss: 0.6164 - val_accuracy: 0.6296\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6393 - accuracy: 0.6640 - val_loss: 0.6154 - val_accuracy: 0.6296\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6422 - accuracy: 0.6320 - val_loss: 0.6213 - val_accuracy: 0.6296\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6377 - accuracy: 0.6400 - val_loss: 0.6172 - val_accuracy: 0.6296\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6388 - accuracy: 0.6480 - val_loss: 0.6067 - val_accuracy: 0.6667\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6382 - accuracy: 0.6400 - val_loss: 0.6108 - val_accuracy: 0.6296\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6329 - accuracy: 0.6640 - val_loss: 0.6207 - val_accuracy: 0.6296\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6340 - accuracy: 0.6720 - val_loss: 0.6140 - val_accuracy: 0.6296\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6287 - accuracy: 0.6720 - val_loss: 0.6079 - val_accuracy: 0.6667\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6275 - accuracy: 0.6720 - val_loss: 0.6071 - val_accuracy: 0.6667\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6253 - accuracy: 0.6880 - val_loss: 0.6097 - val_accuracy: 0.6667\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6240 - accuracy: 0.6720 - val_loss: 0.6139 - val_accuracy: 0.6667\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6230 - accuracy: 0.6480 - val_loss: 0.6078 - val_accuracy: 0.6667\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6228 - accuracy: 0.6800 - val_loss: 0.6097 - val_accuracy: 0.6296\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6187 - accuracy: 0.6880 - val_loss: 0.6154 - val_accuracy: 0.6296\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6166 - accuracy: 0.6800 - val_loss: 0.6150 - val_accuracy: 0.6296\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6256 - accuracy: 0.6480 - val_loss: 0.6234 - val_accuracy: 0.5926\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6142 - accuracy: 0.7040 - val_loss: 0.6042 - val_accuracy: 0.7037\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6172 - accuracy: 0.6800 - val_loss: 0.6127 - val_accuracy: 0.6296\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6132 - accuracy: 0.6880 - val_loss: 0.6181 - val_accuracy: 0.6296\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6108 - accuracy: 0.6960 - val_loss: 0.6131 - val_accuracy: 0.6667\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6158 - accuracy: 0.6800 - val_loss: 0.6146 - val_accuracy: 0.6667\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6110 - accuracy: 0.6800 - val_loss: 0.6262 - val_accuracy: 0.5926\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6105 - accuracy: 0.6880 - val_loss: 0.6137 - val_accuracy: 0.6296\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6053 - accuracy: 0.7040 - val_loss: 0.6148 - val_accuracy: 0.5926\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6064 - accuracy: 0.6960 - val_loss: 0.6238 - val_accuracy: 0.6296\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6073 - accuracy: 0.6800 - val_loss: 0.6189 - val_accuracy: 0.6296\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6020 - accuracy: 0.6880 - val_loss: 0.6199 - val_accuracy: 0.6296\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6011 - accuracy: 0.6960 - val_loss: 0.6236 - val_accuracy: 0.5926\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6027 - accuracy: 0.6800 - val_loss: 0.6274 - val_accuracy: 0.5926\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5953 - accuracy: 0.6880 - val_loss: 0.6314 - val_accuracy: 0.6296\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5909 - accuracy: 0.7120 - val_loss: 0.6458 - val_accuracy: 0.6296\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5927 - accuracy: 0.6880 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5860 - accuracy: 0.6960 - val_loss: 0.6497 - val_accuracy: 0.6296\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5815 - accuracy: 0.7120 - val_loss: 0.6454 - val_accuracy: 0.6296\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5821 - accuracy: 0.7120 - val_loss: 0.6432 - val_accuracy: 0.6296\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5768 - accuracy: 0.7200 - val_loss: 0.6515 - val_accuracy: 0.6296\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5766 - accuracy: 0.7040 - val_loss: 0.6710 - val_accuracy: 0.5926\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5791 - accuracy: 0.7040 - val_loss: 0.6794 - val_accuracy: 0.5926\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5811 - accuracy: 0.6960 - val_loss: 0.6790 - val_accuracy: 0.5185\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5708 - accuracy: 0.7120 - val_loss: 0.6713 - val_accuracy: 0.6667\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5677 - accuracy: 0.6960 - val_loss: 0.6647 - val_accuracy: 0.6667\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5679 - accuracy: 0.7040 - val_loss: 0.6718 - val_accuracy: 0.5926\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5679 - accuracy: 0.7120 - val_loss: 0.6956 - val_accuracy: 0.5556\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5628 - accuracy: 0.7200 - val_loss: 0.6776 - val_accuracy: 0.6667\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5690 - accuracy: 0.6960 - val_loss: 0.6616 - val_accuracy: 0.6667\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5608 - accuracy: 0.6880 - val_loss: 0.6720 - val_accuracy: 0.6667\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5630 - accuracy: 0.7120 - val_loss: 0.6839 - val_accuracy: 0.6296\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5687 - accuracy: 0.6880 - val_loss: 0.6765 - val_accuracy: 0.6667\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5537 - accuracy: 0.7200 - val_loss: 0.6975 - val_accuracy: 0.5926\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5509 - accuracy: 0.7280 - val_loss: 0.6920 - val_accuracy: 0.6296\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5475 - accuracy: 0.7040 - val_loss: 0.6842 - val_accuracy: 0.5926\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5445 - accuracy: 0.7120 - val_loss: 0.7018 - val_accuracy: 0.6296\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5434 - accuracy: 0.7200 - val_loss: 0.7040 - val_accuracy: 0.5926\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5379 - accuracy: 0.7200 - val_loss: 0.6914 - val_accuracy: 0.5926\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5396 - accuracy: 0.7280 - val_loss: 0.7041 - val_accuracy: 0.5185\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5420 - accuracy: 0.7200 - val_loss: 0.7099 - val_accuracy: 0.5556\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5336 - accuracy: 0.7280 - val_loss: 0.7157 - val_accuracy: 0.5556\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5390 - accuracy: 0.7120 - val_loss: 0.7145 - val_accuracy: 0.5556\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5300 - accuracy: 0.7280 - val_loss: 0.7238 - val_accuracy: 0.5926\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5314 - accuracy: 0.7280 - val_loss: 0.7246 - val_accuracy: 0.6296\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5246 - accuracy: 0.7280 - val_loss: 0.7118 - val_accuracy: 0.6296\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5246 - accuracy: 0.7280 - val_loss: 0.7272 - val_accuracy: 0.5926\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5321 - accuracy: 0.7280 - val_loss: 0.7351 - val_accuracy: 0.5556\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5451 - accuracy: 0.7040 - val_loss: 0.7358 - val_accuracy: 0.5556\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5234 - accuracy: 0.7440 - val_loss: 0.7136 - val_accuracy: 0.5556\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5339 - accuracy: 0.7120 - val_loss: 0.7392 - val_accuracy: 0.6296\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5338 - accuracy: 0.6960 - val_loss: 0.7145 - val_accuracy: 0.5926\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5290 - accuracy: 0.7200 - val_loss: 0.7529 - val_accuracy: 0.5556\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5287 - accuracy: 0.7200 - val_loss: 0.8205 - val_accuracy: 0.4444\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5353 - accuracy: 0.7200 - val_loss: 0.7868 - val_accuracy: 0.5926\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5117 - accuracy: 0.7360 - val_loss: 0.7616 - val_accuracy: 0.5556\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5390 - accuracy: 0.6880 - val_loss: 0.9151 - val_accuracy: 0.4444\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4935 - accuracy: 0.7760 - val_loss: 0.9007 - val_accuracy: 0.5556\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5069 - accuracy: 0.7120 - val_loss: 0.9604 - val_accuracy: 0.5185\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5120 - accuracy: 0.7200 - val_loss: 0.9808 - val_accuracy: 0.4444\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4866 - accuracy: 0.7440 - val_loss: 0.9135 - val_accuracy: 0.4815\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4951 - accuracy: 0.7200 - val_loss: 0.9351 - val_accuracy: 0.4815\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4828 - accuracy: 0.7760 - val_loss: 1.0453 - val_accuracy: 0.4815\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4880 - accuracy: 0.7600 - val_loss: 0.9767 - val_accuracy: 0.4074\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4744 - accuracy: 0.7680 - val_loss: 1.0320 - val_accuracy: 0.4444\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4680 - accuracy: 0.7680 - val_loss: 1.0060 - val_accuracy: 0.4074\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4739 - accuracy: 0.7680 - val_loss: 0.9997 - val_accuracy: 0.3704\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4650 - accuracy: 0.7760 - val_loss: 0.9959 - val_accuracy: 0.4444\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4848 - accuracy: 0.7520 - val_loss: 1.0107 - val_accuracy: 0.4074\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4600 - accuracy: 0.7680 - val_loss: 1.0315 - val_accuracy: 0.3704\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4609 - accuracy: 0.7840 - val_loss: 1.1188 - val_accuracy: 0.4074\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4603 - accuracy: 0.7840 - val_loss: 1.0887 - val_accuracy: 0.4444\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4670 - accuracy: 0.7440 - val_loss: 1.0219 - val_accuracy: 0.4444\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4549 - accuracy: 0.7760 - val_loss: 1.0597 - val_accuracy: 0.4444\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4557 - accuracy: 0.7680 - val_loss: 1.1331 - val_accuracy: 0.4444\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 1.0676 - val_accuracy: 0.4074\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4721 - accuracy: 0.7360 - val_loss: 1.0370 - val_accuracy: 0.4444\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4584 - accuracy: 0.7840 - val_loss: 1.0730 - val_accuracy: 0.5185\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4745 - accuracy: 0.7600 - val_loss: 1.1954 - val_accuracy: 0.4815\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4544 - accuracy: 0.7760 - val_loss: 1.1514 - val_accuracy: 0.4074\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4474 - accuracy: 0.7760 - val_loss: 1.0714 - val_accuracy: 0.4444\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4427 - accuracy: 0.8080 - val_loss: 1.0321 - val_accuracy: 0.4815\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4529 - accuracy: 0.8000 - val_loss: 1.0948 - val_accuracy: 0.4815\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4682 - accuracy: 0.7600 - val_loss: 1.1258 - val_accuracy: 0.4444\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4489 - accuracy: 0.7600 - val_loss: 1.1227 - val_accuracy: 0.4815\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4575 - accuracy: 0.7920 - val_loss: 1.2144 - val_accuracy: 0.5185\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4520 - accuracy: 0.8000 - val_loss: 1.1965 - val_accuracy: 0.4444\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4520 - accuracy: 0.7600 - val_loss: 1.0555 - val_accuracy: 0.4815\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4908 - accuracy: 0.7120 - val_loss: 1.1164 - val_accuracy: 0.5185\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4554 - accuracy: 0.7440 - val_loss: 1.3092 - val_accuracy: 0.4444\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4512 - accuracy: 0.7680 - val_loss: 1.3588 - val_accuracy: 0.4444\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4346 - accuracy: 0.7920 - val_loss: 1.2358 - val_accuracy: 0.4444\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4351 - accuracy: 0.8000 - val_loss: 1.1355 - val_accuracy: 0.4444\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4346 - accuracy: 0.8160 - val_loss: 1.2003 - val_accuracy: 0.4815\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4393 - accuracy: 0.7920 - val_loss: 1.3723 - val_accuracy: 0.4815\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4213 - accuracy: 0.8000 - val_loss: 1.3251 - val_accuracy: 0.4444\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4306 - accuracy: 0.7920 - val_loss: 1.3093 - val_accuracy: 0.4444\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4217 - accuracy: 0.7840 - val_loss: 1.3609 - val_accuracy: 0.4444\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4343 - accuracy: 0.8080 - val_loss: 1.3443 - val_accuracy: 0.4815\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4247 - accuracy: 0.7920 - val_loss: 1.2855 - val_accuracy: 0.4444\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4233 - accuracy: 0.8080 - val_loss: 1.3573 - val_accuracy: 0.4815\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4261 - accuracy: 0.7840 - val_loss: 1.3888 - val_accuracy: 0.4074\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4188 - accuracy: 0.8160 - val_loss: 1.4328 - val_accuracy: 0.4074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gvMvEml7qdi",
        "outputId": "03898eae-3b8e-4d7d-f63e-839335d44fd0"
      },
      "execution_count": 881,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 24.0271 - accuracy: 0.5217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[24.027088165283203, 0.52173912525177]"
            ]
          },
          "metadata": {},
          "execution_count": 881
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = tf.keras.models.load_model(f\"/content/model_experiments/{model5.name}\")\n",
        "model5.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "XeQ1W3ycq2Kg",
        "outputId": "735ef07e-7057-46de-a7a0-685cd5512cbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 882,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 132ms/step - loss: 10.2069 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10.20689868927002, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 882
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model6 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model6.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history6 = model6.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model6.name)])"
      ],
      "metadata": {
        "id": "aGjeYTd4eZ7x",
        "outputId": "2cc6893e-6e66-45c6-a8bd-621d8278aa8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 883,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1/4 [======>.......................] - ETA: 1s - loss: 0.6918 - accuracy: 0.6562INFO:tensorflow:Assets written to: model_experiments/sequential_80/assets\n",
            "4/4 [==============================] - 1s 295ms/step - loss: 0.6907 - accuracy: 0.5680 - val_loss: 0.6751 - val_accuracy: 0.6296\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6843 - accuracy: 0.5760 - val_loss: 0.6632 - val_accuracy: 0.6296\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5760 - val_loss: 0.6618 - val_accuracy: 0.6296\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6777 - accuracy: 0.5760 - val_loss: 0.6603 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6777 - accuracy: 0.5760 - val_loss: 0.6606 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6773 - accuracy: 0.5760 - val_loss: 0.6592 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6758 - accuracy: 0.5760 - val_loss: 0.6615 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6749 - accuracy: 0.5760 - val_loss: 0.6615 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6734 - accuracy: 0.5680 - val_loss: 0.6636 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6646 - accuracy: 0.5938INFO:tensorflow:Assets written to: model_experiments/sequential_80/assets\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.6701 - accuracy: 0.5760 - val_loss: 0.6648 - val_accuracy: 0.6667\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6683 - accuracy: 0.5680 - val_loss: 0.6632 - val_accuracy: 0.6667\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6654 - accuracy: 0.5920 - val_loss: 0.6670 - val_accuracy: 0.5926\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6632 - accuracy: 0.6080 - val_loss: 0.6687 - val_accuracy: 0.5926\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6621 - accuracy: 0.6240 - val_loss: 0.6709 - val_accuracy: 0.5185\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6577 - accuracy: 0.6240 - val_loss: 0.6671 - val_accuracy: 0.5926\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6568 - accuracy: 0.6240 - val_loss: 0.6636 - val_accuracy: 0.5926\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6541 - accuracy: 0.6160 - val_loss: 0.6653 - val_accuracy: 0.4444\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6515 - accuracy: 0.6080 - val_loss: 0.6552 - val_accuracy: 0.5556\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6509 - accuracy: 0.6400 - val_loss: 0.6533 - val_accuracy: 0.5185\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6479 - accuracy: 0.6400 - val_loss: 0.6512 - val_accuracy: 0.5185\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6451 - accuracy: 0.6320 - val_loss: 0.6526 - val_accuracy: 0.4815\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6562 - accuracy: 0.5680 - val_loss: 0.6460 - val_accuracy: 0.5556\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6464 - accuracy: 0.6640 - val_loss: 0.6627 - val_accuracy: 0.4815\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6476 - accuracy: 0.6400 - val_loss: 0.6572 - val_accuracy: 0.4815\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6402 - accuracy: 0.6400 - val_loss: 0.6410 - val_accuracy: 0.6296\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6457 - accuracy: 0.6320 - val_loss: 0.6348 - val_accuracy: 0.6667\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6389 - accuracy: 0.6560 - val_loss: 0.6509 - val_accuracy: 0.4815\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6414 - accuracy: 0.6480 - val_loss: 0.6546 - val_accuracy: 0.4815\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6368 - accuracy: 0.6480 - val_loss: 0.6404 - val_accuracy: 0.5556\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6395 - accuracy: 0.6080 - val_loss: 0.6309 - val_accuracy: 0.6667\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6422 - accuracy: 0.6480 - val_loss: 0.6482 - val_accuracy: 0.4815\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6355 - accuracy: 0.6400 - val_loss: 0.6501 - val_accuracy: 0.5185\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6338 - accuracy: 0.6320 - val_loss: 0.6447 - val_accuracy: 0.5556\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6335 - accuracy: 0.6720 - val_loss: 0.6502 - val_accuracy: 0.5185\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6301 - accuracy: 0.6560 - val_loss: 0.6506 - val_accuracy: 0.5185\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6287 - accuracy: 0.6720 - val_loss: 0.6412 - val_accuracy: 0.5556\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6291 - accuracy: 0.6320 - val_loss: 0.6397 - val_accuracy: 0.5556\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6243 - accuracy: 0.6560 - val_loss: 0.6537 - val_accuracy: 0.5185\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6248 - accuracy: 0.6720 - val_loss: 0.6522 - val_accuracy: 0.5556\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6199 - accuracy: 0.6720 - val_loss: 0.6425 - val_accuracy: 0.5556\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6209 - accuracy: 0.6480 - val_loss: 0.6415 - val_accuracy: 0.5185\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6180 - accuracy: 0.6480 - val_loss: 0.6437 - val_accuracy: 0.5185\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6170 - accuracy: 0.6640 - val_loss: 0.6509 - val_accuracy: 0.5185\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6177 - accuracy: 0.6640 - val_loss: 0.6450 - val_accuracy: 0.5185\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6165 - accuracy: 0.6800 - val_loss: 0.6453 - val_accuracy: 0.5556\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6148 - accuracy: 0.6560 - val_loss: 0.6529 - val_accuracy: 0.5185\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6103 - accuracy: 0.6800 - val_loss: 0.6482 - val_accuracy: 0.5556\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6134 - accuracy: 0.6640 - val_loss: 0.6467 - val_accuracy: 0.5185\n",
            "Epoch 49/150\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6337 - accuracy: 0.6562INFO:tensorflow:Assets written to: model_experiments/sequential_80/assets\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.6107 - accuracy: 0.6640 - val_loss: 0.6183 - val_accuracy: 0.7037\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6135 - accuracy: 0.6560 - val_loss: 0.6346 - val_accuracy: 0.5556\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6061 - accuracy: 0.6720 - val_loss: 0.6414 - val_accuracy: 0.5556\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6023 - accuracy: 0.7040 - val_loss: 0.6330 - val_accuracy: 0.5926\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6049 - accuracy: 0.6800 - val_loss: 0.6334 - val_accuracy: 0.5926\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6020 - accuracy: 0.6800 - val_loss: 0.6476 - val_accuracy: 0.6296\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6007 - accuracy: 0.7040 - val_loss: 0.6260 - val_accuracy: 0.6296\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5926 - accuracy: 0.7040 - val_loss: 0.6275 - val_accuracy: 0.6296\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5924 - accuracy: 0.6960 - val_loss: 0.6450 - val_accuracy: 0.6296\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5956 - accuracy: 0.6960 - val_loss: 0.6210 - val_accuracy: 0.6296\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5842 - accuracy: 0.6880 - val_loss: 0.6353 - val_accuracy: 0.6296\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5879 - accuracy: 0.6960 - val_loss: 0.6237 - val_accuracy: 0.6667\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5897 - accuracy: 0.7280 - val_loss: 0.6324 - val_accuracy: 0.6296\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5821 - accuracy: 0.7280 - val_loss: 0.6224 - val_accuracy: 0.6296\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5780 - accuracy: 0.7280 - val_loss: 0.6192 - val_accuracy: 0.6296\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5789 - accuracy: 0.7040 - val_loss: 0.6265 - val_accuracy: 0.6667\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5687 - accuracy: 0.7440 - val_loss: 0.6527 - val_accuracy: 0.6296\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5724 - accuracy: 0.7120 - val_loss: 0.6480 - val_accuracy: 0.6296\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5699 - accuracy: 0.7280 - val_loss: 0.6402 - val_accuracy: 0.6296\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5603 - accuracy: 0.7440 - val_loss: 0.6202 - val_accuracy: 0.6296\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5634 - accuracy: 0.7360 - val_loss: 0.6420 - val_accuracy: 0.6296\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5645 - accuracy: 0.7280 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5561 - accuracy: 0.7280 - val_loss: 0.6292 - val_accuracy: 0.6296\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5569 - accuracy: 0.7200 - val_loss: 0.6480 - val_accuracy: 0.6667\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5475 - accuracy: 0.7360 - val_loss: 0.6471 - val_accuracy: 0.6296\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5535 - accuracy: 0.7360 - val_loss: 0.6439 - val_accuracy: 0.6296\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5447 - accuracy: 0.7360 - val_loss: 0.6611 - val_accuracy: 0.6667\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5367 - accuracy: 0.7440 - val_loss: 0.6218 - val_accuracy: 0.7037\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5607 - accuracy: 0.7200 - val_loss: 0.6337 - val_accuracy: 0.6296\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5403 - accuracy: 0.7200 - val_loss: 0.6892 - val_accuracy: 0.7037\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5395 - accuracy: 0.7200 - val_loss: 0.6536 - val_accuracy: 0.6667\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5502 - accuracy: 0.7200 - val_loss: 0.6155 - val_accuracy: 0.6296\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5466 - accuracy: 0.7280 - val_loss: 0.6801 - val_accuracy: 0.6296\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5297 - accuracy: 0.7360 - val_loss: 0.6611 - val_accuracy: 0.6667\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5573 - accuracy: 0.7040 - val_loss: 0.6478 - val_accuracy: 0.5926\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5463 - accuracy: 0.7280 - val_loss: 0.7068 - val_accuracy: 0.5556\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5500 - accuracy: 0.7040 - val_loss: 0.6501 - val_accuracy: 0.7037\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5343 - accuracy: 0.7280 - val_loss: 0.6771 - val_accuracy: 0.5926\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5330 - accuracy: 0.7200 - val_loss: 0.7166 - val_accuracy: 0.5926\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5366 - accuracy: 0.6800 - val_loss: 0.6632 - val_accuracy: 0.5556\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5230 - accuracy: 0.7040 - val_loss: 0.6757 - val_accuracy: 0.6667\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5228 - accuracy: 0.7200 - val_loss: 0.6590 - val_accuracy: 0.5926\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5182 - accuracy: 0.7360 - val_loss: 0.6757 - val_accuracy: 0.5926\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5208 - accuracy: 0.7440 - val_loss: 0.7439 - val_accuracy: 0.5926\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5071 - accuracy: 0.7200 - val_loss: 0.7081 - val_accuracy: 0.5556\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5118 - accuracy: 0.7280 - val_loss: 0.6683 - val_accuracy: 0.5926\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5096 - accuracy: 0.7120 - val_loss: 0.6777 - val_accuracy: 0.6296\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5181 - accuracy: 0.7200 - val_loss: 0.7838 - val_accuracy: 0.5556\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5158 - accuracy: 0.7360 - val_loss: 0.7157 - val_accuracy: 0.4815\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5040 - accuracy: 0.7280 - val_loss: 0.7150 - val_accuracy: 0.5185\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4955 - accuracy: 0.7440 - val_loss: 0.7325 - val_accuracy: 0.5556\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5043 - accuracy: 0.7360 - val_loss: 0.7245 - val_accuracy: 0.5556\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4879 - accuracy: 0.7600 - val_loss: 0.7452 - val_accuracy: 0.5185\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4994 - accuracy: 0.7520 - val_loss: 0.7650 - val_accuracy: 0.5926\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4876 - accuracy: 0.7600 - val_loss: 0.7841 - val_accuracy: 0.4815\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4944 - accuracy: 0.7040 - val_loss: 0.7249 - val_accuracy: 0.4815\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4853 - accuracy: 0.7360 - val_loss: 0.7248 - val_accuracy: 0.5926\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4757 - accuracy: 0.7680 - val_loss: 0.8098 - val_accuracy: 0.5185\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5019 - accuracy: 0.7440 - val_loss: 0.7747 - val_accuracy: 0.4815\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4999 - accuracy: 0.7520 - val_loss: 0.7690 - val_accuracy: 0.5556\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4786 - accuracy: 0.7440 - val_loss: 0.8278 - val_accuracy: 0.5185\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4866 - accuracy: 0.7680 - val_loss: 0.7291 - val_accuracy: 0.5556\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4708 - accuracy: 0.7680 - val_loss: 0.7843 - val_accuracy: 0.4815\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5066 - accuracy: 0.7440 - val_loss: 0.8592 - val_accuracy: 0.4815\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4587 - accuracy: 0.7600 - val_loss: 0.7529 - val_accuracy: 0.5185\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4793 - accuracy: 0.7920 - val_loss: 0.7965 - val_accuracy: 0.4815\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4728 - accuracy: 0.7520 - val_loss: 0.8512 - val_accuracy: 0.4815\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.7729 - val_accuracy: 0.5556\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4625 - accuracy: 0.7680 - val_loss: 0.8317 - val_accuracy: 0.4815\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4568 - accuracy: 0.7680 - val_loss: 0.8745 - val_accuracy: 0.4815\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4498 - accuracy: 0.7600 - val_loss: 0.8054 - val_accuracy: 0.4815\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4590 - accuracy: 0.7600 - val_loss: 0.7979 - val_accuracy: 0.4815\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4631 - accuracy: 0.7600 - val_loss: 0.8823 - val_accuracy: 0.4815\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4528 - accuracy: 0.7600 - val_loss: 0.7993 - val_accuracy: 0.5926\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.8739 - val_accuracy: 0.4815\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.8043 - val_accuracy: 0.4815\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4451 - accuracy: 0.8000 - val_loss: 0.8896 - val_accuracy: 0.5185\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4531 - accuracy: 0.7840 - val_loss: 0.9543 - val_accuracy: 0.4815\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4496 - accuracy: 0.7840 - val_loss: 0.8382 - val_accuracy: 0.4815\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4317 - accuracy: 0.7840 - val_loss: 0.8682 - val_accuracy: 0.4815\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4499 - accuracy: 0.7840 - val_loss: 0.9007 - val_accuracy: 0.4815\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4332 - accuracy: 0.7520 - val_loss: 0.8522 - val_accuracy: 0.5185\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4457 - accuracy: 0.8000 - val_loss: 0.8938 - val_accuracy: 0.5556\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4113 - accuracy: 0.8000 - val_loss: 0.8836 - val_accuracy: 0.5185\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4322 - accuracy: 0.7760 - val_loss: 0.8847 - val_accuracy: 0.4815\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4299 - accuracy: 0.7760 - val_loss: 0.8640 - val_accuracy: 0.5185\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4266 - accuracy: 0.7920 - val_loss: 0.8898 - val_accuracy: 0.5185\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4051 - accuracy: 0.8160 - val_loss: 0.9319 - val_accuracy: 0.4815\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4102 - accuracy: 0.8240 - val_loss: 0.9142 - val_accuracy: 0.4815\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4207 - accuracy: 0.8000 - val_loss: 0.8840 - val_accuracy: 0.4815\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.9653 - val_accuracy: 0.5185\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4058 - accuracy: 0.8160 - val_loss: 0.9101 - val_accuracy: 0.5185\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4137 - accuracy: 0.7920 - val_loss: 0.8594 - val_accuracy: 0.5185\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4314 - accuracy: 0.7760 - val_loss: 0.9134 - val_accuracy: 0.5556\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.9582 - val_accuracy: 0.5556\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4291 - accuracy: 0.7840 - val_loss: 0.9820 - val_accuracy: 0.5185\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.8698 - val_accuracy: 0.6296\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4439 - accuracy: 0.7760 - val_loss: 0.9021 - val_accuracy: 0.5185\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4332 - accuracy: 0.8080 - val_loss: 1.0102 - val_accuracy: 0.5556\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4245 - accuracy: 0.7680 - val_loss: 0.9346 - val_accuracy: 0.5556\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4018 - accuracy: 0.7920 - val_loss: 0.8456 - val_accuracy: 0.5926\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4184 - accuracy: 0.7920 - val_loss: 0.9807 - val_accuracy: 0.5185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk7CoEfq7r7I",
        "outputId": "faf01d40-fc22-4207-bb3c-9746b3fd8037"
      },
      "execution_count": 884,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step - loss: 74.7819 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[74.7818832397461, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 884
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = tf.keras.models.load_model(f\"/content/model_experiments/{model6.name}\")\n",
        "model6.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "jWwLJ77yq27l",
        "outputId": "ea8382df-144b-4975-8029-f1eb9b888ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 885,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 124ms/step - loss: 9.7797 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.779716491699219, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 885
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model7.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history7 = model7.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=350,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model7.name)])"
      ],
      "metadata": {
        "id": "h_ByrY0Cecaw",
        "outputId": "9f7cdc8a-5862-47c9-ac03-152c50b8f282",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 886,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n",
            "1/4 [======>.......................] - ETA: 5s - loss: 0.6919 - accuracy: 0.6250INFO:tensorflow:Assets written to: model_experiments/sequential_81/assets\n",
            "4/4 [==============================] - 3s 306ms/step - loss: 0.6921 - accuracy: 0.5760 - val_loss: 0.6914 - val_accuracy: 0.6296\n",
            "Epoch 2/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6916 - accuracy: 0.5840 - val_loss: 0.6910 - val_accuracy: 0.6296\n",
            "Epoch 3/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6911 - accuracy: 0.5760 - val_loss: 0.6906 - val_accuracy: 0.6296\n",
            "Epoch 4/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6907 - accuracy: 0.5760 - val_loss: 0.6903 - val_accuracy: 0.6296\n",
            "Epoch 5/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5760 - val_loss: 0.6898 - val_accuracy: 0.6296\n",
            "Epoch 6/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6899 - accuracy: 0.5760 - val_loss: 0.6893 - val_accuracy: 0.6296\n",
            "Epoch 7/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6893 - accuracy: 0.5760 - val_loss: 0.6891 - val_accuracy: 0.6296\n",
            "Epoch 8/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6890 - accuracy: 0.5760 - val_loss: 0.6887 - val_accuracy: 0.6296\n",
            "Epoch 9/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6885 - accuracy: 0.5760 - val_loss: 0.6884 - val_accuracy: 0.6296\n",
            "Epoch 10/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6882 - accuracy: 0.5760 - val_loss: 0.6880 - val_accuracy: 0.6296\n",
            "Epoch 11/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6880 - accuracy: 0.5760 - val_loss: 0.6875 - val_accuracy: 0.6296\n",
            "Epoch 12/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6876 - accuracy: 0.5760 - val_loss: 0.6870 - val_accuracy: 0.6296\n",
            "Epoch 13/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6874 - accuracy: 0.5760 - val_loss: 0.6866 - val_accuracy: 0.6296\n",
            "Epoch 14/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6871 - accuracy: 0.5760 - val_loss: 0.6861 - val_accuracy: 0.6296\n",
            "Epoch 15/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.5760 - val_loss: 0.6856 - val_accuracy: 0.6296\n",
            "Epoch 16/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6863 - accuracy: 0.5760 - val_loss: 0.6851 - val_accuracy: 0.6296\n",
            "Epoch 17/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5760 - val_loss: 0.6842 - val_accuracy: 0.6296\n",
            "Epoch 18/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.5760 - val_loss: 0.6833 - val_accuracy: 0.6296\n",
            "Epoch 19/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6842 - accuracy: 0.5760 - val_loss: 0.6822 - val_accuracy: 0.6296\n",
            "Epoch 20/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5760 - val_loss: 0.6808 - val_accuracy: 0.6296\n",
            "Epoch 21/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6828 - accuracy: 0.5760 - val_loss: 0.6799 - val_accuracy: 0.6296\n",
            "Epoch 22/350\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6828 - accuracy: 0.5760 - val_loss: 0.6790 - val_accuracy: 0.6296\n",
            "Epoch 23/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5760 - val_loss: 0.6782 - val_accuracy: 0.6296\n",
            "Epoch 24/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5760 - val_loss: 0.6773 - val_accuracy: 0.6296\n",
            "Epoch 25/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6807 - accuracy: 0.5760 - val_loss: 0.6766 - val_accuracy: 0.6296\n",
            "Epoch 26/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5760 - val_loss: 0.6758 - val_accuracy: 0.6296\n",
            "Epoch 27/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5760 - val_loss: 0.6751 - val_accuracy: 0.6296\n",
            "Epoch 28/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5760 - val_loss: 0.6744 - val_accuracy: 0.6296\n",
            "Epoch 29/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6793 - accuracy: 0.5760 - val_loss: 0.6739 - val_accuracy: 0.6296\n",
            "Epoch 30/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5760 - val_loss: 0.6732 - val_accuracy: 0.6296\n",
            "Epoch 31/350\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6786 - accuracy: 0.5760 - val_loss: 0.6728 - val_accuracy: 0.6296\n",
            "Epoch 32/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6786 - accuracy: 0.5760 - val_loss: 0.6720 - val_accuracy: 0.6296\n",
            "Epoch 33/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5760 - val_loss: 0.6713 - val_accuracy: 0.6296\n",
            "Epoch 34/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6778 - accuracy: 0.5760 - val_loss: 0.6708 - val_accuracy: 0.6296\n",
            "Epoch 35/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6775 - accuracy: 0.5760 - val_loss: 0.6704 - val_accuracy: 0.6296\n",
            "Epoch 36/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6774 - accuracy: 0.5760 - val_loss: 0.6699 - val_accuracy: 0.6296\n",
            "Epoch 37/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5760 - val_loss: 0.6694 - val_accuracy: 0.6296\n",
            "Epoch 38/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5760 - val_loss: 0.6689 - val_accuracy: 0.6296\n",
            "Epoch 39/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.5760 - val_loss: 0.6686 - val_accuracy: 0.6296\n",
            "Epoch 40/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6767 - accuracy: 0.5760 - val_loss: 0.6684 - val_accuracy: 0.6296\n",
            "Epoch 41/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6765 - accuracy: 0.5760 - val_loss: 0.6682 - val_accuracy: 0.6296\n",
            "Epoch 42/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6764 - accuracy: 0.5760 - val_loss: 0.6679 - val_accuracy: 0.6296\n",
            "Epoch 43/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6762 - accuracy: 0.5760 - val_loss: 0.6677 - val_accuracy: 0.6296\n",
            "Epoch 44/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6762 - accuracy: 0.5760 - val_loss: 0.6675 - val_accuracy: 0.6296\n",
            "Epoch 45/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6761 - accuracy: 0.5760 - val_loss: 0.6673 - val_accuracy: 0.6296\n",
            "Epoch 46/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6759 - accuracy: 0.5760 - val_loss: 0.6671 - val_accuracy: 0.6296\n",
            "Epoch 47/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6758 - accuracy: 0.5760 - val_loss: 0.6668 - val_accuracy: 0.6296\n",
            "Epoch 48/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6757 - accuracy: 0.5760 - val_loss: 0.6667 - val_accuracy: 0.6296\n",
            "Epoch 49/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6755 - accuracy: 0.5760 - val_loss: 0.6665 - val_accuracy: 0.6296\n",
            "Epoch 50/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6754 - accuracy: 0.5760 - val_loss: 0.6664 - val_accuracy: 0.6296\n",
            "Epoch 51/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6752 - accuracy: 0.5760 - val_loss: 0.6663 - val_accuracy: 0.6296\n",
            "Epoch 52/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6751 - accuracy: 0.5760 - val_loss: 0.6660 - val_accuracy: 0.6296\n",
            "Epoch 53/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6750 - accuracy: 0.5760 - val_loss: 0.6658 - val_accuracy: 0.6296\n",
            "Epoch 54/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6749 - accuracy: 0.5760 - val_loss: 0.6656 - val_accuracy: 0.6296\n",
            "Epoch 55/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6748 - accuracy: 0.5760 - val_loss: 0.6654 - val_accuracy: 0.6296\n",
            "Epoch 56/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6746 - accuracy: 0.5760 - val_loss: 0.6652 - val_accuracy: 0.6296\n",
            "Epoch 57/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6746 - accuracy: 0.5760 - val_loss: 0.6650 - val_accuracy: 0.6296\n",
            "Epoch 58/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6744 - accuracy: 0.5760 - val_loss: 0.6649 - val_accuracy: 0.6296\n",
            "Epoch 59/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6743 - accuracy: 0.5760 - val_loss: 0.6647 - val_accuracy: 0.6296\n",
            "Epoch 60/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6742 - accuracy: 0.5760 - val_loss: 0.6645 - val_accuracy: 0.6296\n",
            "Epoch 61/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6741 - accuracy: 0.5760 - val_loss: 0.6645 - val_accuracy: 0.6296\n",
            "Epoch 62/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6740 - accuracy: 0.5760 - val_loss: 0.6644 - val_accuracy: 0.6296\n",
            "Epoch 63/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6739 - accuracy: 0.5760 - val_loss: 0.6644 - val_accuracy: 0.6296\n",
            "Epoch 64/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6738 - accuracy: 0.5760 - val_loss: 0.6640 - val_accuracy: 0.6296\n",
            "Epoch 65/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6736 - accuracy: 0.5760 - val_loss: 0.6638 - val_accuracy: 0.6296\n",
            "Epoch 66/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6735 - accuracy: 0.5760 - val_loss: 0.6636 - val_accuracy: 0.6296\n",
            "Epoch 67/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6733 - accuracy: 0.5760 - val_loss: 0.6635 - val_accuracy: 0.6296\n",
            "Epoch 68/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6732 - accuracy: 0.5760 - val_loss: 0.6634 - val_accuracy: 0.6296\n",
            "Epoch 69/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6731 - accuracy: 0.5760 - val_loss: 0.6632 - val_accuracy: 0.6296\n",
            "Epoch 70/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6730 - accuracy: 0.5760 - val_loss: 0.6630 - val_accuracy: 0.6296\n",
            "Epoch 71/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6729 - accuracy: 0.5760 - val_loss: 0.6630 - val_accuracy: 0.6296\n",
            "Epoch 72/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6727 - accuracy: 0.5760 - val_loss: 0.6628 - val_accuracy: 0.6296\n",
            "Epoch 73/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6725 - accuracy: 0.5760 - val_loss: 0.6627 - val_accuracy: 0.6296\n",
            "Epoch 74/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6724 - accuracy: 0.5760 - val_loss: 0.6625 - val_accuracy: 0.6296\n",
            "Epoch 75/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6722 - accuracy: 0.5760 - val_loss: 0.6623 - val_accuracy: 0.6296\n",
            "Epoch 76/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6721 - accuracy: 0.5760 - val_loss: 0.6623 - val_accuracy: 0.6296\n",
            "Epoch 77/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6720 - accuracy: 0.5760 - val_loss: 0.6622 - val_accuracy: 0.6296\n",
            "Epoch 78/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6718 - accuracy: 0.5760 - val_loss: 0.6621 - val_accuracy: 0.6296\n",
            "Epoch 79/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6717 - accuracy: 0.5760 - val_loss: 0.6619 - val_accuracy: 0.6296\n",
            "Epoch 80/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6715 - accuracy: 0.5760 - val_loss: 0.6618 - val_accuracy: 0.6296\n",
            "Epoch 81/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6714 - accuracy: 0.5760 - val_loss: 0.6617 - val_accuracy: 0.6296\n",
            "Epoch 82/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6712 - accuracy: 0.5760 - val_loss: 0.6616 - val_accuracy: 0.6296\n",
            "Epoch 83/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6711 - accuracy: 0.5760 - val_loss: 0.6614 - val_accuracy: 0.6296\n",
            "Epoch 84/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6710 - accuracy: 0.5760 - val_loss: 0.6613 - val_accuracy: 0.6296\n",
            "Epoch 85/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6710 - accuracy: 0.5760 - val_loss: 0.6610 - val_accuracy: 0.6296\n",
            "Epoch 86/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6707 - accuracy: 0.5760 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 87/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6706 - accuracy: 0.5760 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 88/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6705 - accuracy: 0.5760 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 89/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6704 - accuracy: 0.5760 - val_loss: 0.6606 - val_accuracy: 0.6296\n",
            "Epoch 90/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6703 - accuracy: 0.5760 - val_loss: 0.6607 - val_accuracy: 0.6296\n",
            "Epoch 91/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6701 - accuracy: 0.5760 - val_loss: 0.6606 - val_accuracy: 0.6296\n",
            "Epoch 92/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6700 - accuracy: 0.5760 - val_loss: 0.6603 - val_accuracy: 0.6296\n",
            "Epoch 93/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6698 - accuracy: 0.5760 - val_loss: 0.6601 - val_accuracy: 0.6296\n",
            "Epoch 94/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6698 - accuracy: 0.5760 - val_loss: 0.6602 - val_accuracy: 0.6296\n",
            "Epoch 95/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6695 - accuracy: 0.5760 - val_loss: 0.6601 - val_accuracy: 0.6296\n",
            "Epoch 96/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.5760 - val_loss: 0.6597 - val_accuracy: 0.6296\n",
            "Epoch 97/350\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6693 - accuracy: 0.5760 - val_loss: 0.6596 - val_accuracy: 0.6296\n",
            "Epoch 98/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6692 - accuracy: 0.5760 - val_loss: 0.6595 - val_accuracy: 0.6296\n",
            "Epoch 99/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6690 - accuracy: 0.5760 - val_loss: 0.6595 - val_accuracy: 0.6296\n",
            "Epoch 100/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6689 - accuracy: 0.5760 - val_loss: 0.6593 - val_accuracy: 0.6296\n",
            "Epoch 101/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6687 - accuracy: 0.5760 - val_loss: 0.6592 - val_accuracy: 0.6296\n",
            "Epoch 102/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6687 - accuracy: 0.5760 - val_loss: 0.6590 - val_accuracy: 0.6296\n",
            "Epoch 103/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6684 - accuracy: 0.5760 - val_loss: 0.6589 - val_accuracy: 0.6296\n",
            "Epoch 104/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6684 - accuracy: 0.5760 - val_loss: 0.6589 - val_accuracy: 0.6296\n",
            "Epoch 105/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6682 - accuracy: 0.5760 - val_loss: 0.6588 - val_accuracy: 0.6296\n",
            "Epoch 106/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6680 - accuracy: 0.5760 - val_loss: 0.6587 - val_accuracy: 0.6296\n",
            "Epoch 107/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6679 - accuracy: 0.5760 - val_loss: 0.6585 - val_accuracy: 0.6296\n",
            "Epoch 108/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6677 - accuracy: 0.5760 - val_loss: 0.6584 - val_accuracy: 0.6296\n",
            "Epoch 109/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6676 - accuracy: 0.5760 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 110/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6675 - accuracy: 0.5760 - val_loss: 0.6581 - val_accuracy: 0.6296\n",
            "Epoch 111/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6673 - accuracy: 0.5760 - val_loss: 0.6580 - val_accuracy: 0.6296\n",
            "Epoch 112/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6672 - accuracy: 0.5760 - val_loss: 0.6579 - val_accuracy: 0.6296\n",
            "Epoch 113/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6671 - accuracy: 0.5760 - val_loss: 0.6579 - val_accuracy: 0.6296\n",
            "Epoch 114/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6669 - accuracy: 0.5760 - val_loss: 0.6577 - val_accuracy: 0.6296\n",
            "Epoch 115/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6667 - accuracy: 0.5760 - val_loss: 0.6577 - val_accuracy: 0.6296\n",
            "Epoch 116/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6666 - accuracy: 0.5760 - val_loss: 0.6575 - val_accuracy: 0.6296\n",
            "Epoch 117/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6664 - accuracy: 0.5760 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
            "Epoch 118/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6662 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 119/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6661 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 120/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6659 - accuracy: 0.5760 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
            "Epoch 121/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6659 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 122/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6658 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 123/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6656 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 124/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6654 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 125/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6651 - accuracy: 0.5760 - val_loss: 0.6569 - val_accuracy: 0.6296\n",
            "Epoch 126/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6650 - accuracy: 0.5760 - val_loss: 0.6570 - val_accuracy: 0.6296\n",
            "Epoch 127/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6649 - accuracy: 0.5760 - val_loss: 0.6570 - val_accuracy: 0.6296\n",
            "Epoch 128/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6646 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 129/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6646 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 130/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6642 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 131/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6641 - accuracy: 0.5760 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
            "Epoch 132/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6638 - accuracy: 0.5760 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
            "Epoch 133/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6636 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 134/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6636 - accuracy: 0.5760 - val_loss: 0.6568 - val_accuracy: 0.6296\n",
            "Epoch 135/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6633 - accuracy: 0.5760 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
            "Epoch 136/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6631 - accuracy: 0.5760 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
            "Epoch 137/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6629 - accuracy: 0.5760 - val_loss: 0.6565 - val_accuracy: 0.6296\n",
            "Epoch 138/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6627 - accuracy: 0.5760 - val_loss: 0.6564 - val_accuracy: 0.6296\n",
            "Epoch 139/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6626 - accuracy: 0.5760 - val_loss: 0.6563 - val_accuracy: 0.6296\n",
            "Epoch 140/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6624 - accuracy: 0.5760 - val_loss: 0.6564 - val_accuracy: 0.6296\n",
            "Epoch 141/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6622 - accuracy: 0.5760 - val_loss: 0.6562 - val_accuracy: 0.6296\n",
            "Epoch 142/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6620 - accuracy: 0.5760 - val_loss: 0.6561 - val_accuracy: 0.6296\n",
            "Epoch 143/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6619 - accuracy: 0.5760 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
            "Epoch 144/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6617 - accuracy: 0.5760 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
            "Epoch 145/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6617 - accuracy: 0.5760 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
            "Epoch 146/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6613 - accuracy: 0.5760 - val_loss: 0.6558 - val_accuracy: 0.6296\n",
            "Epoch 147/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6612 - accuracy: 0.5760 - val_loss: 0.6557 - val_accuracy: 0.6296\n",
            "Epoch 148/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6611 - accuracy: 0.5760 - val_loss: 0.6557 - val_accuracy: 0.6296\n",
            "Epoch 149/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6608 - accuracy: 0.5760 - val_loss: 0.6555 - val_accuracy: 0.6296\n",
            "Epoch 150/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6608 - accuracy: 0.5760 - val_loss: 0.6553 - val_accuracy: 0.6296\n",
            "Epoch 151/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6606 - accuracy: 0.5760 - val_loss: 0.6552 - val_accuracy: 0.6296\n",
            "Epoch 152/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6604 - accuracy: 0.5760 - val_loss: 0.6552 - val_accuracy: 0.6296\n",
            "Epoch 153/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6606 - accuracy: 0.5760 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
            "Epoch 154/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6600 - accuracy: 0.5760 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
            "Epoch 155/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6602 - accuracy: 0.5760 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
            "Epoch 156/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6599 - accuracy: 0.5760 - val_loss: 0.6547 - val_accuracy: 0.6296\n",
            "Epoch 157/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6596 - accuracy: 0.5760 - val_loss: 0.6546 - val_accuracy: 0.6296\n",
            "Epoch 158/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6595 - accuracy: 0.5760 - val_loss: 0.6544 - val_accuracy: 0.6296\n",
            "Epoch 159/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6594 - accuracy: 0.5760 - val_loss: 0.6543 - val_accuracy: 0.6296\n",
            "Epoch 160/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6591 - accuracy: 0.5760 - val_loss: 0.6542 - val_accuracy: 0.6296\n",
            "Epoch 161/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6589 - accuracy: 0.5760 - val_loss: 0.6540 - val_accuracy: 0.6296\n",
            "Epoch 162/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6588 - accuracy: 0.5760 - val_loss: 0.6539 - val_accuracy: 0.6296\n",
            "Epoch 163/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6587 - accuracy: 0.5760 - val_loss: 0.6538 - val_accuracy: 0.6296\n",
            "Epoch 164/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6585 - accuracy: 0.5760 - val_loss: 0.6536 - val_accuracy: 0.6296\n",
            "Epoch 165/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6582 - accuracy: 0.5760 - val_loss: 0.6536 - val_accuracy: 0.6296\n",
            "Epoch 166/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6579 - accuracy: 0.5760 - val_loss: 0.6535 - val_accuracy: 0.6296\n",
            "Epoch 167/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6577 - accuracy: 0.5760 - val_loss: 0.6533 - val_accuracy: 0.6296\n",
            "Epoch 168/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6576 - accuracy: 0.5760 - val_loss: 0.6532 - val_accuracy: 0.6296\n",
            "Epoch 169/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6573 - accuracy: 0.5760 - val_loss: 0.6531 - val_accuracy: 0.6296\n",
            "Epoch 170/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6571 - accuracy: 0.5760 - val_loss: 0.6531 - val_accuracy: 0.6296\n",
            "Epoch 171/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6570 - accuracy: 0.5760 - val_loss: 0.6531 - val_accuracy: 0.6296\n",
            "Epoch 172/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6567 - accuracy: 0.5760 - val_loss: 0.6531 - val_accuracy: 0.6296\n",
            "Epoch 173/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6568 - accuracy: 0.5760 - val_loss: 0.6530 - val_accuracy: 0.6296\n",
            "Epoch 174/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6566 - accuracy: 0.5760 - val_loss: 0.6529 - val_accuracy: 0.6296\n",
            "Epoch 175/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6561 - accuracy: 0.5760 - val_loss: 0.6527 - val_accuracy: 0.6296\n",
            "Epoch 176/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6560 - accuracy: 0.5760 - val_loss: 0.6526 - val_accuracy: 0.6296\n",
            "Epoch 177/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6558 - accuracy: 0.5760 - val_loss: 0.6525 - val_accuracy: 0.6296\n",
            "Epoch 178/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6556 - accuracy: 0.5760 - val_loss: 0.6524 - val_accuracy: 0.6296\n",
            "Epoch 179/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6553 - accuracy: 0.5760 - val_loss: 0.6523 - val_accuracy: 0.6296\n",
            "Epoch 180/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6552 - accuracy: 0.5760 - val_loss: 0.6522 - val_accuracy: 0.6296\n",
            "Epoch 181/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6550 - accuracy: 0.5760 - val_loss: 0.6521 - val_accuracy: 0.6296\n",
            "Epoch 182/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6548 - accuracy: 0.5760 - val_loss: 0.6520 - val_accuracy: 0.6296\n",
            "Epoch 183/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6547 - accuracy: 0.5760 - val_loss: 0.6518 - val_accuracy: 0.6296\n",
            "Epoch 184/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6546 - accuracy: 0.5760 - val_loss: 0.6515 - val_accuracy: 0.6296\n",
            "Epoch 185/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6542 - accuracy: 0.5760 - val_loss: 0.6514 - val_accuracy: 0.6296\n",
            "Epoch 186/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6541 - accuracy: 0.5760 - val_loss: 0.6514 - val_accuracy: 0.6296\n",
            "Epoch 187/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6540 - accuracy: 0.5760 - val_loss: 0.6514 - val_accuracy: 0.6296\n",
            "Epoch 188/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6537 - accuracy: 0.5760 - val_loss: 0.6512 - val_accuracy: 0.6296\n",
            "Epoch 189/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6536 - accuracy: 0.5760 - val_loss: 0.6511 - val_accuracy: 0.6296\n",
            "Epoch 190/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6534 - accuracy: 0.5760 - val_loss: 0.6509 - val_accuracy: 0.6296\n",
            "Epoch 191/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6532 - accuracy: 0.5760 - val_loss: 0.6508 - val_accuracy: 0.6296\n",
            "Epoch 192/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6530 - accuracy: 0.5760 - val_loss: 0.6507 - val_accuracy: 0.6296\n",
            "Epoch 193/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6530 - accuracy: 0.5760 - val_loss: 0.6504 - val_accuracy: 0.6296\n",
            "Epoch 194/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6528 - accuracy: 0.5760 - val_loss: 0.6503 - val_accuracy: 0.6296\n",
            "Epoch 195/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6526 - accuracy: 0.5760 - val_loss: 0.6503 - val_accuracy: 0.6296\n",
            "Epoch 196/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6523 - accuracy: 0.5760 - val_loss: 0.6502 - val_accuracy: 0.6296\n",
            "Epoch 197/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6521 - accuracy: 0.5760 - val_loss: 0.6500 - val_accuracy: 0.6296\n",
            "Epoch 198/350\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6519 - accuracy: 0.5760 - val_loss: 0.6499 - val_accuracy: 0.6296\n",
            "Epoch 199/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6517 - accuracy: 0.5760 - val_loss: 0.6497 - val_accuracy: 0.6296\n",
            "Epoch 200/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6516 - accuracy: 0.5760 - val_loss: 0.6497 - val_accuracy: 0.6296\n",
            "Epoch 201/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6513 - accuracy: 0.5760 - val_loss: 0.6493 - val_accuracy: 0.6296\n",
            "Epoch 202/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6514 - accuracy: 0.5760 - val_loss: 0.6491 - val_accuracy: 0.6296\n",
            "Epoch 203/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6511 - accuracy: 0.5760 - val_loss: 0.6490 - val_accuracy: 0.6296\n",
            "Epoch 204/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6508 - accuracy: 0.5760 - val_loss: 0.6490 - val_accuracy: 0.6296\n",
            "Epoch 205/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6506 - accuracy: 0.5760 - val_loss: 0.6489 - val_accuracy: 0.6296\n",
            "Epoch 206/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6503 - accuracy: 0.5760 - val_loss: 0.6488 - val_accuracy: 0.6296\n",
            "Epoch 207/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6502 - accuracy: 0.5760 - val_loss: 0.6486 - val_accuracy: 0.6296\n",
            "Epoch 208/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6501 - accuracy: 0.5760 - val_loss: 0.6485 - val_accuracy: 0.6296\n",
            "Epoch 209/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6498 - accuracy: 0.5760 - val_loss: 0.6483 - val_accuracy: 0.6296\n",
            "Epoch 210/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6499 - accuracy: 0.5760 - val_loss: 0.6483 - val_accuracy: 0.6296\n",
            "Epoch 211/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6496 - accuracy: 0.5760 - val_loss: 0.6481 - val_accuracy: 0.6296\n",
            "Epoch 212/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6493 - accuracy: 0.5760 - val_loss: 0.6480 - val_accuracy: 0.6296\n",
            "Epoch 213/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6496 - accuracy: 0.5760 - val_loss: 0.6478 - val_accuracy: 0.6296\n",
            "Epoch 214/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6492 - accuracy: 0.5760 - val_loss: 0.6477 - val_accuracy: 0.6296\n",
            "Epoch 215/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6489 - accuracy: 0.5760 - val_loss: 0.6476 - val_accuracy: 0.6296\n",
            "Epoch 216/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6487 - accuracy: 0.5760 - val_loss: 0.6475 - val_accuracy: 0.6296\n",
            "Epoch 217/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6486 - accuracy: 0.5760 - val_loss: 0.6474 - val_accuracy: 0.6296\n",
            "Epoch 218/350\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6560 - accuracy: 0.5938INFO:tensorflow:Assets written to: model_experiments/sequential_81/assets\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.6484 - accuracy: 0.5760 - val_loss: 0.6473 - val_accuracy: 0.6667\n",
            "Epoch 219/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6485 - accuracy: 0.6160 - val_loss: 0.6473 - val_accuracy: 0.6296\n",
            "Epoch 220/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6482 - accuracy: 0.6240 - val_loss: 0.6472 - val_accuracy: 0.6667\n",
            "Epoch 221/350\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6698 - accuracy: 0.6250INFO:tensorflow:Assets written to: model_experiments/sequential_81/assets\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.6481 - accuracy: 0.6160 - val_loss: 0.6469 - val_accuracy: 0.7037\n",
            "Epoch 222/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6479 - accuracy: 0.6080 - val_loss: 0.6469 - val_accuracy: 0.6667\n",
            "Epoch 223/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6477 - accuracy: 0.6080 - val_loss: 0.6468 - val_accuracy: 0.6667\n",
            "Epoch 224/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6475 - accuracy: 0.6080 - val_loss: 0.6466 - val_accuracy: 0.6667\n",
            "Epoch 225/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6473 - accuracy: 0.6160 - val_loss: 0.6467 - val_accuracy: 0.6667\n",
            "Epoch 226/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6473 - accuracy: 0.6160 - val_loss: 0.6467 - val_accuracy: 0.6296\n",
            "Epoch 227/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6473 - accuracy: 0.6240 - val_loss: 0.6468 - val_accuracy: 0.6296\n",
            "Epoch 228/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6470 - accuracy: 0.6240 - val_loss: 0.6465 - val_accuracy: 0.6296\n",
            "Epoch 229/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6474 - accuracy: 0.6160 - val_loss: 0.6461 - val_accuracy: 0.6667\n",
            "Epoch 230/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6467 - accuracy: 0.6160 - val_loss: 0.6462 - val_accuracy: 0.6667\n",
            "Epoch 231/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6465 - accuracy: 0.6160 - val_loss: 0.6462 - val_accuracy: 0.6296\n",
            "Epoch 232/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6464 - accuracy: 0.6160 - val_loss: 0.6464 - val_accuracy: 0.6296\n",
            "Epoch 233/350\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6463 - accuracy: 0.6160 - val_loss: 0.6461 - val_accuracy: 0.6296\n",
            "Epoch 234/350\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6461 - accuracy: 0.6160 - val_loss: 0.6461 - val_accuracy: 0.6296\n",
            "Epoch 235/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6460 - accuracy: 0.6160 - val_loss: 0.6459 - val_accuracy: 0.6296\n",
            "Epoch 236/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6458 - accuracy: 0.6160 - val_loss: 0.6457 - val_accuracy: 0.6296\n",
            "Epoch 237/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6457 - accuracy: 0.6240 - val_loss: 0.6455 - val_accuracy: 0.6296\n",
            "Epoch 238/350\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6456 - accuracy: 0.6240 - val_loss: 0.6454 - val_accuracy: 0.6296\n",
            "Epoch 239/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6454 - accuracy: 0.6160 - val_loss: 0.6454 - val_accuracy: 0.6296\n",
            "Epoch 240/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6453 - accuracy: 0.6160 - val_loss: 0.6454 - val_accuracy: 0.6296\n",
            "Epoch 241/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6452 - accuracy: 0.6160 - val_loss: 0.6454 - val_accuracy: 0.6296\n",
            "Epoch 242/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6451 - accuracy: 0.6160 - val_loss: 0.6453 - val_accuracy: 0.6296\n",
            "Epoch 243/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6450 - accuracy: 0.6160 - val_loss: 0.6451 - val_accuracy: 0.6296\n",
            "Epoch 244/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6448 - accuracy: 0.6160 - val_loss: 0.6451 - val_accuracy: 0.6296\n",
            "Epoch 245/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6447 - accuracy: 0.6160 - val_loss: 0.6450 - val_accuracy: 0.6296\n",
            "Epoch 246/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6445 - accuracy: 0.6160 - val_loss: 0.6450 - val_accuracy: 0.6296\n",
            "Epoch 247/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6448 - accuracy: 0.6160 - val_loss: 0.6450 - val_accuracy: 0.6296\n",
            "Epoch 248/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6444 - accuracy: 0.6160 - val_loss: 0.6445 - val_accuracy: 0.6296\n",
            "Epoch 249/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6443 - accuracy: 0.6160 - val_loss: 0.6443 - val_accuracy: 0.6296\n",
            "Epoch 250/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6441 - accuracy: 0.6160 - val_loss: 0.6442 - val_accuracy: 0.6296\n",
            "Epoch 251/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6440 - accuracy: 0.6160 - val_loss: 0.6441 - val_accuracy: 0.6296\n",
            "Epoch 252/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6440 - accuracy: 0.6080 - val_loss: 0.6440 - val_accuracy: 0.6296\n",
            "Epoch 253/350\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6439 - accuracy: 0.6080 - val_loss: 0.6444 - val_accuracy: 0.6296\n",
            "Epoch 254/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6437 - accuracy: 0.6320 - val_loss: 0.6445 - val_accuracy: 0.6296\n",
            "Epoch 255/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6436 - accuracy: 0.6320 - val_loss: 0.6442 - val_accuracy: 0.6296\n",
            "Epoch 256/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6434 - accuracy: 0.6320 - val_loss: 0.6441 - val_accuracy: 0.6296\n",
            "Epoch 257/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6433 - accuracy: 0.6320 - val_loss: 0.6440 - val_accuracy: 0.6296\n",
            "Epoch 258/350\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6431 - accuracy: 0.6320 - val_loss: 0.6439 - val_accuracy: 0.6296\n",
            "Epoch 259/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6430 - accuracy: 0.6320 - val_loss: 0.6436 - val_accuracy: 0.6296\n",
            "Epoch 260/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6429 - accuracy: 0.6240 - val_loss: 0.6435 - val_accuracy: 0.6296\n",
            "Epoch 261/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6431 - accuracy: 0.6320 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 262/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6427 - accuracy: 0.6240 - val_loss: 0.6435 - val_accuracy: 0.6296\n",
            "Epoch 263/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6426 - accuracy: 0.6240 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 264/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6424 - accuracy: 0.6240 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 265/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6423 - accuracy: 0.6240 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 266/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6423 - accuracy: 0.6240 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 267/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6421 - accuracy: 0.6160 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 268/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6422 - accuracy: 0.6160 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 269/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6419 - accuracy: 0.6160 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 270/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6418 - accuracy: 0.6240 - val_loss: 0.6436 - val_accuracy: 0.6296\n",
            "Epoch 271/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6420 - accuracy: 0.6240 - val_loss: 0.6439 - val_accuracy: 0.6296\n",
            "Epoch 272/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6419 - accuracy: 0.6240 - val_loss: 0.6435 - val_accuracy: 0.6296\n",
            "Epoch 273/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6414 - accuracy: 0.6240 - val_loss: 0.6436 - val_accuracy: 0.6296\n",
            "Epoch 274/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6414 - accuracy: 0.6240 - val_loss: 0.6438 - val_accuracy: 0.5926\n",
            "Epoch 275/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6412 - accuracy: 0.6240 - val_loss: 0.6437 - val_accuracy: 0.5926\n",
            "Epoch 276/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6411 - accuracy: 0.6320 - val_loss: 0.6435 - val_accuracy: 0.6296\n",
            "Epoch 277/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6411 - accuracy: 0.6320 - val_loss: 0.6435 - val_accuracy: 0.5556\n",
            "Epoch 278/350\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6409 - accuracy: 0.6320 - val_loss: 0.6435 - val_accuracy: 0.5556\n",
            "Epoch 279/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6408 - accuracy: 0.6320 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 280/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6408 - accuracy: 0.6320 - val_loss: 0.6435 - val_accuracy: 0.5556\n",
            "Epoch 281/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6405 - accuracy: 0.6400 - val_loss: 0.6433 - val_accuracy: 0.5926\n",
            "Epoch 282/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6408 - accuracy: 0.6320 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 283/350\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6404 - accuracy: 0.6400 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 284/350\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6401 - accuracy: 0.6400 - val_loss: 0.6433 - val_accuracy: 0.5926\n",
            "Epoch 285/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6401 - accuracy: 0.6400 - val_loss: 0.6433 - val_accuracy: 0.5926\n",
            "Epoch 286/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6399 - accuracy: 0.6480 - val_loss: 0.6435 - val_accuracy: 0.5556\n",
            "Epoch 287/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6399 - accuracy: 0.6480 - val_loss: 0.6436 - val_accuracy: 0.5556\n",
            "Epoch 288/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6398 - accuracy: 0.6480 - val_loss: 0.6437 - val_accuracy: 0.5556\n",
            "Epoch 289/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6397 - accuracy: 0.6480 - val_loss: 0.6436 - val_accuracy: 0.5556\n",
            "Epoch 290/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6396 - accuracy: 0.6480 - val_loss: 0.6433 - val_accuracy: 0.5556\n",
            "Epoch 291/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6395 - accuracy: 0.6480 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 292/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6395 - accuracy: 0.6480 - val_loss: 0.6432 - val_accuracy: 0.5556\n",
            "Epoch 293/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6392 - accuracy: 0.6480 - val_loss: 0.6432 - val_accuracy: 0.5556\n",
            "Epoch 294/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6393 - accuracy: 0.6480 - val_loss: 0.6433 - val_accuracy: 0.5556\n",
            "Epoch 295/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6391 - accuracy: 0.6480 - val_loss: 0.6432 - val_accuracy: 0.5556\n",
            "Epoch 296/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6391 - accuracy: 0.6480 - val_loss: 0.6431 - val_accuracy: 0.5926\n",
            "Epoch 297/350\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6390 - accuracy: 0.6480 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 298/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6389 - accuracy: 0.6480 - val_loss: 0.6433 - val_accuracy: 0.5556\n",
            "Epoch 299/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6387 - accuracy: 0.6480 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 300/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6386 - accuracy: 0.6480 - val_loss: 0.6433 - val_accuracy: 0.5556\n",
            "Epoch 301/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6385 - accuracy: 0.6560 - val_loss: 0.6432 - val_accuracy: 0.5556\n",
            "Epoch 302/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6384 - accuracy: 0.6560 - val_loss: 0.6432 - val_accuracy: 0.5556\n",
            "Epoch 303/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6383 - accuracy: 0.6640 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 304/350\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6382 - accuracy: 0.6560 - val_loss: 0.6435 - val_accuracy: 0.5556\n",
            "Epoch 305/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6382 - accuracy: 0.6560 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 306/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6380 - accuracy: 0.6560 - val_loss: 0.6433 - val_accuracy: 0.5556\n",
            "Epoch 307/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6386 - accuracy: 0.6640 - val_loss: 0.6430 - val_accuracy: 0.5556\n",
            "Epoch 308/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6379 - accuracy: 0.6560 - val_loss: 0.6432 - val_accuracy: 0.5556\n",
            "Epoch 309/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6378 - accuracy: 0.6640 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 310/350\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6377 - accuracy: 0.6560 - val_loss: 0.6435 - val_accuracy: 0.5556\n",
            "Epoch 311/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6377 - accuracy: 0.6480 - val_loss: 0.6435 - val_accuracy: 0.5556\n",
            "Epoch 312/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6376 - accuracy: 0.6480 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 313/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6374 - accuracy: 0.6560 - val_loss: 0.6433 - val_accuracy: 0.5556\n",
            "Epoch 314/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6376 - accuracy: 0.6640 - val_loss: 0.6431 - val_accuracy: 0.5556\n",
            "Epoch 315/350\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6374 - accuracy: 0.6640 - val_loss: 0.6432 - val_accuracy: 0.5556\n",
            "Epoch 316/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6371 - accuracy: 0.6640 - val_loss: 0.6434 - val_accuracy: 0.5556\n",
            "Epoch 317/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6372 - accuracy: 0.6560 - val_loss: 0.6437 - val_accuracy: 0.5556\n",
            "Epoch 318/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6371 - accuracy: 0.6480 - val_loss: 0.6436 - val_accuracy: 0.5556\n",
            "Epoch 319/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6370 - accuracy: 0.6480 - val_loss: 0.6436 - val_accuracy: 0.5556\n",
            "Epoch 320/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6371 - accuracy: 0.6480 - val_loss: 0.6437 - val_accuracy: 0.5556\n",
            "Epoch 321/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6368 - accuracy: 0.6480 - val_loss: 0.6437 - val_accuracy: 0.5556\n",
            "Epoch 322/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6368 - accuracy: 0.6480 - val_loss: 0.6436 - val_accuracy: 0.5556\n",
            "Epoch 323/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6367 - accuracy: 0.6480 - val_loss: 0.6437 - val_accuracy: 0.5556\n",
            "Epoch 324/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6366 - accuracy: 0.6480 - val_loss: 0.6440 - val_accuracy: 0.5556\n",
            "Epoch 325/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6365 - accuracy: 0.6480 - val_loss: 0.6441 - val_accuracy: 0.5556\n",
            "Epoch 326/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6365 - accuracy: 0.6480 - val_loss: 0.6442 - val_accuracy: 0.5556\n",
            "Epoch 327/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6364 - accuracy: 0.6560 - val_loss: 0.6441 - val_accuracy: 0.5556\n",
            "Epoch 328/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6362 - accuracy: 0.6480 - val_loss: 0.6440 - val_accuracy: 0.5556\n",
            "Epoch 329/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6362 - accuracy: 0.6480 - val_loss: 0.6440 - val_accuracy: 0.5556\n",
            "Epoch 330/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6362 - accuracy: 0.6480 - val_loss: 0.6439 - val_accuracy: 0.5556\n",
            "Epoch 331/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6360 - accuracy: 0.6480 - val_loss: 0.6439 - val_accuracy: 0.5556\n",
            "Epoch 332/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6361 - accuracy: 0.6480 - val_loss: 0.6439 - val_accuracy: 0.5556\n",
            "Epoch 333/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6360 - accuracy: 0.6480 - val_loss: 0.6441 - val_accuracy: 0.5556\n",
            "Epoch 334/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6359 - accuracy: 0.6480 - val_loss: 0.6442 - val_accuracy: 0.5556\n",
            "Epoch 335/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6357 - accuracy: 0.6480 - val_loss: 0.6443 - val_accuracy: 0.5556\n",
            "Epoch 336/350\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6358 - accuracy: 0.6480 - val_loss: 0.6444 - val_accuracy: 0.5556\n",
            "Epoch 337/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6356 - accuracy: 0.6560 - val_loss: 0.6445 - val_accuracy: 0.5556\n",
            "Epoch 338/350\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6356 - accuracy: 0.6560 - val_loss: 0.6445 - val_accuracy: 0.5556\n",
            "Epoch 339/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6354 - accuracy: 0.6560 - val_loss: 0.6444 - val_accuracy: 0.5556\n",
            "Epoch 340/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6354 - accuracy: 0.6560 - val_loss: 0.6445 - val_accuracy: 0.5556\n",
            "Epoch 341/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6353 - accuracy: 0.6560 - val_loss: 0.6445 - val_accuracy: 0.5556\n",
            "Epoch 342/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6355 - accuracy: 0.6480 - val_loss: 0.6445 - val_accuracy: 0.5556\n",
            "Epoch 343/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6353 - accuracy: 0.6560 - val_loss: 0.6447 - val_accuracy: 0.5556\n",
            "Epoch 344/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6351 - accuracy: 0.6560 - val_loss: 0.6449 - val_accuracy: 0.5556\n",
            "Epoch 345/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6352 - accuracy: 0.6560 - val_loss: 0.6448 - val_accuracy: 0.5556\n",
            "Epoch 346/350\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6350 - accuracy: 0.6560 - val_loss: 0.6451 - val_accuracy: 0.5556\n",
            "Epoch 347/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6349 - accuracy: 0.6560 - val_loss: 0.6451 - val_accuracy: 0.5556\n",
            "Epoch 348/350\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6348 - accuracy: 0.6560 - val_loss: 0.6451 - val_accuracy: 0.5556\n",
            "Epoch 349/350\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6348 - accuracy: 0.6560 - val_loss: 0.6451 - val_accuracy: 0.5556\n",
            "Epoch 350/350\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6348 - accuracy: 0.6560 - val_loss: 0.6452 - val_accuracy: 0.5556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuSW-3hF7uM4",
        "outputId": "6e3e76d8-e01e-4199-e872-40fdf67e0312"
      },
      "execution_count": 887,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 4.9923 - accuracy: 0.6522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.992343902587891, 0.6521739363670349]"
            ]
          },
          "metadata": {},
          "execution_count": 887
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = tf.keras.models.load_model(f\"/content/model_experiments/{model7.name}\")\n",
        "model7.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "S7rS6N1nq4HX",
        "outputId": "568f7808-c49a-4c1d-e016-c1c72066a73c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 888,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 122ms/step - loss: 6.0827 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.082678318023682, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 888
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model8 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model8.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history8 = model8.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model8.name)])"
      ],
      "metadata": {
        "id": "6iqdazWeefng",
        "outputId": "664a513a-5643-48e2-e963-ef8bdb4ecbe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 889,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1/4 [======>.......................] - ETA: 1s - loss: 0.6915 - accuracy: 0.4688INFO:tensorflow:Assets written to: model_experiments/sequential_82/assets\n",
            "4/4 [==============================] - 1s 293ms/step - loss: 0.6942 - accuracy: 0.4480 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
            "Epoch 2/150\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6921 - accuracy: 0.5312INFO:tensorflow:Assets written to: model_experiments/sequential_82/assets\n",
            "4/4 [==============================] - 2s 519ms/step - loss: 0.6932 - accuracy: 0.5120 - val_loss: 0.6900 - val_accuracy: 0.7037\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6917 - accuracy: 0.5360 - val_loss: 0.6885 - val_accuracy: 0.5926\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6909 - accuracy: 0.5520 - val_loss: 0.6869 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6898 - accuracy: 0.5680 - val_loss: 0.6854 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5760 - val_loss: 0.6839 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6882 - accuracy: 0.5760 - val_loss: 0.6826 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6876 - accuracy: 0.5760 - val_loss: 0.6813 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6866 - accuracy: 0.5760 - val_loss: 0.6802 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5760 - val_loss: 0.6790 - val_accuracy: 0.6296\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6854 - accuracy: 0.5760 - val_loss: 0.6777 - val_accuracy: 0.6296\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6844 - accuracy: 0.5760 - val_loss: 0.6766 - val_accuracy: 0.6296\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5760 - val_loss: 0.6755 - val_accuracy: 0.6296\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5760 - val_loss: 0.6743 - val_accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5760 - val_loss: 0.6731 - val_accuracy: 0.6296\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6816 - accuracy: 0.5760 - val_loss: 0.6719 - val_accuracy: 0.6296\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5760 - val_loss: 0.6708 - val_accuracy: 0.6296\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6803 - accuracy: 0.5760 - val_loss: 0.6697 - val_accuracy: 0.6296\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6796 - accuracy: 0.5760 - val_loss: 0.6688 - val_accuracy: 0.6296\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6792 - accuracy: 0.5760 - val_loss: 0.6678 - val_accuracy: 0.6296\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.5760 - val_loss: 0.6669 - val_accuracy: 0.6296\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.5760 - val_loss: 0.6658 - val_accuracy: 0.6296\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6777 - accuracy: 0.5760 - val_loss: 0.6652 - val_accuracy: 0.6296\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6775 - accuracy: 0.5760 - val_loss: 0.6644 - val_accuracy: 0.6296\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6771 - accuracy: 0.5760 - val_loss: 0.6637 - val_accuracy: 0.6296\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6770 - accuracy: 0.5760 - val_loss: 0.6630 - val_accuracy: 0.6296\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6767 - accuracy: 0.5760 - val_loss: 0.6623 - val_accuracy: 0.6296\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6764 - accuracy: 0.5760 - val_loss: 0.6617 - val_accuracy: 0.6296\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6761 - accuracy: 0.5760 - val_loss: 0.6613 - val_accuracy: 0.6296\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6759 - accuracy: 0.5760 - val_loss: 0.6608 - val_accuracy: 0.6296\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6758 - accuracy: 0.5760 - val_loss: 0.6605 - val_accuracy: 0.6296\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6757 - accuracy: 0.5760 - val_loss: 0.6599 - val_accuracy: 0.6296\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6755 - accuracy: 0.5760 - val_loss: 0.6594 - val_accuracy: 0.6296\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6752 - accuracy: 0.5760 - val_loss: 0.6591 - val_accuracy: 0.6296\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6750 - accuracy: 0.5760 - val_loss: 0.6589 - val_accuracy: 0.6296\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6747 - accuracy: 0.5760 - val_loss: 0.6586 - val_accuracy: 0.6296\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6746 - accuracy: 0.5760 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6745 - accuracy: 0.5760 - val_loss: 0.6578 - val_accuracy: 0.6296\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6741 - accuracy: 0.5760 - val_loss: 0.6576 - val_accuracy: 0.6296\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6739 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6738 - accuracy: 0.5760 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6734 - accuracy: 0.5760 - val_loss: 0.6569 - val_accuracy: 0.6296\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6731 - accuracy: 0.5760 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6730 - accuracy: 0.5760 - val_loss: 0.6564 - val_accuracy: 0.6296\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6728 - accuracy: 0.5760 - val_loss: 0.6561 - val_accuracy: 0.6296\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6724 - accuracy: 0.5760 - val_loss: 0.6557 - val_accuracy: 0.6296\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6723 - accuracy: 0.5760 - val_loss: 0.6552 - val_accuracy: 0.6296\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6721 - accuracy: 0.5760 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6716 - accuracy: 0.5760 - val_loss: 0.6546 - val_accuracy: 0.6296\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6714 - accuracy: 0.5760 - val_loss: 0.6546 - val_accuracy: 0.6296\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6711 - accuracy: 0.5760 - val_loss: 0.6545 - val_accuracy: 0.6296\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6708 - accuracy: 0.5760 - val_loss: 0.6540 - val_accuracy: 0.6296\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6704 - accuracy: 0.5760 - val_loss: 0.6538 - val_accuracy: 0.6296\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6702 - accuracy: 0.5760 - val_loss: 0.6537 - val_accuracy: 0.6296\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6700 - accuracy: 0.5760 - val_loss: 0.6536 - val_accuracy: 0.6296\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6695 - accuracy: 0.5760 - val_loss: 0.6537 - val_accuracy: 0.6296\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6691 - accuracy: 0.5760 - val_loss: 0.6536 - val_accuracy: 0.6296\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6685 - accuracy: 0.5760 - val_loss: 0.6537 - val_accuracy: 0.6296\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6681 - accuracy: 0.5760 - val_loss: 0.6537 - val_accuracy: 0.6296\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6678 - accuracy: 0.5840 - val_loss: 0.6535 - val_accuracy: 0.6296\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6677 - accuracy: 0.5840 - val_loss: 0.6536 - val_accuracy: 0.6296\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6673 - accuracy: 0.5840 - val_loss: 0.6534 - val_accuracy: 0.6296\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6671 - accuracy: 0.5760 - val_loss: 0.6531 - val_accuracy: 0.6296\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6668 - accuracy: 0.5840 - val_loss: 0.6522 - val_accuracy: 0.6296\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6662 - accuracy: 0.5840 - val_loss: 0.6516 - val_accuracy: 0.6296\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6661 - accuracy: 0.5840 - val_loss: 0.6511 - val_accuracy: 0.6296\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6656 - accuracy: 0.5840 - val_loss: 0.6510 - val_accuracy: 0.6296\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6652 - accuracy: 0.5760 - val_loss: 0.6509 - val_accuracy: 0.6296\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6650 - accuracy: 0.5680 - val_loss: 0.6507 - val_accuracy: 0.6296\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6648 - accuracy: 0.5680 - val_loss: 0.6505 - val_accuracy: 0.6667\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6648 - accuracy: 0.5680 - val_loss: 0.6506 - val_accuracy: 0.6667\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6642 - accuracy: 0.5680 - val_loss: 0.6503 - val_accuracy: 0.6667\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6637 - accuracy: 0.5760 - val_loss: 0.6500 - val_accuracy: 0.6667\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6637 - accuracy: 0.5760 - val_loss: 0.6494 - val_accuracy: 0.6667\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6633 - accuracy: 0.5760 - val_loss: 0.6494 - val_accuracy: 0.6667\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6630 - accuracy: 0.5840 - val_loss: 0.6495 - val_accuracy: 0.6296\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6628 - accuracy: 0.5840 - val_loss: 0.6496 - val_accuracy: 0.6296\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6623 - accuracy: 0.5920 - val_loss: 0.6493 - val_accuracy: 0.6296\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6621 - accuracy: 0.6000 - val_loss: 0.6491 - val_accuracy: 0.6296\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6618 - accuracy: 0.6000 - val_loss: 0.6488 - val_accuracy: 0.6296\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6615 - accuracy: 0.6160 - val_loss: 0.6487 - val_accuracy: 0.7037\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6611 - accuracy: 0.6160 - val_loss: 0.6487 - val_accuracy: 0.7037\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6608 - accuracy: 0.6000 - val_loss: 0.6484 - val_accuracy: 0.7037\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6605 - accuracy: 0.6000 - val_loss: 0.6484 - val_accuracy: 0.7037\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6604 - accuracy: 0.6000 - val_loss: 0.6481 - val_accuracy: 0.7037\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6598 - accuracy: 0.5920 - val_loss: 0.6482 - val_accuracy: 0.7037\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6595 - accuracy: 0.6080 - val_loss: 0.6482 - val_accuracy: 0.7037\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6594 - accuracy: 0.5920 - val_loss: 0.6484 - val_accuracy: 0.7037\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6589 - accuracy: 0.5920 - val_loss: 0.6480 - val_accuracy: 0.7037\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6589 - accuracy: 0.6160 - val_loss: 0.6482 - val_accuracy: 0.7037\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6582 - accuracy: 0.6240 - val_loss: 0.6481 - val_accuracy: 0.7037\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6582 - accuracy: 0.6240 - val_loss: 0.6477 - val_accuracy: 0.7037\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6578 - accuracy: 0.6000 - val_loss: 0.6474 - val_accuracy: 0.7037\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6576 - accuracy: 0.6160 - val_loss: 0.6477 - val_accuracy: 0.7037\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6572 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6296\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6574 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.7037\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6566 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.7037\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6563 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6296\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6560 - accuracy: 0.6480 - val_loss: 0.6481 - val_accuracy: 0.5926\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6556 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.5926\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6554 - accuracy: 0.6480 - val_loss: 0.6478 - val_accuracy: 0.5926\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6554 - accuracy: 0.6320 - val_loss: 0.6476 - val_accuracy: 0.5926\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6547 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.5926\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6551 - accuracy: 0.6320 - val_loss: 0.6482 - val_accuracy: 0.5926\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6544 - accuracy: 0.6320 - val_loss: 0.6479 - val_accuracy: 0.5926\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6540 - accuracy: 0.6320 - val_loss: 0.6475 - val_accuracy: 0.5926\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.5926\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.5926\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6534 - accuracy: 0.6320 - val_loss: 0.6472 - val_accuracy: 0.5926\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6532 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.5926\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6528 - accuracy: 0.6320 - val_loss: 0.6481 - val_accuracy: 0.5926\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6525 - accuracy: 0.6320 - val_loss: 0.6485 - val_accuracy: 0.5926\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6524 - accuracy: 0.6320 - val_loss: 0.6489 - val_accuracy: 0.5556\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6519 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.5926\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6516 - accuracy: 0.6320 - val_loss: 0.6481 - val_accuracy: 0.5926\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6513 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.5926\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6512 - accuracy: 0.6240 - val_loss: 0.6483 - val_accuracy: 0.5556\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6508 - accuracy: 0.6240 - val_loss: 0.6482 - val_accuracy: 0.5556\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6506 - accuracy: 0.6240 - val_loss: 0.6483 - val_accuracy: 0.5556\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6504 - accuracy: 0.6240 - val_loss: 0.6477 - val_accuracy: 0.5556\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6503 - accuracy: 0.6320 - val_loss: 0.6482 - val_accuracy: 0.5185\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6504 - accuracy: 0.6240 - val_loss: 0.6487 - val_accuracy: 0.5185\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6498 - accuracy: 0.6320 - val_loss: 0.6477 - val_accuracy: 0.5556\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6496 - accuracy: 0.6240 - val_loss: 0.6479 - val_accuracy: 0.5185\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6491 - accuracy: 0.6240 - val_loss: 0.6473 - val_accuracy: 0.5556\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6487 - accuracy: 0.6320 - val_loss: 0.6474 - val_accuracy: 0.5556\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6486 - accuracy: 0.6320 - val_loss: 0.6475 - val_accuracy: 0.5556\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6485 - accuracy: 0.6240 - val_loss: 0.6484 - val_accuracy: 0.5185\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6486 - accuracy: 0.6160 - val_loss: 0.6494 - val_accuracy: 0.5556\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6479 - accuracy: 0.6240 - val_loss: 0.6489 - val_accuracy: 0.5185\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6479 - accuracy: 0.6240 - val_loss: 0.6492 - val_accuracy: 0.5556\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6472 - accuracy: 0.6240 - val_loss: 0.6484 - val_accuracy: 0.5556\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6469 - accuracy: 0.6160 - val_loss: 0.6480 - val_accuracy: 0.5556\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6470 - accuracy: 0.6160 - val_loss: 0.6474 - val_accuracy: 0.5926\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6467 - accuracy: 0.6240 - val_loss: 0.6469 - val_accuracy: 0.5926\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6463 - accuracy: 0.6320 - val_loss: 0.6469 - val_accuracy: 0.5556\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6460 - accuracy: 0.6240 - val_loss: 0.6468 - val_accuracy: 0.5556\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6458 - accuracy: 0.6240 - val_loss: 0.6470 - val_accuracy: 0.5556\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6456 - accuracy: 0.6240 - val_loss: 0.6474 - val_accuracy: 0.5556\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6455 - accuracy: 0.6320 - val_loss: 0.6482 - val_accuracy: 0.5556\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6451 - accuracy: 0.6160 - val_loss: 0.6477 - val_accuracy: 0.5556\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6450 - accuracy: 0.6160 - val_loss: 0.6481 - val_accuracy: 0.5556\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6447 - accuracy: 0.6160 - val_loss: 0.6479 - val_accuracy: 0.5556\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6442 - accuracy: 0.6160 - val_loss: 0.6477 - val_accuracy: 0.5556\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6444 - accuracy: 0.6080 - val_loss: 0.6478 - val_accuracy: 0.5556\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6437 - accuracy: 0.6160 - val_loss: 0.6471 - val_accuracy: 0.5556\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6436 - accuracy: 0.6160 - val_loss: 0.6464 - val_accuracy: 0.5556\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6435 - accuracy: 0.6240 - val_loss: 0.6471 - val_accuracy: 0.5556\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6429 - accuracy: 0.6160 - val_loss: 0.6471 - val_accuracy: 0.5556\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6431 - accuracy: 0.6160 - val_loss: 0.6464 - val_accuracy: 0.5556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3z1ldA67vxo",
        "outputId": "58fc53e7-504f-4d41-d48e-7be1ebd3245d"
      },
      "execution_count": 890,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 7.1574 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.157411575317383, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 890
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8 = tf.keras.models.load_model(f\"/content/model_experiments/{model8.name}\")\n",
        "model8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "HDtXkIhQq43p",
        "outputId": "b34e0945-00e9-4651-c8b8-df367e8df26a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 891,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 139ms/step - loss: 0.7060 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7060167193412781, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 891
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model9 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "    tf.keras.layers.Dense(21, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model9.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history9 = model9.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model9.name)])"
      ],
      "metadata": {
        "id": "IwsQafCPeho4",
        "outputId": "bcbf4608-d27f-423c-ccb1-eef5c2163d52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 892,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1/4 [======>.......................] - ETA: 1s - loss: 0.6885 - accuracy: 0.6562INFO:tensorflow:Assets written to: model_experiments/sequential_83/assets\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.6909 - accuracy: 0.5760 - val_loss: 0.6885 - val_accuracy: 0.6667\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6890 - accuracy: 0.5760 - val_loss: 0.6846 - val_accuracy: 0.6296\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6862 - accuracy: 0.5760 - val_loss: 0.6817 - val_accuracy: 0.6296\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6848 - accuracy: 0.5760 - val_loss: 0.6786 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5760 - val_loss: 0.6760 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5760 - val_loss: 0.6733 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5760 - val_loss: 0.6714 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6797 - accuracy: 0.5760 - val_loss: 0.6696 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6784 - accuracy: 0.5760 - val_loss: 0.6683 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6778 - accuracy: 0.5760 - val_loss: 0.6670 - val_accuracy: 0.6296\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6775 - accuracy: 0.5760 - val_loss: 0.6657 - val_accuracy: 0.6296\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6767 - accuracy: 0.5760 - val_loss: 0.6647 - val_accuracy: 0.6296\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6762 - accuracy: 0.5760 - val_loss: 0.6637 - val_accuracy: 0.6296\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6759 - accuracy: 0.5760 - val_loss: 0.6627 - val_accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6752 - accuracy: 0.5760 - val_loss: 0.6619 - val_accuracy: 0.6296\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6748 - accuracy: 0.5760 - val_loss: 0.6612 - val_accuracy: 0.6296\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6742 - accuracy: 0.5760 - val_loss: 0.6607 - val_accuracy: 0.6296\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6739 - accuracy: 0.5760 - val_loss: 0.6602 - val_accuracy: 0.6296\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6735 - accuracy: 0.5760 - val_loss: 0.6598 - val_accuracy: 0.6296\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6730 - accuracy: 0.5760 - val_loss: 0.6593 - val_accuracy: 0.6296\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6725 - accuracy: 0.5760 - val_loss: 0.6588 - val_accuracy: 0.6296\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6727 - accuracy: 0.5760 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6719 - accuracy: 0.5760 - val_loss: 0.6580 - val_accuracy: 0.6296\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6714 - accuracy: 0.5760 - val_loss: 0.6576 - val_accuracy: 0.6296\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6710 - accuracy: 0.5760 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6705 - accuracy: 0.5760 - val_loss: 0.6569 - val_accuracy: 0.6296\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6701 - accuracy: 0.5760 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6696 - accuracy: 0.5760 - val_loss: 0.6562 - val_accuracy: 0.6296\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6691 - accuracy: 0.5760 - val_loss: 0.6562 - val_accuracy: 0.6296\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6686 - accuracy: 0.5760 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6686 - accuracy: 0.5760 - val_loss: 0.6557 - val_accuracy: 0.6296\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6682 - accuracy: 0.5760 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6676 - accuracy: 0.5760 - val_loss: 0.6544 - val_accuracy: 0.6296\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6673 - accuracy: 0.5760 - val_loss: 0.6542 - val_accuracy: 0.6296\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6670 - accuracy: 0.5760 - val_loss: 0.6545 - val_accuracy: 0.6296\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6663 - accuracy: 0.5760 - val_loss: 0.6543 - val_accuracy: 0.6296\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6660 - accuracy: 0.5760 - val_loss: 0.6541 - val_accuracy: 0.6296\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6658 - accuracy: 0.5760 - val_loss: 0.6539 - val_accuracy: 0.6296\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6652 - accuracy: 0.5760 - val_loss: 0.6538 - val_accuracy: 0.6296\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6648 - accuracy: 0.5760 - val_loss: 0.6536 - val_accuracy: 0.6296\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6646 - accuracy: 0.5760 - val_loss: 0.6535 - val_accuracy: 0.6296\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6640 - accuracy: 0.5760 - val_loss: 0.6532 - val_accuracy: 0.6296\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6637 - accuracy: 0.5760 - val_loss: 0.6530 - val_accuracy: 0.6667\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6636 - accuracy: 0.5840 - val_loss: 0.6531 - val_accuracy: 0.6667\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6633 - accuracy: 0.5920 - val_loss: 0.6529 - val_accuracy: 0.6667\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6628 - accuracy: 0.5840 - val_loss: 0.6527 - val_accuracy: 0.6667\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6626 - accuracy: 0.5920 - val_loss: 0.6522 - val_accuracy: 0.6667\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6625 - accuracy: 0.5760 - val_loss: 0.6525 - val_accuracy: 0.6296\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6618 - accuracy: 0.5680 - val_loss: 0.6524 - val_accuracy: 0.6296\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6615 - accuracy: 0.5680 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6611 - accuracy: 0.5760 - val_loss: 0.6525 - val_accuracy: 0.6667\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6609 - accuracy: 0.5760 - val_loss: 0.6521 - val_accuracy: 0.6667\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6604 - accuracy: 0.5760 - val_loss: 0.6520 - val_accuracy: 0.6667\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6602 - accuracy: 0.5920 - val_loss: 0.6521 - val_accuracy: 0.6667\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6601 - accuracy: 0.6000 - val_loss: 0.6521 - val_accuracy: 0.6667\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6595 - accuracy: 0.5920 - val_loss: 0.6524 - val_accuracy: 0.6296\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6594 - accuracy: 0.6000 - val_loss: 0.6523 - val_accuracy: 0.6296\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6588 - accuracy: 0.6160 - val_loss: 0.6527 - val_accuracy: 0.6296\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6586 - accuracy: 0.6000 - val_loss: 0.6529 - val_accuracy: 0.6296\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6586 - accuracy: 0.6080 - val_loss: 0.6528 - val_accuracy: 0.6296\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6584 - accuracy: 0.6000 - val_loss: 0.6533 - val_accuracy: 0.5926\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6582 - accuracy: 0.6240 - val_loss: 0.6536 - val_accuracy: 0.5926\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6580 - accuracy: 0.6240 - val_loss: 0.6536 - val_accuracy: 0.5926\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6577 - accuracy: 0.6320 - val_loss: 0.6530 - val_accuracy: 0.6296\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6571 - accuracy: 0.6160 - val_loss: 0.6526 - val_accuracy: 0.6296\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6571 - accuracy: 0.6160 - val_loss: 0.6526 - val_accuracy: 0.6296\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6566 - accuracy: 0.6240 - val_loss: 0.6529 - val_accuracy: 0.5926\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6563 - accuracy: 0.6320 - val_loss: 0.6530 - val_accuracy: 0.5926\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6560 - accuracy: 0.6240 - val_loss: 0.6531 - val_accuracy: 0.5926\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6560 - accuracy: 0.6240 - val_loss: 0.6531 - val_accuracy: 0.5926\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6560 - accuracy: 0.6320 - val_loss: 0.6535 - val_accuracy: 0.5926\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6553 - accuracy: 0.6400 - val_loss: 0.6532 - val_accuracy: 0.5926\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6548 - accuracy: 0.6320 - val_loss: 0.6530 - val_accuracy: 0.5926\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6550 - accuracy: 0.6480 - val_loss: 0.6529 - val_accuracy: 0.5926\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6545 - accuracy: 0.6400 - val_loss: 0.6534 - val_accuracy: 0.5926\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6544 - accuracy: 0.6240 - val_loss: 0.6537 - val_accuracy: 0.5926\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6542 - accuracy: 0.6480 - val_loss: 0.6540 - val_accuracy: 0.5926\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6536 - val_accuracy: 0.5926\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6534 - accuracy: 0.6320 - val_loss: 0.6534 - val_accuracy: 0.5926\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6532 - accuracy: 0.6320 - val_loss: 0.6532 - val_accuracy: 0.5926\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6531 - accuracy: 0.6320 - val_loss: 0.6532 - val_accuracy: 0.5926\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6526 - accuracy: 0.6320 - val_loss: 0.6534 - val_accuracy: 0.5926\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6524 - accuracy: 0.6400 - val_loss: 0.6535 - val_accuracy: 0.5926\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6522 - accuracy: 0.6400 - val_loss: 0.6537 - val_accuracy: 0.5926\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6523 - accuracy: 0.6400 - val_loss: 0.6536 - val_accuracy: 0.5926\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6516 - accuracy: 0.6400 - val_loss: 0.6538 - val_accuracy: 0.5926\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6515 - accuracy: 0.6480 - val_loss: 0.6543 - val_accuracy: 0.5926\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6514 - accuracy: 0.6240 - val_loss: 0.6546 - val_accuracy: 0.5926\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6510 - accuracy: 0.6400 - val_loss: 0.6541 - val_accuracy: 0.5926\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6511 - accuracy: 0.6400 - val_loss: 0.6542 - val_accuracy: 0.5926\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6504 - accuracy: 0.6240 - val_loss: 0.6540 - val_accuracy: 0.5926\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6506 - accuracy: 0.6320 - val_loss: 0.6538 - val_accuracy: 0.5926\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6503 - accuracy: 0.6400 - val_loss: 0.6535 - val_accuracy: 0.5926\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6504 - accuracy: 0.6320 - val_loss: 0.6546 - val_accuracy: 0.5926\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6499 - accuracy: 0.6320 - val_loss: 0.6550 - val_accuracy: 0.5556\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6504 - accuracy: 0.6240 - val_loss: 0.6540 - val_accuracy: 0.5926\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6494 - accuracy: 0.6320 - val_loss: 0.6536 - val_accuracy: 0.5926\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6490 - accuracy: 0.6400 - val_loss: 0.6540 - val_accuracy: 0.5926\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6490 - accuracy: 0.6400 - val_loss: 0.6547 - val_accuracy: 0.5556\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6486 - accuracy: 0.6400 - val_loss: 0.6547 - val_accuracy: 0.5556\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6484 - accuracy: 0.6400 - val_loss: 0.6545 - val_accuracy: 0.5556\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6485 - accuracy: 0.6320 - val_loss: 0.6542 - val_accuracy: 0.5556\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6478 - accuracy: 0.6400 - val_loss: 0.6545 - val_accuracy: 0.5556\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6481 - accuracy: 0.6480 - val_loss: 0.6554 - val_accuracy: 0.5556\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6474 - accuracy: 0.6480 - val_loss: 0.6555 - val_accuracy: 0.5556\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6472 - accuracy: 0.6480 - val_loss: 0.6551 - val_accuracy: 0.5556\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6470 - accuracy: 0.6480 - val_loss: 0.6552 - val_accuracy: 0.5556\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6467 - accuracy: 0.6480 - val_loss: 0.6555 - val_accuracy: 0.5556\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6464 - accuracy: 0.6480 - val_loss: 0.6557 - val_accuracy: 0.5556\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6463 - accuracy: 0.6560 - val_loss: 0.6560 - val_accuracy: 0.5556\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6458 - accuracy: 0.6480 - val_loss: 0.6561 - val_accuracy: 0.5556\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6456 - accuracy: 0.6480 - val_loss: 0.6565 - val_accuracy: 0.5556\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6453 - accuracy: 0.6400 - val_loss: 0.6567 - val_accuracy: 0.5556\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6450 - accuracy: 0.6480 - val_loss: 0.6563 - val_accuracy: 0.5556\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6447 - accuracy: 0.6480 - val_loss: 0.6563 - val_accuracy: 0.5556\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6443 - accuracy: 0.6480 - val_loss: 0.6563 - val_accuracy: 0.5556\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6440 - accuracy: 0.6480 - val_loss: 0.6563 - val_accuracy: 0.5556\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6435 - accuracy: 0.6480 - val_loss: 0.6562 - val_accuracy: 0.5556\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6434 - accuracy: 0.6560 - val_loss: 0.6561 - val_accuracy: 0.5556\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6431 - accuracy: 0.6560 - val_loss: 0.6556 - val_accuracy: 0.5556\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6430 - accuracy: 0.6560 - val_loss: 0.6558 - val_accuracy: 0.5556\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6428 - accuracy: 0.6320 - val_loss: 0.6559 - val_accuracy: 0.5556\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6425 - accuracy: 0.6240 - val_loss: 0.6562 - val_accuracy: 0.5556\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6423 - accuracy: 0.6560 - val_loss: 0.6567 - val_accuracy: 0.5556\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6416 - accuracy: 0.6560 - val_loss: 0.6566 - val_accuracy: 0.5556\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6414 - accuracy: 0.6480 - val_loss: 0.6572 - val_accuracy: 0.5556\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6412 - accuracy: 0.6560 - val_loss: 0.6570 - val_accuracy: 0.5556\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6409 - accuracy: 0.6480 - val_loss: 0.6570 - val_accuracy: 0.5556\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6418 - accuracy: 0.6560 - val_loss: 0.6581 - val_accuracy: 0.5556\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6406 - accuracy: 0.6320 - val_loss: 0.6575 - val_accuracy: 0.5556\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6404 - accuracy: 0.6320 - val_loss: 0.6570 - val_accuracy: 0.5556\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6397 - accuracy: 0.6320 - val_loss: 0.6558 - val_accuracy: 0.5556\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6394 - accuracy: 0.6400 - val_loss: 0.6561 - val_accuracy: 0.5556\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6397 - accuracy: 0.6480 - val_loss: 0.6555 - val_accuracy: 0.5556\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6392 - accuracy: 0.6480 - val_loss: 0.6562 - val_accuracy: 0.5556\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6387 - accuracy: 0.6400 - val_loss: 0.6565 - val_accuracy: 0.5556\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6383 - accuracy: 0.6400 - val_loss: 0.6568 - val_accuracy: 0.5556\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6382 - accuracy: 0.6320 - val_loss: 0.6559 - val_accuracy: 0.5556\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6379 - accuracy: 0.6400 - val_loss: 0.6555 - val_accuracy: 0.5556\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6379 - accuracy: 0.6400 - val_loss: 0.6561 - val_accuracy: 0.5556\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6374 - accuracy: 0.6480 - val_loss: 0.6558 - val_accuracy: 0.5556\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6371 - accuracy: 0.6400 - val_loss: 0.6555 - val_accuracy: 0.5556\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6369 - accuracy: 0.6400 - val_loss: 0.6546 - val_accuracy: 0.5556\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6363 - accuracy: 0.6400 - val_loss: 0.6554 - val_accuracy: 0.5556\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6365 - accuracy: 0.6400 - val_loss: 0.6552 - val_accuracy: 0.5556\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6356 - accuracy: 0.6640 - val_loss: 0.6551 - val_accuracy: 0.5556\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6356 - accuracy: 0.6560 - val_loss: 0.6553 - val_accuracy: 0.5556\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6356 - accuracy: 0.6560 - val_loss: 0.6556 - val_accuracy: 0.5556\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6349 - accuracy: 0.6560 - val_loss: 0.6557 - val_accuracy: 0.5556\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6357 - accuracy: 0.6560 - val_loss: 0.6545 - val_accuracy: 0.5556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model9.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd_oLO0b7xF-",
        "outputId": "e811d942-7066-46cb-d347-4fc7d6997cab"
      },
      "execution_count": 893,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 4.0638 - accuracy: 0.6522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.0637993812561035, 0.6521739363670349]"
            ]
          },
          "metadata": {},
          "execution_count": 893
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model9 = tf.keras.models.load_model(f\"/content/model_experiments/{model9.name}\")\n",
        "model9.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "PNeldcfCq6b9",
        "outputId": "3f8c7909-e6c4-4c50-c4e6-e631319936ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 894,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 123ms/step - loss: 0.7371 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7370572090148926, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 894
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MLbBeyiit_4Z"
      },
      "execution_count": 894,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pZYMdY3Ht__h"
      },
      "execution_count": 894,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3jGW7vHzcyKG"
      },
      "execution_count": 894,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model10 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model10.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history10 = model10.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model10.name)])"
      ],
      "metadata": {
        "id": "en9K52fle0pU",
        "outputId": "3954f8da-967c-4a36-e59e-2e67ba3f4950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 895,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1/4 [======>.......................] - ETA: 1s - loss: 0.6919 - accuracy: 0.6250INFO:tensorflow:Assets written to: model_experiments/sequential_84/assets\n",
            "4/4 [==============================] - 1s 294ms/step - loss: 0.6921 - accuracy: 0.5760 - val_loss: 0.6914 - val_accuracy: 0.6296\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6916 - accuracy: 0.5840 - val_loss: 0.6910 - val_accuracy: 0.6296\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.6911 - accuracy: 0.5760 - val_loss: 0.6906 - val_accuracy: 0.6296\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6907 - accuracy: 0.5760 - val_loss: 0.6903 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6903 - accuracy: 0.5760 - val_loss: 0.6898 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6899 - accuracy: 0.5760 - val_loss: 0.6893 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6893 - accuracy: 0.5760 - val_loss: 0.6891 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6890 - accuracy: 0.5760 - val_loss: 0.6887 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6885 - accuracy: 0.5760 - val_loss: 0.6884 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6882 - accuracy: 0.5760 - val_loss: 0.6880 - val_accuracy: 0.6296\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6880 - accuracy: 0.5760 - val_loss: 0.6875 - val_accuracy: 0.6296\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6876 - accuracy: 0.5760 - val_loss: 0.6870 - val_accuracy: 0.6296\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6874 - accuracy: 0.5760 - val_loss: 0.6866 - val_accuracy: 0.6296\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6871 - accuracy: 0.5760 - val_loss: 0.6861 - val_accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.5760 - val_loss: 0.6856 - val_accuracy: 0.6296\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5760 - val_loss: 0.6851 - val_accuracy: 0.6296\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6858 - accuracy: 0.5760 - val_loss: 0.6842 - val_accuracy: 0.6296\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6852 - accuracy: 0.5760 - val_loss: 0.6833 - val_accuracy: 0.6296\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5760 - val_loss: 0.6822 - val_accuracy: 0.6296\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5760 - val_loss: 0.6808 - val_accuracy: 0.6296\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5760 - val_loss: 0.6799 - val_accuracy: 0.6296\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5760 - val_loss: 0.6790 - val_accuracy: 0.6296\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6816 - accuracy: 0.5760 - val_loss: 0.6782 - val_accuracy: 0.6296\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5760 - val_loss: 0.6773 - val_accuracy: 0.6296\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.5760 - val_loss: 0.6766 - val_accuracy: 0.6296\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5760 - val_loss: 0.6758 - val_accuracy: 0.6296\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5760 - val_loss: 0.6751 - val_accuracy: 0.6296\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5760 - val_loss: 0.6744 - val_accuracy: 0.6296\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5760 - val_loss: 0.6739 - val_accuracy: 0.6296\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5760 - val_loss: 0.6732 - val_accuracy: 0.6296\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5760 - val_loss: 0.6728 - val_accuracy: 0.6296\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5760 - val_loss: 0.6720 - val_accuracy: 0.6296\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6782 - accuracy: 0.5760 - val_loss: 0.6713 - val_accuracy: 0.6296\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.5760 - val_loss: 0.6708 - val_accuracy: 0.6296\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.5760 - val_loss: 0.6704 - val_accuracy: 0.6296\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6774 - accuracy: 0.5760 - val_loss: 0.6699 - val_accuracy: 0.6296\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6773 - accuracy: 0.5760 - val_loss: 0.6694 - val_accuracy: 0.6296\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5760 - val_loss: 0.6689 - val_accuracy: 0.6296\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6768 - accuracy: 0.5760 - val_loss: 0.6686 - val_accuracy: 0.6296\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6767 - accuracy: 0.5760 - val_loss: 0.6684 - val_accuracy: 0.6296\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6765 - accuracy: 0.5760 - val_loss: 0.6682 - val_accuracy: 0.6296\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6764 - accuracy: 0.5760 - val_loss: 0.6679 - val_accuracy: 0.6296\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6762 - accuracy: 0.5760 - val_loss: 0.6677 - val_accuracy: 0.6296\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6762 - accuracy: 0.5760 - val_loss: 0.6675 - val_accuracy: 0.6296\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6761 - accuracy: 0.5760 - val_loss: 0.6673 - val_accuracy: 0.6296\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6759 - accuracy: 0.5760 - val_loss: 0.6671 - val_accuracy: 0.6296\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6758 - accuracy: 0.5760 - val_loss: 0.6668 - val_accuracy: 0.6296\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6757 - accuracy: 0.5760 - val_loss: 0.6667 - val_accuracy: 0.6296\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6755 - accuracy: 0.5760 - val_loss: 0.6665 - val_accuracy: 0.6296\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6754 - accuracy: 0.5760 - val_loss: 0.6664 - val_accuracy: 0.6296\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6752 - accuracy: 0.5760 - val_loss: 0.6663 - val_accuracy: 0.6296\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6751 - accuracy: 0.5760 - val_loss: 0.6660 - val_accuracy: 0.6296\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6750 - accuracy: 0.5760 - val_loss: 0.6658 - val_accuracy: 0.6296\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6749 - accuracy: 0.5760 - val_loss: 0.6656 - val_accuracy: 0.6296\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6748 - accuracy: 0.5760 - val_loss: 0.6654 - val_accuracy: 0.6296\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6746 - accuracy: 0.5760 - val_loss: 0.6652 - val_accuracy: 0.6296\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6746 - accuracy: 0.5760 - val_loss: 0.6650 - val_accuracy: 0.6296\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6744 - accuracy: 0.5760 - val_loss: 0.6649 - val_accuracy: 0.6296\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6743 - accuracy: 0.5760 - val_loss: 0.6647 - val_accuracy: 0.6296\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6742 - accuracy: 0.5760 - val_loss: 0.6645 - val_accuracy: 0.6296\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6741 - accuracy: 0.5760 - val_loss: 0.6645 - val_accuracy: 0.6296\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6740 - accuracy: 0.5760 - val_loss: 0.6644 - val_accuracy: 0.6296\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6739 - accuracy: 0.5760 - val_loss: 0.6644 - val_accuracy: 0.6296\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6738 - accuracy: 0.5760 - val_loss: 0.6640 - val_accuracy: 0.6296\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6736 - accuracy: 0.5760 - val_loss: 0.6638 - val_accuracy: 0.6296\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6735 - accuracy: 0.5760 - val_loss: 0.6636 - val_accuracy: 0.6296\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6733 - accuracy: 0.5760 - val_loss: 0.6635 - val_accuracy: 0.6296\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6732 - accuracy: 0.5760 - val_loss: 0.6634 - val_accuracy: 0.6296\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6731 - accuracy: 0.5760 - val_loss: 0.6632 - val_accuracy: 0.6296\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6730 - accuracy: 0.5760 - val_loss: 0.6630 - val_accuracy: 0.6296\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6729 - accuracy: 0.5760 - val_loss: 0.6630 - val_accuracy: 0.6296\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6727 - accuracy: 0.5760 - val_loss: 0.6628 - val_accuracy: 0.6296\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6725 - accuracy: 0.5760 - val_loss: 0.6627 - val_accuracy: 0.6296\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6724 - accuracy: 0.5760 - val_loss: 0.6625 - val_accuracy: 0.6296\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6722 - accuracy: 0.5760 - val_loss: 0.6623 - val_accuracy: 0.6296\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6721 - accuracy: 0.5760 - val_loss: 0.6623 - val_accuracy: 0.6296\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6720 - accuracy: 0.5760 - val_loss: 0.6622 - val_accuracy: 0.6296\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6718 - accuracy: 0.5760 - val_loss: 0.6621 - val_accuracy: 0.6296\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6717 - accuracy: 0.5760 - val_loss: 0.6619 - val_accuracy: 0.6296\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6715 - accuracy: 0.5760 - val_loss: 0.6618 - val_accuracy: 0.6296\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6714 - accuracy: 0.5760 - val_loss: 0.6617 - val_accuracy: 0.6296\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6712 - accuracy: 0.5760 - val_loss: 0.6616 - val_accuracy: 0.6296\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6711 - accuracy: 0.5760 - val_loss: 0.6614 - val_accuracy: 0.6296\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6710 - accuracy: 0.5760 - val_loss: 0.6613 - val_accuracy: 0.6296\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6710 - accuracy: 0.5760 - val_loss: 0.6610 - val_accuracy: 0.6296\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6707 - accuracy: 0.5760 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6706 - accuracy: 0.5760 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6705 - accuracy: 0.5760 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6704 - accuracy: 0.5760 - val_loss: 0.6606 - val_accuracy: 0.6296\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6703 - accuracy: 0.5760 - val_loss: 0.6607 - val_accuracy: 0.6296\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6701 - accuracy: 0.5760 - val_loss: 0.6606 - val_accuracy: 0.6296\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6700 - accuracy: 0.5760 - val_loss: 0.6603 - val_accuracy: 0.6296\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6698 - accuracy: 0.5760 - val_loss: 0.6601 - val_accuracy: 0.6296\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6698 - accuracy: 0.5760 - val_loss: 0.6602 - val_accuracy: 0.6296\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6695 - accuracy: 0.5760 - val_loss: 0.6601 - val_accuracy: 0.6296\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6696 - accuracy: 0.5760 - val_loss: 0.6597 - val_accuracy: 0.6296\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6693 - accuracy: 0.5760 - val_loss: 0.6596 - val_accuracy: 0.6296\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6692 - accuracy: 0.5760 - val_loss: 0.6595 - val_accuracy: 0.6296\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6690 - accuracy: 0.5760 - val_loss: 0.6595 - val_accuracy: 0.6296\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6689 - accuracy: 0.5760 - val_loss: 0.6593 - val_accuracy: 0.6296\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6687 - accuracy: 0.5760 - val_loss: 0.6592 - val_accuracy: 0.6296\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6687 - accuracy: 0.5760 - val_loss: 0.6590 - val_accuracy: 0.6296\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6684 - accuracy: 0.5760 - val_loss: 0.6589 - val_accuracy: 0.6296\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6684 - accuracy: 0.5760 - val_loss: 0.6589 - val_accuracy: 0.6296\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6682 - accuracy: 0.5760 - val_loss: 0.6588 - val_accuracy: 0.6296\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6680 - accuracy: 0.5760 - val_loss: 0.6587 - val_accuracy: 0.6296\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6679 - accuracy: 0.5760 - val_loss: 0.6585 - val_accuracy: 0.6296\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6677 - accuracy: 0.5760 - val_loss: 0.6584 - val_accuracy: 0.6296\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6676 - accuracy: 0.5760 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6675 - accuracy: 0.5760 - val_loss: 0.6581 - val_accuracy: 0.6296\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6673 - accuracy: 0.5760 - val_loss: 0.6580 - val_accuracy: 0.6296\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6672 - accuracy: 0.5760 - val_loss: 0.6579 - val_accuracy: 0.6296\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6671 - accuracy: 0.5760 - val_loss: 0.6579 - val_accuracy: 0.6296\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6669 - accuracy: 0.5760 - val_loss: 0.6577 - val_accuracy: 0.6296\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6667 - accuracy: 0.5760 - val_loss: 0.6577 - val_accuracy: 0.6296\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6666 - accuracy: 0.5760 - val_loss: 0.6575 - val_accuracy: 0.6296\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6664 - accuracy: 0.5760 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6662 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6661 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6659 - accuracy: 0.5760 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6659 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6658 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6656 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6654 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6651 - accuracy: 0.5760 - val_loss: 0.6569 - val_accuracy: 0.6296\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6650 - accuracy: 0.5760 - val_loss: 0.6570 - val_accuracy: 0.6296\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6649 - accuracy: 0.5760 - val_loss: 0.6570 - val_accuracy: 0.6296\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6646 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6646 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6642 - accuracy: 0.5760 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6641 - accuracy: 0.5760 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6638 - accuracy: 0.5760 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6636 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6636 - accuracy: 0.5760 - val_loss: 0.6568 - val_accuracy: 0.6296\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6633 - accuracy: 0.5760 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6631 - accuracy: 0.5760 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6629 - accuracy: 0.5760 - val_loss: 0.6565 - val_accuracy: 0.6296\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6627 - accuracy: 0.5760 - val_loss: 0.6564 - val_accuracy: 0.6296\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6626 - accuracy: 0.5760 - val_loss: 0.6563 - val_accuracy: 0.6296\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6624 - accuracy: 0.5760 - val_loss: 0.6564 - val_accuracy: 0.6296\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6622 - accuracy: 0.5760 - val_loss: 0.6562 - val_accuracy: 0.6296\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6620 - accuracy: 0.5760 - val_loss: 0.6561 - val_accuracy: 0.6296\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6619 - accuracy: 0.5760 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6617 - accuracy: 0.5760 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6617 - accuracy: 0.5760 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6613 - accuracy: 0.5760 - val_loss: 0.6558 - val_accuracy: 0.6296\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6612 - accuracy: 0.5760 - val_loss: 0.6557 - val_accuracy: 0.6296\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6611 - accuracy: 0.5760 - val_loss: 0.6557 - val_accuracy: 0.6296\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6608 - accuracy: 0.5760 - val_loss: 0.6555 - val_accuracy: 0.6296\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6608 - accuracy: 0.5760 - val_loss: 0.6553 - val_accuracy: 0.6296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model10.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2fxE1Nm7yn9",
        "outputId": "5ca2e7c6-1c8a-4f27-b159-9a676288f4d0"
      },
      "execution_count": 896,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 5.3177 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.317729949951172, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 896
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model10 = tf.keras.models.load_model(f\"/content/model_experiments/{model10.name}\")\n",
        "model10.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "lpKDkcyxq8F8",
        "outputId": "41fb8375-2abf-41db-b7d0-335ae5452de6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 897,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 129ms/step - loss: 0.5643 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5643192529678345, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 897
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model11 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model11.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history11 = model11.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model11.name)])"
      ],
      "metadata": {
        "id": "d0mJOMoge0ri",
        "outputId": "e6838783-07f2-4abb-e8ad-09da200d36db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 898,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            " 1/25 [>.............................] - ETA: 11s - loss: 0.6927 - accuracy: 0.6000INFO:tensorflow:Assets written to: model_experiments/sequential_85/assets\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.6918 - accuracy: 0.5680 - val_loss: 0.6906 - val_accuracy: 0.6296\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5760 - val_loss: 0.6893 - val_accuracy: 0.6296\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5760 - val_loss: 0.6883 - val_accuracy: 0.6296\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5760 - val_loss: 0.6867 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5760 - val_loss: 0.6849 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5760 - val_loss: 0.6817 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.5760 - val_loss: 0.6799 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5760 - val_loss: 0.6779 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.5760 - val_loss: 0.6767 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.5760 - val_loss: 0.6749 - val_accuracy: 0.6296\n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.5760 - val_loss: 0.6728 - val_accuracy: 0.6296\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.5760 - val_loss: 0.6719 - val_accuracy: 0.6296\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5760 - val_loss: 0.6706 - val_accuracy: 0.6296\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5760 - val_loss: 0.6687 - val_accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5760 - val_loss: 0.6685 - val_accuracy: 0.6296\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.5760 - val_loss: 0.6678 - val_accuracy: 0.6296\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5760 - val_loss: 0.6674 - val_accuracy: 0.6296\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5760 - val_loss: 0.6668 - val_accuracy: 0.6296\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.5760 - val_loss: 0.6663 - val_accuracy: 0.6296\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.5760 - val_loss: 0.6657 - val_accuracy: 0.6296\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.5760 - val_loss: 0.6652 - val_accuracy: 0.6296\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5760 - val_loss: 0.6639 - val_accuracy: 0.6296\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5760 - val_loss: 0.6649 - val_accuracy: 0.6296\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5760 - val_loss: 0.6638 - val_accuracy: 0.6296\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.5760 - val_loss: 0.6633 - val_accuracy: 0.6296\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5760 - val_loss: 0.6628 - val_accuracy: 0.6296\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.5760 - val_loss: 0.6627 - val_accuracy: 0.6296\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.5760 - val_loss: 0.6623 - val_accuracy: 0.6296\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.5760 - val_loss: 0.6625 - val_accuracy: 0.6296\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.5760 - val_loss: 0.6617 - val_accuracy: 0.6296\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.5760 - val_loss: 0.6618 - val_accuracy: 0.6296\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.5760 - val_loss: 0.6602 - val_accuracy: 0.6296\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.5760 - val_loss: 0.6598 - val_accuracy: 0.6296\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.5760 - val_loss: 0.6602 - val_accuracy: 0.6296\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.5760 - val_loss: 0.6603 - val_accuracy: 0.6296\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.5760 - val_loss: 0.6590 - val_accuracy: 0.6296\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.5760 - val_loss: 0.6585 - val_accuracy: 0.6296\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.5760 - val_loss: 0.6586 - val_accuracy: 0.6296\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.5760 - val_loss: 0.6586 - val_accuracy: 0.6296\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.5760 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.5760 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.5760 - val_loss: 0.6570 - val_accuracy: 0.6296\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.5760 - val_loss: 0.6569 - val_accuracy: 0.6296\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.5760 - val_loss: 0.6564 - val_accuracy: 0.6296\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.5760 - val_loss: 0.6556 - val_accuracy: 0.6296\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.5760 - val_loss: 0.6549 - val_accuracy: 0.6296\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.5760 - val_loss: 0.6563 - val_accuracy: 0.6296\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.5760 - val_loss: 0.6553 - val_accuracy: 0.6296\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.5760 - val_loss: 0.6555 - val_accuracy: 0.6296\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.5760 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5760 - val_loss: 0.6540 - val_accuracy: 0.6296\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.5760 - val_loss: 0.6541 - val_accuracy: 0.6296\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.5760 - val_loss: 0.6535 - val_accuracy: 0.6296\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.5760 - val_loss: 0.6526 - val_accuracy: 0.6296\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.5760 - val_loss: 0.6527 - val_accuracy: 0.6296\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.5760 - val_loss: 0.6519 - val_accuracy: 0.6296\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.5760 - val_loss: 0.6520 - val_accuracy: 0.6296\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.5760 - val_loss: 0.6513 - val_accuracy: 0.6296\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.5760 - val_loss: 0.6508 - val_accuracy: 0.6296\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.5760 - val_loss: 0.6513 - val_accuracy: 0.6296\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.5760 - val_loss: 0.6505 - val_accuracy: 0.6296\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.5760 - val_loss: 0.6497 - val_accuracy: 0.6296\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.5760 - val_loss: 0.6484 - val_accuracy: 0.6296\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.5760 - val_loss: 0.6486 - val_accuracy: 0.6296\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.5760 - val_loss: 0.6480 - val_accuracy: 0.6296\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.5760 - val_loss: 0.6473 - val_accuracy: 0.6296\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.5760 - val_loss: 0.6465 - val_accuracy: 0.6296\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.5760 - val_loss: 0.6465 - val_accuracy: 0.6296\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.5760 - val_loss: 0.6451 - val_accuracy: 0.6296\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.5760 - val_loss: 0.6434 - val_accuracy: 0.6296\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.5760 - val_loss: 0.6438 - val_accuracy: 0.6296\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.5760 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.5760 - val_loss: 0.6437 - val_accuracy: 0.6296\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.5760 - val_loss: 0.6427 - val_accuracy: 0.6296\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.5760 - val_loss: 0.6418 - val_accuracy: 0.6296\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.5760 - val_loss: 0.6419 - val_accuracy: 0.6296\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.5760 - val_loss: 0.6428 - val_accuracy: 0.6296\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.5760 - val_loss: 0.6422 - val_accuracy: 0.6296\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.5760 - val_loss: 0.6416 - val_accuracy: 0.6296\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.5760 - val_loss: 0.6402 - val_accuracy: 0.6296\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.5760 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.5760 - val_loss: 0.6408 - val_accuracy: 0.6296\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.5760 - val_loss: 0.6401 - val_accuracy: 0.6296\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.5760 - val_loss: 0.6395 - val_accuracy: 0.6296\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.5760 - val_loss: 0.6387 - val_accuracy: 0.6296\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.5760 - val_loss: 0.6391 - val_accuracy: 0.6296\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.5760 - val_loss: 0.6391 - val_accuracy: 0.6296\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.5760 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.5760 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.5760 - val_loss: 0.6386 - val_accuracy: 0.6296\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.5760 - val_loss: 0.6379 - val_accuracy: 0.6296\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.5760 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.5920 - val_loss: 0.6370 - val_accuracy: 0.5926\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6240 - val_loss: 0.6373 - val_accuracy: 0.5926\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.6080 - val_loss: 0.6371 - val_accuracy: 0.6296\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6240 - val_loss: 0.6357 - val_accuracy: 0.6296\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.6160 - val_loss: 0.6355 - val_accuracy: 0.5926\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6080 - val_loss: 0.6343 - val_accuracy: 0.5556\n",
            "Epoch 100/150\n",
            " 1/25 [>.............................] - ETA: 0s - loss: 0.6419 - accuracy: 0.2000INFO:tensorflow:Assets written to: model_experiments/sequential_85/assets\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 0.6475 - accuracy: 0.6080 - val_loss: 0.6345 - val_accuracy: 0.6667\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6240 - val_loss: 0.6343 - val_accuracy: 0.5926\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6160 - val_loss: 0.6339 - val_accuracy: 0.5926\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6240 - val_loss: 0.6325 - val_accuracy: 0.6667\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6160 - val_loss: 0.6326 - val_accuracy: 0.6296\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6080 - val_loss: 0.6319 - val_accuracy: 0.6667\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6160 - val_loss: 0.6314 - val_accuracy: 0.6667\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6160 - val_loss: 0.6309 - val_accuracy: 0.6296\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6400 - val_loss: 0.6308 - val_accuracy: 0.6667\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6240 - val_loss: 0.6300 - val_accuracy: 0.6296\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6480 - val_loss: 0.6297 - val_accuracy: 0.6296\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6320 - val_loss: 0.6286 - val_accuracy: 0.6667\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6480 - val_loss: 0.6291 - val_accuracy: 0.5926\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6480 - val_loss: 0.6283 - val_accuracy: 0.6667\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6320 - val_loss: 0.6275 - val_accuracy: 0.6667\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6480 - val_loss: 0.6274 - val_accuracy: 0.6667\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6640 - val_loss: 0.6270 - val_accuracy: 0.6667\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6480 - val_loss: 0.6273 - val_accuracy: 0.6296\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6560 - val_loss: 0.6267 - val_accuracy: 0.6667\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6480 - val_loss: 0.6267 - val_accuracy: 0.5926\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6560 - val_loss: 0.6263 - val_accuracy: 0.6296\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6560 - val_loss: 0.6256 - val_accuracy: 0.6667\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6480 - val_loss: 0.6263 - val_accuracy: 0.5556\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6480 - val_loss: 0.6253 - val_accuracy: 0.6667\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6640 - val_loss: 0.6247 - val_accuracy: 0.6667\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6720 - val_loss: 0.6246 - val_accuracy: 0.6667\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6640 - val_loss: 0.6243 - val_accuracy: 0.6667\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6720 - val_loss: 0.6243 - val_accuracy: 0.6667\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6560 - val_loss: 0.6236 - val_accuracy: 0.6667\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6400 - val_loss: 0.6258 - val_accuracy: 0.5926\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6400 - val_loss: 0.6237 - val_accuracy: 0.6667\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6560 - val_loss: 0.6240 - val_accuracy: 0.5926\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6640 - val_loss: 0.6234 - val_accuracy: 0.6296\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6480 - val_loss: 0.6237 - val_accuracy: 0.6296\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6720 - val_loss: 0.6228 - val_accuracy: 0.6296\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6640 - val_loss: 0.6233 - val_accuracy: 0.5926\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6320 - val_loss: 0.6227 - val_accuracy: 0.6296\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6400 - val_loss: 0.6229 - val_accuracy: 0.5926\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6640 - val_loss: 0.6224 - val_accuracy: 0.6296\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6720 - val_loss: 0.6218 - val_accuracy: 0.6296\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6240 - val_loss: 0.6231 - val_accuracy: 0.6296\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6720 - val_loss: 0.6215 - val_accuracy: 0.6296\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6400 - val_loss: 0.6212 - val_accuracy: 0.6296\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6640 - val_loss: 0.6207 - val_accuracy: 0.6296\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6240 - val_loss: 0.6216 - val_accuracy: 0.6296\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.6480 - val_loss: 0.6211 - val_accuracy: 0.6296\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6480 - val_loss: 0.6211 - val_accuracy: 0.6296\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6560 - val_loss: 0.6210 - val_accuracy: 0.6296\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6320 - val_loss: 0.6215 - val_accuracy: 0.6296\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6480 - val_loss: 0.6204 - val_accuracy: 0.6296\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.6720 - val_loss: 0.6196 - val_accuracy: 0.6296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model11.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "talbzlnM7z6g",
        "outputId": "b82d7f19-824a-40c5-b7b5-f964d39af147"
      },
      "execution_count": 899,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 4.6396 - accuracy: 0.6522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.639610767364502, 0.6521739363670349]"
            ]
          },
          "metadata": {},
          "execution_count": 899
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model11 = tf.keras.models.load_model(f\"/content/model_experiments/{model11.name}\")\n",
        "model11.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "0QMLEXq_q-aZ",
        "outputId": "37d32563-68c8-4d61-d397-1570253eff8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 900,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 130ms/step - loss: 5.3990 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.398956298828125, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 900
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model12 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model12.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history12 = model12.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model12.name)])"
      ],
      "metadata": {
        "id": "HOLGhvTfe0t1",
        "outputId": "13066a00-91ac-408e-dac5-8dfa25c8f8a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 901,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            " 1/25 [>.............................] - ETA: 11s - loss: 0.7257 - accuracy: 0.4000INFO:tensorflow:Assets written to: model_experiments/sequential_86/assets\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.6859 - accuracy: 0.5760 - val_loss: 0.6698 - val_accuracy: 0.6296\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.5760 - val_loss: 0.6670 - val_accuracy: 0.6296\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5760 - val_loss: 0.6671 - val_accuracy: 0.6296\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.5760 - val_loss: 0.6648 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.5760 - val_loss: 0.6645 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5760 - val_loss: 0.6628 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5760 - val_loss: 0.6635 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.5760 - val_loss: 0.6624 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.5760 - val_loss: 0.6621 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.5760 - val_loss: 0.6614 - val_accuracy: 0.6296\n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.5760 - val_loss: 0.6601 - val_accuracy: 0.6296\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.5760 - val_loss: 0.6600 - val_accuracy: 0.6296\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.5760 - val_loss: 0.6599 - val_accuracy: 0.6296\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.5760 - val_loss: 0.6581 - val_accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.5760 - val_loss: 0.6586 - val_accuracy: 0.6296\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5760 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.5760 - val_loss: 0.6581 - val_accuracy: 0.6296\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.5760 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.5760 - val_loss: 0.6565 - val_accuracy: 0.6296\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.5760 - val_loss: 0.6561 - val_accuracy: 0.6296\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.5760 - val_loss: 0.6556 - val_accuracy: 0.6296\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.5760 - val_loss: 0.6545 - val_accuracy: 0.6296\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.5680 - val_loss: 0.6553 - val_accuracy: 0.6296\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.5760 - val_loss: 0.6542 - val_accuracy: 0.6296\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.5920 - val_loss: 0.6534 - val_accuracy: 0.6296\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.6000 - val_loss: 0.6536 - val_accuracy: 0.5926\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.5920 - val_loss: 0.6540 - val_accuracy: 0.5926\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.6000 - val_loss: 0.6536 - val_accuracy: 0.5926\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.5920 - val_loss: 0.6544 - val_accuracy: 0.5926\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.6000 - val_loss: 0.6541 - val_accuracy: 0.6296\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.5920 - val_loss: 0.6541 - val_accuracy: 0.6296\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.5840 - val_loss: 0.6522 - val_accuracy: 0.6296\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.5920 - val_loss: 0.6526 - val_accuracy: 0.6296\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6160 - val_loss: 0.6522 - val_accuracy: 0.5926\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6000 - val_loss: 0.6526 - val_accuracy: 0.5926\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.6080 - val_loss: 0.6519 - val_accuracy: 0.6296\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6160 - val_loss: 0.6520 - val_accuracy: 0.6296\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6240 - val_loss: 0.6511 - val_accuracy: 0.5926\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6080 - val_loss: 0.6503 - val_accuracy: 0.5926\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6320 - val_loss: 0.6515 - val_accuracy: 0.5926\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6160 - val_loss: 0.6512 - val_accuracy: 0.5926\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6080 - val_loss: 0.6503 - val_accuracy: 0.6296\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6320 - val_loss: 0.6508 - val_accuracy: 0.5926\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6160 - val_loss: 0.6506 - val_accuracy: 0.5926\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6400 - val_loss: 0.6505 - val_accuracy: 0.5926\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.6400 - val_loss: 0.6507 - val_accuracy: 0.5926\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6240 - val_loss: 0.6498 - val_accuracy: 0.5926\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6080 - val_loss: 0.6499 - val_accuracy: 0.5926\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6240 - val_loss: 0.6481 - val_accuracy: 0.5926\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.6320 - val_loss: 0.6493 - val_accuracy: 0.5926\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6240 - val_loss: 0.6482 - val_accuracy: 0.5926\n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.5926\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6320 - val_loss: 0.6481 - val_accuracy: 0.5185\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.5926\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6480 - val_loss: 0.6469 - val_accuracy: 0.5926\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6320 - val_loss: 0.6481 - val_accuracy: 0.5556\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6400 - val_loss: 0.6470 - val_accuracy: 0.5556\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6240 - val_loss: 0.6482 - val_accuracy: 0.5556\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6320 - val_loss: 0.6471 - val_accuracy: 0.5556\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6240 - val_loss: 0.6460 - val_accuracy: 0.5926\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6240 - val_loss: 0.6476 - val_accuracy: 0.5556\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6160 - val_loss: 0.6476 - val_accuracy: 0.5185\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6160 - val_loss: 0.6469 - val_accuracy: 0.5556\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.6400 - val_loss: 0.6444 - val_accuracy: 0.5926\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6640 - val_loss: 0.6466 - val_accuracy: 0.5556\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6560 - val_loss: 0.6465 - val_accuracy: 0.5556\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6240 - val_loss: 0.6447 - val_accuracy: 0.5556\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.6000 - val_loss: 0.6447 - val_accuracy: 0.5926\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6160 - val_loss: 0.6442 - val_accuracy: 0.5556\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6320 - val_loss: 0.6450 - val_accuracy: 0.5926\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.6240 - val_loss: 0.6439 - val_accuracy: 0.5185\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6160 - val_loss: 0.6428 - val_accuracy: 0.5926\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6160 - val_loss: 0.6428 - val_accuracy: 0.5926\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.6320 - val_loss: 0.6433 - val_accuracy: 0.5926\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6000 - val_loss: 0.6435 - val_accuracy: 0.5556\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6240 - val_loss: 0.6422 - val_accuracy: 0.5926\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6240 - val_loss: 0.6429 - val_accuracy: 0.5926\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6240 - val_loss: 0.6407 - val_accuracy: 0.5926\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6320 - val_loss: 0.6414 - val_accuracy: 0.5926\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6320 - val_loss: 0.6393 - val_accuracy: 0.5926\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6240 - val_loss: 0.6417 - val_accuracy: 0.5556\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6240 - val_loss: 0.6400 - val_accuracy: 0.5926\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6240 - val_loss: 0.6365 - val_accuracy: 0.5926\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6240 - val_loss: 0.6379 - val_accuracy: 0.5926\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6320 - val_loss: 0.6372 - val_accuracy: 0.5926\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6320 - val_loss: 0.6384 - val_accuracy: 0.5926\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6240 - val_loss: 0.6378 - val_accuracy: 0.5926\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6160 - val_loss: 0.6375 - val_accuracy: 0.5926\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6320 - val_loss: 0.6357 - val_accuracy: 0.5926\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6320 - val_loss: 0.6373 - val_accuracy: 0.5926\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6240 - val_loss: 0.6333 - val_accuracy: 0.5926\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6480 - val_loss: 0.6345 - val_accuracy: 0.5926\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6560 - val_loss: 0.6336 - val_accuracy: 0.5926\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6480 - val_loss: 0.6364 - val_accuracy: 0.5926\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6400 - val_loss: 0.6302 - val_accuracy: 0.6296\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6240 - val_loss: 0.6341 - val_accuracy: 0.5926\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.6480 - val_loss: 0.6340 - val_accuracy: 0.5926\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6480 - val_loss: 0.6323 - val_accuracy: 0.5926\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6400 - val_loss: 0.6357 - val_accuracy: 0.5556\n",
            "Epoch 100/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6560 - val_loss: 0.6324 - val_accuracy: 0.5926\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6560 - val_loss: 0.6321 - val_accuracy: 0.5926\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.6320 - val_loss: 0.6316 - val_accuracy: 0.5926\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6480 - val_loss: 0.6316 - val_accuracy: 0.5926\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6480 - val_loss: 0.6340 - val_accuracy: 0.5926\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.6640 - val_loss: 0.6303 - val_accuracy: 0.6296\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.6640 - val_loss: 0.6304 - val_accuracy: 0.6296\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.6400 - val_loss: 0.6316 - val_accuracy: 0.5926\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6560 - val_loss: 0.6301 - val_accuracy: 0.6296\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6720 - val_loss: 0.6308 - val_accuracy: 0.5926\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.6480 - val_loss: 0.6315 - val_accuracy: 0.5926\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6400 - val_loss: 0.6320 - val_accuracy: 0.5926\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6560 - val_loss: 0.6327 - val_accuracy: 0.5926\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6640 - val_loss: 0.6295 - val_accuracy: 0.6296\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6640 - val_loss: 0.6281 - val_accuracy: 0.6296\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6480 - val_loss: 0.6300 - val_accuracy: 0.6296\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6560 - val_loss: 0.6292 - val_accuracy: 0.6296\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6560 - val_loss: 0.6317 - val_accuracy: 0.6296\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6640 - val_loss: 0.6311 - val_accuracy: 0.6296\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6480 - val_loss: 0.6337 - val_accuracy: 0.6296\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.6640 - val_loss: 0.6340 - val_accuracy: 0.6296\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.6400 - val_loss: 0.6308 - val_accuracy: 0.6296\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.6640 - val_loss: 0.6303 - val_accuracy: 0.6296\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.6560 - val_loss: 0.6325 - val_accuracy: 0.6296\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6240 - val_loss: 0.6351 - val_accuracy: 0.5926\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6640 - val_loss: 0.6307 - val_accuracy: 0.6296\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6640 - val_loss: 0.6339 - val_accuracy: 0.5926\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6640 - val_loss: 0.6331 - val_accuracy: 0.5926\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6640 - val_loss: 0.6301 - val_accuracy: 0.6296\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6640 - val_loss: 0.6343 - val_accuracy: 0.6296\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6560 - val_loss: 0.6310 - val_accuracy: 0.6296\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6560 - val_loss: 0.6400 - val_accuracy: 0.5926\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6560 - val_loss: 0.6309 - val_accuracy: 0.6296\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6640 - val_loss: 0.6355 - val_accuracy: 0.6296\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6640 - val_loss: 0.6353 - val_accuracy: 0.5926\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6640 - val_loss: 0.6369 - val_accuracy: 0.5926\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6560 - val_loss: 0.6323 - val_accuracy: 0.6296\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.6640 - val_loss: 0.6352 - val_accuracy: 0.6296\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6720 - val_loss: 0.6344 - val_accuracy: 0.6296\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.6800 - val_loss: 0.6374 - val_accuracy: 0.5926\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6720 - val_loss: 0.6392 - val_accuracy: 0.5926\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6720 - val_loss: 0.6340 - val_accuracy: 0.6296\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.6640 - val_loss: 0.6349 - val_accuracy: 0.6296\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6186 - accuracy: 0.6800 - val_loss: 0.6350 - val_accuracy: 0.6296\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6960 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.6800 - val_loss: 0.6375 - val_accuracy: 0.5926\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6880 - val_loss: 0.6385 - val_accuracy: 0.6296\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6880 - val_loss: 0.6378 - val_accuracy: 0.6296\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6720 - val_loss: 0.6423 - val_accuracy: 0.5926\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6800 - val_loss: 0.6351 - val_accuracy: 0.6296\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6880 - val_loss: 0.6392 - val_accuracy: 0.6296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model12.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-hHajVs71Ly",
        "outputId": "5218b596-9235-49c2-8600-e697a2bbe0bc"
      },
      "execution_count": 902,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 8.1560 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.156012535095215, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 902
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model12 = tf.keras.models.load_model(f\"/content/model_experiments/{model12.name}\")\n",
        "model12.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "iB5xbBGeq_Tn",
        "outputId": "e3574b79-9cc1-4b2f-adce-bd2e739e5134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 903,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 127ms/step - loss: 4.1998 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.1997599601745605, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 903
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model13 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model13.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history13 = model13.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model13.name)])"
      ],
      "metadata": {
        "id": "etsSl4HktL8C",
        "outputId": "20143aab-391d-4ecf-f5ad-ba4d6dfe563b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 904,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            " 1/25 [>.............................] - ETA: 11s - loss: 0.6895 - accuracy: 0.6000INFO:tensorflow:Assets written to: model_experiments/sequential_87/assets\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.6937 - accuracy: 0.4800 - val_loss: 0.6891 - val_accuracy: 0.6667\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5600 - val_loss: 0.6837 - val_accuracy: 0.6296\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5760 - val_loss: 0.6809 - val_accuracy: 0.6296\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.5760 - val_loss: 0.6760 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5760 - val_loss: 0.6733 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.5760 - val_loss: 0.6695 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6798 - accuracy: 0.5760 - val_loss: 0.6685 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.5760 - val_loss: 0.6662 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.5760 - val_loss: 0.6648 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.5760 - val_loss: 0.6632 - val_accuracy: 0.6296\n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.5760 - val_loss: 0.6612 - val_accuracy: 0.6296\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.5760 - val_loss: 0.6613 - val_accuracy: 0.6296\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5760 - val_loss: 0.6609 - val_accuracy: 0.6296\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.5760 - val_loss: 0.6590 - val_accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.5760 - val_loss: 0.6593 - val_accuracy: 0.6296\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.5760 - val_loss: 0.6582 - val_accuracy: 0.6296\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.5760 - val_loss: 0.6580 - val_accuracy: 0.6296\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.5760 - val_loss: 0.6569 - val_accuracy: 0.6296\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.5760 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.5760 - val_loss: 0.6563 - val_accuracy: 0.6296\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.5760 - val_loss: 0.6560 - val_accuracy: 0.6296\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.5760 - val_loss: 0.6542 - val_accuracy: 0.6296\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5760 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.5680 - val_loss: 0.6555 - val_accuracy: 0.6667\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.5680 - val_loss: 0.6552 - val_accuracy: 0.6667\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.5680 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6000 - val_loss: 0.6559 - val_accuracy: 0.6667\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.6080 - val_loss: 0.6556 - val_accuracy: 0.6667\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.6160 - val_loss: 0.6555 - val_accuracy: 0.6667\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6000 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.6080 - val_loss: 0.6553 - val_accuracy: 0.6296\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.6240 - val_loss: 0.6528 - val_accuracy: 0.6667\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.6000 - val_loss: 0.6531 - val_accuracy: 0.6667\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6160 - val_loss: 0.6558 - val_accuracy: 0.5926\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.6160 - val_loss: 0.6564 - val_accuracy: 0.5926\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6240 - val_loss: 0.6540 - val_accuracy: 0.6296\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6000 - val_loss: 0.6546 - val_accuracy: 0.6296\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6160 - val_loss: 0.6577 - val_accuracy: 0.5926\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.6320 - val_loss: 0.6567 - val_accuracy: 0.5926\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6320 - val_loss: 0.6557 - val_accuracy: 0.5926\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6320 - val_loss: 0.6562 - val_accuracy: 0.5926\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6400 - val_loss: 0.6530 - val_accuracy: 0.5926\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.6320 - val_loss: 0.6555 - val_accuracy: 0.5926\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6400 - val_loss: 0.6551 - val_accuracy: 0.5926\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.6320 - val_loss: 0.6546 - val_accuracy: 0.5926\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6160 - val_loss: 0.6535 - val_accuracy: 0.5926\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.6480 - val_loss: 0.6537 - val_accuracy: 0.5926\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6240 - val_loss: 0.6559 - val_accuracy: 0.5556\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6480 - val_loss: 0.6495 - val_accuracy: 0.5926\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6320 - val_loss: 0.6516 - val_accuracy: 0.5926\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6320 - val_loss: 0.6498 - val_accuracy: 0.5926\n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6400 - val_loss: 0.6493 - val_accuracy: 0.5926\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.6400 - val_loss: 0.6534 - val_accuracy: 0.5185\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6240 - val_loss: 0.6511 - val_accuracy: 0.5926\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.6480 - val_loss: 0.6482 - val_accuracy: 0.5926\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6320 - val_loss: 0.6517 - val_accuracy: 0.5185\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6320 - val_loss: 0.6494 - val_accuracy: 0.5926\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.6240 - val_loss: 0.6500 - val_accuracy: 0.5556\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6240 - val_loss: 0.6503 - val_accuracy: 0.5185\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6080 - val_loss: 0.6478 - val_accuracy: 0.5926\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.6080 - val_loss: 0.6504 - val_accuracy: 0.5556\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.6080 - val_loss: 0.6487 - val_accuracy: 0.5556\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6160 - val_loss: 0.6491 - val_accuracy: 0.5556\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.6080 - val_loss: 0.6421 - val_accuracy: 0.6296\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6320 - val_loss: 0.6473 - val_accuracy: 0.5926\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6320 - val_loss: 0.6491 - val_accuracy: 0.5556\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6320 - val_loss: 0.6469 - val_accuracy: 0.5556\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6160 - val_loss: 0.6460 - val_accuracy: 0.5556\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6160 - val_loss: 0.6442 - val_accuracy: 0.6296\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6320 - val_loss: 0.6460 - val_accuracy: 0.5556\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6240 - val_loss: 0.6485 - val_accuracy: 0.4815\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6240 - val_loss: 0.6430 - val_accuracy: 0.5556\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6320 - val_loss: 0.6426 - val_accuracy: 0.5556\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6320 - val_loss: 0.6399 - val_accuracy: 0.6296\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6240 - val_loss: 0.6476 - val_accuracy: 0.4815\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6320 - val_loss: 0.6463 - val_accuracy: 0.4815\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6160 - val_loss: 0.6443 - val_accuracy: 0.5185\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6240 - val_loss: 0.6406 - val_accuracy: 0.5926\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6400 - val_loss: 0.6448 - val_accuracy: 0.5185\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6080 - val_loss: 0.6390 - val_accuracy: 0.5926\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6400 - val_loss: 0.6447 - val_accuracy: 0.5185\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6160 - val_loss: 0.6435 - val_accuracy: 0.5185\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.6080 - val_loss: 0.6371 - val_accuracy: 0.6667\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6240 - val_loss: 0.6414 - val_accuracy: 0.5556\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6400 - val_loss: 0.6395 - val_accuracy: 0.5556\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.6240 - val_loss: 0.6429 - val_accuracy: 0.5185\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6160 - val_loss: 0.6416 - val_accuracy: 0.5556\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6240 - val_loss: 0.6423 - val_accuracy: 0.5185\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6400 - val_loss: 0.6392 - val_accuracy: 0.5556\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6320 - val_loss: 0.6419 - val_accuracy: 0.5185\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6240 - val_loss: 0.6380 - val_accuracy: 0.5556\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.6320 - val_loss: 0.6385 - val_accuracy: 0.5556\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.6320 - val_loss: 0.6395 - val_accuracy: 0.5556\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6240 - val_loss: 0.6443 - val_accuracy: 0.5185\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6240 - val_loss: 0.6359 - val_accuracy: 0.5926\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6400 - val_loss: 0.6363 - val_accuracy: 0.6296\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6240 - val_loss: 0.6379 - val_accuracy: 0.5556\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6240 - val_loss: 0.6399 - val_accuracy: 0.5185\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6560 - val_loss: 0.6432 - val_accuracy: 0.5185\n",
            "Epoch 100/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6400 - val_loss: 0.6358 - val_accuracy: 0.5926\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6560 - val_loss: 0.6383 - val_accuracy: 0.5185\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.6320 - val_loss: 0.6367 - val_accuracy: 0.5556\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6480 - val_loss: 0.6383 - val_accuracy: 0.5185\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6480 - val_loss: 0.6435 - val_accuracy: 0.5185\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6400 - val_loss: 0.6346 - val_accuracy: 0.5926\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6480 - val_loss: 0.6339 - val_accuracy: 0.5926\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.6400 - val_loss: 0.6365 - val_accuracy: 0.5556\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6480 - val_loss: 0.6364 - val_accuracy: 0.5556\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6640 - val_loss: 0.6378 - val_accuracy: 0.5185\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6560 - val_loss: 0.6402 - val_accuracy: 0.5185\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6400 - val_loss: 0.6369 - val_accuracy: 0.5185\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6560 - val_loss: 0.6413 - val_accuracy: 0.5185\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6480 - val_loss: 0.6385 - val_accuracy: 0.5185\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6480 - val_loss: 0.6308 - val_accuracy: 0.6296\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6560 - val_loss: 0.6360 - val_accuracy: 0.5926\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.6400 - val_loss: 0.6340 - val_accuracy: 0.6296\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6240 - val_loss: 0.6373 - val_accuracy: 0.5185\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6560 - val_loss: 0.6346 - val_accuracy: 0.5926\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6480 - val_loss: 0.6394 - val_accuracy: 0.4815\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.6560 - val_loss: 0.6371 - val_accuracy: 0.4815\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.6400 - val_loss: 0.6389 - val_accuracy: 0.4815\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.6400 - val_loss: 0.6377 - val_accuracy: 0.5185\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6560 - val_loss: 0.6304 - val_accuracy: 0.6296\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6480 - val_loss: 0.6384 - val_accuracy: 0.4815\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6480 - val_loss: 0.6311 - val_accuracy: 0.6296\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6560 - val_loss: 0.6373 - val_accuracy: 0.4815\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.6480 - val_loss: 0.6393 - val_accuracy: 0.4815\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.6560 - val_loss: 0.6347 - val_accuracy: 0.5926\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.6640 - val_loss: 0.6374 - val_accuracy: 0.4815\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.6480 - val_loss: 0.6298 - val_accuracy: 0.6296\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.6720 - val_loss: 0.6409 - val_accuracy: 0.4815\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.6720 - val_loss: 0.6321 - val_accuracy: 0.6296\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.6800 - val_loss: 0.6350 - val_accuracy: 0.5185\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6640 - val_loss: 0.6376 - val_accuracy: 0.4815\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6640 - val_loss: 0.6376 - val_accuracy: 0.4815\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6480 - val_loss: 0.6337 - val_accuracy: 0.5185\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.6800 - val_loss: 0.6364 - val_accuracy: 0.5185\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6560 - val_loss: 0.6348 - val_accuracy: 0.5185\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6800 - val_loss: 0.6391 - val_accuracy: 0.4815\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.6480 - val_loss: 0.6430 - val_accuracy: 0.4815\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6720 - val_loss: 0.6291 - val_accuracy: 0.6296\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6400 - val_loss: 0.6364 - val_accuracy: 0.5556\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6880 - val_loss: 0.6323 - val_accuracy: 0.5926\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6640 - val_loss: 0.6326 - val_accuracy: 0.5926\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6640 - val_loss: 0.6388 - val_accuracy: 0.4815\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6720 - val_loss: 0.6366 - val_accuracy: 0.4815\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6880 - val_loss: 0.6339 - val_accuracy: 0.5556\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6560 - val_loss: 0.6431 - val_accuracy: 0.4815\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6640 - val_loss: 0.6290 - val_accuracy: 0.5926\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.6720 - val_loss: 0.6331 - val_accuracy: 0.5556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model13.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTAuxujt72VG",
        "outputId": "e462cea5-4cb6-442e-bc73-d6dd6271b9ba"
      },
      "execution_count": 905,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 4.5775 - accuracy: 0.6522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.577537536621094, 0.6521739363670349]"
            ]
          },
          "metadata": {},
          "execution_count": 905
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model13 = tf.keras.models.load_model(f\"/content/model_experiments/{model13.name}\")\n",
        "model13.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "FFd7l6LPrAGn",
        "outputId": "c3971884-8ec9-423d-ce38-2fc898bdc3df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 906,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 135ms/step - loss: 0.6496 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.649634838104248, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 906
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model14 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model14.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history14 = model14.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model14.name)])"
      ],
      "metadata": {
        "id": "T3c16NIOtOyF",
        "outputId": "3316c3d2-d0d2-4731-b745-5c18e4e6bd5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 907,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            " 1/25 [>.............................] - ETA: 42s - loss: 0.7017 - accuracy: 0.2000INFO:tensorflow:Assets written to: model_experiments/sequential_88/assets\n",
            "25/25 [==============================] - 3s 49ms/step - loss: 0.6929 - accuracy: 0.5440 - val_loss: 0.6860 - val_accuracy: 0.6296\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5760 - val_loss: 0.6791 - val_accuracy: 0.6296\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.5760 - val_loss: 0.6764 - val_accuracy: 0.6296\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6805 - accuracy: 0.5760 - val_loss: 0.6701 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6785 - accuracy: 0.5760 - val_loss: 0.6690 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.5760 - val_loss: 0.6672 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.5760 - val_loss: 0.6685 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.5760 - val_loss: 0.6668 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.5760 - val_loss: 0.6672 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.5760 - val_loss: 0.6667 - val_accuracy: 0.6296\n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.5760 - val_loss: 0.6653 - val_accuracy: 0.6296\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.5520 - val_loss: 0.6662 - val_accuracy: 0.6296\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.5520 - val_loss: 0.6670 - val_accuracy: 0.5926\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.6240 - val_loss: 0.6650 - val_accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.5840 - val_loss: 0.6674 - val_accuracy: 0.5926\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.6000 - val_loss: 0.6677 - val_accuracy: 0.5926\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.6080 - val_loss: 0.6692 - val_accuracy: 0.5926\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.6160 - val_loss: 0.6691 - val_accuracy: 0.5926\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.6240 - val_loss: 0.6707 - val_accuracy: 0.5556\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.6240 - val_loss: 0.6706 - val_accuracy: 0.5926\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.6000 - val_loss: 0.6722 - val_accuracy: 0.5185\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6662 - accuracy: 0.6000 - val_loss: 0.6688 - val_accuracy: 0.5926\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.5920 - val_loss: 0.6746 - val_accuracy: 0.4815\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6240 - val_loss: 0.6708 - val_accuracy: 0.5926\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6400 - val_loss: 0.6731 - val_accuracy: 0.5185\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.6400 - val_loss: 0.6739 - val_accuracy: 0.5185\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.6240 - val_loss: 0.6769 - val_accuracy: 0.5185\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.6240 - val_loss: 0.6768 - val_accuracy: 0.5185\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6240 - val_loss: 0.6767 - val_accuracy: 0.5185\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6320 - val_loss: 0.6771 - val_accuracy: 0.5185\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.6240 - val_loss: 0.6766 - val_accuracy: 0.5185\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6320 - val_loss: 0.6778 - val_accuracy: 0.5185\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6320 - val_loss: 0.6762 - val_accuracy: 0.5185\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6480 - val_loss: 0.6775 - val_accuracy: 0.5185\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.6320 - val_loss: 0.6796 - val_accuracy: 0.5185\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6320 - val_loss: 0.6783 - val_accuracy: 0.5185\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6400 - val_loss: 0.6797 - val_accuracy: 0.5185\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6240 - val_loss: 0.6821 - val_accuracy: 0.4815\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6320 - val_loss: 0.6789 - val_accuracy: 0.5185\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.6480 - val_loss: 0.6820 - val_accuracy: 0.5185\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6240 - val_loss: 0.6824 - val_accuracy: 0.5185\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6240 - val_loss: 0.6796 - val_accuracy: 0.5185\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6560 - val_loss: 0.6836 - val_accuracy: 0.4815\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6240 - val_loss: 0.6839 - val_accuracy: 0.5185\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6320 - val_loss: 0.6844 - val_accuracy: 0.5185\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6480 - val_loss: 0.6838 - val_accuracy: 0.5185\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6480 - val_loss: 0.6837 - val_accuracy: 0.5185\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.6160 - val_loss: 0.6864 - val_accuracy: 0.4815\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6560 - val_loss: 0.6783 - val_accuracy: 0.5556\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6320 - val_loss: 0.6834 - val_accuracy: 0.5185\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6400 - val_loss: 0.6824 - val_accuracy: 0.5185\n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6480 - val_loss: 0.6837 - val_accuracy: 0.5185\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6320 - val_loss: 0.6851 - val_accuracy: 0.4815\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6480 - val_loss: 0.6834 - val_accuracy: 0.5556\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6480 - val_loss: 0.6843 - val_accuracy: 0.5185\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6400 - val_loss: 0.6883 - val_accuracy: 0.5185\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6400 - val_loss: 0.6867 - val_accuracy: 0.5185\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6480 - val_loss: 0.6853 - val_accuracy: 0.5185\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6560 - val_loss: 0.6892 - val_accuracy: 0.5185\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.6720 - val_loss: 0.6863 - val_accuracy: 0.5185\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6320 - val_loss: 0.6907 - val_accuracy: 0.5185\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6320 - val_loss: 0.6894 - val_accuracy: 0.5185\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.6560 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6480 - val_loss: 0.6877 - val_accuracy: 0.5185\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6560 - val_loss: 0.6879 - val_accuracy: 0.5185\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6560 - val_loss: 0.6893 - val_accuracy: 0.4815\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6480 - val_loss: 0.6892 - val_accuracy: 0.5185\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6480 - val_loss: 0.6885 - val_accuracy: 0.5185\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6560 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6560 - val_loss: 0.6883 - val_accuracy: 0.5185\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6560 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6320 - val_loss: 0.6906 - val_accuracy: 0.5185\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.6640 - val_loss: 0.6912 - val_accuracy: 0.5185\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6640 - val_loss: 0.6905 - val_accuracy: 0.5185\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6480 - val_loss: 0.6945 - val_accuracy: 0.4815\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6720 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6640 - val_loss: 0.6917 - val_accuracy: 0.4815\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6800 - val_loss: 0.6895 - val_accuracy: 0.5185\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6800 - val_loss: 0.6941 - val_accuracy: 0.5185\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6426 - accuracy: 0.6640 - val_loss: 0.6926 - val_accuracy: 0.5185\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.6560 - val_loss: 0.6935 - val_accuracy: 0.5185\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6720 - val_loss: 0.6961 - val_accuracy: 0.5185\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6720 - val_loss: 0.6945 - val_accuracy: 0.5185\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6320 - val_loss: 0.6930 - val_accuracy: 0.5185\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6400 - val_loss: 0.6939 - val_accuracy: 0.5185\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6640 - val_loss: 0.6946 - val_accuracy: 0.5185\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6720 - val_loss: 0.6955 - val_accuracy: 0.5185\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6720 - val_loss: 0.6982 - val_accuracy: 0.4815\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6800 - val_loss: 0.6944 - val_accuracy: 0.5185\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.6560 - val_loss: 0.6982 - val_accuracy: 0.5185\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6880 - val_loss: 0.6964 - val_accuracy: 0.5185\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6800 - val_loss: 0.6966 - val_accuracy: 0.5185\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6720 - val_loss: 0.6950 - val_accuracy: 0.5185\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6720 - val_loss: 0.6994 - val_accuracy: 0.5185\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6800 - val_loss: 0.6957 - val_accuracy: 0.5185\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6800 - val_loss: 0.6990 - val_accuracy: 0.4815\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.6560 - val_loss: 0.6966 - val_accuracy: 0.5185\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.6800 - val_loss: 0.7012 - val_accuracy: 0.5185\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6560 - val_loss: 0.6997 - val_accuracy: 0.4815\n",
            "Epoch 100/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6320 - val_loss: 0.6988 - val_accuracy: 0.5185\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6800 - val_loss: 0.7005 - val_accuracy: 0.4815\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.6560 - val_loss: 0.6984 - val_accuracy: 0.5185\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6800 - val_loss: 0.6988 - val_accuracy: 0.4815\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6560 - val_loss: 0.7031 - val_accuracy: 0.4815\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.6800 - val_loss: 0.7004 - val_accuracy: 0.5185\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6880 - val_loss: 0.7006 - val_accuracy: 0.4815\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6640 - val_loss: 0.7006 - val_accuracy: 0.5185\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.6640 - val_loss: 0.7052 - val_accuracy: 0.4815\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6880 - val_loss: 0.7027 - val_accuracy: 0.4815\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6720 - val_loss: 0.7015 - val_accuracy: 0.4815\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6720 - val_loss: 0.7083 - val_accuracy: 0.4815\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6800 - val_loss: 0.7048 - val_accuracy: 0.4815\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6560 - val_loss: 0.7028 - val_accuracy: 0.4815\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6720 - val_loss: 0.7004 - val_accuracy: 0.5185\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6800 - val_loss: 0.7049 - val_accuracy: 0.4815\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6800 - val_loss: 0.7019 - val_accuracy: 0.4815\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.6720 - val_loss: 0.7053 - val_accuracy: 0.4815\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6640 - val_loss: 0.7080 - val_accuracy: 0.4815\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.7057 - val_accuracy: 0.5185\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6720 - val_loss: 0.7060 - val_accuracy: 0.5185\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6560 - val_loss: 0.7069 - val_accuracy: 0.4815\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6480 - val_loss: 0.7068 - val_accuracy: 0.5185\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6640 - val_loss: 0.7037 - val_accuracy: 0.4815\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6320 - val_loss: 0.7079 - val_accuracy: 0.5185\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6400 - val_loss: 0.7034 - val_accuracy: 0.4815\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.6720 - val_loss: 0.7136 - val_accuracy: 0.5185\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.6640 - val_loss: 0.7029 - val_accuracy: 0.5185\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6560 - val_loss: 0.7031 - val_accuracy: 0.5185\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6560 - val_loss: 0.7026 - val_accuracy: 0.5185\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6640 - val_loss: 0.7051 - val_accuracy: 0.4815\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.6640 - val_loss: 0.7046 - val_accuracy: 0.4815\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6720 - val_loss: 0.6983 - val_accuracy: 0.5185\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.6720 - val_loss: 0.7014 - val_accuracy: 0.5185\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6480 - val_loss: 0.7014 - val_accuracy: 0.5185\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6560 - val_loss: 0.7010 - val_accuracy: 0.5185\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6640 - val_loss: 0.7069 - val_accuracy: 0.5185\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.6720 - val_loss: 0.7029 - val_accuracy: 0.5185\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.6640 - val_loss: 0.7039 - val_accuracy: 0.5185\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6560 - val_loss: 0.7070 - val_accuracy: 0.5185\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6560 - val_loss: 0.7069 - val_accuracy: 0.4815\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6051 - accuracy: 0.6560 - val_loss: 0.7079 - val_accuracy: 0.5185\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6480 - val_loss: 0.7033 - val_accuracy: 0.5185\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.6720 - val_loss: 0.7077 - val_accuracy: 0.5185\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.6560 - val_loss: 0.7005 - val_accuracy: 0.5185\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6800 - val_loss: 0.7012 - val_accuracy: 0.5185\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6560 - val_loss: 0.7045 - val_accuracy: 0.5185\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.6720 - val_loss: 0.7057 - val_accuracy: 0.5185\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.6720 - val_loss: 0.7093 - val_accuracy: 0.5185\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.6640 - val_loss: 0.7101 - val_accuracy: 0.5185\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.6800 - val_loss: 0.7112 - val_accuracy: 0.5185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model14.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHC9jAs273i8",
        "outputId": "75107582-c781-45a7-afa1-2b6a59128cbd"
      },
      "execution_count": 908,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 19.8075 - accuracy: 0.3913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19.807527542114258, 0.3913043439388275]"
            ]
          },
          "metadata": {},
          "execution_count": 908
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model14 = tf.keras.models.load_model(f\"/content/model_experiments/{model14.name}\")\n",
        "model14.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "ey6oyFQIrA1B",
        "outputId": "d48a45be-49ed-4acd-a9f2-2eb29fcf04ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 909,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 156ms/step - loss: 0.9099 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9099339842796326, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 909
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model15 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model15.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history15 = model15.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=150,\n",
        "                    batch_size=5,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[create_model_checkpoint(model_name=model15.name)])"
      ],
      "metadata": {
        "id": "ytfYzYMftS79",
        "outputId": "c40bae2c-a3aa-41e2-9490-ef101c594e7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 910,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "19/25 [=====================>........] - ETA: 0s - loss: 0.6920 - accuracy: 0.5474 INFO:tensorflow:Assets written to: model_experiments/sequential_89/assets\n",
            "25/25 [==============================] - 2s 58ms/step - loss: 0.6916 - accuracy: 0.5600 - val_loss: 0.6810 - val_accuracy: 0.6296\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5760 - val_loss: 0.6664 - val_accuracy: 0.6296\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.5760 - val_loss: 0.6677 - val_accuracy: 0.6296\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.5760 - val_loss: 0.6607 - val_accuracy: 0.6296\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.5760 - val_loss: 0.6612 - val_accuracy: 0.6296\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5760 - val_loss: 0.6603 - val_accuracy: 0.6296\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.5760 - val_loss: 0.6632 - val_accuracy: 0.6296\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.5760 - val_loss: 0.6605 - val_accuracy: 0.6296\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.5760 - val_loss: 0.6594 - val_accuracy: 0.6296\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.5760 - val_loss: 0.6581 - val_accuracy: 0.6296\n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.5760 - val_loss: 0.6563 - val_accuracy: 0.6296\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.5760 - val_loss: 0.6605 - val_accuracy: 0.6296\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.5600 - val_loss: 0.6616 - val_accuracy: 0.5926\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.6240 - val_loss: 0.6632 - val_accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.5520 - val_loss: 0.6651 - val_accuracy: 0.5185\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.6160 - val_loss: 0.6627 - val_accuracy: 0.5926\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.6000 - val_loss: 0.6658 - val_accuracy: 0.5185\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.6080 - val_loss: 0.6666 - val_accuracy: 0.5926\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6607 - accuracy: 0.6160 - val_loss: 0.6702 - val_accuracy: 0.5185\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.6160 - val_loss: 0.6718 - val_accuracy: 0.5185\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6400 - val_loss: 0.6736 - val_accuracy: 0.5185\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.6080 - val_loss: 0.6756 - val_accuracy: 0.5185\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.6320 - val_loss: 0.6749 - val_accuracy: 0.5185\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6080 - val_loss: 0.6742 - val_accuracy: 0.5926\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.6160 - val_loss: 0.6776 - val_accuracy: 0.5185\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6240 - val_loss: 0.6793 - val_accuracy: 0.5185\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6400 - val_loss: 0.6846 - val_accuracy: 0.5185\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6580 - accuracy: 0.6000 - val_loss: 0.6758 - val_accuracy: 0.5556\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6766 - val_accuracy: 0.5185\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.6320 - val_loss: 0.6791 - val_accuracy: 0.5185\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.6400 - val_loss: 0.6850 - val_accuracy: 0.5185\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6240 - val_loss: 0.6888 - val_accuracy: 0.5185\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6400 - val_loss: 0.6864 - val_accuracy: 0.4815\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6240 - val_loss: 0.6906 - val_accuracy: 0.5185\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.6400 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6480 - val_loss: 0.6956 - val_accuracy: 0.5185\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6400 - val_loss: 0.6937 - val_accuracy: 0.5185\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6480 - val_loss: 0.6970 - val_accuracy: 0.5185\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.6320 - val_loss: 0.6999 - val_accuracy: 0.5185\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.6480 - val_loss: 0.7028 - val_accuracy: 0.5185\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6400 - val_loss: 0.7103 - val_accuracy: 0.4815\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6320 - val_loss: 0.7099 - val_accuracy: 0.5185\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.6560 - val_loss: 0.7174 - val_accuracy: 0.5185\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6400 - val_loss: 0.7285 - val_accuracy: 0.5185\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6480 - val_loss: 0.7127 - val_accuracy: 0.5185\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6080 - val_loss: 0.7080 - val_accuracy: 0.5185\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6560 - val_loss: 0.7286 - val_accuracy: 0.5185\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6320 - val_loss: 0.7222 - val_accuracy: 0.4815\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.6480 - val_loss: 0.7379 - val_accuracy: 0.5185\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6480 - val_loss: 0.7286 - val_accuracy: 0.4815\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6400 - val_loss: 0.7387 - val_accuracy: 0.5185\n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6640 - val_loss: 0.7391 - val_accuracy: 0.5185\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6480 - val_loss: 0.7466 - val_accuracy: 0.5185\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6480 - val_loss: 0.7630 - val_accuracy: 0.5185\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6560 - val_loss: 0.7650 - val_accuracy: 0.4815\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.6640 - val_loss: 0.7675 - val_accuracy: 0.4815\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6400 - val_loss: 0.7264 - val_accuracy: 0.5185\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6240 - val_loss: 0.7266 - val_accuracy: 0.4815\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.6560 - val_loss: 0.7435 - val_accuracy: 0.5185\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6320 - val_loss: 0.7475 - val_accuracy: 0.5185\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6640 - val_loss: 0.7728 - val_accuracy: 0.5556\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6560 - val_loss: 0.7655 - val_accuracy: 0.4815\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.6640 - val_loss: 0.7732 - val_accuracy: 0.4815\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.6640 - val_loss: 0.7593 - val_accuracy: 0.5185\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6560 - val_loss: 0.7740 - val_accuracy: 0.5185\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.6800 - val_loss: 0.7594 - val_accuracy: 0.5185\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.6800 - val_loss: 0.7918 - val_accuracy: 0.5185\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6720 - val_loss: 0.7952 - val_accuracy: 0.5185\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.6560 - val_loss: 0.7674 - val_accuracy: 0.5185\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.6880 - val_loss: 0.7502 - val_accuracy: 0.4815\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.6880 - val_loss: 0.7926 - val_accuracy: 0.5185\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.6480 - val_loss: 0.7497 - val_accuracy: 0.5556\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.6640 - val_loss: 0.7980 - val_accuracy: 0.5185\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.6720 - val_loss: 0.7441 - val_accuracy: 0.5185\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.6800 - val_loss: 0.7949 - val_accuracy: 0.4815\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.7040 - val_loss: 0.7772 - val_accuracy: 0.5185\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7040 - val_loss: 0.8517 - val_accuracy: 0.4815\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5818 - accuracy: 0.6720 - val_loss: 0.7764 - val_accuracy: 0.5556\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7040 - val_loss: 0.8090 - val_accuracy: 0.4815\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.6880 - val_loss: 0.7800 - val_accuracy: 0.5556\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.6560 - val_loss: 0.8302 - val_accuracy: 0.5185\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.6800 - val_loss: 0.7945 - val_accuracy: 0.5185\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.6800 - val_loss: 0.8133 - val_accuracy: 0.5185\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.6720 - val_loss: 0.8173 - val_accuracy: 0.4815\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7280 - val_loss: 0.7950 - val_accuracy: 0.5185\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7040 - val_loss: 0.7867 - val_accuracy: 0.5185\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.6880 - val_loss: 0.8160 - val_accuracy: 0.4815\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.6960 - val_loss: 0.8479 - val_accuracy: 0.4815\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.6720 - val_loss: 0.7674 - val_accuracy: 0.5556\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.6720 - val_loss: 0.8334 - val_accuracy: 0.5185\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.6960 - val_loss: 0.8077 - val_accuracy: 0.5185\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.7040 - val_loss: 0.7463 - val_accuracy: 0.4815\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.6960 - val_loss: 0.8642 - val_accuracy: 0.5185\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6880 - val_loss: 0.7883 - val_accuracy: 0.4815\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7040 - val_loss: 0.8337 - val_accuracy: 0.5185\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.6800 - val_loss: 0.8675 - val_accuracy: 0.4815\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6880 - val_loss: 0.8125 - val_accuracy: 0.5556\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.6880 - val_loss: 0.8284 - val_accuracy: 0.4815\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.7120 - val_loss: 0.8220 - val_accuracy: 0.4815\n",
            "Epoch 100/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.6960 - val_loss: 0.7861 - val_accuracy: 0.5556\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7040 - val_loss: 0.8724 - val_accuracy: 0.4815\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.6960 - val_loss: 0.8121 - val_accuracy: 0.5556\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.6960 - val_loss: 0.8687 - val_accuracy: 0.5185\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.6800 - val_loss: 0.8315 - val_accuracy: 0.4815\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.6880 - val_loss: 0.8545 - val_accuracy: 0.5185\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7120 - val_loss: 0.8320 - val_accuracy: 0.5556\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5409 - accuracy: 0.7040 - val_loss: 0.8304 - val_accuracy: 0.5185\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7040 - val_loss: 0.8947 - val_accuracy: 0.5185\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.6960 - val_loss: 0.8744 - val_accuracy: 0.5185\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.6880 - val_loss: 0.8484 - val_accuracy: 0.5185\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.6960 - val_loss: 0.8331 - val_accuracy: 0.4815\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.6880 - val_loss: 0.7958 - val_accuracy: 0.5185\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7040 - val_loss: 0.9859 - val_accuracy: 0.4815\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.6960 - val_loss: 0.8283 - val_accuracy: 0.5185\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.6960 - val_loss: 0.9477 - val_accuracy: 0.4815\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5630 - accuracy: 0.6560 - val_loss: 0.8882 - val_accuracy: 0.5556\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.6560 - val_loss: 0.8638 - val_accuracy: 0.4815\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.6960 - val_loss: 0.8385 - val_accuracy: 0.4815\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7120 - val_loss: 0.8612 - val_accuracy: 0.5556\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7120 - val_loss: 0.8505 - val_accuracy: 0.4815\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7200 - val_loss: 0.9169 - val_accuracy: 0.5556\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7200 - val_loss: 0.8828 - val_accuracy: 0.5926\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.6880 - val_loss: 0.8309 - val_accuracy: 0.5185\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7280 - val_loss: 0.9710 - val_accuracy: 0.5185\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7200 - val_loss: 0.8907 - val_accuracy: 0.5185\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7200 - val_loss: 0.8648 - val_accuracy: 0.4815\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.6880 - val_loss: 0.9293 - val_accuracy: 0.4815\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7360 - val_loss: 0.8651 - val_accuracy: 0.5185\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7280 - val_loss: 0.9714 - val_accuracy: 0.4815\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7040 - val_loss: 0.8710 - val_accuracy: 0.4444\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.6720 - val_loss: 0.9706 - val_accuracy: 0.5926\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.6720 - val_loss: 0.8909 - val_accuracy: 0.5185\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7200 - val_loss: 0.8608 - val_accuracy: 0.5185\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.6960 - val_loss: 0.9052 - val_accuracy: 0.5556\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7440 - val_loss: 0.8892 - val_accuracy: 0.5926\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7440 - val_loss: 0.7995 - val_accuracy: 0.5185\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7280 - val_loss: 0.8998 - val_accuracy: 0.5556\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.6960 - val_loss: 0.8906 - val_accuracy: 0.4444\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7280 - val_loss: 0.9343 - val_accuracy: 0.5556\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7600 - val_loss: 0.9887 - val_accuracy: 0.5185\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.6960 - val_loss: 0.9370 - val_accuracy: 0.4815\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.6960 - val_loss: 0.9421 - val_accuracy: 0.5926\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.6880 - val_loss: 0.9009 - val_accuracy: 0.4815\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7120 - val_loss: 0.9262 - val_accuracy: 0.4815\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7360 - val_loss: 0.9191 - val_accuracy: 0.5185\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7440 - val_loss: 0.9158 - val_accuracy: 0.5556\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7360 - val_loss: 0.8506 - val_accuracy: 0.4815\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.6720 - val_loss: 0.8543 - val_accuracy: 0.4815\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7440 - val_loss: 0.8984 - val_accuracy: 0.5556\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7680 - val_loss: 0.8222 - val_accuracy: 0.5556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model15.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zF-Vflf74n8",
        "outputId": "6d6ad003-3c9d-41c5-a815-494df773b021"
      },
      "execution_count": 911,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 48.1071 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[48.107112884521484, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 911
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model15 = tf.keras.models.load_model(f\"/content/model_experiments/{model15.name}\")\n",
        "model15.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "hnN5jGe7rBrV",
        "outputId": "f2c61bf4-4cbc-4cf2-bcaf-4c35bd4d4307",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 912,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 150ms/step - loss: 0.7842 - accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7841835021972656, 0.6086956262588501]"
            ]
          },
          "metadata": {},
          "execution_count": 912
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aSFXiJDIe0wL"
      },
      "execution_count": 912,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "HwrvwOX0cyMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5880cec4-1340-4add-eac2-8d8b20f4e8dd"
      },
      "execution_count": 914,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1.0\n",
              "1      1.0\n",
              "2      0.0\n",
              "3      1.0\n",
              "4      0.0\n",
              "      ... \n",
              "170    0.0\n",
              "171    0.0\n",
              "172    0.0\n",
              "173    1.0\n",
              "174    1.0\n",
              "Name: psqi больше 5, Length: 175, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 914
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sGr_oqlJHh4h"
      },
      "execution_count": 912,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xSCrBKNIHh7K"
      },
      "execution_count": 912,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 913,
      "metadata": {
        "id": "jxDbWXbvvMEV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "7ba982e9-5718-4d42-aff7-3159c2fad684"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Нарушения сна больше 5'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-913-3819433a1a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Нарушения сна больше 5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# X = data.drop(columns=['Нарушения сна больше 5'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Пол'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Удовлетворенность семейными отношениями'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ЧМТ'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Стаж шизофр'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Образование'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Насл отягощенность'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'G'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# X = data[[ 'P', 'N', 'G']] # Only with these 3 values we can get very good result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Нарушения сна больше 5'"
          ]
        }
      ],
      "source": [
        "y = data['Нарушения сна больше 5']\n",
        "# X = data.drop(columns=['Нарушения сна больше 5'])\n",
        "# X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование']]\n",
        "X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "# X = data[[ 'P', 'N', 'G']] # Only with these 3 values we can get very good result\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kZTjgK7vMG8"
      },
      "outputs": [],
      "source": [
        "# Scale X from 0 to 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "X_train_scaled = minmax_scaler.fit_transform(X_train)\n",
        "X_valid_scaled = minmax_scaler.transform(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOQOcCCXPrrL"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.003), # lr=0.003\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Create a learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # Learning rate will increase at each epoch\n",
        "\n",
        "history0 = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVMn6WFCPEHX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zFAGeTMPvxf"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXokhoC2PwQk"
      },
      "source": [
        "### Find bels LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH0ZyOMevW6o"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(), # lr=0.003\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Create a learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # Learning rate will increase at each epoch\n",
        "\n",
        "history_lr = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=100,\n",
        "                    validation_data = (X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWTprQ0aOC_S"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the learning rate vs loss\n",
        "lrs = 1e-4 * (10 ** (tf.range(100)/20))\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, history_lr.history[\"loss\"]) # lrs - x-axis, history - y-axis\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs. loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPZdm2LqvMQs"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    # tf.keras.layers.Dense(10, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(0.03),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "history1 = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJCjkFO-Pb3f"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1n34k49Pebz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqB5o19TPfeV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pofTvAKuPfhO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XzO4JMrPfjd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtdAN5vAPfmH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMlFZkEuPCer"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jzqVz0-vMSw"
      },
      "outputs": [],
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AdEsLsQhl-L"
      },
      "outputs": [],
      "source": [
        "train_data = data[:121] # 70%\n",
        "validation_data = data[121:155] # 20%\n",
        "test_data = data[155:174] # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD1BAgypjWbC"
      },
      "outputs": [],
      "source": [
        "y_train = train_data['Нарушения сна больше 5']\n",
        "y_validation = validation_data['Нарушения сна больше 5']\n",
        "y_test = test_data['Нарушения сна больше 5']\n",
        "\n",
        "X_train = train_data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "X_validation = validation_data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "X_test = test_data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgi-q_Iujyt-"
      },
      "outputs": [],
      "source": [
        "len(y_train), len(y_validation), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w3owV7dhnfn"
      },
      "outputs": [],
      "source": [
        "# y = data['Нарушения сна']\n",
        "# # X = data.drop(columns=['Нарушения сна'])\n",
        "# # X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование']]\n",
        "# # X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']]\n",
        "# X = data[[ 'P', 'N', 'G']] # Only with these 3 values we can get very good result\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5EEQckhaLgC"
      },
      "outputs": [],
      "source": [
        "# Scale X from 0 to 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_validation_scaled = scaler.fit_transform(X_validation)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVjPP8UokzzF"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(), # lr=0.03\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(X_train_scaled, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    validation_data = (X_validation_scaled, y_validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc5mFrJQhMsd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEAMkOEmhOE9"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yZGlBKrhNN1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrA_ArvkOh9c"
      },
      "source": [
        "### It is very likely that the model has overfitted. It is necessary to add data augmentation, validation data, visualization\n",
        "Find best lr\n",
        "\n",
        "Вывести наиболее значимые характеристики\n",
        "\n",
        "\n",
        "\n",
        "Check result on different scalers. For example:\n",
        "\n",
        "1) Min Max Scaler (try it)\n",
        "\n",
        "2) Standard Scaler\n",
        "\n",
        "3) Max Abs Scaler\n",
        "\n",
        "4) Robust Scaler\n",
        "\n",
        "5) Quantile Transformer Scaler\n",
        "\n",
        "6) Power Transformer Scaler\n",
        "\n",
        "7) Unit Vector Scaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io90TB1dlcBf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDAqLqo5DT74"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNhuw9AgDT-L"
      },
      "outputs": [],
      "source": [
        "# Let's try to use 'Нарушения сна' as y value\n",
        "data = ds.drop(columns=['Тревога больше 7', 'Madrs больше 6', 'Калгари больше 5'])\n",
        "y = data['Нарушения сна больше 5']\n",
        "# X = data.drop(columns=['Нарушения сна'])\n",
        "X = data[['Пол', 'Удовлетворенность семейными отношениями', 'ЧМТ','Стаж шизофр', 'Образование', 'Насл отягощенность', 'P', 'N', 'G']] # 'Были ли нарушения сна', \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,)\n",
        "\n",
        "# Scale X from 0 to 1\n",
        "scaler2 = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler2.fit_transform(X_train)\n",
        "X_test_scaled = scaler2.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR0dXD6DEdDg"
      },
      "outputs": [],
      "source": [
        "X_train_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKvqJHX3DWyj"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(), # lr=0.03\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history2 = model2.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGzI7qA1DrxS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "mental_disorders.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}